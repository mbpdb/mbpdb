{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c171d489-8e4e-4099-8180-5ebea1acbf5c",
   "metadata": {
    "id": "d32ff626",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Core data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from itertools import cycle\n",
    "\n",
    "# Utility imports\n",
    "import re, io, warnings, os, copy, base64, gc, traceback, time\n",
    "from io import BytesIO\n",
    "from functools import partial\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "\n",
    "# Jupyter-specific imports\n",
    "from traitlets import HasTraits, Instance, observe\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import (\n",
    "    interact, interactive, fixed, interact_manual,\n",
    "    GridspecLayout, VBox, HBox, Layout, Output\n",
    ")\n",
    "#from ipydatagrid import DataGrid\n",
    "\n",
    "# Initialize settings\n",
    "import _settings as settings\n",
    "from utils.uniprot_client import UniProtClient\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Declare global variables\n",
    "global spec_translate_list, valid_discrete_cmaps, valid_gradient_cmaps\n",
    "global default_hm_color, default_lp_color, default_avglp_color\n",
    "global hm_selected_color, cmap, lp_selected_color\n",
    "global avglp_selected_color, avg_cmap, port_hm_settings\n",
    "global chuck_size, plot_heatmap, plot_zero, legend_title\n",
    "global data_transformer, HeatmapPlotHandler\n",
    "\n",
    "def initialize_global_variables():\n",
    "    \"\"\"Initialize all global variables used in the notebook.\"\"\"\n",
    "    global spec_translate_list, valid_discrete_cmaps, valid_gradient_cmaps\n",
    "    global default_hm_color, default_lp_color, default_avglp_color\n",
    "    global hm_selected_color, cmap, lp_selected_color\n",
    "    global avglp_selected_color, avg_cmap, port_hm_settings\n",
    "    global chuck_size, plot_heatmap, plot_zero, legend_title\n",
    "    global data_transformer, HeatmapPlotHandler\n",
    "    \n",
    "    # Global variables from settings\n",
    "    spec_translate_list = settings.SPEC_TRANSLATE_LIST\n",
    "    valid_discrete_cmaps = settings.valid_discrete_cmaps\n",
    "    valid_gradient_cmaps = settings.all_gradient_cmaps\n",
    "    \n",
    "    # Define default values for the color maps\n",
    "    default_hm_color = 'RdYlGn_r'\n",
    "    #default_hm_color = 'Purples'\n",
    "    \n",
    "    default_lp_color = 'Set3'\n",
    "    default_avglp_color = 'Dark2'\n",
    "    \n",
    "    # Define the color map for the heatmap\n",
    "    hm_selected_color = default_hm_color\n",
    "    cmap = plt.get_cmap(hm_selected_color)\n",
    "    \n",
    "    # Define the color map for the individual line plots\n",
    "    lp_selected_color = default_lp_color\n",
    "    \n",
    "    # Define the color for the averaged line plots\n",
    "    avglp_selected_color = default_avglp_color\n",
    "    avg_cmap = plt.get_cmap(avglp_selected_color)\n",
    "    \n",
    "    # Define settings for different numbers of variables\n",
    "    port_hm_settings = {\n",
    "        #num_var: (lineplot_height, scale_factor)\n",
    "        1: (35, 0.075),\n",
    "        2: (20, 0.125),\n",
    "        3: (20, 0.15),\n",
    "        4: (20, 0.175),\n",
    "        5: (20, 0.225),\n",
    "        6: (20, 0.25),\n",
    "        7: (20, 0.275),\n",
    "        8: (20, 0.3),\n",
    "        9: (20, 0.325),\n",
    "        10: (20, 0.36),\n",
    "        11: (20, 0.38),\n",
    "        12: (20, 0.41)\n",
    "    }\n",
    "    \n",
    "    chuck_size = 78\n",
    "    plot_heatmap, plot_zero = 'yes', 'no'\n",
    "    legend_title = ['Sample Type:','Peptide Counts:','Bioactivity Function:','Peptide Interval:', 'Average Absorbance:']\n",
    "    \n",
    "    data_transformer = HeatmapPlotHandler = None\n",
    "\n",
    "# Call the function to initialize all global variables\n",
    "initialize_global_variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "897ffa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions outside of class\n",
    "def update_filenames(input_filename_port, input_filename_land):\n",
    "    # Append directory and .png only when necessary\n",
    "    #updated_filename_port = f'{images_folder_name}/{input_filename_port}.png' if input_filename_port else None\n",
    "    #updated_filename_land = f'{images_folder_name}/{input_filename_land}.png' if input_filename_land else None\n",
    "    updated_filename_port = f'{input_filename_port}' if input_filename_port else None\n",
    "    updated_filename_land = f'{input_filename_land}' if input_filename_land else None\n",
    "\n",
    "    return updated_filename_land, updated_filename_port\n",
    "\n",
    "def proceed_with_label_specific_options(selected_bio_or_pep, bio_or_pep):\n",
    "    # Initialize selected_peptides and selected_functions to ensure they are always defined\n",
    "    selected_peptides = []\n",
    "    selected_functions = []\n",
    "\n",
    "    # Check and handle different cases based on bio_or_pep value\n",
    "    if bio_or_pep == '1':  # Assuming '1' indicates selection of peptides\n",
    "        selected_peptides = list(selected_bio_or_pep) if isinstance(selected_bio_or_pep, (list, tuple)) else [\n",
    "            selected_bio_or_pep]\n",
    "    elif bio_or_pep == '2':  # Assuming '2' indicates selection of functions\n",
    "        selected_functions = list(selected_bio_or_pep) if isinstance(selected_bio_or_pep, (list, tuple)) else [\n",
    "            selected_bio_or_pep]\n",
    "    # Optional: handle unexpected bio_or_pep values\n",
    "    else:\n",
    "        error_message = f\"Unexpected value for bio_or_pep: {bio_or_pep}\"\n",
    "        display(HTML(f\"<div style='display: inline-block; margin: 10px 0;'><b style='color: red'>{error_message}</b></div>\"))\n",
    "    #print(f\" DEBUG: selected_peptides: {selected_peptides}\")\n",
    "    return selected_peptides, selected_functions\n",
    "\n",
    "def get_interval_start(peptide_label):\n",
    "    \"\"\"\n",
    "    Extract numeric start from labels like '193-207' or '193-207 (Oxidation)'.\n",
    "    \"\"\"\n",
    "    base = peptide_label.split()[0]  # take '193-207' from '193-207 (Oxidation)'\n",
    "    return int(base.split('-')[0])\n",
    "\n",
    "\"\"\"-----------------Export_Function---------------------------------\"\"\" \n",
    "\n",
    "def calculate_centralized_y_limits(available_data_variables_dict, selected_peptides, selected_functions, \n",
    "                                   ms_average_choice, bio_or_pep, filter_type, log_transform, \n",
    "                                   manual_y_axis=False, y_min_manual=None, y_max_manual=None):\n",
    "    \"\"\"\n",
    "    Centralized function to calculate y_min and y_max from all data sources (individual peptides and averaged data)\n",
    "    Supports manual y-axis scaling override\n",
    "    Returns: (y_min, y_max, all_min_values, all_max_values)\n",
    "    \"\"\"\n",
    "    all_min_values = []\n",
    "    all_max_values = []\n",
    "    \n",
    "    for var in available_data_variables_dict:\n",
    "        # Get MS average data if needed\n",
    "        if ms_average_choice in ['yes', 'only']:\n",
    "            var_ms_data = available_data_variables_dict[var]['ms_data_list']\n",
    "            if isinstance(var_ms_data, (pd.DataFrame, pd.Series)):\n",
    "                ms_values = var_ms_data.values\n",
    "            else:\n",
    "                ms_values = var_ms_data\n",
    "            \n",
    "            # Remove NaN and zero values\n",
    "            ms_values = [val for val in ms_values if not pd.isna(val) and val > 0]\n",
    "            if ms_values:\n",
    "                all_min_values.extend(ms_values)\n",
    "                all_max_values.extend(ms_values)\n",
    "        \n",
    "        # Get individual peptide data if needed\n",
    "        if bio_or_pep != 'no' and ms_average_choice != 'only':\n",
    "            bp_abs = available_data_variables_dict[var]['bioactive_peptide_abs_df']\n",
    "            bp_func = available_data_variables_dict[var]['bioactive_peptide_func_df']\n",
    "            var_name = available_data_variables_dict[var]['label']\n",
    "            \n",
    "\n",
    "            # Filter data based on selection\n",
    "            try:\n",
    "                filtered_bp_abs, filtered_bp_func, _ = filter_data_by_selection(\n",
    "                    bp_abs, bp_func, selected_peptides, selected_functions, \n",
    "                    bio_or_pep, filter_type, ms_average_choice, var_name,\n",
    "                    )\n",
    "                \n",
    "                # Extract values from filtered data\n",
    "                for col in filtered_bp_abs.columns:\n",
    "                    if col != 'average':\n",
    "                        y_values = pd.to_numeric(filtered_bp_abs[col], errors='coerce')\n",
    "                        y_values = y_values[y_values > 0].dropna()\n",
    "                        if not y_values.empty:\n",
    "                            all_min_values.extend(y_values.tolist())\n",
    "                            all_max_values.extend(y_values.tolist())\n",
    "                            \n",
    "            except Exception as e:\n",
    "                # If filtering fails, continue without this data\n",
    "                continue\n",
    "    \n",
    "    # Override min/max values with manual settings if enabled (same logic as original process_available_data)\n",
    "    if manual_y_axis:\n",
    "        min_values = [y_min_manual]\n",
    "        max_values = [y_max_manual]\n",
    "    else:\n",
    "        min_values = all_min_values\n",
    "        max_values = all_max_values\n",
    "    \n",
    "    # Calculate final y_min and y_max\n",
    "    if min_values and max_values:\n",
    "        y_min = min(min_values)\n",
    "        y_max = max(max_values) * 1.1  # Add 10% padding\n",
    "        \n",
    "        # Handle log transform constraints\n",
    "        if log_transform:\n",
    "            y_min = max(y_min, 0.1)\n",
    "    else:\n",
    "        # Fallback defaults\n",
    "        y_min = 0.1 if log_transform else 0\n",
    "        y_max = 1.0\n",
    "    \n",
    "    return y_min, y_max, min_values, max_values\n",
    "\n",
    "# Function to calculate y-ticks based on the min and max values of datasets\n",
    "def calculate_y_ticks(min_values, max_values, log_transform):\n",
    "    \"\"\"\n",
    "    Calculate y-ticks with proper handling of zero/negative values\n",
    "    \"\"\"\n",
    "    # Check for empty lists or all zeros\n",
    "    if not min_values or not max_values:\n",
    "        return [0, 1, 10]  # Default scale if no data\n",
    "        \n",
    "    # Filter out zeros and negative values, keep valid positives\n",
    "    valid_mins = [x for x in min_values if x > 0]\n",
    "    valid_maxs = [x for x in max_values if x > 0]\n",
    "    \n",
    "    # If no valid values after filtering\n",
    "    if not valid_mins or not valid_maxs:\n",
    "        return [0, 1, 10]\n",
    "    \n",
    "    try:\n",
    "        overall_min = np.nanmin(valid_mins)\n",
    "        overall_max = np.nanmax(valid_maxs)\n",
    "        \n",
    "        # If min or max are zero or negative after nanmin/nanmax\n",
    "\n",
    "        \n",
    "        if log_transform:\n",
    "            if overall_min <= 0 or overall_max <= 0:\n",
    "                return [0, 1, 10]\n",
    "            # Apply log transformation for log scale\n",
    "            min_power = 10 ** np.floor(np.log10(overall_min))\n",
    "            max_power = 10 ** np.ceil(np.log10(overall_max))\n",
    "            \n",
    "            # Calculate midpoint in log space\n",
    "            mid_point = np.sqrt(min_power * max_power)\n",
    "            mid_point_rounded = 10 ** np.round(np.log10(mid_point))\n",
    "            \n",
    "            return [min_power, mid_point_rounded, max_power]\n",
    "        else:\n",
    "            # For linear scale, return min, mid, max rounded to 2 sigfigs\n",
    "            mid_point = (overall_min + overall_max) / 2\n",
    "            def round_sig(x, sig=2):\n",
    "                if x == 0:\n",
    "                    return 0\n",
    "                exponent = int(np.floor(np.log10(abs(x))))\n",
    "                factor = 10**(exponent - sig + 1)\n",
    "                return round(x / factor) * factor\n",
    "            def round_sig_ceil(x, sig=2):\n",
    "                if x == 0:\n",
    "                    return 0\n",
    "                exponent = int(np.floor(np.log10(abs(x))))\n",
    "                factor = 10**(exponent - sig + 1)\n",
    "                return np.ceil(x / factor) * factor\n",
    "\n",
    "            def round_sig_floor(x, sig=2):\n",
    "                if x == 0:\n",
    "                    return 0\n",
    "                exponent = int(np.floor(np.log10(abs(x))))\n",
    "                factor = 10**(exponent - sig + 1)\n",
    "                return np.floor(x / factor) * factor\n",
    "            overall_min_rounded = round_sig_floor(overall_min, 2)\n",
    "            overall_max_rounded = round_sig(overall_max, 2)\n",
    "            mid_point_rounded = round_sig_floor(mid_point, 2)\n",
    "            return [overall_min_rounded, mid_point_rounded, overall_max_rounded]\n",
    "        \n",
    "    except (ValueError, RuntimeWarning):\n",
    "        return [0, 1, 10]  # Fallback for any calculation errors\n",
    "\n",
    "def calculate_abundance(protein_sequence, peptide_dataframe, grouping_variable):\n",
    "    protein_sequence_length = len(protein_sequence)\n",
    "    data = []\n",
    "    Avg_column = f'Avg_{grouping_variable}'\n",
    "\n",
    "    for idx, row in peptide_dataframe.iterrows():\n",
    "        try:\n",
    "            start_idx = int(row['start']) - 1\n",
    "            stop_idx = int(row['stop'])\n",
    "            abundance_value = row[Avg_column]\n",
    "\n",
    "            values = [0] * protein_sequence_length\n",
    "            if abundance_value > 0:\n",
    "                values[start_idx:stop_idx] = [abundance_value] * (stop_idx - start_idx)\n",
    "            data.append(values)\n",
    "\n",
    "        except (KeyError, ValueError) as e:\n",
    "            error_message = f'{type(e).__name__}: {e} - Skipping this row'\n",
    "            display(HTML(f\"<div style='display: inline-block; margin: 10px 0;'><b style='color: red'>{error_message}</b></div>\"))\n",
    "            continue\n",
    "\n",
    "    if not data:\n",
    "        display(HTML(f\"<div style='display: inline-block; margin: 10px 0;'><b style='color: orange'>No valid data to process. Returning empty DataFrame.</b></div>\"))\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Create the initial DataFrame\n",
    "    abundance_df = pd.DataFrame(data).T\n",
    "    abundance_df.columns = [\n",
    "        f\"{int(row['start'])}-{int(row['stop'])}\" + (f\" {row['Unique Peptide ID']}\" if 'Unique Peptide ID' in row and not pd.isnull(row['Unique Peptide ID']) else \"\")\n",
    "        for _, row in peptide_dataframe.iterrows()\n",
    "    ]\n",
    "\n",
    "    \n",
    "    # Initialize count list\n",
    "    count_list = []\n",
    "    \n",
    "    # Check if abundance_df is empty or has no non-zero values\n",
    "    if abundance_df.empty or abundance_df.eq(0).all().all():\n",
    "        # Create all zeros for counts and averages\n",
    "        count_list = [0] * len(protein_sequence)\n",
    "        abundance_df['average'] = 0\n",
    "    else:\n",
    "        # Calculate counts and averages normally\n",
    "        count_list = abundance_df.gt(0).sum(axis=1)\n",
    "        abundance_df['average'] = abundance_df.replace(0, np.nan).mean(axis=1)\n",
    "    \n",
    "    # Assign the counts and amino acids\n",
    "    abundance_df['count'] = count_list\n",
    "    abundance_df['AA'] = list(protein_sequence)\n",
    "    return abundance_df\n",
    "\n",
    "def calculate_function(protein_sequence, peptide_dataframe, grouping_variable):\n",
    "    protein_sequence_length = len(protein_sequence)\n",
    "    data = []\n",
    "\n",
    "    for _, row in peptide_dataframe.iterrows():\n",
    "        start_idx = int(row['start'] - 1)\n",
    "        stop_idx = int(row['stop'])\n",
    "        if stop_idx > protein_sequence_length:\n",
    "            stop_idx -= 1\n",
    "            \n",
    "        function_value = row['function'] if 'function' in peptide_dataframe.columns else np.nan\n",
    "        \n",
    "        values = [None] * protein_sequence_length\n",
    "        for i in range(start_idx, stop_idx):\n",
    "            values[i] = function_value\n",
    "\n",
    "        data.append(values)\n",
    "\n",
    "    function_df = pd.DataFrame(data).T\n",
    "    function_df.columns = [\n",
    "        f\"{int(row['start'])}-{int(row['stop'])}\" + (f\" {row['Unique Peptide ID']}\" if 'Unique Peptide ID' in row and not pd.isnull(row['Unique Peptide ID']) else \"\")\n",
    "        for _, row in peptide_dataframe.iterrows()\n",
    "    ]\n",
    "    return function_df\n",
    "\n",
    "def export_heatmap_data_to_dict(protein_id, group_key, group_info, protein_sequence, \n",
    "                               protein_species, protein_name, protein_df, is_all_null):\n",
    "    \"\"\"\n",
    "    Exports the heatmap data to a dictionary based on filter type.\n",
    "    \"\"\"\n",
    "    grouping_var = group_info['grouping_variable']\n",
    "    relevant_columns = group_info['abundance_columns']\n",
    "    \n",
    "    # Check if required columns exist, if not create default DataFrame\n",
    "    required_columns = ['function', 'start', 'stop']\n",
    "    if not all(col in protein_df.columns for col in required_columns):\n",
    "        filtered_df = pd.DataFrame({\n",
    "            'start': [0],\n",
    "            'stop': [1],\n",
    "            'function': ['0']\n",
    "        })\n",
    "        filtered_protein_df = filtered_df.copy()\n",
    "    else:\n",
    "        filtered_protein_df = protein_df.dropna(subset=['function', 'start', 'stop'])\n",
    "        if 'Unique Peptide ID' in filtered_protein_df.columns:\n",
    "            filtered_df = filtered_protein_df[['start', 'stop', 'function', 'Unique Peptide ID']]\n",
    "        else:\n",
    "            filtered_df = filtered_protein_df[['start', 'stop', 'function']]\n",
    "\n",
    "    # Calculate the heatmap data\n",
    "    func_heatmap_df = calculate_function(protein_sequence, filtered_df, grouping_var)\n",
    "    heatmap_df = calculate_abundance(protein_sequence, protein_df, grouping_var)\n",
    "    filtered_heatmap_df = calculate_abundance(protein_sequence, filtered_protein_df, grouping_var)\n",
    "\n",
    "    # Create the dictionary to store the results\n",
    "    heatmap_data = {\n",
    "        'protein_id': protein_id,\n",
    "        'protein_sequence': protein_sequence,\n",
    "        'protein_name': protein_name,\n",
    "        'protein_species': protein_species,\n",
    "        'func_heatmap_df': func_heatmap_df,\n",
    "        'heatmap_df': heatmap_df,\n",
    "        'filtered_heatmap_df': filtered_heatmap_df\n",
    "    }\n",
    "    \n",
    "    return heatmap_data\n",
    "\n",
    "def chunk_dataframe(df, chunk_size, exclude_columns=3):\n",
    "    # Select all rows and all but the last 'exclude_columns' columns\n",
    "    df_subset = df.iloc[:, :-exclude_columns] if exclude_columns else df\n",
    "    \n",
    "    # Check if df_subset is empty or all zeros\n",
    "    if df_subset.empty or (df_subset == 0).all().all():\n",
    "        # Return a single chunk with the default structure\n",
    "        default_chunk = pd.DataFrame(\n",
    "            np.zeros((chunk_size, df_subset.shape[1])), \n",
    "            columns=df_subset.columns\n",
    "        )\n",
    "        return [default_chunk]\n",
    "    \n",
    "    # Calculate the number of rows needed to make the last chunk exactly 'chunk_size'\n",
    "    total_rows = df_subset.shape[0]\n",
    "    remainder = total_rows % chunk_size\n",
    "    \n",
    "    if remainder != 0:\n",
    "        # Rows needed to complete the last chunk\n",
    "        rows_to_add = chunk_size - remainder\n",
    "        # Create a DataFrame with zero values for the missing rows\n",
    "        additional_rows = pd.DataFrame(\n",
    "            np.zeros((rows_to_add, df_subset.shape[1])), \n",
    "            columns=df_subset.columns\n",
    "        )\n",
    "        # Append these rows to df_subset\n",
    "        df_subset = pd.concat(\n",
    "            [df_subset, additional_rows], \n",
    "            ignore_index=True, \n",
    "            copy=False,\n",
    "            verify_integrity=True\n",
    "        )\n",
    "    \n",
    "    # Create chunks of the DataFrame\n",
    "    max_index = df_subset.index.max() + 1\n",
    "    return [df_subset.iloc[i:i + chunk_size] for i in range(0, max_index, chunk_size)]\n",
    "    \n",
    "def process_available_data(available_data_variables_dict, filter_type, selected_functions, selected_peptides, bio_or_pep, log_transform, manual_y_axis=False, y_min_manual=None, y_max_manual=None):\n",
    "    \"\"\"\n",
    "    Process data for visualization when update_plot is called\n",
    "    Returns: dict with data and 'errors' key containing list of error messages\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    if not available_data_variables_dict:\n",
    "        return {'errors': [\"No data available for processing\"]} \n",
    "\n",
    "    count_list = []\n",
    "    min_values = []\n",
    "    max_values = []\n",
    "    seq_len_list = []\n",
    "    chunk_size = 78\n",
    "    \n",
    "    # Process each variable's data for visualization\n",
    "    for var in available_data_variables_dict:\n",
    "        if filter_type == 'all-peptides':\n",
    "            df = available_data_variables_dict[var]['heatmap_df']\n",
    "        elif filter_type == 'bioactive-only':\n",
    "            df = available_data_variables_dict[var]['filtered_heatmap_df']\n",
    "        elif filter_type == 'functional-only':\n",
    "            if not selected_functions and bio_or_pep == '2':\n",
    "                errors.append(f'Invalid menu selection or there are no results available to display for {var}. Please select \"Bioactive Functions\" for \"Plot Specific Peptides\", with at least one function containing data from the \"Specific Options\" dropdown menu selected.')\n",
    "            if not selected_peptides and bio_or_pep == '1':\n",
    "                errors.append(f'Invalid menu selection or there are no results available to display for {var}. Please select \"Peptide Intervals\" for \"Plot Specific Peptides\", with at least one peptide interval containing data from the \"Specific Options\" dropdown menu selected.')    \n",
    "            \n",
    "            # Filter both functional and absorbance data for specific functions\n",
    "            func_df = available_data_variables_dict[var]['function_heatmap_df']\n",
    "            if func_df is not None and not func_df.empty:\n",
    "                # Get list of columns that contain any of the selected functions\n",
    "                functional_positions = []\n",
    "                for col in func_df.columns:\n",
    "                    # Check if any selected function appears in any cell of this column\n",
    "                    if any(any(func in str(cell) for func in selected_functions) for cell in func_df[col]):\n",
    "                        functional_positions.append(col)\n",
    "                              \n",
    "                # Get absorbance data for these positions\n",
    "                abs_df = available_data_variables_dict[var]['filtered_heatmap_df']\n",
    "                if abs_df is not None and not abs_df.empty and functional_positions:\n",
    "                    # Only keep columns that exist in abs_df\n",
    "                    valid_columns = [col for col in functional_positions if col in abs_df.columns]\n",
    "                    if valid_columns:\n",
    "                        # Get the filtered absorbance data for selected columns\n",
    "                        selected_abs_df = abs_df[valid_columns]\n",
    "                        \n",
    "                        # Create DataFrame with sequence and selected columns\n",
    "                        df = pd.DataFrame({\n",
    "                            'AA': abs_df['AA'],\n",
    "                        })\n",
    "                        \n",
    "                        # Add the selected columns\n",
    "                        df = pd.concat([df, selected_abs_df], axis=1)\n",
    "                        \n",
    "                        # Now calculate count and average from all data\n",
    "                        non_zero_mask = df.drop('AA', axis=1) > 0\n",
    "                        df['count'] = non_zero_mask.sum(axis=1)\n",
    "                        df['average'] = df.drop('AA', axis=1).where(non_zero_mask).mean(axis=1)\n",
    "                    else:\n",
    "                        df = None\n",
    "                else:\n",
    "                    df = None\n",
    "            else:\n",
    "                df = None\n",
    "\n",
    "        # Get counts and MS data\n",
    "        if df is None or df.empty or 'count' not in df.columns or 'average' not in df.columns:\n",
    "            # Create default DataFrame with zero values\n",
    "            protein_length = len(available_data_variables_dict[var]['protein_sequence'])\n",
    "            df = pd.DataFrame({\n",
    "                'count': [0] * protein_length,\n",
    "                'average': [0] * protein_length,\n",
    "                'AA': list(available_data_variables_dict[var]['protein_sequence'])\n",
    "            })\n",
    "\n",
    "        # Get counts and MS data\n",
    "        peptide_counts = df['count']\n",
    "        ms_data = df['average']\n",
    "        count_list.append(peptide_counts)\n",
    "  \n",
    "        # Calculate min/max MS values\n",
    "        min_ms = ms_data[ms_data > 0].min()\n",
    "        max_ms = ms_data.max()\n",
    "        min_values.append(min_ms)\n",
    "        max_values.append(max_ms)\n",
    "        \n",
    "        # Add computed properties to the variable data\n",
    "        available_data_variables_dict[var].update({\n",
    "            'peptide_counts': peptide_counts,\n",
    "            'ms_data': ms_data,\n",
    "            'ms_data_list': list(ms_data),\n",
    "            'AA_list': df['AA'].tolist(),\n",
    "            'max_peptide_counts': peptide_counts.max(),\n",
    "            'min_peptide_counts': peptide_counts.min(),\n",
    "            'max_ms_data': max_ms,\n",
    "            'min_ms_data': min_ms,\n",
    "            \n",
    "            # Generate chunks\n",
    "            'amino_acids_chunks': [\n",
    "                available_data_variables_dict[var]['protein_sequence'][i:i + chunk_size]\n",
    "                for i in range(0, len(available_data_variables_dict[var]['protein_sequence']), chunk_size)\n",
    "            ],\n",
    "            'peptide_counts_chunks': [\n",
    "                peptide_counts[i:i + chunk_size]\n",
    "                for i in range(0, len(peptide_counts), chunk_size)\n",
    "            ],\n",
    "            'ms_data_chunks': [\n",
    "                ms_data[i:i + chunk_size]\n",
    "                for i in range(0, len(ms_data), chunk_size)\n",
    "            ]\n",
    "        })\n",
    "        \n",
    "        # Process bioactive peptide data\n",
    "        columns_to_include = df.columns.difference(['AA', 'count'])\n",
    "        df_filtered = df[columns_to_include]\n",
    "        \n",
    "        available_data_variables_dict[var].update({\n",
    "            'bioactive_peptide_abs_df': df_filtered,\n",
    "            #'bioactive_peptide_chunks': chunk_dataframe(df_filtered, chunk_size),\n",
    "            #'bioactive_function_chunks': chunk_dataframe(available_data_variables_dict[var]['function_heatmap_df'], chunk_size),\n",
    "            'bioactive_peptide_func_df': available_data_variables_dict[var]['function_heatmap_df']\n",
    "        })\n",
    "        \n",
    "        seq_len_list.append(len(available_data_variables_dict[var]['amino_acids_chunks'][0]))\n",
    "\n",
    "    # Calculate global values\n",
    "    global axis_number, total_plots, y_ticks\n",
    "    max_sequence_length = max(seq_len_list)\n",
    "    axis_number = len(available_data_variables_dict) + 2\n",
    "    num_sets = len(next(iter(available_data_variables_dict.values()))['amino_acids_chunks'])\n",
    "    total_plots = num_sets * axis_number\n",
    "    style_map = assign_line_styles(available_data_variables_dict)\n",
    "    \n",
    "    # Process counts\n",
    "    if len(set([item for sublist in count_list for item in sublist])) >= 1:\n",
    "        flat_list = [item for sublist in count_list for item in sublist]\n",
    "        # Check if there are any non-zero values before filtering\n",
    "        non_zero_values = [item for item in flat_list if item != 0]\n",
    "        if non_zero_values:  # If there are non-zero values\n",
    "            list_of_counts = set(non_zero_values)\n",
    "            max_count = max(non_zero_values)\n",
    "            num_unique_count = len(set(non_zero_values))\n",
    "        else:  # If all values are zero\n",
    "            list_of_counts = {0}\n",
    "            max_count = 0\n",
    "            num_unique_count = 1\n",
    "    else:\n",
    "        max_count = 0\n",
    "        num_unique_count = 0\n",
    "        list_of_counts = set()\n",
    "    # Calculate number of colors\n",
    "    num_colors = 6 if num_unique_count >= 6 else num_unique_count\n",
    "\n",
    "    # Override min/max values with manual settings if enabled\n",
    "    if manual_y_axis:\n",
    "        min_values = [y_min_manual]\n",
    "        max_values = [y_max_manual]\n",
    "    # Calculate global values\n",
    "    if min_values and max_values:\n",
    "        y_ticks = calculate_y_ticks(min_values, max_values, log_transform)\n",
    "        y_ticks_str = ', '.join(f'{tick:.2e}' for tick in y_ticks)\n",
    "        y_ticks_html = f'<b>Max/Min of MS data (y-ticks):</b> {y_ticks_str}'\n",
    "    else:\n",
    "        y_ticks = [0.1, 1, 10]  # Default log scale values\n",
    "        y_ticks_html = '<span style=\"color:red;\">Insufficient data to calculate MS data y-ticks.</span>'\n",
    "        y_ticks_html += f'<b>Protein Sequence Length:</b> {max_sequence_length}'\n",
    "\n",
    "\n",
    "    return {\n",
    "        'list_of_counts': list_of_counts,\n",
    "        'min_values': min_values,\n",
    "        'max_values': max_values,\n",
    "        'seq_len_list': seq_len_list,\n",
    "        'max_sequence_length': max_sequence_length,\n",
    "        'y_ticks': y_ticks,\n",
    "        'max_count': max_count,\n",
    "        'num_unique_count': num_unique_count,\n",
    "        'num_colors': num_colors,\n",
    "        'total_plots': total_plots,\n",
    "        'style_map': style_map,\n",
    "        'errors': errors\n",
    "\n",
    "    }\n",
    "\n",
    "# Update plot function\n",
    "def update_plot(available_data_variables_dict, ms_average_choice, bio_or_pep, selected_peptides, selected_functions,\n",
    "                hm_selected_color, lp_selected_color, avglp_selected_color,\n",
    "                xaxis_label, yaxis_label, yaxis_position, legend_title_input_1, legend_title_input_2,\n",
    "                legend_title_input_3, plot_land, plot_port, filter_type, log_transform,\n",
    "                manual_y_axis, y_min_manual, y_max_manual):\n",
    "    all_errors = []\n",
    "    \n",
    "    if not available_data_variables_dict:  # Check if data is available\n",
    "        all_errors.append('No data is available for plotting.')\n",
    "        return (None, None, all_errors, [])  # Return tuple with errors\n",
    "    \n",
    "    result = process_available_data(available_data_variables_dict, filter_type, selected_functions,  selected_peptides, bio_or_pep, log_transform, manual_y_axis, y_min_manual, y_max_manual)\n",
    "    # Initialize fig_port and fig_land to None\n",
    "    fig_port_return = None\n",
    "    fig_land_return = None\n",
    "\n",
    "    # Unpack the dictionary into individual global variables\n",
    "    import _settings as settings\n",
    "    if result:\n",
    "        # Check for processing errors\n",
    "        if 'errors' in result and result['errors']:\n",
    "            all_errors.extend(result['errors'])\n",
    "        \n",
    "        # Unpack the dictionary into individual global variables\n",
    "        global list_of_counts, min_values, max_values, seq_len_list, max_sequence_length\n",
    "        global max_count, num_unique_count, num_colors, total_plots, style_map, y_ticks\n",
    "        \n",
    "        lineplot_height, scale_factor = port_hm_settings.get(len(available_data_variables_dict), (20, 0.1))\n",
    "        list_of_counts = result['list_of_counts']\n",
    "        min_values = result['min_values']\n",
    "        max_values = result['max_values']\n",
    "        seq_len_list = result['seq_len_list']\n",
    "        max_sequence_length = result['max_sequence_length']\n",
    "        y_ticks = result['y_ticks']\n",
    "        max_count = result['max_count']\n",
    "        num_unique_count = result['num_unique_count']\n",
    "        num_colors = result['num_colors']\n",
    "        total_plots = result['total_plots']\n",
    "        style_map = result['style_map']\n",
    "\n",
    "        yaxis_position_land = yaxis_position_port = 0.0 - 0.01 * yaxis_position\n",
    "        if log_transform or (y_ticks[1] - y_ticks[0] > 9999):\n",
    "            yaxis_position_land = -0.01 - 0.01 * yaxis_position\n",
    "        selected_legend_title = [legend_title_input_1, legend_title_input_2, legend_title_input_3, legend_title[4]]\n",
    "\n",
    "        # Your plotting code here, using the widget values as inputs\n",
    "\n",
    "        cmap = plt.get_cmap(hm_selected_color)\n",
    "        avg_cmap = plt.get_cmap(avglp_selected_color)\n",
    "\n",
    "        # Comprehensive validation of plotting configuration\n",
    "        config_errors = []\n",
    "        \n",
    "        # Scenario 1: No averaged data + no specific peptides selected\n",
    "        if ms_average_choice == 'no' and (not bio_or_pep or bio_or_pep == 'no'):\n",
    "            config_errors.append('Invalid configuration: \"Plot Averaged Data\" is set to \"No\" and \"Plot Specific Peptides\" is not selected. Please enable at least one data source for plotting.')\n",
    "        \n",
    "        # Scenario 2: Peptide intervals selected but no actual intervals provided  \n",
    "        elif bio_or_pep == '1' and (not selected_peptides or len(selected_peptides) == 0):\n",
    "            config_errors.append('Invalid configuration: \"Plot Specific Peptides\" is set to \"Peptide Intervals\" but no peptide intervals are selected. Please select peptide intervals from the \"Specific Options\" dropdown or change the plotting configuration.')\n",
    "        \n",
    "        # Scenario 3: Bioactive functions selected but no actual functions provided\n",
    "        elif bio_or_pep == '2' and (not selected_functions or len(selected_functions) == 0):\n",
    "            config_errors.append('Invalid configuration: \"Plot Specific Peptides\" is set to \"Bioactive Functions\" but no bioactive functions are selected. Please select bioactive functions from the \"Specific Options\" dropdown or change the plotting configuration.')\n",
    "        \n",
    "        # Scenario 4: Only averaged data but filter is set to selected peptides/functions\n",
    "        elif ms_average_choice == 'only' and filter_type in ['peptide-only', 'functional-only']:\n",
    "            if filter_type == 'peptide-only':\n",
    "                config_errors.append('Invalid configuration: \"Plot Averaged Data\" is set to \"Only\" but \"Plot Filter\" is set to \"Selected Peptides Only\". When plotting only averaged data, use \"All Peptides\" or \"All Functional Peptides\" filter.')\n",
    "            else:\n",
    "                config_errors.append('Invalid configuration: \"Plot Averaged Data\" is set to \"Only\" but \"Plot Filter\" is set to \"Selected Functions Only\". When plotting only averaged data, use \"All Peptides\" or \"All Functional Peptides\" filter.')\n",
    "        \n",
    "        # Scenario 5: Additional edge case - no data will be available for plotting\n",
    "        elif ms_average_choice == 'no' and bio_or_pep != 'no' and filter_type in ['peptide-only', 'functional-only']:\n",
    "            if bio_or_pep == '1' and filter_type == 'functional-only':\n",
    "                config_errors.append('Invalid configuration: \"Plot Specific Peptides\" is set to \"Peptide Intervals\" but \"Plot Filter\" is set to \"Selected Functions Only\". These settings are incompatible. Either change to \"Selected Peptides Only\" filter or switch to \"Bioactive Functions\" for specific peptides.')\n",
    "            elif bio_or_pep == '2' and filter_type == 'peptide-only':\n",
    "                config_errors.append('Invalid configuration: \"Plot Specific Peptides\" is set to \"Bioactive Functions\" but \"Plot Filter\" is set to \"Selected Peptides Only\". These settings are incompatible. Either change to \"Selected Functions Only\" filter or switch to \"Peptide Intervals\" for specific peptides.')\n",
    "        \n",
    "        # Scenario 6: All Functional Peptides filter with Peptide Intervals selection\n",
    "        elif bio_or_pep == '1' and filter_type == 'all-functional':\n",
    "            config_errors.append('Invalid configuration: \"Plot Specific Peptides\" is set to \"Peptide Intervals\" but \"Plot Filter\" is set to \"All Functional Peptides\". These settings are incompatible. Either change to \"All Peptides\" filter or switch to \"Bioactive Functions\" for specific peptides.')\n",
    "        \n",
    "        # Scenario 7: All Peptides filter with Bioactive Functions selection (opposite case)\n",
    "        #elif bio_or_pep == '2' and filter_type == 'all-peptides':\n",
    "        #    config_errors.append('Invalid configuration: \"Plot Specific Peptides\" is set to \"Bioactive Functions\" but \"Plot Filter\" is set to \"All Peptides\". These settings are incompatible. Either change to \"All Functional Peptides\" filter or switch to \"Peptide Intervals\" for specific peptides.')\n",
    "        \n",
    "        if config_errors:\n",
    "            all_errors.extend(config_errors)\n",
    "            return None, None, all_errors, []\n",
    "\n",
    "        else:\n",
    "            \"\"\" #                                       Function Call to Generate Plot\n",
    "            #---------------------------------------------------------------------------------------------------------------------------------------------\n",
    "            \"\"\"\n",
    "\n",
    "            if plot_port and bio_or_pep:\n",
    "                # Temporarily suppress specific warning\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter('ignore', UserWarning)\n",
    "                    if ms_average_choice in ['yes', 'only']:\n",
    "                        fig_port = visualize_sequence_heatmap_portrait(\n",
    "                            available_data_variables_dict,\n",
    "                            0.001,  \n",
    "                            lineplot_height,  \n",
    "                            1,  \n",
    "                            xaxis_label,  \n",
    "                            yaxis_label,  \n",
    "                            selected_legend_title,  \n",
    "                            yaxis_position_port,  \n",
    "                            cmap,\n",
    "                            avg_cmap,\n",
    "                            lp_selected_color,\n",
    "                            avglp_selected_color,\n",
    "                            selected_functions,\n",
    "                            ms_average_choice,\n",
    "                            bio_or_pep,\n",
    "                            log_transform,\n",
    "                            y_ticks,\n",
    "                            78)  # removed chunk_size= to make it a positional argument\n",
    "                    else:\n",
    "                        all_errors.append('No was selected earlier regarding the plotting of averaged absorbances, preventing the plotting of the averaged plot.')\n",
    "                    if max_count <= 1:\n",
    "                        # Check if this is due to missing function data\n",
    "                        if bio_or_pep == '2' and selected_functions:\n",
    "                            missing_functions = []\n",
    "                            for func in selected_functions:\n",
    "                                func_found = False\n",
    "                                for var in available_data_variables_dict:\n",
    "                                    bp_func = available_data_variables_dict[var]['bioactive_peptide_func_df']\n",
    "                                    # Check if this function exists in any data\n",
    "                                    for col in bp_func.columns:\n",
    "                                        func_values = bp_func[col].dropna()\n",
    "                                        if not func_values.empty:\n",
    "                                            for val in func_values:\n",
    "                                                sub_vals = [s.strip() for s in str(val).split(';')]\n",
    "                                                if any(func.lower().replace(\" \", \"\") == sub_val.lower().replace(\" \", \"\") for sub_val in sub_vals):\n",
    "                                                    func_found = True\n",
    "                                                    break\n",
    "                                        if func_found:\n",
    "                                            break\n",
    "                                    if func_found:\n",
    "                                        break\n",
    "                                if not func_found:\n",
    "                                    missing_functions.append(func)\n",
    "                            \n",
    "                            if missing_functions:\n",
    "                                if len(missing_functions) == 1:\n",
    "                                    all_errors.append(f'No data available for the selected function \"{missing_functions[0]}\". Please select a different function or check your data.')\n",
    "                                else:\n",
    "                                    all_errors.append(f'No data available for the selected functions: {\", \".join(missing_functions)}. Please select different functions or check your data.')\n",
    "                            else:\n",
    "                                all_errors.append('You have too few peptides for proper heatmapping.')\n",
    "                        # Check if this is due to missing peptide data\n",
    "                        elif bio_or_pep == '1' and selected_peptides:\n",
    "                            missing_peptides = []\n",
    "                            for peptide in selected_peptides:\n",
    "                                peptide_found = False\n",
    "                                for var in available_data_variables_dict:\n",
    "                                    bp_abs = available_data_variables_dict[var]['bioactive_peptide_abs_df']\n",
    "                                    # Check if this peptide interval exists as a column\n",
    "                                    if peptide in bp_abs.columns:\n",
    "                                        # Check if the column has any non-zero, non-NaN data\n",
    "                                        peptide_data = pd.to_numeric(bp_abs[peptide], errors='coerce')\n",
    "                                        if not peptide_data.dropna().empty and (peptide_data > 0).any():\n",
    "                                            peptide_found = True\n",
    "                                            break\n",
    "                                if not peptide_found:\n",
    "                                    missing_peptides.append(peptide)\n",
    "                            \n",
    "                            if missing_peptides:\n",
    "                                if len(missing_peptides) == 1:\n",
    "                                    all_errors.append(f'No data available for the selected peptide interval \"{missing_peptides[0]}\". Please select a different peptide interval or check your data.')\n",
    "                                else:\n",
    "                                    all_errors.append(f'No data available for the selected peptide intervals: {\", \".join(missing_peptides)}. Please select different peptide intervals or check your data.')\n",
    "                            else:\n",
    "                                all_errors.append('You have too few peptides for proper heatmapping.')\n",
    "                        else:\n",
    "                            all_errors.append('You have too few peptides for proper heatmapping.')\n",
    "            else:\n",
    "                fig_port = None\n",
    "            \"\"\"_____________________________________________________EXECUTING CODE TO PLOT W/ UPDATES_________________________________________________________________\"\"\"\n",
    "            \n",
    "            # Plotting code\n",
    "            if plot_land:\n",
    "                amino_acid_height = 0.25 + 0.1 * (\n",
    "                    len(available_data_variables_dict) // 4 if len(available_data_variables_dict) >= 8 else 0)\n",
    "                indices_height = amino_acid_height + 0.08\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter('ignore', UserWarning)\n",
    "                    fig_land, land_errors = visualize_sequence_heatmap_lanscape(\n",
    "                        available_data_variables_dict,\n",
    "                        amino_acid_height,\n",
    "                        7.5,\n",
    "                        indices_height,\n",
    "                        xaxis_label,\n",
    "                        yaxis_label,\n",
    "                        selected_legend_title,\n",
    "                        yaxis_position_land,\n",
    "                        cmap,\n",
    "                        avg_cmap,\n",
    "                        lp_selected_color,\n",
    "                        avglp_selected_color,\n",
    "                        selected_peptides,\n",
    "                        selected_functions,\n",
    "                        ms_average_choice,\n",
    "                        bio_or_pep,\n",
    "                        log_transform,\n",
    "                        y_ticks,\n",
    "                        filter_type,\n",
    "                        manual_y_axis,\n",
    "                        y_min_manual,\n",
    "                        y_max_manual)\n",
    "                \n",
    "                # Collect landscape plotting errors\n",
    "                all_errors.extend(land_errors)\n",
    "\n",
    "                if max_count <= 1:\n",
    "                    # Check if this is due to missing function data\n",
    "                    if bio_or_pep == '2' and selected_functions:\n",
    "                        missing_functions = []\n",
    "                        for func in selected_functions:\n",
    "                            func_found = False\n",
    "                            for var in available_data_variables_dict:\n",
    "                                bp_func = available_data_variables_dict[var]['bioactive_peptide_func_df']\n",
    "                                # Check if this function exists in any data\n",
    "                                for col in bp_func.columns:\n",
    "                                    func_values = bp_func[col].dropna()\n",
    "                                    if not func_values.empty:\n",
    "                                        for val in func_values:\n",
    "                                            sub_vals = [s.strip() for s in str(val).split(';')]\n",
    "                                            if any(func.lower().replace(\" \", \"\") == sub_val.lower().replace(\" \", \"\") for sub_val in sub_vals):\n",
    "                                                func_found = True\n",
    "                                                break\n",
    "                                    if func_found:\n",
    "                                        break\n",
    "                                if func_found:\n",
    "                                    break\n",
    "                            if not func_found:\n",
    "                                missing_functions.append(func)\n",
    "                        \n",
    "                        if missing_functions:\n",
    "                            if len(missing_functions) == 1:\n",
    "                                all_errors.append(f'No data available for the selected function \"{missing_functions[0]}\". Please select a different function or check your data.')\n",
    "                            else:\n",
    "                                all_errors.append(f'No data available for the selected functions: {\", \".join(missing_functions)}. Please select different functions or check your data.')\n",
    "                        else:\n",
    "                            all_errors.append('You have too few peptides for proper heatmapping.')\n",
    "                    # Check if this is due to missing peptide data\n",
    "                    elif bio_or_pep == '1' and selected_peptides:\n",
    "                        missing_peptides = []\n",
    "                        for peptide in selected_peptides:\n",
    "                            peptide_found = False\n",
    "                            for var in available_data_variables_dict:\n",
    "                                bp_abs = available_data_variables_dict[var]['bioactive_peptide_abs_df']\n",
    "                                # Check if this peptide interval exists as a column\n",
    "                                if peptide in bp_abs.columns:\n",
    "                                    # Check if the column has any non-zero, non-NaN data\n",
    "                                    peptide_data = pd.to_numeric(bp_abs[peptide], errors='coerce')\n",
    "                                    if not peptide_data.dropna().empty and (peptide_data > 0).any():\n",
    "                                        peptide_found = True\n",
    "                                        break\n",
    "                            if not peptide_found:\n",
    "                                missing_peptides.append(peptide)\n",
    "                        \n",
    "                        if missing_peptides:\n",
    "                            if len(missing_peptides) == 1:\n",
    "                                all_errors.append(f'No data available for the selected peptide interval \"{missing_peptides[0]}\". Please select a different peptide interval or check your data.')\n",
    "                            else:\n",
    "                                all_errors.append(f'No data available for the selected peptide intervals: {\", \".join(missing_peptides)}. Please select different peptide intervals or check your data.')\n",
    "                        else:\n",
    "                            all_errors.append('You have too few peptides for proper heatmapping.')\n",
    "                    else:\n",
    "                        all_errors.append('You have too few peptides for proper heatmapping.')\n",
    "            else:\n",
    "                fig_land = None\n",
    "        # Fixed return statement logic to check if the variables exist and have valid axes\n",
    "        if plot_port:\n",
    "            if bio_or_pep != 'no':\n",
    "                all_errors.append('The portrait plot only supports plotting averaged absorbance of peptides which is not formatted to be combined with specified peptide intervals or functions.')\n",
    "                fig_port_return = None \n",
    "            else:\n",
    "                # Check if fig_port is defined and has axes\n",
    "                if fig_port is not None and hasattr(fig_port, 'axes') and len(fig_port.axes) > 0:\n",
    "                    fig_port_return = fig_port\n",
    "        \n",
    "        if plot_land:\n",
    "            # Check if fig_land is defined and has axes\n",
    "            if fig_land is not None and hasattr(fig_land, 'axes') and len(fig_land.axes) > 0:\n",
    "                fig_land_return = fig_land\n",
    "\n",
    "        if not plot_port and not plot_land:\n",
    "            all_errors.append(\"One or both of the create plot checkbox must be selected to generate a plot.\")\n",
    "\n",
    "        # Collect missing data notifications for user feedback\n",
    "        missing_data_notifications = collect_missing_data_notifications(\n",
    "            available_data_variables_dict, selected_peptides, selected_functions, bio_or_pep\n",
    "        )\n",
    "        \n",
    "        return fig_port_return, fig_land_return, all_errors, missing_data_notifications  # Return the figures with errors and notifications\n",
    "    else:\n",
    "        all_errors.append('Reselect \"Variable Options\", no data is available for plotting.')\n",
    "        return None, None, all_errors, []  # Return None values with errors if no result\n",
    "\"\"\"_________________________________________Data Visualization Functions_________________________________\"\"\"\n",
    "# Function to plot rows of amino acids with backgrounds colored\n",
    "def plot_row_color(ax, amino_acids, colors):\n",
    "    ax.axis('off')\n",
    "    ax.set_xlim(0, max_sequence_length)\n",
    "    ax.set_xlabel('')\n",
    "    for j, (aa, color) in enumerate(zip(amino_acids, colors)):\n",
    "        ax.text(j + 0.5, 0.5, aa, color='black', ha='center', va='center', fontsize=14,\n",
    "                backgroundcolor=mcolors.rgb2hex(color))\n",
    "\n",
    "# Assigns line type for landscape plot if plotting individual peptides\n",
    "def assign_line_styles(data_variables):\n",
    "    # Define a set of line styles you find visually distinct\n",
    "    line_styles = cycle(['-', '--', ':', '-.'])\n",
    "    #line_styles = cycle(['-'])\n",
    "\n",
    "    # Extract unique labels from your data variables\n",
    "    unique_labels = set(data['label'] for data in data_variables.values())\n",
    "\n",
    "    # Map each unique label to a line style\n",
    "    style_map = {label: next(line_styles) for label in unique_labels}\n",
    "\n",
    "    # Map each unique label to a line style\n",
    "    #style_map = {'Gastric IVT': '--',\n",
    "    #             'Intestinal IVT': ':',\n",
    "    #             'J1H': '-', 'J2H': '-', 'J3H': '-', 'J4H': '-',}\n",
    "    return style_map\n",
    "\n",
    "# Function to plot rows of amino acids with NO backgrounds colored\n",
    "def plot_row(ax, amino_acids):\n",
    "    ax.axis('off')\n",
    "    ax.set_xlim(0, max_sequence_length)\n",
    "    ax.set_xlabel('')\n",
    "    for j, (aa) in enumerate(amino_acids):\n",
    "        ax.text(j + 0.5, 0.5, aa, color='black', ha='center', va='center', fontsize=8)  # backgroundcolor='white')\n",
    "\n",
    "def sci_notation(x, pos):\n",
    "    if x == 0:\n",
    "        return \"0\"\n",
    "    exponent = int(np.floor(np.log10(abs(x))))\n",
    "    coeff = x / 10**exponent\n",
    "    return r\"${:.1f}\\times10^{{{}}}$\".format(coeff, exponent)\n",
    "\n",
    "def plot_average_ms_data(ax, ms_data, label, var_index, y_ticks, i, chunk_size, avg_cmap, log_transform, line_style, sci_threshold=9999):\n",
    "    start_limit = i * chunk_size\n",
    "    end_limit = (i + 1) * chunk_size - 1\n",
    "    ax.set_xlim(start_limit, end_limit)\n",
    "\n",
    "    if isinstance(ms_data, (pd.DataFrame, pd.Series)):\n",
    "        x_values = ms_data.index.tolist()\n",
    "        y_values = ms_data.values.tolist() if hasattr(ms_data.values, 'tolist') else list(ms_data.values)\n",
    "    else:\n",
    "        x_values = list(range(len(ms_data)))\n",
    "        y_values = list(ms_data) if not isinstance(ms_data, list) else ms_data\n",
    "\n",
    "    num_colors = avg_cmap.N\n",
    "    color = avg_cmap(var_index % num_colors)\n",
    "    \n",
    "    try:\n",
    "        line, = ax.plot(x_values, y_values, label=label, color=color, linestyle=line_style)\n",
    "    except Exception as e:\n",
    "        # If plotting fails, create a dummy line and log the error\n",
    "        print(f\"Error in plot_average_ms_data for {label}: {str(e)}\")\n",
    "        print(f\"x_values type: {type(x_values)}, length: {len(x_values) if hasattr(x_values, '__len__') else 'N/A'}\")\n",
    "        print(f\"y_values type: {type(y_values)}, length: {len(y_values) if hasattr(y_values, '__len__') else 'N/A'}\")\n",
    "        # Create a dummy line to prevent further errors\n",
    "        line, = ax.plot([], [], label=label, color=color, linestyle=line_style)\n",
    "\n",
    "    if log_transform:\n",
    "        ax.set_yscale('log')\n",
    "        # Force matplotlib to use only our custom y_ticks for log scale\n",
    "        if y_ticks:\n",
    "            ax.yaxis.set_major_locator(mticker.FixedLocator(y_ticks))\n",
    "            ax.yaxis.set_minor_locator(mticker.NullLocator())  # Remove minor ticks\n",
    "            ax.yaxis.set_major_formatter(mticker.FuncFormatter(sci_notation))\n",
    "    else:\n",
    "        ax.set_yscale('linear')\n",
    "        if y_ticks:\n",
    "            y_range = max(y_ticks) - min(y_ticks)\n",
    "            if y_range >= sci_threshold:\n",
    "                formatter = mticker.FuncFormatter(sci_notation)\n",
    "            else:\n",
    "                formatter = mticker.StrMethodFormatter(\"{x:.2f}\")\n",
    "            ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "    # Set y-ticks and y-axis limits (restored original formatting)\n",
    "    if y_ticks:\n",
    "        ax.set_yticks(y_ticks)\n",
    "        ax.set_ylim(min(y_ticks), max(y_ticks))\n",
    "    \n",
    "    #ax.tick_params(axis='y', labelsize=12)\n",
    "    ax.yaxis.tick_left()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "    # Return y_values for centralized y-axis limit calculation\n",
    "    return line, label, var_index, y_values\n",
    "# Function to extract non-zero, non-NaN values\n",
    "def extract_non_zero_non_nan_values(df):\n",
    "    unique_functions = set()\n",
    "    # Iterate over each value in the DataFrame\n",
    "    for value in df.stack().values:  # df.stack() stacks the DataFrame into a Series\n",
    "        if value != 0 and not pd.isna(value):  # Check if value is non-zero and not NaN\n",
    "            if isinstance(value, str):\n",
    "                # If the value is a string, it could contain multiple delimited entries\n",
    "                entries = value.split('; ')\n",
    "                unique_functions.update(entries)\n",
    "            else:\n",
    "                unique_functions.add(value)\n",
    "    return unique_functions\n",
    "\n",
    "    # This function is used in plotting to filter the data to only plot selected peptides or bioactive peptides, independent of averaged data\n",
    "\n",
    "def filter_data_by_selection(bp_abs, bp_func, selected_peptides, selected_functions, bio_or_pep, filter_type, ms_average_choice, var_name):\n",
    "    \"\"\"\n",
    "    Final simplified version that uses a completely different approach to avoid Series truth value issues.\n",
    "    Returns: (filtered_bp_abs, filtered_bp_func, errors)\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    # ---------- Helper functions ----------\n",
    "    def safe_str(value):\n",
    "        \"\"\"Safely convert any value to string, handling None, NaN, and Series objects\"\"\"\n",
    "        try:\n",
    "            if value is None:\n",
    "                return \"\"\n",
    "            \n",
    "            # For Series objects, just return empty string to avoid truth value errors\n",
    "            if hasattr(value, 'iloc'):\n",
    "                return \"\"\n",
    "                \n",
    "            # Convert to string\n",
    "            return str(value)\n",
    "        except:\n",
    "            return \"\"\n",
    "    \n",
    "    # ---------- Main function logic ----------\n",
    "    # Early return cases\n",
    "    if bp_abs is None or not isinstance(bp_abs, pd.DataFrame) or bp_abs.empty:\n",
    "        errors.append(f\"Absorbance DataFrame is empty for variable: {var_name}\")\n",
    "        return pd.DataFrame(), pd.DataFrame(), errors\n",
    "        \n",
    "    if bp_func is None or not isinstance(bp_func, pd.DataFrame) or bp_func.empty:\n",
    "        errors.append(f\"Function DataFrame is empty for variable: {var_name}\")\n",
    "        return pd.DataFrame(), pd.DataFrame(), errors\n",
    "    \n",
    "    # ---------- Handle peptide intervals selection (bio_or_pep = '1') ----------\n",
    "    if bio_or_pep == '1' and selected_peptides:\n",
    "        # Find our selected peptide columns that exist in the DataFrame\n",
    "    \n",
    "        peptide_columns = [col for col in selected_peptides if col in bp_abs.columns]\n",
    "        non_matching_peptides = [col for col in selected_peptides if col not in bp_abs.columns]\n",
    "        \n",
    "        if peptide_columns:\n",
    "            # Add metadata columns if they exist\n",
    "            meta_columns = ['AA', 'count', 'average']\n",
    "            keep_columns = [col for col in meta_columns if col in bp_abs.columns]\n",
    "            all_columns = keep_columns + peptide_columns\n",
    "\n",
    "            # Create new DataFrames with only the columns we want\n",
    "            filtered_bp_abs = bp_abs[all_columns].copy()\n",
    "            filtered_bp_func = pd.DataFrame()\n",
    "            \n",
    "            # Add warning for non-matching peptides if any\n",
    "            if non_matching_peptides:\n",
    "                errors.append(f'Some peptide columns not found in data for variable: {var_name}. Missing: {non_matching_peptides}')\n",
    "            \n",
    "            return filtered_bp_abs, filtered_bp_func, errors\n",
    "        else:\n",
    "            errors.append(f'No matching peptide columns found in data for variable: {var_name}. Non-matching peptides: {non_matching_peptides}')\n",
    "            return pd.DataFrame(), pd.DataFrame(), errors\n",
    "    \n",
    "    # ---------- Handle bioactive functions selection (bio_or_pep = '2') ----------\n",
    "    elif bio_or_pep == '2' and selected_functions:\n",
    "        try:\n",
    "            # Simple string-based approach that completely avoids pandas operations\n",
    "            # This manually scans the DataFrame for columns containing the selected functions\n",
    "            columns_with_functions = []\n",
    "            functions_found = set()\n",
    "            \n",
    "            # Get list of column names first\n",
    "            all_columns = list(bp_func.columns)\n",
    "            \n",
    "            # Iterate through the function DataFrame columns\n",
    "            for col_name in all_columns:\n",
    "                # Process a column at a time - get non-NA function values\n",
    "                func_values = bp_func[col_name].dropna()\n",
    "                \n",
    "                if func_values.empty:\n",
    "                    continue\n",
    "                \n",
    "                # Track matched functions for this column\n",
    "                matched_functions = set()\n",
    "                \n",
    "                # Check for matches with selected functions, splitting on ';' like in process_chunk_data\n",
    "                for val in func_values:\n",
    "                    # Convert to string (safely)\n",
    "                    try:\n",
    "                        value_str = str(val)\n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "                    # Skip empty strings or 'nan'\n",
    "                    if not value_str or value_str == 'nan':\n",
    "                        continue\n",
    "                    \n",
    "                    # Split the value on ';' and strip whitespace\n",
    "                    sub_vals = [s.strip() for s in value_str.split(';')]\n",
    "                    \n",
    "                    for sub_val in sub_vals:\n",
    "                        # Only match if sub_val matches exactly one of the selected_functions (case-insensitive, ignoring whitespace)\n",
    "                        for func in selected_functions:\n",
    "                            if func.lower().replace(\" \", \"\") == sub_val.lower().replace(\" \", \"\"):\n",
    "                                matched_functions.add(func)\n",
    "                \n",
    "                # If we found any matches in this column, add it to the list\n",
    "                if matched_functions:\n",
    "                    columns_with_functions.append(col_name)\n",
    "                \n",
    "                # Add matched functions to the global set\n",
    "                functions_found.update(matched_functions)\n",
    "            \n",
    "            # Remove any duplicates\n",
    "            columns_with_functions = list(set(columns_with_functions))\n",
    "            \n",
    "            # Identify non-matching functions\n",
    "            non_matching_functions = [func for func in selected_functions if func not in functions_found]\n",
    "            \n",
    "            if columns_with_functions:\n",
    "                # Only include columns that are in both DataFrames  \n",
    "                valid_cols_abs = [col for col in columns_with_functions if col in bp_abs.columns]\n",
    "                valid_cols_func = [col for col in columns_with_functions if col in bp_func.columns]\n",
    "                \n",
    "                # Create filtered DataFrames\n",
    "                if valid_cols_abs:\n",
    "                    filtered_bp_abs = bp_abs[valid_cols_abs].copy()\n",
    "                else:\n",
    "                    filtered_bp_abs = pd.DataFrame()\n",
    "                    \n",
    "                if valid_cols_func:\n",
    "                    filtered_bp_func = bp_func[valid_cols_func].copy()\n",
    "                else:\n",
    "                    filtered_bp_func = pd.DataFrame()\n",
    "                \n",
    "                # Add warning for non-matching functions if any\n",
    "                if non_matching_functions:\n",
    "                    errors.append(f'Some selected functions not found in data for variable: {var_name}. Missing: {non_matching_functions}')\n",
    "                \n",
    "                return filtered_bp_abs, filtered_bp_func, errors\n",
    "            else:\n",
    "                errors.append(f'No columns found containing any of the selected functions for variable: {var_name}. Non-matching functions: {non_matching_functions}')\n",
    "                return pd.DataFrame(), pd.DataFrame(), errors\n",
    "                \n",
    "        except Exception as e:\n",
    "            errors.append(f\"Error in function filtering for variable: {var_name}: {str(e)}\")\n",
    "            return pd.DataFrame(), pd.DataFrame(), errors\n",
    "    \n",
    "    else:\n",
    "        return bp_abs, bp_func, errors\n",
    "\n",
    "def process_chunk_data(ax2, chunk_abs, chunk_func, chunk_size, i, y_ticks, handles, labels, \n",
    "                      sample_list, var_name_list, line_style, var_name, var_ms_data, \n",
    "                      selected_peptides, selected_functions, lp_selected_color, ms_average_choice, log_transform, bio_or_pep):\n",
    "    \n",
    "    footnote_list = []\n",
    "    errors = []\n",
    "    min_values = []\n",
    "    max_values = []\n",
    "    \n",
    "    # Track peptides already processed to avoid duplicates\n",
    "    processed_peptides = {}\n",
    "\n",
    "    start_limit = i * chunk_size\n",
    "    end_limit = (i + 1) * chunk_size - 1\n",
    "    ax2.set_xlim(start_limit, end_limit)\n",
    "\n",
    "    # Set up colormap\n",
    "    common_columns = []\n",
    "    colormap = plt.get_cmap(lp_selected_color)\n",
    "    \n",
    "    # Create a dictionary to map functions to colors\n",
    "    if bio_or_pep == '1':\n",
    "        num_colors = max(len(selected_peptides), 1)\n",
    "        items_to_color = selected_peptides\n",
    "    elif bio_or_pep == '2':\n",
    "        num_colors = max(len(selected_functions), 1)\n",
    "        items_to_color = selected_functions\n",
    "    else:\n",
    "        num_colors = 1\n",
    "        items_to_color = []\n",
    "    \n",
    "    # Generate evenly spaced colors\n",
    "    colors = colormap(np.linspace(0, 1, num_colors))\n",
    "    \n",
    "    # Create a dictionary mapping each function to a specific color\n",
    "    function_colors = {item: colors[i % len(colors)] for i, item in enumerate(items_to_color)}\n",
    "    function_colors['Multiple'] = 'black'  # Keep 'Multiple' as black\n",
    "    \n",
    "    # Track which functions we've already plotted\n",
    "    plotted_functions = set()\n",
    "    \n",
    "    # Process each column in the abundance data\n",
    "    columns_processed = 0\n",
    "\n",
    "    for col in chunk_abs.columns:\n",
    "        if col != 'average':\n",
    "            try:\n",
    "                # Force y_values to be numeric and drop NaN/zeros\n",
    "                y_values = pd.to_numeric(chunk_abs[col], errors='coerce')\n",
    "                y_values = y_values[y_values > 0]\n",
    "                \n",
    "                if not y_values.empty:\n",
    "                    columns_processed += 1\n",
    "                    # Ensure x_values and y_values are proper arrays for matplotlib\n",
    "                    x_values = list(y_values.index)\n",
    "                    y_values_list = list(y_values.values)\n",
    "                    \n",
    "                    # Additional validation\n",
    "                    if len(x_values) != len(y_values_list):\n",
    "                        errors.append(f\"Mismatch in data lengths for column {col}: x_values={len(x_values)}, y_values_list={len(y_values_list)}\")\n",
    "                        continue\n",
    "                    \n",
    "                    if len(x_values) == 0:\n",
    "                        errors.append(f\"Empty data for column {col}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Get a default label\n",
    "                    label_value = col\n",
    "\n",
    "                    # Get function label if available\n",
    "                    #print(f\"[DEBUG] bio_or_pep: {bio_or_pep}\")\n",
    "                    #print(f\"[DEBUG] col: {col}\")\n",
    "                    #print(f\"[DEBUG] chunk_func.columns: {chunk_func.columns}\")\n",
    "                    #print(f\"[DEBUG] selected_functions: {selected_functions}\")\n",
    "\n",
    "                    if bio_or_pep == '2' and col in chunk_func.columns:\n",
    "                        # Get non-NA function values\n",
    "                        func_values = chunk_func[col].dropna()\n",
    "                        if not func_values.empty:\n",
    "                            # Check for matches with selected functions, splitting on ';'\n",
    "                            #print(f\"[DEBUG] selected_functions: {selected_functions}\")\n",
    "                            found_functions = set()\n",
    "                            for val in func_values:\n",
    "                                # Split the value on ';' and strip whitespace\n",
    "                                sub_vals = [s.strip() for s in str(val).split(';')]\n",
    "                                for sub_val in sub_vals:\n",
    "                                    # Only match if sub_val matches exactly one of the selected_functions (case-insensitive, ignoring whitespace)\n",
    "                                    for func in selected_functions:\n",
    "                                        if func.lower().replace(\" \", \"\") == sub_val.lower().replace(\" \", \"\"):\n",
    "                                            found_functions.add(func)\n",
    "                            if found_functions:\n",
    "                                if len(found_functions) > 1:\n",
    "                                    label_value = 'Multiple'\n",
    "                                    # Check if this peptide was already processed to avoid duplicates\n",
    "                                    if col not in processed_peptides:\n",
    "                                        processed_peptides[col] = set()\n",
    "                                    \n",
    "                                    # Add functions to the existing set for this peptide\n",
    "                                    processed_peptides[col].update(found_functions)\n",
    "                                else:\n",
    "                                    label_value = list(found_functions)[0]\n",
    "                            else:\n",
    "                                break\n",
    "                            #print(f\"[DEBUG] label_value: {label_value}\")\n",
    "                            #print(f\"[DEBUG] found_functions: {found_functions}\")\n",
    "                        elif bio_or_pep == '1' and col in selected_peptides:\n",
    "                            label_value = col\n",
    "\n",
    "\n",
    "                    # Get appropriate color\n",
    "                    if label_value in function_colors:\n",
    "                        color = function_colors[label_value]\n",
    "                    else:\n",
    "                        color = 'grey'\n",
    "                    \n",
    "                    # Use solid lines for better visibility\n",
    "                    current_line_style = '-'\n",
    "                    \n",
    "                    # Plot with increased line width for visibility\n",
    "                    try:\n",
    "                        lines = ax2.plot(x_values, y_values_list, \n",
    "                                    label=label_value,\n",
    "                                    linestyle=line_style, \n",
    "                                    color=color)\n",
    "                    except Exception as e:\n",
    "                        error_msg = f\"Error plotting line for column {col} in variable {var_name}: {str(e)}\"\n",
    "                        error_msg += f\" | x_values type: {type(x_values)}, length: {len(x_values) if hasattr(x_values, '__len__') else 'N/A'}\"\n",
    "                        error_msg += f\" | y_values_list type: {type(y_values_list)}, length: {len(y_values_list) if hasattr(y_values_list, '__len__') else 'N/A'}\"\n",
    "                        errors.append(error_msg)\n",
    "                        continue\n",
    "                    \n",
    "                    line = lines[0]\n",
    "                    \n",
    "                    # Only add to legend if we haven't seen this function before\n",
    "                    if label_value not in plotted_functions or bio_or_pep == '1':\n",
    "                        handles.append(line)\n",
    "                        labels.append(label_value)\n",
    "                        sample_list.append(current_line_style)\n",
    "                        var_name_list.append(var_name)\n",
    "                        plotted_functions.add(label_value)\n",
    "                        # Update min and max values logic to ignore NaNs and handle empty y_values\n",
    "                        if len(y_values_list) > 0:\n",
    "                            y_min_val = np.nanmin(y_values_list)\n",
    "                            y_max_val = np.nanmax(y_values_list)\n",
    "                            if not np.isnan(y_min_val):\n",
    "                                min_values.append(y_min_val)\n",
    "                            if not np.isnan(y_max_val):\n",
    "                                max_values.append(y_max_val)\n",
    "\n",
    "                #else:\n",
    "                    \n",
    "            except Exception as e:\n",
    "                errors.append(f\"Error plotting line for column {col} in variable {var_name}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    #print(f\"Debug: Total columns processed with data: {columns_processed}\")\n",
    "        \n",
    "    # Set up axis properties with original y-axis formatting restored\n",
    "    if log_transform:\n",
    "        ax2.set_yscale('log')\n",
    "        # Force matplotlib to use only our custom y_ticks for log scale\n",
    "        if y_ticks:\n",
    "            ax2.yaxis.set_major_locator(mticker.FixedLocator(y_ticks))\n",
    "            ax2.yaxis.set_minor_locator(mticker.NullLocator())  # Remove minor ticks\n",
    "            ax2.yaxis.set_major_formatter(mticker.FuncFormatter(sci_notation))\n",
    "    else:\n",
    "        ax2.set_yscale('linear')\n",
    "        formatter = mticker.FuncFormatter(sci_notation)\n",
    "        ax2.yaxis.set_major_formatter(formatter)\n",
    "    \n",
    "    # Force y-axis limits to ensure data is visible (restored original logic)\n",
    "    if y_ticks:\n",
    "        ax2.set_yticks(y_ticks)\n",
    "        ax2.set_ylim(min(y_ticks), max(y_ticks))\n",
    "    \n",
    "    ax2.tick_params(axis='y', labelsize=16)\n",
    "    ax2.yaxis.tick_left()\n",
    "    ax2.set_xticks([])\n",
    "    ax2.set_xticklabels([])\n",
    "    \n",
    "    # Convert processed_peptides to the format expected by footnote generation\n",
    "    for peptide_col, functions in processed_peptides.items():\n",
    "        if len(functions) > 1:  # Only include peptides with multiple functions\n",
    "            peptide_info = {\n",
    "                'peptide_column': peptide_col,\n",
    "                'functions': sorted(list(functions))\n",
    "            }\n",
    "            footnote_list.append(peptide_info)\n",
    "    \n",
    "    return footnote_list, errors, min_values, max_values\n",
    "\n",
    "def get_grouped_colors(counts, max_count, num_groups, plot_zero, cmap):\n",
    "    # Initialize colors list with None to maintain length\n",
    "    colors = [None] * len(counts)\n",
    "\n",
    "    # Set the start point based on the user's input\n",
    "    start_point = 0 if plot_zero == 'yes' else 1\n",
    "\n",
    "    # Group counts into fewer categories if necessary, excluding zeros\n",
    "    group_bounds = np.linspace(start_point, max_count, num_groups + 1)\n",
    "    group_labels = np.digitize(counts, bins=group_bounds, right=True)  # Find group labels for counts\n",
    "    ##print(\"DEBUG: group_labels\", group_labels)\n",
    "    norm = Normalize(vmin=start_point, vmax=num_groups)  # Normalize based on the number of groups\n",
    "\n",
    "    # Map each count to a color\n",
    "    #for i, count in enumerate(counts):\n",
    "    for i, (count, label) in enumerate(zip(counts, group_labels)):\n",
    "        if plot_zero == 'no' and count == 0:\n",
    "            colors[i] = 'white'\n",
    "        else:\n",
    "            # Find which group the count belongs to\n",
    "            group_idx = np.digitize(count, group_bounds) - 1\n",
    "            \n",
    "            if max_count > 20:\n",
    "                # For large ranges, use continuous color mapping\n",
    "                colors[i] = cmap(count / max_count)\n",
    "            else:\n",
    "                # For smaller ranges, use discrete color groups\n",
    "                #colors[i] = cmap(norm(group_bounds[min(group_idx, len(group_bounds)-1)]))\n",
    "                colors[i] = cmap(norm(label))\n",
    "\n",
    "    #print(\"DEBUG: label\",label)\n",
    "    return colors\n",
    "\n",
    "# Function to create legend for heatmap\n",
    "def create_heatmap_legend_handles(cmap, num_colors, max_count, plot_zero):\n",
    "    \"\"\"\n",
    "    Create color-coded legend handles for the heatmap with proper handling of zero values\n",
    "    and error cases\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Handle case where all values are zero\n",
    "        if max_count == 0:\n",
    "           norm = Normalize(vmin=0, vmax=1)\n",
    "           color = cmap(norm(0))\n",
    "           return [patches.Patch(color=color, label='0')], ['0']\n",
    "                 \n",
    "        # Set the start point based on plot_zero\n",
    "        start_point = 0 if plot_zero == 'yes' else 1\n",
    "        \n",
    "        # Create group boundaries to match get_grouped_colors\n",
    "        count_ranges = np.linspace(start_point, max_count, num_colors + 1)\n",
    "        \n",
    "        # Determine interval type based on count vs intervals\n",
    "        if max_count > num_colors:\n",
    "           plt_interval = max_count\n",
    "        else:\n",
    "           plt_interval = num_colors\n",
    "           \n",
    "        legend_handles = []\n",
    "        heatmap_labels = []\n",
    "        norm = Normalize(vmin=start_point, vmax=max_count)\n",
    "\n",
    "        # For small ranges, start from index 1 to skip the duplicate 1\n",
    "        start_idx = 1 if plt_interval <= 6 else 0\n",
    "        for i in range(start_idx, len(count_ranges)):\n",
    "            color = cmap(norm(count_ranges[i]))\n",
    "            if plt_interval <= 6 and plot_zero == 'no':\n",
    "                label = f'{int(count_ranges[i])}'\n",
    "            elif plt_interval <= 6 and plot_zero == 'yes':\n",
    "                label = f'{int(count_ranges[i])}'\n",
    "            elif i + 1 >= len(count_ranges):\n",
    "                label = f'{int(count_ranges[i])} - {max(count_ranges)}'\n",
    "                break\n",
    "            else:\n",
    "                # Create label showing range\n",
    "                start_val = int(count_ranges[i])\n",
    "                end_val = int(count_ranges[i + 1])\n",
    "                label = f'{start_val} - {end_val}'\n",
    "                \n",
    "            #if i = len(count_ranges):\n",
    "            #    color = cmap(norm(count_ranges[i]))\n",
    " \n",
    "            #print(\"DEBUG: i:\",i,\"label:\",label)\n",
    "            #legend_handles.append(patches.Patch(color=color, label=label))\n",
    "            legend_handles.append(patches.Patch(color=color, label=label))\n",
    "            heatmap_labels.append(label)\n",
    "        return legend_handles, heatmap_labels\n",
    "       \n",
    "    except Exception as e:\n",
    "       # Fallback for error cases\n",
    "       color = cmap(0)\n",
    "       handle = patches.Patch(color=color, label='0')\n",
    "       return [handle], ['0']\n",
    "\n",
    "def create_custom_legends(fig, labels, handles, var_name_list, legend_titles, heatmap_legend_handles,\n",
    "                          heatmap_legend_labels, ms_average_choice, bio_or_pep, plot_type):\n",
    "    \n",
    "    handles_dict = {}\n",
    "    sample_handles_dict = {}\n",
    "\n",
    "    # Modify label if needed and populate dictionaries\n",
    "    for label, handle, sample_name in zip(labels, handles, var_name_list):\n",
    "        handles_dict[label] = handle  # Store or update the handle with modified label\n",
    "\n",
    "        # Store handles for sample types (assuming sample_name correctly aligns with the handles)\n",
    "        if sample_name not in sample_handles_dict:\n",
    "            sample_handles_dict[sample_name] = handle\n",
    "\n",
    "    # Create new handles for the legend with modified properties\n",
    "    new_handles_func = [copy.copy(handle) for handle in handles_dict.values()]\n",
    "    new_labels_func = [label for label in handles_dict.keys()]\n",
    "\n",
    "    # Initial empty lists for combined handles and labels\n",
    "    combined_handles = []\n",
    "    combined_labels = []\n",
    "    # Filter for \"Averaged\" labels\n",
    "    averaged_handles = []\n",
    "    averaged_labels = []\n",
    "    other_handles = []\n",
    "    other_labels = []\n",
    "\n",
    "    for handle, label in zip(new_handles_func, new_labels_func):\n",
    "        if \"Averaged\" in label:\n",
    "            clean_label = label.replace(\"Averaged \", \"\")  # Remove 'Averaged ' from the label\n",
    "            averaged_handles.append(handle)\n",
    "            averaged_labels.append(clean_label)  # Append the cleaned label\n",
    "\n",
    "        else:\n",
    "            handle.set_linestyle('-')  # Set line style to solid\n",
    "            other_handles.append(handle)\n",
    "            other_labels.append(label)\n",
    "\n",
    "    new_handles_samples = []\n",
    "    if not averaged_handles:\n",
    "        for handle in sample_handles_dict.values():\n",
    "            new_handle = copy.copy(handle)\n",
    "            new_handle.set_color('black')  # Set color to black for sample type handles\n",
    "            new_handles_samples.append(new_handle)\n",
    "\n",
    "    # Dummy handles for subtitles\n",
    "    line_type = mlines.Line2D([], [], color='none', label='Line Type')\n",
    "    average_color = mlines.Line2D([], [], color='none', label='Average Absorbance')\n",
    "    line_color = mlines.Line2D([], [], color='none', label='Line Color')\n",
    "    pep_count_placeholder = mlines.Line2D([], [], color='none', label='Line Type')\n",
    "\n",
    "\n",
    "    #legend_title = [0-'Sample Type:',1-'Peptide Counts:','2-'Bioactivity Function:' or '2-'Peptide Interval:', '3-'Average Absorbance:']\n",
    "\n",
    "    line_type_title = legend_titles[0]\n",
    "    avgline_color_title = legend_titles[2] if bio_or_pep == 'no' else legend_titles[3]\n",
    "    color_title = legend_titles[2] \n",
    "\n",
    "    if ms_average_choice == 'yes':\n",
    "        if bio_or_pep != 'no':\n",
    "            combined_handles = [line_color] + other_handles + [average_color] + averaged_handles\n",
    "            combined_labels = [color_title] + other_labels + [avgline_color_title] + averaged_labels\n",
    "\n",
    "        else: #if bio_or_pep == 'no':\n",
    "            combined_handles = [average_color] + averaged_handles\n",
    "            combined_labels = [avgline_color_title] + averaged_labels\n",
    "\n",
    "    if ms_average_choice == 'only':\n",
    "        combined_handles = [average_color] + averaged_handles\n",
    "        combined_labels = [avgline_color_title] + averaged_labels\n",
    "\n",
    "    if ms_average_choice == 'no' and bio_or_pep != 'no':\n",
    "        combined_handles = [line_color] + other_handles + [line_type] + new_handles_samples\n",
    "        combined_labels = [color_title] + other_labels + [line_type_title] + [key for key in sample_handles_dict.keys()]\n",
    "\n",
    "    legend_peptide_count = None\n",
    "    if plot_type == \"land\":\n",
    "        # Create the peptide count legend separately\n",
    "        if plot_heatmap == 'yes':\n",
    "            legend_peptide_count = fig.legend(handles=heatmap_legend_handles, loc='center',\n",
    "                                              fontsize=14,\n",
    "                                              title=legend_titles[1],\n",
    "                                              title_fontsize=14,\n",
    "                                              bbox_to_anchor=(0.5, -0.1),\n",
    "                                              ncol=len(heatmap_legend_handles))\n",
    "\n",
    "        # Create the combined legend (for other handles/labels)\n",
    "        combined_legend = fig.legend(handles=combined_handles, labels=combined_labels,\n",
    "                                     loc='upper left', bbox_to_anchor=(0.99, 0.975),\n",
    "                                     fontsize=14, handlelength=2)\n",
    "        plt.tight_layout()\n",
    "        fig.subplots_adjust(right=0.9)  # Make room for side legend\n",
    "\n",
    "    # Create a single combined legend\n",
    "    elif plot_type == \"port\":\n",
    "\n",
    "        # Combine heatmap handles with other handles for a single legend\n",
    "        combined_handles = [line_color] + other_handles + [pep_count_placeholder] + heatmap_legend_handles\n",
    "        combined_labels = [avgline_color_title] + other_labels + [legend_titles[1]] + heatmap_legend_labels\n",
    "\n",
    "        # Create a single combined legend with just the combined handles (no need for additional labels)\n",
    "        combined_legend = fig.legend(handles=combined_handles,\n",
    "                                     labels=combined_labels,\n",
    "                                     loc='upper left',\n",
    "                                     bbox_to_anchor=(0.9025, 0.875),\n",
    "                                     fontsize=14)\n",
    "\n",
    "    return combined_legend, legend_peptide_count\n",
    "\n",
    "def collect_missing_data_notifications(available_data_variables_dict, selected_peptides, selected_functions, bio_or_pep):\n",
    "    \"\"\"\n",
    "    Collect notifications about missing data for specific variables during plotting.\n",
    "    Returns a list of notification messages for user display.\n",
    "    \"\"\"\n",
    "    notifications = []\n",
    "    \n",
    "    if bio_or_pep == '1' and selected_peptides:  # Peptide intervals selected\n",
    "        # Track which peptides are missing from which variables\n",
    "        missing_by_variable = {}\n",
    "        \n",
    "        for var_name, var_data in available_data_variables_dict.items():\n",
    "            missing_peptides = []\n",
    "            if 'heatmap_df' in var_data:\n",
    "                available_columns = var_data['heatmap_df'].columns.tolist()\n",
    "                for peptide in selected_peptides:\n",
    "                    if peptide not in available_columns:\n",
    "                        missing_peptides.append(peptide)\n",
    "            \n",
    "            if missing_peptides:\n",
    "                missing_by_variable[var_name] = missing_peptides\n",
    "        \n",
    "        # Create notification messages\n",
    "        for var_name, missing_peptides in missing_by_variable.items():\n",
    "            if len(missing_peptides) == 1:\n",
    "                notifications.append(f\" Variable '{var_name}': Peptide interval '{missing_peptides[0]}' is not available in this dataset.\")\n",
    "            else:\n",
    "                peptide_list = \"', '\".join(missing_peptides)\n",
    "                notifications.append(f\" Variable '{var_name}': Peptide intervals '{peptide_list}' are not available in this dataset.\")\n",
    "    \n",
    "    elif bio_or_pep == '2' and selected_functions:  # Bioactive functions selected\n",
    "        # Track which functions are missing from which variables\n",
    "        missing_by_variable = {}\n",
    "        \n",
    "        for var_name, var_data in available_data_variables_dict.items():\n",
    "            missing_functions = []\n",
    "            if 'function_heatmap_df' in var_data:\n",
    "                func_df = var_data['function_heatmap_df']\n",
    "                if func_df is not None and not func_df.empty:\n",
    "                    # Extract all functions present in this variable\n",
    "                    present_functions = set()\n",
    "                    for col in func_df.columns:\n",
    "                        for cell in func_df[col]:\n",
    "                            if pd.notna(cell) and str(cell) != '0':\n",
    "                                cell_str = str(cell)\n",
    "                                if ';' in cell_str:\n",
    "                                    present_functions.update(cell_str.split(';'))\n",
    "                                else:\n",
    "                                    present_functions.add(cell_str)\n",
    "                    \n",
    "                    # Check which selected functions are missing\n",
    "                    for function in selected_functions:\n",
    "                        if function not in present_functions:\n",
    "                            missing_functions.append(function)\n",
    "            else:\n",
    "                # If no function data at all, all selected functions are missing\n",
    "                missing_functions = selected_functions.copy()\n",
    "            \n",
    "            if missing_functions:\n",
    "                missing_by_variable[var_name] = missing_functions\n",
    "        \n",
    "        # Create notification messages\n",
    "        for var_name, missing_functions in missing_by_variable.items():\n",
    "            if len(missing_functions) == 1:\n",
    "                notifications.append(f\" Variable '{var_name}': Bioactive function '{missing_functions[0]}' is not available in this dataset.\")\n",
    "            else:\n",
    "                function_list = \"', '\".join(missing_functions)\n",
    "                notifications.append(f\" Variable '{var_name}': Bioactive functions '{function_list}' are not available in this dataset.\")\n",
    "    \n",
    "    return notifications\n",
    "\n",
    "\n",
    "\"\"\"_________________________________________Landscape Plot________________________________________\"\"\"\n",
    "### def visualize_sequence_heatmap_individual_lines(available_data_variables_dict, amino_acid_height, lineplot_height, indices_height, filename, xaxis_label, yaxis_label, legend_title, yaxis_position):\n",
    "def visualize_sequence_heatmap_lanscape(available_data_variables_dict,\n",
    "                                                         amino_acid_height,\n",
    "                                                         lineplot_height,\n",
    "                                                         indices_height,\n",
    "                                                         xaxis_label,\n",
    "                                                         yaxis_label,\n",
    "                                                         legend_title,\n",
    "                                                         yaxis_position,\n",
    "                                                         cmap,\n",
    "                                                         avg_cmap,\n",
    "                                                         lp_selected_color,\n",
    "                                                         avglp_selected_color,\n",
    "                                                         selected_peptides,\n",
    "                                                         selected_functions,\n",
    "                                                         ms_average_choice,\n",
    "                                                         bio_or_pep, log_transform, y_ticks, filter_type,\n",
    "                                                         manual_y_axis=False, y_min_manual=None, y_max_manual=None):\n",
    "    all_errors = []\n",
    "    # Use a list comprehension to find the maximum length of 'AA_list' across all variables\n",
    "    max_sequence_length = max([len(available_data_variables_dict[var]['AA_list']) for var in available_data_variables_dict])\n",
    "\n",
    "    # Check if there are multiple distinct protein IDs in available_data_variables_dict\n",
    "    multiple_proteins = len(set([available_data_variables_dict[var]['protein_id'] for var in available_data_variables_dict])) > 1\n",
    "\n",
    "    chunk_size = max_sequence_length\n",
    "    # Create legend handles for the heatmap\n",
    "    heatmap_legend_handles, heatmap_legend_labels = create_heatmap_legend_handles(cmap, num_colors, max_count, plot_zero)  # You can change the number 5 to have more or fewer color intervals\n",
    "\n",
    "    # Function to plot rows of amino acids with backgrounds colored\n",
    "    # Function to plot rows of amino acids with backgrounds colored\n",
    "    def plot_row_color_landscape(ax, amino_acids, colors):\n",
    "        ax.axis('off')\n",
    "        ax.set_xlim(0, max_sequence_length)\n",
    "        ax.set_xlabel('')\n",
    "        # Height and width for each cell\n",
    "        cell_width = 1  # Each amino acid is spaced evenly by 1 unit on the x-axis\n",
    "        cell_height = 1  # Set height of the row\n",
    "\n",
    "        for j, (aa, color) in enumerate(zip(amino_acids, colors)):\n",
    "            # Create a rectangle (cell) with the background color\n",
    "            rect = patches.Rectangle((j, 0), cell_width, cell_height, color=mcolors.rgb2hex(color))\n",
    "            ax.add_patch(rect)  # Add the colored rectangle to the plot\n",
    "\n",
    "    # Function to plot rows of amino acids with backgrounds colored\n",
    "    def plot_row_landscape(ax, amino_acids):\n",
    "        ax3.axis('off')\n",
    "        ax3.set_xlim(0, max_sequence_length)\n",
    "        ax3.set_xlabel('')\n",
    "        aa_font_size = 10\n",
    "        if max_sequence_length > 200:\n",
    "            aa_font_size -= 0.5\n",
    "        if max_sequence_length > 250:\n",
    "            aa_font_size -= 1\n",
    "        if max_sequence_length > 300:\n",
    "            return\n",
    "        for j, (aa) in enumerate(amino_acids):\n",
    "                ax3.text(j + 0.5, 0.5, aa, color='black', ha='center', va='center',\n",
    "                         fontsize=aa_font_size)\n",
    "\n",
    "    axis_number = 3  # Total number of plots per set of data\n",
    "    if plot_heatmap == 'yes':\n",
    "        # Define height ratios for each subplot in a set\n",
    "        height_ratios = (\n",
    "                    [lineplot_height] + [indices_height] + [amino_acid_height] * len(available_data_variables_dict) + [amino_acid_height])\n",
    "        axis_number = len(available_data_variables_dict) + 3\n",
    "\n",
    "    elif plot_heatmap == 'no':\n",
    "        height_ratios = ([lineplot_height] +[indices_height] + [amino_acid_height] )\n",
    "        axis_number = 3\n",
    "\n",
    "    fig, axes = plt.subplots(axis_number, 1, figsize=(25, (lineplot_height + indices_height + amino_acid_height)),\n",
    "                             gridspec_kw={'height_ratios': height_ratios, 'hspace': 0})\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate centralized y-axis limits before plotting  \n",
    "    y_min_central, y_max_central, all_min_vals, all_max_vals = calculate_centralized_y_limits(\n",
    "        available_data_variables_dict, selected_peptides, selected_functions, \n",
    "        ms_average_choice, bio_or_pep, filter_type, log_transform,\n",
    "        manual_y_axis, y_min_manual, y_max_manual\n",
    "    )\n",
    "    \n",
    "    # Use centralized values to calculate proper y_ticks that will be consistently applied\n",
    "    if all_min_vals and all_max_vals:\n",
    "        y_ticks = calculate_y_ticks(all_min_vals, all_max_vals, log_transform)\n",
    "\n",
    "    # Initialize for legend handling\n",
    "    handles, labels, sample_list, var_name_list = [], [], [], []\n",
    "    total_count = 0\n",
    "\n",
    "    # Loop through each set of data and create plots\n",
    "    for var_index, var in enumerate(available_data_variables_dict):\n",
    "        ax1 = axes[0]\n",
    "        ax1.axis('off')\n",
    "        ax1 = ax1.twinx()  # Create a twin y-axis\n",
    "        ax1.yaxis.set_minor_locator(plt.NullLocator())\n",
    "\n",
    "        var_amino_acids = available_data_variables_dict[var]['AA_list']\n",
    "        var_counts = available_data_variables_dict[var]['peptide_counts']\n",
    "        var_ms_data = available_data_variables_dict[var]['ms_data_list']\n",
    "        var_name = available_data_variables_dict[var]['label']\n",
    "        var_colors = get_grouped_colors(var_counts, max_count, num_colors, plot_zero, cmap)\n",
    "        bp_abs = available_data_variables_dict[var]['bioactive_peptide_abs_df']\n",
    "        bp_func = available_data_variables_dict[var]['bioactive_peptide_func_df']\n",
    "        # Default line style\n",
    "        line_style = '-'  # Default style if other conditions don't apply\n",
    "\n",
    "        #if ms_average_choice == 'yes' and bio_or_pep == 'no':\n",
    "        #   line_style = '-'  # This can stay '-' or change as per your requirement\n",
    "        #else:\n",
    "        line_style = style_map[var_name]  # Get assigned line style from the style map\n",
    "\n",
    "        if bio_or_pep != 'no' and ms_average_choice != 'only':\n",
    "            filtered_bp_abs, filtered_bp_fun, filter_errors = filter_data_by_selection(bp_abs, bp_func, selected_peptides,\n",
    "                                                                        selected_functions, bio_or_pep, filter_type, ms_average_choice, var_name)\n",
    "      \n",
    "            footnote_list, process_errors, min_vals, max_vals = process_chunk_data(ax1, filtered_bp_abs, filtered_bp_fun, chunk_size, 0, y_ticks, handles,\n",
    "                                            labels, sample_list, var_name_list, line_style, var_name, var_ms_data,\n",
    "                                            selected_peptides, selected_functions, lp_selected_color, ms_average_choice,\n",
    "                                            log_transform, bio_or_pep)\n",
    "            # Collect all errors\n",
    "            all_errors.extend(filter_errors)\n",
    "            all_errors.extend(process_errors)\n",
    "\n",
    "        if ms_average_choice in ['yes', 'only']:\n",
    "            # Ensure that line_style is defined before this point or provide a default value\n",
    "            line, label, _, avg_y_values = plot_average_ms_data(ax1, var_ms_data, f'Averaged {var_name}', var_index, y_ticks, 0,\n",
    "                                                  chunk_size, avg_cmap, log_transform, line_style)\n",
    "            handles.append(line)\n",
    "            labels.append(f'{label}')\n",
    "            sample_list.append(line_style)\n",
    "            var_name_list.append(var_name)\n",
    "            ax1.tick_params(axis='y', labelsize=14)\n",
    "        # Plot indices below the MS line plot\n",
    "        ax2 = axes[1]\n",
    "        ax2.axis('off')\n",
    "        ax2.set_xlim(0, max_sequence_length)\n",
    "        indices = [0]\n",
    "        if var_index == 0:\n",
    "            # Add indices at increments of 20, starting from 20 up to the length of the array, but not including the last index if it's less than 20 away\n",
    "            indices.extend(range(20, max_sequence_length - 5, 20))\n",
    "            # Always add the last index of the array\n",
    "            indices.append(max_sequence_length - 1)\n",
    "            for idx in indices:\n",
    "                ax2.text(idx + 0.5, 0.5, str(total_count + idx + 1), ha='center', va='center', fontsize=16)\n",
    "            total_count += max_sequence_length\n",
    "\n",
    "            # Amino acid plots\n",
    "            ax3 = axes[2]\n",
    "\n",
    "            # Check if there's only one distinct protein\n",
    "            if not multiple_proteins:\n",
    "                plot_row_landscape(ax3, var_amino_acids)  # Call plot_row_landscape if only 1 protein\n",
    "            else:\n",
    "                ax3.axis('off')  # Plot a blank line by turning off the axis\n",
    "\n",
    "        if plot_heatmap == 'yes':\n",
    "            # Amino acid plots\n",
    "            ax = axes[var_index + 3]\n",
    "            plot_row_color_landscape(ax, var_amino_acids, var_colors)\n",
    "            ax.text(0, 0.5, var_name, ha='right', va='center', fontsize=14)\n",
    "    \n",
    "    # Create the legend after the plotting loop, using the handles and labels without duplicates\n",
    "    # This will create a dictionary only with entries where the label is not '0'abs\n",
    "    create_custom_legends(fig, labels, handles, var_name_list, legend_title, heatmap_legend_handles,\n",
    "                          heatmap_legend_labels, ms_average_choice, bio_or_pep, plot_type=\"land\")\n",
    "        \n",
    "\n",
    "    if bio_or_pep == '2' and ms_average_choice != 'only':\n",
    "        # Process the footnote_list which now contains deduplicated peptide info\n",
    "        if footnote_list:\n",
    "            # Create header for the detailed table\n",
    "            footnote_lines = [\n",
    "                \"For peptides with multiple bioactive functions, the label has been changed to 'Multiple'.\",\n",
    "                \"The following table shows the affected peptides and their associated functions:\",\n",
    "                \"\",\n",
    "                \"Peptide Interval/Name  Bioactive Functions:\"\n",
    "            ]\n",
    "            \n",
    "            # Sort footnote_list by peptide column for consistent ordering\n",
    "            sorted_footnotes = sorted(footnote_list, key=lambda x: x['peptide_column'])\n",
    "            \n",
    "            # Format each peptide entry (already deduplicated during collection)\n",
    "            for i, item in enumerate(sorted_footnotes, 1):\n",
    "                peptide_col = item['peptide_column']\n",
    "                functions = item['functions']\n",
    "                \n",
    "                # Parse peptide column to separate interval from Unique Peptide ID\n",
    "                if ' ' in peptide_col:\n",
    "                    interval, unique_id = peptide_col.split(' ', 1)\n",
    "                    peptide_display = f\"{interval} ({unique_id})\"\n",
    "                else:\n",
    "                    peptide_display = peptide_col\n",
    "                \n",
    "                functions_str = \", \".join(functions)  # Already sorted during collection\n",
    "                footnote_lines.append(f\"     {i}. {peptide_display}  {functions_str}\")\n",
    "            \n",
    "            # Join all lines\n",
    "            footnote = '\\n'.join(footnote_lines)\n",
    "        else:\n",
    "            footnote = \"\"\n",
    "\n",
    "\n",
    "\n",
    "    fig.text(yaxis_position, 0.90, yaxis_label, va='top', rotation='vertical', fontsize=16)\n",
    "    fig.text(0.5, -0.025, xaxis_label, ha='center', va='center', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    #plt.subplots_adjust(left=0.05)  # Create space on the left for the y-label\n",
    "\n",
    "    if ms_average_choice == 'only' and bio_or_pep == '1':\n",
    "        all_errors.append('The selection of Plot Averaged Data option \"only\" and Plot Specific Peptides option \"Peptide Intervals\" is invalid. Only the average absorbance will be plotted.')\n",
    "\n",
    "    if bio_or_pep == '2' and ms_average_choice != 'only':\n",
    "        if footnote_list and footnote:  # Only display if there's actual footnote content\n",
    "            #print(footnote)\n",
    "            display(HTML(f\"<div style='display: inline-block; margin: 10px 0; padding: 10px; background-color: #f0f8ff; border-left: 4px solid #0066cc;'><b style='color: #0066cc'>{footnote.replace(chr(10), '<br>')}</b></div>\"))\n",
    "    return fig, all_errors\n",
    "\n",
    "\"\"\"_______________________________Portrait Plot______________________________________________\"\"\"\n",
    "def visualize_sequence_heatmap_portrait(available_data_variables_dict,\n",
    "                                             amino_acid_height,\n",
    "                                             lineplot_height,\n",
    "                                             indices_height,\n",
    "                                             xaxis_label,\n",
    "                                             yaxis_label,\n",
    "                                             legend_title,\n",
    "                                             yaxis_position,\n",
    "                                             cmap,\n",
    "                                             avg_cmap,\n",
    "                                             lp_selected_color,\n",
    "                                             avglp_selected_color,\n",
    "                                             selected_functions,\n",
    "                                             ms_average_choice,\n",
    "                                             bio_or_pep,\n",
    "                                             log_transform,\n",
    "                                             y_ticks,\n",
    "                                             chunk_size):\n",
    "\n",
    "\n",
    "    lineplot_height, scale_factor = port_hm_settings.get(\n",
    "        len(available_data_variables_dict), (20, 0.1))\n",
    "    plot_zero == 'no'\n",
    "    handles, labels, sample_list, var_name_list = [], [], [], []\n",
    "\n",
    "    for var in available_data_variables_dict:\n",
    "        num_sets = len(available_data_variables_dict[var]['amino_acids_chunks'])\n",
    "    # Create legend handles for the heatmap\n",
    "    heatmap_legend_handles, heatmap_legend_labels = create_heatmap_legend_handles(cmap, num_colors, max_count,\n",
    "                                                                                  plot_zero)  # You can change the number 5 to have more or fewer color intervals\n",
    "\n",
    "    # Define height ratios for each subplot in a set\n",
    "    height_ratios = ([lineplot_height] + [indices_height] + [amino_acid_height] * len(available_data_variables_dict)) * num_sets\n",
    "\n",
    "    # Create a figure and set of subplots\n",
    "    fig = plt.figure()\n",
    "\n",
    "    fig, axes = plt.subplots(total_plots, 1, figsize=(20, num_sets * (\n",
    "            lineplot_height + indices_height + amino_acid_height * len(available_data_variables_dict)) * scale_factor),\n",
    "                             gridspec_kw={'height_ratios': height_ratios, 'hspace': 1})\n",
    "\n",
    "    # Initialize for legend handling\n",
    "    handles, labels = [], []\n",
    "    total_count = 0\n",
    "\n",
    "\n",
    "\n",
    "    # Loop through each set of data and create plots\n",
    "    for i in range(num_sets):\n",
    "\n",
    "        # Determine the max_var_amino_acids for the current i across all variables\n",
    "        max_var_amino_acids = max(\n",
    "            len(available_data_variables_dict[var]['amino_acids_chunks'][i])\n",
    "            for var in available_data_variables_dict\n",
    "        )\n",
    "\n",
    "        for var_index, var in enumerate(available_data_variables_dict):\n",
    "            ax1 = axes[axis_number * i]\n",
    "            ax1.axis('off')\n",
    "            ax2 = ax1.twinx()  # Create a twin y-axis\n",
    "\n",
    "            # Get data chunks for the current variable\n",
    "            var_amino_acids = available_data_variables_dict[var]['amino_acids_chunks'][i]\n",
    "            var_counts = available_data_variables_dict[var]['peptide_counts_chunks'][i]\n",
    "            var_ms_data = available_data_variables_dict[var]['ms_data_chunks'][i]\n",
    "            var_name = available_data_variables_dict[var]['label']\n",
    "            var_colors = get_grouped_colors(var_counts, max_count, num_colors, plot_zero, cmap)          \n",
    "            line_style = '-'\n",
    "\n",
    "            # Plot MS data using plot_average_ms_data and handle the returned line object\n",
    "            line, label, _, average_y_values = plot_average_ms_data(ax2, var_ms_data, var_name, var_index, y_ticks, i, chunk_size,\n",
    "                                                  avg_cmap, log_transform, line_style='-')\n",
    "            ax1.tick_params(axis='y', labelsize=10)\n",
    "            handles.append(line)\n",
    "            labels.append(label)\n",
    "            var_name_list.append(var_name)\n",
    "\n",
    "            # Plot indices below the MS line plot\n",
    "            ax = axes[axis_number * i + 1]\n",
    "            ax.axis('off')\n",
    "            ax.set_xlim(0, max_sequence_length)\n",
    "            indices = [0]\n",
    "            if var_index == 0:\n",
    "                # Add indices at increments of 20, starting from 20 up to the length of the array, but not including the last index if it's less than 20 away\n",
    "                indices.extend(range(20, max_var_amino_acids - 5, 20))\n",
    "                # Always add the last index of the array\n",
    "                indices.append(max_var_amino_acids - 1)\n",
    "                for idx in indices:\n",
    "                    ax.text(idx + 0.5, 0.5, str(total_count + idx + 1), ha='center', va='center', fontsize=16)\n",
    "                total_count += max_var_amino_acids\n",
    "\n",
    "            # Amino acid plots\n",
    "            ax = axes[axis_number * i + var_index + 2]\n",
    "            plot_row_color(ax, var_amino_acids, var_colors)\n",
    "            ax.text(0, 0.5, f'{var_name}  ', ha='right', va='center', fontsize=14)\n",
    "\n",
    "    # Create the legend after the plotting loop, using the handles and labels without duplicates\n",
    "    # Create legend handles for the heatmap\n",
    "    # Initialize for legend handling\n",
    "    total_count = 0\n",
    "\n",
    "    # Create the legend after the plotting loop, using the handles and labels without duplicates\n",
    "    # This will create a dictionary only with entries where the label is not '0'abs\n",
    "    create_custom_legends(fig, labels, handles, var_name_list, legend_title, heatmap_legend_handles,\n",
    "                          heatmap_legend_labels, ms_average_choice, bio_or_pep, plot_type=\"port\")\n",
    "\n",
    "    \"\"\"\n",
    "    handles_dict = dict(zip(labels, handles))\n",
    "    legend_samples = fig.legend(handles_dict.values(), handles_dict.keys(), loc='center left',\n",
    "                                bbox_to_anchor=(.905, top_legend_pos), fontsize=16, title=legend_title[0], title_fontsize=18)\n",
    "    legend_peptide_count = fig.legend(handles=heatmap_legend_handles, loc='center left',\n",
    "                                      bbox_to_anchor=(.905, bot_legend_pos), fontsize=16, title=legend_title[1], title_fontsize=18)\n",
    "    \"\"\"\n",
    "    # Adjust layout and save the figure\n",
    "    plt.tight_layout()\n",
    "    #plt.subplots_adjust(left=0.15)  # Create space on the left for the y-label\n",
    "    fig.text(yaxis_position, 0.5, yaxis_label, va='center', rotation='vertical', fontsize=16)\n",
    "    fig.text(0.5, 0.05, xaxis_label, ha='center', va='center', fontsize=16)\n",
    "\n",
    "    # Display the plot inline\n",
    "    #display(fig)\n",
    "    #plt.close(fig)  # Close the figure to avoid duplicate display in some environments\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e1c7392-437f-45c3-a4c0-b28facdf8357",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation(HasTraits):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.merged_df = pd.DataFrame()\n",
    "        self.protein_dict = {}\n",
    "        self.group_data_dict = {}\n",
    "        self.output_area = None\n",
    "        self.merged_uploader = None\n",
    "        self.fasta_uploader = None\n",
    "        self.uniprot_client = None\n",
    "        self.col_order = []\n",
    "        self.uniprot_client = UniProtClient()  # Add this line\n",
    "        self.fasta_file_uploaded_placeholder = False\n",
    "        #self.merged_df = Instance(pd.DataFrame, allow_none=True)\n",
    "        #self.group_data_dict = Instance(dict, allow_none=True)\n",
    "        \n",
    "    def create_download_link(self, file_path, label):\n",
    "        \"\"\"Create a download link for a file.\"\"\"\n",
    "        if os.path.exists(file_path):\n",
    "            # Read file content and encode it as base64\n",
    "            with open(file_path, 'rb') as f:\n",
    "                content = f.read()\n",
    "            b64_content = base64.b64encode(content).decode('utf-8')\n",
    "\n",
    "            # Generate the download link HTML\n",
    "            return widgets.HTML(f\"\"\"\n",
    "                <a download=\"{os.path.basename(file_path)}\" \n",
    "                    href=\"data:application/octet-stream;base64,{b64_content}\" \n",
    "                    style=\"color: #0366d6; text-decoration: none; margin-left: 20px; font-size: 14px;\">\n",
    "                    {label}\n",
    "                </a>\n",
    "            \"\"\")\n",
    "        else:\n",
    "            # Show an error message if the file does not exist\n",
    "            return widgets.HTML(f\"\"\"\n",
    "                <span style=\"color: red; margin-left: 20px; font-size: 14px;\">\n",
    "                    File \"{file_path}\" not found!\n",
    "                </span>\n",
    "                \"\"\")\n",
    "\n",
    "    def setup_data_loading_ui(self):\n",
    "        \"\"\"Initialize and display the data loading UI.\"\"\"\n",
    "        # Create file upload widgets\n",
    "        self.merged_uploader = widgets.FileUpload(\n",
    "            accept='.csv,.txt,.tsv,.xlsx',\n",
    "            multiple=False,\n",
    "            description='Upload Merged Data File',\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "\n",
    "        self.fasta_uploader = widgets.FileUpload(\n",
    "            accept='.fasta',\n",
    "            multiple=True,\n",
    "            disabled=True,\n",
    "            description='Upload FASTA Files',\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.uniprot_search = widgets.Checkbox(\n",
    "            value=True,\n",
    "            description='Query UniProt for missing protein information',\n",
    "            layout=widgets.Layout(width='325px'),\n",
    "            disabled=True,\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "\n",
    "        self.output_area = widgets.Output()\n",
    "\n",
    "        # Create individual upload boxes with example links\n",
    "        merged_box = widgets.HBox([\n",
    "            self.merged_uploader,\n",
    "            self.create_download_link(\"examples/example_merged_dataframe.csv\", \"Example\")\n",
    "        ], layout=widgets.Layout(align_items='center'))\n",
    "\n",
    "        fasta_box = widgets.HBox([\n",
    "            self.fasta_uploader,\n",
    "            self.create_download_link(\"examples/example_fasta.fasta\", \"Example\")\n",
    "        ], layout=widgets.Layout(align_items='center'))\n",
    "        \n",
    "        uniprot_box = widgets.VBox([\n",
    "            widgets.HTML(\"<h4><u>Option 2: Import from UniProt:</u></h4>\"),\n",
    "            self.uniprot_search\n",
    "        ])\n",
    "\n",
    "        combined_box = widgets.HBox([\n",
    "            widgets.VBox([\n",
    "            widgets.HTML(\"<h4><u>Option 1: Upload Protein FASTA Files:</u></h4>\"),\n",
    "            fasta_box]),\n",
    "            widgets.HTML(\"<div style='margin: 0 20px; line-height: 100px;'><b>OR</b></div>\"),\n",
    "            uniprot_box\n",
    "            ], layout=widgets.Layout(\n",
    "                width='850px',\n",
    "                margin='0 0 0 0px'\n",
    "            ))\n",
    "\n",
    "        # Create left column with upload widgets\n",
    "        self.upload_widgets  = widgets.VBox([\n",
    "            widgets.HTML(\"<h4><u>Upload Peptidomic Data File:</u></h4>\"),\n",
    "            merged_box,\n",
    "            combined_box,\n",
    "            self.output_area\n",
    "        ], layout=widgets.Layout(\n",
    "            width='800px',\n",
    "            margin='0 20px 0 0',\n",
    "            overflow='hidden'\n",
    "        ))\n",
    "\n",
    "        # Register observers\n",
    "        self.merged_uploader.observe(self._on_merged_upload_change, names='value')\n",
    "        self.fasta_uploader.observe(self._on_fasta_upload_change, names='value')\n",
    "        self.uniprot_search.observe(self._on_uniprot_search_change, names='value')\n",
    "\n",
    "    def _clear_error_messages(self):\n",
    "        \"\"\"Clear error messages from all associated handlers when checkbox state changes\"\"\"\n",
    "        # Clear main output area\n",
    "        if hasattr(self, 'output_area'):\n",
    "            with self.output_area:\n",
    "                clear_output()\n",
    "        \n",
    "        # Clear message output from any associated handlers\n",
    "        # This is a bit of a hack since we need to find handlers that might have error messages\n",
    "        # We look for any attributes that might be handlers with message output areas\n",
    "        for attr_name in dir(self):\n",
    "            attr = getattr(self, attr_name)\n",
    "            if hasattr(attr, 'message_output_label'):\n",
    "                try:\n",
    "                    with attr.message_output_label:\n",
    "                        attr.message_output_label.clear_output(wait=True)\n",
    "                    # Re-enable buttons that might have been disabled\n",
    "                    if hasattr(attr, 'update_label_button'):\n",
    "                        attr.update_label_button.disabled = False\n",
    "                    if hasattr(attr, 'update_order_button'):\n",
    "                        attr.update_order_button.disabled = False\n",
    "                except:\n",
    "                    pass  # Ignore errors if output areas don't exist or are not accessible\n",
    "\n",
    "    def _on_uniprot_search_change(self, change):\n",
    "        \"\"\"Handle UniProt search checkbox toggle - simplified version\"\"\"\n",
    "        \n",
    "        # Only process 'value' changes\n",
    "        if change['type'] != 'change' or change['name'] != 'value':\n",
    "            return\n",
    "        \n",
    "        # Clear any existing error messages when checkbox state changes\n",
    "        self._clear_error_messages()\n",
    "        \n",
    "        if change['new']:  # When checkbox is checked\n",
    "            # Initialize UniProt client if needed\n",
    "            if self.uniprot_client is None:\n",
    "                try:\n",
    "                    self.uniprot_client = UniProtClient()\n",
    "                    with self.output_area:\n",
    "                        clear_output()\n",
    "                        display(HTML('<b style=\"color:green;\">UniProt client initialized successfully.</b>'))\n",
    "                except ImportError as e:\n",
    "                    with self.output_area:\n",
    "                        clear_output()\n",
    "                        display(HTML(f'<b style=\"color:red;\">Error importing UniProt client: {str(e)}</b>'))\n",
    "                    self.uniprot_search.value = False\n",
    "                    return\n",
    "            \n",
    "            # Only fetch if we have merged data and missing proteins\n",
    "            if (hasattr(self, 'merged_df') and self.merged_df is not None and \n",
    "                not self.merged_df.empty and 'Protein' in self.merged_df.columns):\n",
    "                \n",
    "                unique_protein_ids = set(self.merged_df['Protein'].dropna().unique())\n",
    "                missing_proteins = unique_protein_ids - set(self.protein_dict.keys())\n",
    "                \n",
    "                if missing_proteins:\n",
    "                    with self.output_area:\n",
    "                        clear_output()\n",
    "                        success_count = 0\n",
    "                        for protein_id in missing_proteins:\n",
    "                            try:\n",
    "                                name, species, sequence = self.uniprot_client.fetch_protein_info_with_sequence(protein_id)\n",
    "                                if sequence:\n",
    "                                    self.protein_dict[protein_id] = {\n",
    "                                        \"name\": name if name else protein_id,\n",
    "                                        \"sequence\": sequence,\n",
    "                                        \"species\": species if species else \"Unknown\"\n",
    "                                    }\n",
    "                                    success_count += 1\n",
    "                                    display(HTML(f'<span style=\"color:green;\"> {protein_id}: {name or \"Unknown\"} ({species or \"Unknown\"})</span>'))\n",
    "                                else:\n",
    "                                    display(HTML(f'<span style=\"color:orange;\"> No sequence found for {protein_id}</span>'))\n",
    "                            except Exception as e:\n",
    "                                display(HTML(f'<span style=\"color:orange;\"> Error fetching {protein_id}: {str(e)}</span>'))\n",
    "                        \n",
    "                        if success_count > 0:\n",
    "                            display(HTML(f'<b style=\"color:green;\">Successfully fetched {success_count} out of {len(missing_proteins)} missing proteins.</b>'))\n",
    "\n",
    "    def check_missing_proteins_in_merged_data(self):\n",
    "        \"\"\"Check for proteins in merged data that are missing from protein_dict and prompt to fetch from UniProt\"\"\"\n",
    "        if not hasattr(self, 'merged_df') or self.merged_df is None or self.merged_df.empty:\n",
    "            return\n",
    "            \n",
    "        if 'Protein' not in self.merged_df.columns:\n",
    "            return\n",
    "            \n",
    "        # Get unique protein IDs from merged data\n",
    "        unique_protein_ids = set(self.merged_df['Protein'].dropna().unique())\n",
    "        \n",
    "        # Find missing proteins\n",
    "        missing_proteins = unique_protein_ids - set(self.protein_dict.keys())\n",
    "        \n",
    "        if not missing_proteins:\n",
    "            return\n",
    "            \n",
    "        # Initialize UniProt client if needed\n",
    "        if self.uniprot_search.value and self.uniprot_client is None:\n",
    "            try:\n",
    "                self.uniprot_client = UniProtClient()\n",
    "            except ImportError:\n",
    "                with self.output_area:\n",
    "                    display(HTML('<b style=\"color:red;\">Error initializing UniProt client.</b>'))\n",
    "                return\n",
    "                \n",
    "        if self.uniprot_search.value and self.uniprot_client:\n",
    "            with self.output_area:\n",
    "                display(HTML(f'<b>Found {len(missing_proteins)} proteins missing sequence information.</b><br>' +\n",
    "                            f'<b>Attempting to fetch from UniProt...</b>'))\n",
    "                \n",
    "                success_count = 0\n",
    "                for protein_id in missing_proteins:\n",
    "                    try:\n",
    "                        name, species, sequence = self.uniprot_client.fetch_protein_info_with_sequence(protein_id)\n",
    "                        \n",
    "                        if sequence:\n",
    "                            self.protein_dict[protein_id] = {\n",
    "                                \"name\": name if name else protein_id,\n",
    "                                \"sequence\": sequence,\n",
    "                                \"species\": species if species else \"Unknown\"\n",
    "                            }\n",
    "                            success_count += 1\n",
    "                        else:\n",
    "                            display(HTML(f'<span style=\"color:orange;\">No sequence found for {protein_id}</span>'))\n",
    "                    except Exception as e:\n",
    "                        display(HTML(f'<span style=\"color:orange;\">Error fetching {protein_id}: {str(e)}</span>'))\n",
    "                        \n",
    "                display(HTML(f'<b style=\"color:green;\">Successfully fetched {success_count} out of {len(missing_proteins)} missing proteins.</b>'))\n",
    "        else:\n",
    "            with self.output_area:\n",
    "                missing_list = \", \".join(list(missing_proteins)[:10])\n",
    "                if len(missing_proteins) > 10:\n",
    "                    missing_list += f\" and {len(missing_proteins) - 10} more\"\n",
    "                    \n",
    "                display(HTML(\n",
    "                    f'<b style=\"color:orange;\">Warning: {len(missing_proteins)} proteins in your data are missing sequences.</b><br>' +\n",
    "                    f'Missing proteins: {missing_list}<br>' +\n",
    "                    f'<b>To automatically fetch these proteins, check \"Query UniProt for missing protein information\" above.</b>'\n",
    "                ))         \n",
    "        \n",
    "    def _on_merged_upload_change(self, change):\n",
    "        \"\"\"Simplified merged file upload handler\"\"\"\n",
    "        \n",
    "        if change['type'] != 'change' or change['name'] != 'value':\n",
    "            return\n",
    "        \n",
    "        with self.output_area:\n",
    "            self.output_area.clear_output()\n",
    "            if change['new'] and len(change['new']) > 0:\n",
    "                file_data = change['new'][0]\n",
    "                \n",
    "                # Check if this is the same file\n",
    "                current_file_name = getattr(self, 'current_merged_file_name', None)\n",
    "                new_file_name = getattr(file_data, 'name', None)\n",
    "                \n",
    "                if current_file_name == new_file_name:\n",
    "                    display(HTML(f'<b style=\"color:blue;\">File \"{new_file_name}\" is already loaded.</b>'))\n",
    "                    return\n",
    "                \n",
    "                self.current_merged_file_name = new_file_name\n",
    "                \n",
    "                self.merged_df, merged_status = self._load_data(\n",
    "                    file_data,\n",
    "                    required_columns=['Protein'],\n",
    "                    file_type='Merged'\n",
    "                )\n",
    "\n",
    "                # Only process protein info if data loading was successful\n",
    "                if merged_status == 'yes' and self.merged_df is not None:\n",
    "                    self.process_protein_info(self.merged_df)\n",
    "                elif merged_status == 'no':\n",
    "                    display(HTML('<b style=\"color:red;\">Data processing stopped due to validation errors. Please fix the data issues and try again.</b>'))\n",
    "                    return\n",
    "\n",
    "                if merged_status == 'yes' and self.merged_df is not None:\n",
    "                    avg_columns = [col for col in self.merged_df.columns if col.startswith('Avg_')]\n",
    "                    self.col_order = [col.replace('Avg_', '') for col in avg_columns]\n",
    "\n",
    "                    if avg_columns:\n",
    "                        self.group_data_dict = {}\n",
    "                        for i, col in enumerate(avg_columns, 1):\n",
    "                            group_name = col[4:]\n",
    "                            self.group_data_dict[str(i)] = {\n",
    "                                \"grouping_variable\": group_name,\n",
    "                                \"abundance_columns\": [col]\n",
    "                            }\n",
    "                        \n",
    "                        # Only check for missing proteins if not already handled\n",
    "                        self.check_missing_proteins_in_merged_data()\n",
    "                    else:\n",
    "                        # Handle case where no Avg_ columns exist\n",
    "                        numerical_cols = list(self.merged_df.select_dtypes(include=['number']).columns)\n",
    "                        if numerical_cols:\n",
    "                            # Show column selector (your existing code)\n",
    "                            pass\n",
    "            \n",
    "            # Enable other widgets now that we have merged data\n",
    "            self.check_missing_proteins_in_merged_data()\n",
    "            self.fasta_uploader.disabled = False\n",
    "            self.uniprot_search.disabled = False\n",
    "\n",
    "    def _on_fasta_upload_change(self, change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            with self.output_area:\n",
    "                self.output_area.clear_output()\n",
    "                if change['new'] and len(change['new']) > 0:\n",
    "                    for file_data in change['new']:\n",
    "                        try:\n",
    "                            if file_data.name.endswith('.fasta'):\n",
    "                                self.fasta_filename = file_data.name\n",
    "\n",
    "                                # Validate FASTA format before parsing\n",
    "                                if not self._validate_fasta_format(file_data):\n",
    "                                    display(HTML(f\"<b style='color:red'>Error: Invalid FASTA format in {file_data.name}</b>\"))\n",
    "                                    self.fasta_file_uploaded_placeholder = False\n",
    "\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    display(HTML(f'<b style=\"color:green;\">Successfully imported {file_data.name}</b>'))\n",
    "                                    self.fasta_file_uploaded_placeholder = True\n",
    "\n",
    "                                new_proteins = self._parse_uploaded_fasta(file_data)\n",
    "\n",
    "                                if self.merged_df is not None:\n",
    "                                    protein_ids = set(self.merged_df['Protein'].dropna().unique())\n",
    "                                    match_count = 0\n",
    "\n",
    "                                    for protein_id, protein_data in new_proteins.items():\n",
    "                                        if protein_id in protein_ids:\n",
    "                                            self.protein_dict[protein_id] = protein_data\n",
    "                                            match_count += 1\n",
    "\n",
    "                                    display(HTML(\n",
    "                                        f'<b style=\"color:green;\">Successfully imported FASTA file: {self.fasta_filename} '\n",
    "                                        f'({len(new_proteins)} proteins, {match_count} matched to dataset)</b>'\n",
    "                                    ))\n",
    "\n",
    "                                else:\n",
    "                                    self.protein_dict.update(new_proteins)\n",
    "                                    display(HTML(f'<b style=\"color:green;\">Successfully imported Entire FASTA file: {self.fasta_filename} ({len(new_proteins)} proteins)</b>'))\n",
    "                            else:\n",
    "                                display(HTML(f'<b style=\"color:red;\">Invalid file format. Please upload FASTA files only.</b>'))\n",
    "                            self.uniprot_search.value = False\n",
    "                        except Exception as e:\n",
    "                            display(HTML(f'<b style=\"color:red;\">Error processing FASTA file: {str(e)}</b>'))\n",
    "\n",
    "    def _validate_fasta_format(self, file_data):\n",
    "        \"\"\"\n",
    "        Validate that the uploaded file follows proper FASTA format.\n",
    "        Returns True if valid, False otherwise.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Read file content\n",
    "            content = file_data.content.tobytes().decode('utf-8')\n",
    "            lines = content.strip().split('\\n')\n",
    "            \n",
    "            if not lines:\n",
    "                return False\n",
    "\n",
    "            # Check that at least one line starts with '>'\n",
    "            if not any(line.strip().startswith('>') for line in lines):\n",
    "                display(HTML(\"<b style='color:red'>Improper FASTA header: At least one line must start with '>'</b>\"))\n",
    "                return False\n",
    "            \n",
    "            # Check basic FASTA format requirements\n",
    "            has_header = False\n",
    "            has_sequence = False\n",
    "            current_sequence_length = 0\n",
    "            \n",
    "            for i, line in enumerate(lines):\n",
    "                line = line.strip()\n",
    "                \n",
    "                # Skip empty lines\n",
    "                if not line:\n",
    "                    continue\n",
    "                    \n",
    "                if line.startswith('>'):\n",
    "                    # This is a header line\n",
    "                    if len(line) <= 1:  # Header with no identifier\n",
    "                        return False\n",
    "                    has_header = True\n",
    "                    \n",
    "                    # If we were reading a sequence, check it had content\n",
    "                    if i > 0 and current_sequence_length == 0:\n",
    "                        return False\n",
    "                    current_sequence_length = 0\n",
    "                    \n",
    "                else:\n",
    "                    # This should be sequence data\n",
    "                    if not has_header:  # Sequence without preceding header\n",
    "                        return False\n",
    "                    \n",
    "                    # Check for valid sequence characters (amino acids or nucleotides)\n",
    "                    valid_chars = set('ACDEFGHIKLMNPQRSTVWYXBZJOU*-')  # Extended amino acid alphabet\n",
    "                    if not all(c.upper() in valid_chars for c in line):\n",
    "                        # If not amino acids, check if it could be nucleotides\n",
    "                        nucleotide_chars = set('ATCGRYSWKMBDHVN-')\n",
    "                        if not all(c.upper() in nucleotide_chars for c in line):\n",
    "                            return False\n",
    "                    \n",
    "                    has_sequence = True\n",
    "                    current_sequence_length += len(line)\n",
    "            \n",
    "            # Must have at least one header and one sequence\n",
    "            return has_header and has_sequence\n",
    "            \n",
    "        except Exception as e:\n",
    "            display(HTML(f\"<b style='color:red'>Validation error: {str(e)}</b>\"))\n",
    "            return False\n",
    "\n",
    "    def validate_and_standardize_columns(self, df: pd.DataFrame):\n",
    "        SOFTWARE_START_STOP_COLUMNS = {\n",
    "            #'Positions in Proteins': ('start', 'stop'),\n",
    "            'Start position': 'start',\n",
    "            'End position': 'stop',\n",
    "            'Peptide Start': 'start',\n",
    "            'Peptide End': 'stop',\n",
    "            'StartPosition': 'start',\n",
    "            'EndPosition': 'stop',            \n",
    "            'Peptide start': 'start',\n",
    "            'Peptide end': 'stop',\n",
    "            'Startposition': 'start',\n",
    "            'Endposition': 'stop',\n",
    "            'Peptide Start Position': 'start',\n",
    "            'Peptide End Position': 'stop',\n",
    "            'Peptide start position': 'start',\n",
    "            'Peptide end position': 'stop',\n",
    "        }\n",
    "\n",
    "        SOFTWARE_PROTEIN_ID_COLUMNS = [\n",
    "            'Protein', 'Leading proteins', 'Protein Name',\n",
    "            'Protein Accession', 'Accession Number', 'ProteinGroupId',\n",
    "            'Protein ID', 'Accession', 'protein_accession', 'Protein'\n",
    "        ]\n",
    "\n",
    "        # Rename start/stop columns\n",
    "        for col in df.columns:\n",
    "            if col in SOFTWARE_START_STOP_COLUMNS:\n",
    "                mapping = SOFTWARE_START_STOP_COLUMNS[col]\n",
    "                if isinstance(mapping, tuple):\n",
    "                    start_col, stop_col = col, col\n",
    "                else:\n",
    "                    if SOFTWARE_START_STOP_COLUMNS[col] == 'start':\n",
    "                        df.rename(columns={col: 'start'}, inplace=True)\n",
    "                    elif SOFTWARE_START_STOP_COLUMNS[col] == 'stop':\n",
    "                        df.rename(columns={col: 'stop'}, inplace=True)\n",
    "\n",
    "        # Validate start/stop columns\n",
    "        if 'start' not in df.columns or 'stop' not in df.columns:\n",
    "            raise ValueError(\"Missing required columns 'start' or 'stop'.\")\n",
    "\n",
    "        # Rename Protein ID column\n",
    "        for col in SOFTWARE_PROTEIN_ID_COLUMNS:\n",
    "            if col in df.columns:\n",
    "                df.rename(columns={col: 'Protein'}, inplace=True)\n",
    "                break\n",
    "\n",
    "        if 'Protein' not in df.columns:\n",
    "            raise ValueError(\"Missing required column 'Protein'.\")\n",
    "\n",
    "\n",
    "        multi_id_rows = df[df['Protein'].str.contains(';', na=False)]\n",
    "        \n",
    "        if not multi_id_rows.empty:\n",
    "            display(HTML('<b style=\"color:red;\">Rows with multiple protein IDs detected:</b>'))\n",
    "            display(multi_id_rows)\n",
    "            raise ValueError(\n",
    "                \"Multiple protein IDs detected for one or more peptides; either exclude these rows or use another strategy to handle them.\"\n",
    "            )\n",
    "        # Extract UniProt ID from FASTA header\n",
    "        df['Protein'] = df['Protein'].apply(\n",
    "            lambda x: re.search(r'\\|([A-Z0-9]+)\\|', x).group(1) if '|' in x else x\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _load_data(self, file_obj, required_columns, file_type):\n",
    "        try:\n",
    "            content = file_obj.content\n",
    "            self.pd_filename = file_obj.name\n",
    "            extension = self.pd_filename.split('.')[-1].lower()\n",
    "            file_stream = io.BytesIO(content)\n",
    "\n",
    "            if extension == 'csv':\n",
    "                df = pd.read_csv(file_stream)\n",
    "            elif extension in ['txt', 'tsv']:\n",
    "                df = pd.read_csv(file_stream, delimiter='\\t')\n",
    "            elif extension == 'xlsx':\n",
    "                df = pd.read_excel(file_stream)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported file format.\")\n",
    "\n",
    "            df.columns = df.columns.str.strip()\n",
    "\n",
    "            # Standardize columns\n",
    "            try:\n",
    "                df = self.validate_and_standardize_columns(df)\n",
    "            except ValueError as e:\n",
    "                display(HTML(f'<b style=\"color:red;\">{file_type} File Error: {e}</b>'))\n",
    "                return None, 'no'\n",
    "\n",
    "            # Check again for required columns\n",
    "            if not set(required_columns).issubset(df.columns):\n",
    "                missing = set(required_columns) - set(df.columns)\n",
    "                display(HTML(\n",
    "                    f'<b style=\"color:red;\">{file_type} File Error: Missing required columns after standardization: {\", \".join(missing)}</b>'\n",
    "                ))\n",
    "                return None, 'no'\n",
    "\n",
    "            return df, 'yes'\n",
    "        except Exception as e:\n",
    "            display(HTML(f'<b style=\"color:red;\">{file_type} File Error: {str(e)}</b>'))\n",
    "            return None, 'no'\n",
    "    \n",
    "    def process_protein_info(self, df):\n",
    "        # Check if df is None (data loading failed)\n",
    "        if df is None:\n",
    "            display(HTML('<b style=\"color:red;\">Error: Cannot process protein info - data loading failed. Please check your data format and fix any errors before proceeding.</b>'))\n",
    "            return 0\n",
    "            \n",
    "        # Check if we need to fetch any data from UniProt\n",
    "        has_protein_info = all(col in df.columns for col in ['protein_name', 'protein_species'])\n",
    "        if has_protein_info:\n",
    "            # Check if we have valid data for all entries\n",
    "            all_data_present = (\n",
    "                df['protein_name'].notna().all() and \n",
    "                df['protein_species'].notna().all() and\n",
    "                (df['protein_name'] != '').all() and\n",
    "                (df['protein_species'] != '').all()\n",
    "            )\n",
    "            if all_data_present:\n",
    "                # If we have all data, just process it silently\n",
    "                protein_info = df.groupby('Protein').agg({\n",
    "                    'protein_name': 'first',\n",
    "                    'protein_species': 'first'\n",
    "                }).reset_index()\n",
    "                \n",
    "                for _, row in protein_info.iterrows():\n",
    "                    protein_id = row['Protein']\n",
    "                    self.protein_dict[protein_id] = {\n",
    "                        \"name\": row['protein_name'],\n",
    "                        \"species\": row['protein_species'],\n",
    "                        \"sequence\":''\n",
    "                    }\n",
    "                return len(self.protein_dict)\n",
    "\n",
    "    def _find_species(self, header):\n",
    "        \"\"\"Find species in FASTA header\"\"\"\n",
    "\n",
    "        header_lower = header.lower()\n",
    "        for spec_group in spec_translate_list:\n",
    "            for term in spec_group[1:]:\n",
    "                if term.lower() in header_lower:\n",
    "                    return spec_group[0]\n",
    "        return \"unknown\"\n",
    "\n",
    "    def _parse_uploaded_fasta(self, file_data):\n",
    "        \"\"\"Parse uploaded FASTA file content\"\"\"\n",
    "        fasta_dict = {}\n",
    "        fasta_text = bytes(file_data.content).decode('utf-8')\n",
    "        lines = fasta_text.split('\\n')\n",
    "        \n",
    "        protein_id = \"\"\n",
    "        protein_name = \"\"\n",
    "        sequence = \"\"\n",
    "        species = \"\"\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                if protein_id:\n",
    "                    fasta_dict[protein_id] = {\n",
    "                        \"name\": protein_name,\n",
    "                        \"sequence\": sequence,\n",
    "                        \"species\": species\n",
    "                    }\n",
    "                sequence = \"\"\n",
    "                header_parts = line[1:].split('|')\n",
    "                if len(header_parts) > 2:\n",
    "                    protein_id = header_parts[1]\n",
    "                    protein_name_full = re.split(r' OS=', header_parts[2])[0]\n",
    "                    protein_name = protein_name_full if ' ' in protein_name_full else protein_name_full\n",
    "                    species = self._find_species(line)\n",
    "            else:\n",
    "                sequence += line\n",
    "                \n",
    "        if protein_id:\n",
    "            fasta_dict[protein_id] = {\n",
    "                \"name\": protein_name,\n",
    "                \"sequence\": sequence,\n",
    "                \"species\": species\n",
    "            }\n",
    "        \n",
    "        return fasta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "698a284c-c8be-4fe1-a8e5-d81a31d243d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeatmapDataHandler():\n",
    "    def __init__(self, data_transformer):    \n",
    "        # Add filter_type to the existing initialization\n",
    "        self.data_transformer = data_transformer\n",
    "        self.filter_type = 'all-peptides'  # Set default value\n",
    "        self.protein_name_short = ''\n",
    "        # Initialize UI widgets\n",
    "        self.protein_selector = widgets.SelectMultiple(description='Protein:')\n",
    "        self.var_key_dropdown = widgets.SelectMultiple(description='Variable Key:')\n",
    "        self.button_box = HBox([widgets.Button(description='Submit')])\n",
    "        \n",
    "        # Initialize data structures\n",
    "        self.available_data_variables_dict = {}\n",
    "        self.label_widgets = {}\n",
    "        self.data_variables = {}\n",
    "        \n",
    "        # Extract protein information\n",
    "        self.protein_mapping = {\n",
    "            key.split('_')[0]: value['protein_name']\n",
    "            for key, value in self.data_variables.items()\n",
    "        } if self.data_variables else {}\n",
    "        \n",
    "        self.available_proteins = set([key.split('_')[0] for key in self.data_variables.keys()]) if self.data_variables else set()\n",
    "        \n",
    "        # Get available grouping variables from data transformer\n",
    "        if self.data_transformer.group_data_dict:\n",
    "            self.available_grouping_vars = [group['grouping_variable'] for group in self.data_transformer.group_data_dict.values()]\n",
    "        else:\n",
    "            self.available_grouping_vars = []\n",
    "            \n",
    "        self.selected_var_keys_list = set()\n",
    "        if self.data_transformer.col_order:\n",
    "            self.col_order = self.data_transformer.col_order\n",
    "            \n",
    "        # Initialize filtered variables\n",
    "        self.filtered_data_variables = {}\n",
    "        self.available_data_variables_dict = {}\n",
    "        self.label_widgets = {}\n",
    "        self.order_widgets = {}\n",
    "        self.default_label_values = {}\n",
    "        self.default_order_values = {}\n",
    "\n",
    "        # Create widgets\n",
    "        self.create_widgets()\n",
    "        \n",
    "        # Initialize variables for plotting (just the defaults, actual widgets created by PlotHandler)\n",
    "        self.bio_or_pep = None  # Default: None\n",
    "        self.ms_average_choice = 'yes'  # Default: Plot averaged data\n",
    "        self.filter_type = 'all-peptides'  # Default: Show all peptides\n",
    "        self.selected_peptides = []\n",
    "        self.selected_functions = []\n",
    "       \n",
    "        self.initialize_empty_label_order_widgets()\n",
    "    \n",
    "    def _notify_data_change(self):\n",
    "        \"\"\"Notify plot handler when available_data_variables_dict changes\"\"\"\n",
    "        if hasattr(self, '_on_data_changed_callback') and self._on_data_changed_callback:\n",
    "            try:\n",
    "                self._on_data_changed_callback()\n",
    "            except Exception as e:\n",
    "                # Silently handle callback errors\n",
    "                # print(f\"Data change callback error: {e}\")  # Uncomment for debugging\n",
    "                pass\n",
    "\n",
    "    def add_group_with_notification(self):\n",
    "        \"\"\"Enhanced add_group that notifies observers of data changes\"\"\"\n",
    "        # Call the original add_group logic\n",
    "        self.add_group()\n",
    "        # Notify observers that data has changed\n",
    "        self._notify_data_change()\n",
    "\n",
    "    def initialize_empty_label_order_widgets(self):\n",
    "        \"\"\"Create and display the label/order widgets\"\"\"\n",
    "        # Create buttons if they don't already exist\n",
    "        if not hasattr(self, 'update_label_button'):\n",
    "            self.update_label_button = widgets.Button(\n",
    "                description=\"Update Labels\",\n",
    "                button_style='success',\n",
    "                disabled = True,\n",
    "                layout=widgets.Layout(width='125px', height='30px', min_height='30px')\n",
    "            )\n",
    "            self.update_order_button = widgets.Button(\n",
    "                description=\"Update Order\",\n",
    "                button_style='success',\n",
    "                disabled= True,\n",
    "                layout=widgets.Layout(width='125px', height='30px')\n",
    "            )\n",
    "\n",
    "\n",
    "            # Attach click event handlers\n",
    "            self.update_label_button.on_click(self.on_update_label_click)\n",
    "            self.update_order_button.on_click(self.on_update_order_click)\n",
    "\n",
    "            # Display buttons\n",
    "            self.label_order_button_box = widgets.HBox([self.update_order_button], \n",
    "                                      layout=widgets.Layout(width='500px', justify_content='flex-start'))\n",
    "           \n",
    "            \n",
    "        # Create container for label widgets if it doesn't exist\n",
    "        if not hasattr(self, 'label_widgets_container'):\n",
    "            self.label_widgets_container = widgets.VBox([\n",
    "                widgets.HTML(\"<p>Labels will appear here when protein and variable selection is made.</p>\")\n",
    "            ], layout=widgets.Layout( width='620px',\n",
    "                                      height='340px',\n",
    "                                      overflow='hidden',\n",
    "                                      margin='0px'  # Remove any margins\n",
    "                                      ))\n",
    "        \n",
    "        # Create text area for order input if it doesn't exist\n",
    "        if not hasattr(self, 'new_order_input'):\n",
    "            self.new_order_input = widgets.Textarea(\n",
    "                value=\"\",\n",
    "                placeholder=\"Sample labels will appear here protein and variable selection is made.\",\n",
    "                disabled=True,\n",
    "                layout=widgets.Layout(width='90%', height='75px')\n",
    "            )\n",
    "        \n",
    "        # Create message output area if it doesn't exist\n",
    "        if not hasattr(self, 'message_output_order'):\n",
    "            self.message_output_order = widgets.Output()\n",
    "        if not hasattr(self, 'message_output_label'):\n",
    "            self.message_output_label = widgets.Output()\n",
    "        \n",
    "        # Create the complete layout\n",
    "        self.update_order_initial_layout = widgets.VBox([\n",
    "\n",
    "            widgets.HTML(\"<u>Re-order Samples (optional):</u>\"),\n",
    "            self.new_order_input,\n",
    "            self.label_order_button_box,\n",
    "            self.message_output_order\n",
    "        ],layout=widgets.Layout(width='800px'))\n",
    "\n",
    "    def update_label_order_widgets(self):\n",
    "        \"\"\"Update existing label/order widgets with current data in a grid layout\"\"\"\n",
    "        # Only proceed if we have data\n",
    "        if not hasattr(self, 'available_data_variables_dict') or not self.available_data_variables_dict:\n",
    "            return\n",
    "        \n",
    "        # Initialize label_widgets dictionary if it doesn't exist\n",
    "        if not hasattr(self, 'label_widgets'):\n",
    "            self.label_widgets = {}\n",
    "        \n",
    "        # Create new list of widget rows\n",
    "        widgets_list = []\n",
    "        \n",
    "        # Populate rows - each available_data_variables_dict becomes a row\n",
    "        for i, (var, info) in enumerate(self.available_data_variables_dict.items(), 1):\n",
    "            # Create editable text field with current label\n",
    "            label_text_widget = widgets.Text(\n",
    "                value=info['label'],\n",
    "                layout=widgets.Layout(width='150px')\n",
    "            )\n",
    "            \n",
    "            # Store the text widget in label_widgets dictionary\n",
    "            self.label_widgets[var] = label_text_widget\n",
    "            \n",
    "            # Create row with HTML text for all except the input field\n",
    "            # Set fixed widths and use ellipsis for overflow\n",
    "            row_widgets = [\n",
    "                # Number - smaller width\n",
    "                widgets.HTML(f\"<div style='width:20px; padding:2px;'>{i})</div>\"),\n",
    "                \n",
    "                # Label - use ellipsis for overflow\n",
    "                widgets.HTML(f\"<div style='width:90px; padding:2px; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;' title='{info['label']}'>{info['label']}</div>\"),\n",
    "                \n",
    "                # Protein Species - use ellipsis for overflow\n",
    "                widgets.HTML(f\"<div style='width:90px; padding:2px; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;' title='{info.get('protein_species', '')}'>{info.get('protein_species', '')}</div>\"),\n",
    "                \n",
    "                # Protein Name - use ellipsis for overflow\n",
    "                widgets.HTML(f\"<div style='width:200px; padding:2px; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;' title='{info.get('protein_name', '')}'>{info.get('protein_name', '')}</div>\"),\n",
    "                \n",
    "                # Editable text field\n",
    "                label_text_widget\n",
    "            ]\n",
    "            \n",
    "            # Create row with horizontal box - no horizontal overflow\n",
    "            row = widgets.HBox(\n",
    "                children=row_widgets, \n",
    "                layout=widgets.Layout(\n",
    "                    width='600px',\n",
    "                    margin='2px 0',\n",
    "                    overflow='hidden',\n",
    "                    min_height='30px'\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            widgets_list.append(row)\n",
    "        \n",
    "        # Create a VBox with the list of rows - explicitly pass children\n",
    "        label_container = widgets.VBox(\n",
    "            children=widgets_list,\n",
    "            layout=widgets.Layout(\n",
    "                width='610px',  # Slightly wider than rows to prevent horizontal scroll\n",
    "                height='340px',\n",
    "                padding='0px',\n",
    "                overflow='auto'  # Standard overflow property - will scroll vertically when needed\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Update the container - this avoids the previous potential TraitError\n",
    "        self.label_widgets_container.children = (label_container,)\n",
    "\n",
    "        # Update order input with current labels\n",
    "        label_list = [info['label'] for info in self.available_data_variables_dict.values()]\n",
    "        self.new_order_input.value = ', '.join(label_list)\n",
    "  \n",
    "    def create_filtered_data_variables(self):\n",
    "        return {key: self.data_variables[key] \n",
    "                for key in self.selected_var_keys_list\n",
    "                if key in self.data_variables}\n",
    "         \n",
    "    def update_protein_info(self, protein_name):\n",
    "        self.protein_name_short = protein_name\n",
    "        # Update plot handler if it exists\n",
    "        if hasattr(self, 'plot_handler'):\n",
    "            self.plot_handler.update_protein_name(protein_name)\n",
    "  \n",
    "    def process_export(self):       \n",
    "        # Dictionary to hold all data for saving\n",
    "        self.complete_data = {}\n",
    "\n",
    "        # Get unique proteins from selected_var_keys_list\n",
    "        selected_proteins = set()\n",
    "        for key in self.selected_var_keys_list:\n",
    "            # Handle the case where key might be a tuple or a string\n",
    "            if isinstance(key, tuple):\n",
    "                # If it's a tuple, extract the first element and then split\n",
    "                for item in key:\n",
    "                    protein_id = item.split('_')[0] if '_' in item else item\n",
    "                    selected_proteins.add(protein_id)\n",
    "            else:\n",
    "                # If it's a string, process as before\n",
    "                protein_id = key.split('_')[0] if '_' in key else key\n",
    "                selected_proteins.add(protein_id)\n",
    "        # Process each selected protein\n",
    "        for protein_id in selected_proteins:\n",
    "            protein_df = data_transformer.merged_df[data_transformer.merged_df['Protein'] == protein_id]\n",
    "            is_all_null = 'function' in protein_df.columns and protein_df['function'].isna().all()\n",
    "\n",
    "\n",
    "            if protein_id in data_transformer.protein_dict:\n",
    "                species ='unknown'\n",
    "                name = protein_id\n",
    "                # Check if we need to fetch sequence from UniProt\n",
    "                if 'sequence' not in data_transformer.protein_dict[protein_id] or not data_transformer.protein_dict[protein_id]['sequence']:\n",
    "                    # Check if UniProt search is enabled\n",
    "                    uniprot_search_widget = getattr(data_transformer, 'uniprot_search', None)\n",
    "                    if not uniprot_search_widget or not uniprot_search_widget.value:\n",
    "                        with self.message_output_label:\n",
    "                            self.message_output_label.clear_output(wait=True)\n",
    "                            display(HTML(f\"<b style='color:orange;'>Sequence for {protein_id} not found in local data.</b>\"))\n",
    "                            display(HTML(f\"<b style='color:orange;'>UniProt search is disabled. Please provide a FASTA file containing {protein_id}'s sequence to continue visualization or enable UniProt search.</b>\"))\n",
    "                        self.update_label_button.disabled = True\n",
    "                        self.update_order_button.disabled = True\n",
    "                        return\n",
    "                    try:\n",
    "                        # Initialize UniProt client if not already available\n",
    "                        if not hasattr(data_transformer, 'uniprot_client'):\n",
    "                            data_transformer.uniprot_client = UniProtClient()\n",
    "                        \n",
    "                        # Fetch the protein info with sequence\n",
    "                        name, species, sequence = data_transformer.uniprot_client.fetch_protein_info_with_sequence(protein_id)\n",
    "                        # Update the protein_dict with the sequence\n",
    "                        if sequence:\n",
    "                            data_transformer.protein_dict[protein_id]['sequence'] = sequence\n",
    "                            \n",
    "                            with self.message_output_label:\n",
    "                                self.message_output_label.clear_output(wait=True)\n",
    "                                display(HTML(f\"<b style='color:green;'>Sequence for {protein_id} fetched from UniProt with a legnth of {len(data_transformer.protein_dict[protein_id]['sequence'])} AAs.</b>\"))\n",
    "                                display(HTML(\"<p><strong>Update Labels Tip:</strong> To remove selected sample(s), type <code>remove</code> in the update label field and click \\\"Update Labels\\\".</p>\")) if len(selected_proteins) > 1 and len(selected_proteins) != len(self.available_data_variables_dict) else None\n",
    "\n",
    "                                self.update_label_button.disabled = False \n",
    "                                self.update_order_button.disabled = False\n",
    "                        else:\n",
    "                            with self.message_output_label:\n",
    "                                self.message_output_label.clear_output(wait=True)\n",
    "                                display(HTML(f\"<b style='color:orange;'>Sequence for {protein_id} not found in UniProt.</b>\"))\n",
    "                                display(HTML(f\"<b style='color:orange;'>Please provide a FASTA file containing {protein_id}'s sequence to continue visualization or select a different protein.</b>\"))\n",
    "                            self.update_label_button.disabled = True\n",
    "                            self.update_order_button.disabled = True\n",
    "                            return\n",
    "                    except Exception as e:\n",
    "                        with self.message_output_label:\n",
    "                            self.message_output_label.clear_output(wait=True)\n",
    "                            display(HTML(f\"<b style='color:red;'>Error fetching sequence for {protein_id}: {str(e)}</b>\"))\n",
    "                else:\n",
    "                    with self.message_output_label:\n",
    "                        self.message_output_label.clear_output(wait=True)\n",
    "                        display(HTML(f\"<b style='color:green;'>Sequence for {protein_id} retrived from protein dictionary with a legnth of {len(data_transformer.protein_dict[protein_id]['sequence'])} AAs.</b>\")); \n",
    "                        display(HTML(\"<p><strong>Update Labels Tip:</strong> To remove selected sample(s), type <code>remove</code> in the update label field and click \\\"Update Labels\\\".</p>\")) if len(selected_proteins) > 1 and len(selected_proteins) != len(self.available_data_variables_dict) else None\n",
    "                    self.update_label_button.disabled = False\n",
    "                    self.update_order_button.disabled = False\n",
    "\n",
    "                # Get protein data - now with sequence if available\n",
    "                protein_sequence = data_transformer.protein_dict[protein_id].get('sequence', '')\n",
    "                protein_species = data_transformer.protein_dict[protein_id].get('species', species)\n",
    "                protein_name = data_transformer.protein_dict[protein_id].get('name', name)\n",
    "\n",
    "                protein_data = {}\n",
    "\n",
    "                # Process each group for this protein\n",
    "                for group_key, group_info in data_transformer.group_data_dict.items():\n",
    "                    grouping_var_name = group_info['grouping_variable']\n",
    "                    \n",
    "                    # Only process if this combination exists in selected_var_keys_list\n",
    "                    if f\"{protein_id}_{grouping_var_name}\" in self.selected_var_keys_list:\n",
    "                        heatmap_data = export_heatmap_data_to_dict(\n",
    "                            protein_id, grouping_var_name, group_info,\n",
    "                            protein_sequence, protein_species, protein_name,\n",
    "                            protein_df, is_all_null\n",
    "                        )\n",
    "                        protein_data[grouping_var_name] = heatmap_data\n",
    "\n",
    "                # Only add to complete_data if we have data for this protein\n",
    "                if protein_data:\n",
    "                    self.complete_data[protein_id] = protein_data\n",
    "            else:\n",
    "                display(HTML(f\"<b style='color:red;'>Data for {protein_id} not found in protein dictionary.</b>\"))\n",
    "        \n",
    "    def update_filter_type(self, new_filter_type):\n",
    "        \"\"\"Update the filter type and reprocess data\"\"\"\n",
    "        self.filter_type = new_filter_type\n",
    "        self.process_export()\n",
    "        if hasattr(self, '_on_data_changed_callback'):\n",
    "            self._on_data_changed_callback()\n",
    "    \n",
    "    def extract_and_format_data(self):\n",
    "        # Load the data from the saved directory\n",
    "        self.process_export()  # Remove the self argument\n",
    "        self.loaded_data = self.complete_data\n",
    "        lenofdict = len(self.loaded_data.keys())\n",
    "        # Initialize the new dictionary\n",
    "        data_variables = {}\n",
    "\n",
    "        # Iterate over the loaded data to extract and reorganize it\n",
    "        for protein_id, protein_data in self.loaded_data.items():\n",
    "            protein_sequence = protein_data.get('protein_sequence')\n",
    "\n",
    "            for grouping_var_name, group_info in protein_data.items():\n",
    "                # Extract the required DataFrames and other information\n",
    "                func_df = group_info.get('func_heatmap_df')\n",
    "                abs_df = group_info.get('heatmap_df')\n",
    "                filtered_abs_df = group_info.get('filtered_heatmap_df')\n",
    "\n",
    "                label = grouping_var_name\n",
    "                protein_sequence = group_info.get('protein_sequence')\n",
    "                protein_name = group_info.get('protein_name')\n",
    "                protein_species = group_info.get('protein_species')\n",
    "\n",
    "                # Determine if the func_df is all None\n",
    "                is_func_df_all_none = func_df.isnull().all().all() if func_df is not None else True\n",
    "\n",
    "                # Create a unique key combining protein_id and grouping_var_name\n",
    "                var_key = f\"{protein_id}_{grouping_var_name}\"\n",
    "\n",
    "                # Populate the data_variables dictionary using the unique key\n",
    "                data_variables[var_key] = {\n",
    "                    'protein_id': protein_id,\n",
    "                    'protein_sequence': protein_sequence,\n",
    "                    'protein_name': protein_name,\n",
    "                    'protein_species': protein_species,\n",
    "                    'heatmap_df': abs_df,\n",
    "                    'function_heatmap_df': func_df,\n",
    "                    'label': label if lenofdict == 1 else var_key,\n",
    "                    'is_func_df_all_none': is_func_df_all_none,\n",
    "                    'filtered_heatmap_df': filtered_abs_df\n",
    "                }\n",
    "\n",
    "        return data_variables\n",
    "    \n",
    "    def process_data_variables(self):\n",
    "        \"\"\"\n",
    "        Minimal processing to pass essential data from filtered to available data variables\n",
    "        \"\"\"\n",
    "        # Dynamically generate the list of variable names based on loaded data\n",
    "        variables = list(self.filtered_data_variables.keys())\n",
    "        protein_id_list = []\n",
    "        protein_name_list = []\n",
    "        \n",
    "        # Pass through only essential data to available_data_variables_dict\n",
    "        self.available_data_variables_dict = {}\n",
    "        \n",
    "        for var in variables:\n",
    "            if var in self.filtered_data_variables:\n",
    "                # Create new dict for this variable\n",
    "                self.available_data_variables_dict[var] = {\n",
    "                    # Core data frames\n",
    "                    'heatmap_df': self.filtered_data_variables[var]['heatmap_df'],\n",
    "                    'function_heatmap_df': self.filtered_data_variables[var]['function_heatmap_df'],\n",
    "                    'filtered_heatmap_df': self.filtered_data_variables[var]['filtered_heatmap_df'],\n",
    "    \n",
    "                    # Essential metadata\n",
    "                    'protein_id': self.filtered_data_variables[var]['protein_id'],\n",
    "                    'protein_name': self.filtered_data_variables[var]['protein_name'],\n",
    "                    'protein_sequence': self.filtered_data_variables[var]['protein_sequence'],\n",
    "                    'label': self.filtered_data_variables[var]['label'],\n",
    "                    \n",
    "                    # Track if function data is all null\n",
    "                    'is_func_df_all_none': self.filtered_data_variables[var]['function_heatmap_df'].isnull().all().all() \n",
    "                        if self.filtered_data_variables[var]['function_heatmap_df'] is not None else True\n",
    "                }\n",
    "                \n",
    "                protein_id_list.append(self.filtered_data_variables[var]['protein_id'])\n",
    "                protein_name_list.append(self.filtered_data_variables[var]['protein_name'])\n",
    "    \n",
    "        # Set protein ID and name\n",
    "        user_protein_id_set = list(set(protein_id_list))\n",
    "        user_protein_name_set = list(set(protein_name_list))\n",
    "    \n",
    "        if len(user_protein_id_set) > 1 and len(user_protein_name_set) == 1:\n",
    "            self.user_protein_id = '_'.join(user_protein_id_set)\n",
    "            self.protein_name_short = user_protein_name_set[0]\n",
    "        elif len(user_protein_id_set) > 1 and len(user_protein_name_set) > 1:\n",
    "            self.user_protein_id = '_'.join(user_protein_id_set)\n",
    "            self.protein_name_short = '_'.join(user_protein_name_set)\n",
    "        elif len(user_protein_name_set) == 1:\n",
    "            self.user_protein_id = user_protein_id_set[0]\n",
    "            self.protein_name_short = user_protein_name_set[0]\n",
    "            \n",
    "        self.protein_name_short = str(self.protein_name_short)\n",
    "                \n",
    "    def create_widgets(self):\n",
    "        if data_transformer:\n",
    "            if not data_transformer.merged_df.empty:\n",
    "                # Create widgets for protein selection\n",
    "                # Count occurrences of each protein\n",
    "                protein_counts = data_transformer.merged_df['Protein'].value_counts()\n",
    "                sorted_proteins = protein_counts.index.tolist()\n",
    "                \n",
    "                # Create dropdown options list with first protein selected by default\n",
    "                dropdown_options = [(f\"{protein} - {data_transformer.protein_dict.get(protein, {'name': 'Unknown'})['name']}\", protein) \n",
    "                                for protein in sorted_proteins]\n",
    "            else: \n",
    "                sorted_proteins = None\n",
    "                dropdown_options = [('No proteins available', '')]\n",
    "        else:\n",
    "            sorted_proteins = None\n",
    "            dropdown_options = [('No proteins available', '')]\n",
    "        \n",
    "        # Create a custom class for SelectMultiple with text-overflow ellipsis\n",
    "        class EllipsisSelectMultiple(widgets.SelectMultiple):\n",
    "            def __init__(self, **kwargs):\n",
    "                super().__init__(**kwargs)\n",
    "                self._dom_classes = ['ellipsis-select']\n",
    "                \n",
    "        # Apply CSS styling for ellipsis\n",
    "        display(HTML(\"\"\"\n",
    "        <style>\n",
    "        .ellipsis-select select option {\n",
    "            text-overflow: ellipsis;\n",
    "            overflow: hidden;\n",
    "            white-space: nowrap;\n",
    "        }\n",
    "        </style>\n",
    "        \"\"\"))\n",
    "        \n",
    "        self.protein_selector = EllipsisSelectMultiple(\n",
    "            options=dropdown_options,\n",
    "            value=(sorted_proteins[0]) if sorted_proteins else ('',),  # Empty tuple for no initial selection\n",
    "            #description='Protein ID:',\n",
    "            disabled=False,\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(\n",
    "                width='325px',\n",
    "                height='150px',\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.var_key_dropdown = widgets.SelectMultiple(\n",
    "            #description='Select Groups',\n",
    "            style={'description_width': 'initial'},\n",
    "            disabled=False,\n",
    "            layout=widgets.Layout(\n",
    "                width='325px',\n",
    "                height='150px',\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if sorted_proteins:\n",
    "            self.update_var_keys({'new': sorted_proteins[0], 'type': 'change', 'name': 'value'})\n",
    "       \n",
    "        # Set widget events\n",
    "        self.protein_selector.observe(self.update_var_keys, names='value')\n",
    "        self.protein_selector.observe(self.on_group_selection_change, names='value')  # Add this line\n",
    "        self.var_key_dropdown.observe(self.on_group_selection_change, names='value')  # Add this line\n",
    "\n",
    "    def on_group_selection_change(self, change):\n",
    "        # Auto-trigger add_group functionality if both protein and group selections exist\n",
    "        if (self.protein_selector.value and len(self.protein_selector.value) > 0 and \n",
    "            self.var_key_dropdown.value and len(self.var_key_dropdown.value) > 0):\n",
    "            self.reset_selection()\n",
    "            self.add_group()\n",
    "\n",
    "    def update_var_keys(self, change):\n",
    "        self.selected_protein = change['new']\n",
    "        \n",
    "        # Handle case when dropdown hasn't been populated yet\n",
    "        if not hasattr(self.var_key_dropdown, 'value'):\n",
    "            return\n",
    "            \n",
    "        current_selection = set(self.var_key_dropdown.value)\n",
    "        \n",
    "        # Use col_order to maintain the same order, but only include available grouping vars\n",
    "        if hasattr(self, 'col_order') and self.col_order:\n",
    "            new_options = [str(col) for col in self.col_order \n",
    "                        if str(col) in map(str, self.available_grouping_vars)]\n",
    "        else:\n",
    "            # Fallback if col_order isn't available\n",
    "            new_options = [str(col) for col in self.available_grouping_vars]\n",
    "        \n",
    "        # Update options while preserving order from col_order\n",
    "        self.var_key_dropdown.options = new_options\n",
    "        \n",
    "        # Keep selected values that are still valid and return as tuple\n",
    "        valid_selections = [val for val in current_selection if val in new_options]\n",
    "        self.var_key_dropdown.value = tuple(valid_selections) \n",
    "            \n",
    "    def add_group(self):\n",
    "        \"\"\"\n",
    "        Add grouping variables to the current selection.\n",
    "        \n",
    "        Handles single and multiple protein selections with corresponding grouping variables.\n",
    "        Updates selected proteins, group variables, and combined lists.\n",
    "        \"\"\"\n",
    "        # Enable relevant buttons\n",
    "        self.new_order_input.disabled = False\n",
    "        self.update_label_button.disabled = False\n",
    "        self.update_order_button.disabled = False\n",
    "        \n",
    "        # Extract the protein value, handling both single values and tuples\n",
    "        protein_value = self.protein_selector.value\n",
    "        if isinstance(protein_value, tuple):\n",
    "            current_proteins = list(protein_value)\n",
    "        else:\n",
    "            current_proteins = [protein_value] if protein_value else []\n",
    "        \n",
    "        # Get selected grouping variables\n",
    "        selected_keys = list(self.var_key_dropdown.value)\n",
    "        \n",
    "       \n",
    "        # Generate and manage keys\n",
    "        generated_keys = set()\n",
    "        \n",
    "        # Generate individual and combined protein keys\n",
    "        for i, protein in enumerate(current_proteins):\n",
    "            for group_var in selected_keys:\n",
    "                # Individual protein keys\n",
    "                generated_keys.add(f\"{protein}_{group_var}\")\n",
    "              \n",
    "        # Ensure selected_protein is a list \n",
    "        if not hasattr(self, 'selected_protein'):\n",
    "            self.selected_protein = []\n",
    "        \n",
    "        # Convert to list if it's a tuple\n",
    "        if isinstance(self.selected_protein, tuple):\n",
    "            self.selected_protein = list(self.selected_protein)\n",
    "        \n",
    "        # Update selected proteins list\n",
    "        for protein in current_proteins:\n",
    "            if protein not in self.selected_protein:\n",
    "                self.selected_protein.append(protein)\n",
    "        \n",
    "        # Update group variables list\n",
    "        if not hasattr(self, 'selected_group_vars'):\n",
    "            self.selected_group_vars = []\n",
    "        \n",
    "        for group_var in selected_keys:\n",
    "            if group_var not in self.selected_group_vars:\n",
    "                self.selected_group_vars.append(group_var)\n",
    "        \n",
    "        # Add new keys\n",
    "        self.selected_var_keys_list.update(generated_keys)\n",
    "\n",
    "\n",
    "        self.data_variables = self.extract_and_format_data()\n",
    "        self.filtered_data_variables = self.create_filtered_data_variables()\n",
    "        self.process_data_variables()\n",
    "        self.available_data_variables_dict = self.filtered_data_variables.copy()\n",
    "\n",
    "        # Update widgets and display\n",
    "        self.default_label_values = {key: self.label_widgets[key].value for key in self.label_widgets}\n",
    "        self.default_order_values = [info['label'] for info in self.available_data_variables_dict.values()]\n",
    "        with self.message_output_label:\n",
    "            self.message_output_label.clear_output(wait=True)\n",
    "            #display(HTML(''))\n",
    "        with self.message_output_order:\n",
    "            self.message_output_order.clear_output(wait=True)\n",
    "            display(HTML(''))\n",
    "        self.update_label_order_widgets()\n",
    "        \n",
    "        # CRITICAL: Trigger specific options refresh after data is ready\n",
    "        if hasattr(self, '_on_data_changed_callback') and self._on_data_changed_callback:\n",
    "            self._on_data_changed_callback()\n",
    "\n",
    "    #Function to reset the selection\n",
    "    def reset_selection(self):\n",
    "        # Preserve loaded data\n",
    "        preserved_data = {\n",
    "            'data_variables': self.data_variables,\n",
    "            'loaded_data': getattr(self, 'loaded_data', None),\n",
    "            'complete_data': getattr(self, 'complete_data', None)\n",
    "        }\n",
    "        \n",
    "        # Reset selection-related attributes\n",
    "        self.selected_var_keys_list = set()\n",
    "        #self.protein_selector.value = ('',)\n",
    "        #self.var_key_dropdown.options = []\n",
    "        \n",
    "        # Reset visualization-related attributes\n",
    "        self.filtered_data_variables = {}\n",
    "        self.available_data_variables_dict = {}\n",
    "        \n",
    "        # Reset widgets\n",
    "        #self.label_widgets = {}\n",
    "        #self.order_widgets = {}\n",
    "        #self.default_label_values = {}\n",
    "        #self.default_order_values = []\n",
    "        \n",
    "\n",
    "        \n",
    "        # Clear plots if plot handler exists\n",
    "        if hasattr(self, '_plot_handler') and self._plot_handler:\n",
    "            with self._plot_handler.plot_output:\n",
    "                self._plot_handler.plot_output.clear_output()\n",
    "                plt.close('all')  # Close all matplotlib figures\n",
    "            \n",
    "            # Reset plot-related attributes in plot handler\n",
    "            self._plot_handler.fig_port = None\n",
    "            self._plot_handler.fig_land = None\n",
    "        \n",
    "        # Restore preserved data\n",
    "        self.data_variables = preserved_data['data_variables']\n",
    "        if preserved_data['loaded_data'] is not None:\n",
    "            self.loaded_data = preserved_data['loaded_data']\n",
    "        if preserved_data['complete_data'] is not None:\n",
    "            self.complete_data = preserved_data['complete_data']\n",
    "        \n",
    "        # Update available grouping variables if they exist\n",
    "        if hasattr(data_transformer, 'group_data_dict') and data_transformer.group_data_dict:\n",
    "            self.available_grouping_vars = [\n",
    "                group['grouping_variable'] \n",
    "                for group in data_transformer.group_data_dict.values()\n",
    "            ]\n",
    "        \n",
    "        # Trigger any necessary UI updates\n",
    "        if hasattr(self, '_on_data_changed_callback'):\n",
    "            self._on_data_changed_callback()\n",
    "\n",
    "        self._notify_data_change()\n",
    "    # Function to update order based on new order input\n",
    "    def update_order(self, order_labels):\n",
    "        \"\"\"\n",
    "        Updates the order of available_data_variables_dict based on provided labels.\n",
    "        The order of items in the dictionary will match the order of labels in order_labels.\n",
    "        \n",
    "        Args:\n",
    "            order_labels (list): List of labels in the desired order\n",
    "        \"\"\"\n",
    "        # Clean the input labels - strip whitespace and empty strings\n",
    "        order_labels = [label.strip() for label in order_labels if label.strip()]\n",
    "        \n",
    "        # Get current label to key mapping\n",
    "        label_to_key = {info['label']: key for key, info in self.available_data_variables_dict.items()}\n",
    "        \n",
    "        # Validate input\n",
    "        if len(order_labels) != len(self.available_data_variables_dict):\n",
    "            raise ValueError(f\"Number of labels provided ({len(order_labels)}) does not match number of variables ({len(self.available_data_variables_dict)})\")\n",
    "        \n",
    "        if len(set(order_labels)) != len(order_labels):\n",
    "            raise ValueError(\"Duplicate labels found in input\")\n",
    "        \n",
    "        if not all(label in label_to_key for label in order_labels):\n",
    "            invalid_labels = [label for label in order_labels if label not in label_to_key]\n",
    "            raise ValueError(f\"Invalid labels found: {invalid_labels}\")\n",
    "        \n",
    "        # Create a new ordered dictionary with items in the specified order\n",
    "        ordered_data = {}\n",
    "        for new_label in order_labels:\n",
    "            key = label_to_key[new_label]\n",
    "            ordered_data[key] = self.available_data_variables_dict[key]\n",
    "            \n",
    "            # Update the label in the data to match the new order\n",
    "            ordered_data[key]['label'] = new_label\n",
    "        \n",
    "        # Replace the available_data_variables_dict with the new ordered dictionary\n",
    "        self.available_data_variables_dict = ordered_data\n",
    "        \n",
    "\n",
    "        \n",
    "        # Update the text input to show the new order\n",
    "        current_labels = [info['label'] for info in self.available_data_variables_dict.values()]\n",
    "        self.new_order_input.value = ', '.join(current_labels)\n",
    "        \n",
    "        return self.available_data_variables_dict\n",
    "    \n",
    "    # Event handler for updating labels\n",
    "    def on_update_label_click(self, b):\n",
    "        try:\n",
    "            update_info = self.update_labels()\n",
    "            \n",
    "            # Create success message based on what was updated/removed\n",
    "            if update_info['removed_count'] > 0:\n",
    "                removed_text = ', '.join(update_info['removed_labels'])\n",
    "                if update_info['removed_count'] == 1:\n",
    "                    message = f'<b style=\"color:green;\">Labels updated successfully! Removed 1 sample: {removed_text}. {update_info[\"remaining_count\"]} samples remaining.</b>'\n",
    "                else:\n",
    "                    message = f'<b style=\"color:green;\">Labels updated successfully! Removed {update_info[\"removed_count\"]} samples: {removed_text}. {update_info[\"remaining_count\"]} samples remaining.</b>'\n",
    "            else:\n",
    "                message = '<b style=\"color:green;\">Labels updated successfully!</b>'\n",
    "            \n",
    "            # Display success message\n",
    "            with self.message_output_label:\n",
    "                self.message_output_label.clear_output(wait=True)\n",
    "                display(HTML(message))\n",
    "            \n",
    "            # Trigger data changed callback if it exists\n",
    "            if hasattr(self, '_on_data_changed_callback'):\n",
    "                self._on_data_changed_callback()\n",
    "            \n",
    "        except Exception as e:\n",
    "            with self.message_output_label:\n",
    "                self.message_output_label.clear_output(wait=True)\n",
    "                display(HTML(f'<b style=\"color:red;\">Error updating labels: {str(e)}</b>'))\n",
    "\n",
    "            # Trigger data changed callback if it exists\n",
    "            if hasattr(self, '_on_data_changed_callback'):\n",
    "                self._on_data_changed_callback()\n",
    "\n",
    "    # Event handler for updating order\n",
    "    def on_update_order_click(self, b):\n",
    "        \"\"\"Event handler for updating order\"\"\"\n",
    "        try:\n",
    "            # Get the order input and split it into a list\n",
    "            order_input = self.new_order_input.value\n",
    "            order_list = [label.strip() for label in order_input.split(',')]\n",
    "            \n",
    "            # Update the order\n",
    "            self.update_order(order_list)\n",
    "            \n",
    "            # Update the label widgets with the new order\n",
    "            for i, (key, info) in enumerate(self.available_data_variables_dict.items()):\n",
    "                if key in self.label_widgets:\n",
    "                    self.label_widgets[key].value = info['label']\n",
    "            \n",
    "            self.update_label_order_widgets()\n",
    "            \n",
    "            # Display success message\n",
    "            with self.message_output_order:\n",
    "                self.message_output_order.clear_output(wait=True)\n",
    "                display(HTML('<b style=\"color:green;\">Order updated successfully!</b>'))\n",
    "            \n",
    "            # Trigger data changed callback if it exists\n",
    "            if hasattr(self, '_on_data_changed_callback'):\n",
    "                self._on_data_changed_callback()\n",
    "                \n",
    "        except Exception as e:\n",
    "            with self.message_output_order:\n",
    "                self.message_output_order.clear_output(wait=True)\n",
    "                display(HTML(f'<b style=\"color:red;\">Error updating order: {str(e)}</b>'))\n",
    "  \n",
    "    def update_labels(self):\n",
    "        # Update labels in available_data_variables_dict based on label_widgets\n",
    "        # Track keys to remove to avoid modifying dict during iteration\n",
    "        keys_to_remove = []\n",
    "        removed_labels = []\n",
    "        \n",
    "        for key in self.available_data_variables_dict:\n",
    "            label_value = self.label_widgets[key].value.strip()\n",
    "            \n",
    "            # Check if user wants to remove this sample (case-insensitive)\n",
    "            if label_value.lower() == 'remove':\n",
    "                keys_to_remove.append(key)\n",
    "                # Store the original label for reporting\n",
    "                removed_labels.append(self.available_data_variables_dict[key]['label'])\n",
    "            else:\n",
    "                # Update the label normally\n",
    "                self.available_data_variables_dict[key]['label'] = label_value\n",
    "        \n",
    "        # Remove the keys that were marked for removal\n",
    "        for key in keys_to_remove:\n",
    "            if key in self.available_data_variables_dict:\n",
    "                del self.available_data_variables_dict[key]\n",
    "            if key in self.label_widgets:\n",
    "                del self.label_widgets[key]\n",
    "        \n",
    "        # If any keys were removed, update the display widgets\n",
    "        if keys_to_remove:\n",
    "            self.update_label_order_widgets()\n",
    "        \n",
    "        # Return information about what was updated/removed\n",
    "        return {\n",
    "            'removed_count': len(keys_to_remove),\n",
    "            'removed_labels': removed_labels,\n",
    "            'remaining_count': len(self.available_data_variables_dict)\n",
    "        }\n",
    "\n",
    "    # Function to display the initial selection widgets         \n",
    "    def display_widgets(self):\n",
    "        # Create a grid layout with 3 rows and 2 columns\n",
    "    \n",
    "        # Input widgets\n",
    "        # Make sure it's added like this\n",
    "        input_widgets = VBox([\n",
    "            widgets.HTML(\"<u>Select Groups (Required):</u>\"), \n",
    "            self.var_key_dropdown,\n",
    "            widgets.HTML(\"<u>Select Proteins (Required):</u>\"),\n",
    "            self.protein_selector],\n",
    "            layout=widgets.Layout(height = '400px', width = '90%', max_width ='1000px', margin='0px', padding='0px', overflow='hidden',))  # Minimize widget margins\n",
    "\n",
    "        \n",
    "        return input_widgets, #vert_button_box#, update_label_box, update_order_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbe4a26c-a505-45bf-a9d1-4b2347b7ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicVisualizationHandler:\n",
    "    def __init__(self, data_transformer):\n",
    "        self.data_transformer = data_transformer\n",
    "        self.selector = HeatmapDataHandler(data_transformer)\n",
    "        self.app = None\n",
    "        self.initialize_instructions()\n",
    "\n",
    "        \n",
    "        # Add a flag to track if the label/order section has been created\n",
    "        self.label_order_section_created = False\n",
    "        \n",
    "        # Add flags to track visualization state\n",
    "        self._protein_selected = False\n",
    "        self._variable_selected = False\n",
    "\n",
    "        # Initialize the visualization components immediately\n",
    "        self._initialize_visualization()\n",
    "        # Add observers to data transformer's file uploaders\n",
    "        self.data_transformer.merged_uploader.observe(self._on_file_change, names='value')\n",
    "        self.data_transformer.fasta_uploader.observe(self._on_file_change, names='value')\n",
    "        self.data_transformer.uniprot_search.observe(self._on_file_change, names='value')\n",
    "    \n",
    "    def _register_plot_handler_observers(self):\n",
    "        \"\"\"Register observers to refresh specific options when data changes.\"\"\"\n",
    "        if hasattr(self, 'app') and self.app and hasattr(self.app, '_data_change_observer_registered'):\n",
    "            if not self.app._data_change_observer_registered:\n",
    "                # Register observers for protein and group selection changes\n",
    "                if hasattr(self, 'selector'):\n",
    "                    if hasattr(self.selector, 'protein_selector'):\n",
    "                        self.selector.protein_selector.observe(self.app.on_data_change_observer, names='value')\n",
    "                    if hasattr(self.selector, 'var_key_dropdown'):\n",
    "                        self.selector.var_key_dropdown.observe(self.app.on_data_change_observer, names='value')\n",
    "                \n",
    "                self.app._data_change_observer_registered = True\n",
    "                \n",
    "    def initialize_instructions(self):\n",
    "        \"\"\"Initialize the instructions for the user\"\"\"\n",
    "        self.stepone_output_html_message = \"\"\"\n",
    "            <div style='padding: 10px; background-color: #f8f9fa; border-left: 5px solid #007bff; margin: 10px 0;'>\n",
    "                <h3>Step 1: Upload Data</h3>\n",
    "                <p>Please upload your data files to begin:</p>\n",
    "                <ul style='list-style-type: circle;'>\n",
    "                    <li>Upload a merged data file (.csv/.txt/.tsv/.xlsx) exported from the Data Transformation module</li>\n",
    "                    <li>Upload FASTA files for non-uniprot proteins (optional)</li>\n",
    "                    <li>Enable UniProt search to automatically add UniProt sequences to your plot (default)</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        self.stepone_status_output = widgets.Output(\n",
    "            layout=widgets.Layout(\n",
    "                max_width='1000px',  # Set your desired maximum width here\n",
    "                width='100%'        # This makes it fill the available space up to the max-width\n",
    "            )\n",
    "        )        \n",
    "        with self.stepone_status_output:\n",
    "            clear_output(wait=True)\n",
    "            display(HTML(self.stepone_output_html_message))    \n",
    "\n",
    "        # Status message for Plot Controls step\n",
    "        self.steptwo_output_html_message = \"\"\"\n",
    "            <div style='padding: 10px; background-color: #f8f9fa; border-left: 5px solid #007bff; margin: 10px 0;'>\n",
    "                <h3>Step 2: Select Data to Visualize</h3>\n",
    "                <p>Choose which data to include in your visualization:</p>\n",
    "                <ul style='list-style-type: circle;'>\n",
    "                    <li> Required: Select a protein from the dropdown</li>\n",
    "                    <li> Required: Choose a grouping variable</li>\n",
    "                    <li> Optional: Customize your plot using the Update Labels and Reorder Samples options</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        # Create Plot Controls status output\n",
    "        self.steptwo_status_output = widgets.Output(\n",
    "            layout=widgets.Layout(\n",
    "                max_width='1000px',  # Set your desired maximum width here\n",
    "                width='100%'        # This makes it fill the available space up to the max-width\n",
    "            )\n",
    "        )        \n",
    "        with self.steptwo_status_output:\n",
    "            clear_output(wait=True)\n",
    "            display(HTML(self.steptwo_output_html_message))\n",
    "            \n",
    "        # Status message for Plotting Options step\n",
    "        # Define the collapsible HTML message\n",
    "        self.stepthree_output_html_message = \"\"\"\n",
    "        <div style='padding: 10px; background-color: #f8f9fa; border-left: 5px solid #007bff; margin: 10px 0;'>\n",
    "            <h3>Step 3: Visualization Options</h3>\n",
    "            <p>Choose how to visualize your protein peptide data:</p>\n",
    "            \n",
    "            <details>\n",
    "                <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Plot Filter</summary>\n",
    "                <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                    <li><b>All Peptides:</b> Display data for all detected peptides across your protein sequence</li>\n",
    "                    <li><b>All Functional Peptides:</b> Display only peptides that have assigned bioactive functions</li>\n",
    "                    <li><b>Selected Functional Peptides:</b> Display only peptides with specific functions chosen in the \"Specific Options\" dropdown</li>\n",
    "                </ul>\n",
    "            </details>\n",
    "            \n",
    "            <details>\n",
    "                <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Plot Averaged Data</summary>\n",
    "                <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                    <li><b>Yes:</b> Display both individual peptide data and the average Absorbance across the protein</li>\n",
    "                    <li><b>No:</b> Display only individual peptide data without averaging</li>\n",
    "                    <li><b>Only:</b> Display only the averaged data as a line plot, hiding individual peptide data</li>\n",
    "                </ul>\n",
    "            </details>\n",
    "            \n",
    "            <details>\n",
    "                <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Plot Specific Peptides</summary>\n",
    "                <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                    <li><b>None:</b> Display data for all peptides according to the Plot Filter selection</li>\n",
    "                    <li><b>Peptide Intervals:</b> Highlight specific peptide segments selected from the \"Specific Options\" dropdown</li>\n",
    "                    <li><b>Bioactive Functions:</b> Highlight peptides with specific bioactive functions selected from the \"Specific Options\" dropdown</li>\n",
    "                </ul>\n",
    "            </details>\n",
    "            \n",
    "            <details>\n",
    "                <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Specific Options</summary>\n",
    "                <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                    <li>Multi-select dropdown that changes based on your \"Plot Specific Peptides\" selection:</li>\n",
    "                    <li style=\"margin-left: 20px;\"><b>When \"Peptide Intervals\" is selected:</b> Choose specific peptide segments by their position (e.g., \"1-20\", \"21-40\")</li>\n",
    "                    <li style=\"margin-left: 20px;\"><b>When \"Bioactive Functions\" is selected:</b> Choose specific biological functions to highlight (e.g., \"ACE Inhibitor\", \"Antioxidant\")</li>\n",
    "                </ul>\n",
    "            </details>\n",
    "\n",
    "            <details>\n",
    "                <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Log Transform</summary>\n",
    "                <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                    <li>Apply a log transformation to the abundnace data (Y-axis) to improve visualization of low absorbance data</li>\n",
    "                </ul>\n",
    "            </details>\n",
    "\n",
    "            <details>\n",
    "                <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Appearance Settings</summary>\n",
    "                <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                    <li>Customize the appearance of your plot using the following settings:</li>\n",
    "                    <li style=\"margin-left: 20px;\"><b>Heatmap:</b> Choose a color scheme for your heatmap (default: RdYlGn_r)</li>\n",
    "                    <li style=\"margin-left: 20px;\"><b>Line Plot:</b> Select line plot color scheme (default:  Set3)</li>\n",
    "                    <li style=\"margin-left: 20px;\"><b>Avg Line Plot:</b> Choose average line color scheme (default:  Dark2)</li>\n",
    "                    <li style=\"margin-left: 20px;\"><b>x-axis label:</b> Set the horizontal axis label (e.g., Beta-casein Sequence)</li>\n",
    "                    <li style=\"margin-left: 20px;\"><b>y-axis label:</b> Set the vertical axis label (e.g., Averaged Peptide Absorbance)</li>\n",
    "                    <li style=\"margin-left: 20px;\"><b>y-axis title position:</b> Adjust the position of the y-axis title</li>\n",
    "                    <li style=\"margin-left: 20px;\"><b>Legend titles:</b> Customize labels for Sample Type, Peptide Counts, and Average Absorbance</li>\n",
    "                </ul>\n",
    "            </details>\n",
    "            <details>\n",
    "                <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Display and Export</summary>\n",
    "                <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                    <li>Choose your display options and export your visualization:</li>\n",
    "                    <li style=\"margin-left: 20px;\"><b>Plot Orientation:</b>\n",
    "                        <ul style=\"list-style-type: none; margin-left: 10px;\">\n",
    "                            <li> Plot Portrait Graph</li>\n",
    "                            <li> Plot Landscape Graph</li>\n",
    "                        </ul>\n",
    "                    </li>\n",
    "                    <li style=\"margin-left: 20px;\"><b>Actions:</b>\n",
    "                        <ul style=\"list-style-type: none; margin-left: 10px;\">\n",
    "                            <li style=\"display: inline-block; margin-right: 10px;\"><button style=\"background-color: #28a745; color: white; border: none; padding: 5px 10px; border-radius: 3px;\"> Generate/Update</button></li>\n",
    "                            <li style=\"display: inline-block;\"><button style=\"background-color: #17a2b8; color: white; border: none; padding: 5px 10px; border-radius: 3px;\"> Save Plot</button></li>\n",
    "                        </ul>\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </details>\n",
    "\n",
    "            <p style=\"margin-top: 10px;\">Select your desired visualization options below and click \"Generate/Update\" to create your plots.</p>\n",
    "        \"\"\"\n",
    "        # Create Plotting Options status output\n",
    "        self.stepthree_status_output = widgets.Output(            \n",
    "            layout=widgets.Layout(\n",
    "                max_width='1000px',  # Set your desired maximum width here\n",
    "                width='100%'        # This makes it fill the available space up to the max-width\n",
    "            )\n",
    "        )        \n",
    "        with self.stepthree_status_output:\n",
    "            clear_output(wait=True)\n",
    "            display(HTML(self.stepthree_output_html_message))\n",
    "    \n",
    "    def _initialize_visualization(self):\n",
    "        \"\"\"Initialize the visualization with widgets in disabled state\"\"\"\n",
    "        # Create the selector even if we don't have data yet\n",
    "        self.selector = HeatmapDataHandler(self.data_transformer)\n",
    "        \n",
    "        # Create the app with the selector\n",
    "        self.app = HeatmapPlotHandler(self.data_transformer)\n",
    "        \n",
    "        # Set up bidirectional references properly\n",
    "        self.app.set_data_handler(self)  # Set the visualization handler as the data handler\n",
    "        self.app.selector = self.selector  # Explicitly connect the app to the selector\n",
    "        \n",
    "    \n",
    "        self.selector.protein_selector.observe(self.app.add_group_change, names='value')\n",
    "        # Add observer for plot controls status\n",
    "        self.selector.protein_selector.observe(self._update_plot_controls_status, names='value')\n",
    "\n",
    "        self.selector.var_key_dropdown.observe(self.app.add_group_change, names='value')\n",
    "        # Add observer for plot controls status\n",
    "        self.selector.var_key_dropdown.observe(self._update_plot_controls_status, names='value')\n",
    "    \n",
    "        # Disable widgets that require data\n",
    "        self._update_widget_states(enabled=False)\n",
    "\n",
    "        # Set the label_order_section_created flag to True\n",
    "        self.label_order_section_created = True\n",
    "        \n",
    "        # Set up event handlers for the visualization handler\n",
    "        self.selector.protein_selector.observe(self._on_selector_data_change)\n",
    "        \n",
    "        # Initialize the selector's label/order widgets\n",
    "        self.selector.initialize_empty_label_order_widgets()\n",
    "        \n",
    "        # Ensure event handlers are attached for label/order widgets\n",
    "        if hasattr(self.selector, \"update_label_button\"):\n",
    "            self.selector.update_label_button.on_click(self._on_selector_data_change)\n",
    "        if hasattr(self.selector, \"update_order_button\"):\n",
    "            self.selector.update_order_button.on_click(self._on_selector_data_change)\n",
    "\n",
    "        # Set up the selector's data changed callback\n",
    "        self.selector._on_data_changed_callback = self._on_selector_data_change\n",
    "\n",
    "        if hasattr(self, 'app') and self.app:\n",
    "                self.selector._on_data_changed_callback = self.app.refresh_specific_options_external\n",
    "\n",
    "    def _update_widget_states(self, enabled=True):\n",
    "        \"\"\"Update the enabled/disabled state of all widgets without redisplaying\"\"\"\n",
    "        if self.selector:\n",
    "            # Essential selector widgets\n",
    "            widgets_to_update = [\n",
    "                'protein_selector', \n",
    "                'var_key_dropdown',\n",
    "                'plot_filter'\n",
    "            ]\n",
    "            \n",
    "            for widget_name in widgets_to_update:\n",
    "                if hasattr(self.selector, widget_name):\n",
    "                    widget = getattr(self.selector, widget_name)\n",
    "                    if hasattr(widget, 'disabled'):\n",
    "                        widget.disabled = not enabled\n",
    "            \n",
    "            # Also check if there's a label_order_button_box with children\n",
    "            if hasattr(self.selector, 'label_order_button_box') and hasattr(self.selector.label_order_button_box, 'children'):\n",
    "                for child in self.selector.label_order_button_box.children:\n",
    "                    if hasattr(child, 'disabled'):\n",
    "                        child.disabled = not enabled\n",
    "            \n",
    "            # Update widgets in button_box if it exists\n",
    "            if hasattr(self.selector, 'button_box') and hasattr(self.selector.button_box, 'children'):\n",
    "                for child in self.selector.button_box.children:\n",
    "                    if hasattr(child, 'disabled'):\n",
    "                        child.disabled = not enabled\n",
    "                        \n",
    "            # Check for any nested VBox or HBox that might contain the buttons\n",
    "            if hasattr(self.selector, 'label_order_output'):\n",
    "                # Try to find buttons inside this output\n",
    "                for widget in self.selector.label_order_output.outputs:\n",
    "                    if hasattr(widget, 'children'):\n",
    "                        for child in widget.children:\n",
    "                            if isinstance(child, widgets.Button):\n",
    "                                child.disabled = not enabled\n",
    "                            # Check for nested containers\n",
    "                            if hasattr(child, 'children'):\n",
    "                                for nested_child in child.children:\n",
    "                                    if isinstance(nested_child, widgets.Button):\n",
    "                                        nested_child.disabled = not enabled\n",
    "            \n",
    "            # Label and order widgets\n",
    "            for widget_dict_name in ['label_widgets', 'order_widgets']:\n",
    "                if hasattr(self.selector, widget_dict_name):\n",
    "                    widget_dict = getattr(self.selector, widget_dict_name)\n",
    "                    if isinstance(widget_dict, dict):\n",
    "                        for widget in widget_dict.values():\n",
    "                            if hasattr(widget, 'disabled'):\n",
    "                                widget.disabled = not enabled                \n",
    "\n",
    "    def _populate_selectors(self):\n",
    "        \"\"\"Populate the protein and group selectors with available data\"\"\"\n",
    "        if not self.selector:\n",
    "            return\n",
    "        \n",
    "        # Check if we have the necessary data\n",
    "        if not hasattr(self.data_transformer, 'merged_df') or self.data_transformer.merged_df is None:\n",
    "            return\n",
    "            \n",
    "        if not hasattr(self.data_transformer, 'protein_dict') or not self.data_transformer.protein_dict:\n",
    "            return\n",
    "        \n",
    "        # 1. Populate the protein dropdown\n",
    "        if hasattr(self.selector, 'protein_selector'):\n",
    "            # Count occurrences of each protein\n",
    "            protein_counts = self.data_transformer.merged_df['Protein'].value_counts()\n",
    "            sorted_proteins = protein_counts.index.tolist()\n",
    "            \n",
    "            # Create dropdown options with protein names\n",
    "            dropdown_options = [(f\"{protein} - {self.data_transformer.protein_dict.get(protein, {'name': 'Unknown'})['name']}\", protein) \n",
    "                            for protein in sorted_proteins]\n",
    "            \n",
    "            # Update the dropdown\n",
    "            self.selector.protein_selector.options = dropdown_options\n",
    "            \n",
    "            # Important fix: For SelectMultiple widget, value must be a tuple\n",
    "            if dropdown_options and hasattr(self.selector.protein_selector, 'value'):\n",
    "                # Create a tuple with the first protein as its only element\n",
    "                self.selector.protein_selector.value = (sorted_proteins[0],)  # Note the comma to create a tuple\n",
    "        \n",
    "        # 2. Populate the grouping variables\n",
    "        if hasattr(self.data_transformer, 'group_data_dict') and hasattr(self.selector, 'available_grouping_vars'):\n",
    "            self.selector.available_grouping_vars = [\n",
    "                group['grouping_variable'] \n",
    "                for group in self.data_transformer.group_data_dict.values()\n",
    "            ]\n",
    "            \n",
    "            # If we have col_order, make sure it's set in the selector\n",
    "            if hasattr(self.data_transformer, 'col_order'):\n",
    "                self.selector.col_order = self.data_transformer.col_order\n",
    "        \n",
    "        # 3. Force update of the var_key dropdown based on selected protein\n",
    "        if hasattr(self.selector, 'update_var_keys') and hasattr(self.selector.protein_selector, 'value') and self.selector.protein_selector.value:\n",
    "            # Create a simulated change event with the first value from the tuple\n",
    "            # Extracting the first element from the tuple for the change event\n",
    "            first_selected = self.selector.protein_selector.value[0] if self.selector.protein_selector.value else None\n",
    "            \n",
    "            change_event = {\n",
    "                'name': 'value',\n",
    "                'new': first_selected,  # This will be a string, not a tuple\n",
    "                'type': 'change'\n",
    "            }\n",
    "            \n",
    "            self.selector.update_var_keys(change_event)\n",
    "        \n",
    "    def _on_file_change(self, change):\n",
    "        \"\"\"Handle file upload changes without recreating the UI\"\"\"\n",
    "        # Debounce rapid successive calls to prevent multiple displays\n",
    "        current_time = time.time()\n",
    "        if hasattr(self, '_last_file_change_update') and (current_time - self._last_file_change_update) < 0.1:\n",
    "            return\n",
    "        self._last_file_change_update = current_time\n",
    "        \n",
    "        # Check if we now have all required data\n",
    "        #has_required_data = self._check_required_data()\n",
    "        has_merged, has_groups, has_proteins, has_fasta_files, has_uniprot_search = self._check_required_data()\n",
    "        has_required_data = has_merged and has_groups# and has_proteins# and has_fasta_files and has_uniprot_search\n",
    "        if has_required_data and has_fasta_files and has_uniprot_search:\n",
    "            # We have all necessary data, so populate the selectors and enable widgets\n",
    "            self._populate_selectors()\n",
    "            self._update_widget_states(enabled=True)\n",
    "            self.stepone_output_html_message = f\"\"\"\n",
    "            <div style='padding: 10px; background-color: #e8f5e9; border-left: 5px solid #4caf50; margin: 10px 0;'>\n",
    "                <h3>Step 1: Upload Data</h3>\n",
    "                <p>Data successfully loaded:</p>\n",
    "                <ul style=\"list-style-type: none;\">\n",
    "                    <li> <b>{self.data_transformer.pd_filename}</b> successfully upload as a merged data file</li> \n",
    "                    <li> <b>{self.data_transformer.fasta_filename}</b> successfully upload as a FASTA files for non-uniprot proteins</li>\n",
    "                    <li> UniProt API successfully connected and enabled</li>\n",
    "                </ul>\n",
    "                <p>All required data has been loaded. You can now proceed to step 2.</p>\n",
    "            </div>\n",
    "            \"\"\"       \n",
    "        if has_required_data and has_fasta_files and not has_uniprot_search:\n",
    "            # We have all necessary data, so populate the selectors and enable widgets\n",
    "            self._populate_selectors()\n",
    "            self._update_widget_states(enabled=True)\n",
    "            self.stepone_output_html_message = f\"\"\"\n",
    "            <div style='padding: 10px; background-color: #e8f5e9; border-left: 5px solid #4caf50; margin: 10px 0;'>\n",
    "                <h3>Step 1: Upload Data</h3>\n",
    "                <p>Data successfully loaded:</p>\n",
    "                <ul style=\"list-style-type: none;\">\n",
    "                    <li> <b>{self.data_transformer.pd_filename}</b> successfully upload as a merged data file</li> \n",
    "                    <li> <b>{self.data_transformer.fasta_filename}</b> successfully upload as a FASTA files for non-uniprot proteins</li>\n",
    "                    <li> Enable UniProt search to automatically add UniProt sequences to your plot (optional)</li>\n",
    "                </ul>\n",
    "                <p>All required data has been loaded. You can now proceed to step 2.</p>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        elif has_required_data and not has_fasta_files and has_uniprot_search:\n",
    "            # We have all necessary data, so populate the selectors and enable widgets\n",
    "            self._populate_selectors()\n",
    "            self._update_widget_states(enabled=True)\n",
    "            self.stepone_output_html_message = f\"\"\"\n",
    "            <div style='padding: 10px; background-color: #e8f5e9; border-left: 5px solid #4caf50; margin: 10px 0;'>\n",
    "                <h3>Step 1: Upload Data</h3>\n",
    "                <p>Data successfully loaded:</p>\n",
    "                <ul style=\"list-style-type: none;\">\n",
    "                    <li> <b>{self.data_transformer.pd_filename}</b> successfully upload as a merged data file (.csv/.txt/.tsv/.xlsx)</li> \n",
    "                    <li> Upload FASTA files for non-uniprot proteins (optional)</li>\n",
    "                    <li> UniProt API successfully connected and enabled</li>\n",
    "                </ul>\n",
    "                <p>All required data has been loaded. You can now proceed to step 2.</p>\n",
    "            </div>\n",
    "            \"\"\"        \n",
    "        elif has_required_data and not (has_fasta_files and has_uniprot_search):\n",
    "            # We have all necessary data, so populate the selectors and enable widgets\n",
    "            self._populate_selectors()\n",
    "            self._update_widget_states(enabled=True)\n",
    "            self.stepone_output_html_message = f\"\"\"\n",
    "            <div style='padding: 10px; background-color: #e8f5e9; border-left: 5px solid #4caf50; margin: 10px 0;'>\n",
    "                <h3>Step 1: Upload Data</h3>\n",
    "                <p>Additional actions are required:</p>\n",
    "                <ul style=\"list-style-type: none;\">\n",
    "                    <li> <b>{self.data_transformer.pd_filename}</b> successfully upload as a merged data file (.csv/.txt/.tsv/.xlsx)</li> \n",
    "                    <li> Upload FASTA files for non-uniprot proteins (optional)</li>\n",
    "                    <li> Enable UniProt search to automatically add UniProt sequences to your plot (optional)</li>\n",
    "                </ul>\n",
    "                <p>Pleaase upload a Fasta File containing protein data or enable UniProt Searching.</p>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        elif has_fasta_files and not has_uniprot_search:\n",
    "            self._populate_selectors()\n",
    "            self._update_widget_states(enabled=True)\n",
    "            self.stepone_output_html_message = f\"\"\"\n",
    "            <div style='padding: 10px; background-color: #e8f5e9; border-left: 5px solid #4caf50; margin: 10px 0;'>\n",
    "                <h3>Step 1: Upload Data</h3>\n",
    "                <p>Data successfully loaded:</p>\n",
    "                <ul style=\"list-style-type: none;\">\n",
    "                    <li> Upload a merged data file (.csv/.txt/.tsv/.xlsx)</li>\n",
    "                    <li> Upload FASTA files for non-uniprot proteins (optional)</li>\n",
    "                    <li> Enable UniProt search to automatically add UniProt sequences to your plot (default)</li>\n",
    "                </ul>\n",
    "                <p>All required data has been loaded. You can now use the interface.</p>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        elif not has_required_data and not (has_fasta_files or has_uniprot_search):\n",
    "            # Still missing data, update the message\n",
    "            self.stepone_output_html_message = f\"\"\"\n",
    "            <div style='padding: 10px; background-color: #fff3e0; border-left: 5px solid #ff9800; margin: 10px 0;'>\n",
    "               <h3>Step 1: Upload Data</h3>\n",
    "                <p>Additional actions are required:</p>\n",
    "                <ul style=\"list-style-type: none;\">\n",
    "                    <li> Upload a merged data file (.csv/.txt/.tsv/.xlsx)</li>\n",
    "                    <li> Upload FASTA files for non-uniprot proteins (optional)</li>\n",
    "                    <li> Enable UniProt search to automatically add UniProt sequences to your plot (default)</li>\n",
    "                </ul>\n",
    "                <p>Pleaase upload peptidomic data and either a Fasta File containing protein data or enable UniProt Searching.</p>\n",
    "\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        if has_required_data:\n",
    "            # Register plot handler observers after data is available\n",
    "            self._register_plot_handler_observers()\n",
    "            \n",
    "            # CRITICAL: Refresh specific options when files are uploaded\n",
    "            if hasattr(self, 'app') and self.app and hasattr(self.app, 'refresh_specific_options_external'):\n",
    "                self.app.refresh_specific_options_external()\n",
    "        \n",
    "        # Always update the display at the end of the method\n",
    "        if hasattr(self, 'stepone_status_output'):\n",
    "            with self.stepone_status_output:\n",
    "                clear_output(wait=True)\n",
    "                display(HTML(self.stepone_output_html_message))\n",
    "\n",
    "    def _update_selector_data(self):\n",
    "        \"\"\"Update the selector with new data from data_transformer\"\"\"\n",
    "        if self.selector is None:\n",
    "            return\n",
    "            \n",
    "        # Update proteins dictionary\n",
    "        self.selector.protein_dict = self.data_transformer.protein_dict\n",
    "        \n",
    "        # Update available proteins\n",
    "        if hasattr(self.data_transformer, 'merged_df'):\n",
    "            self.selector.available_proteins = set(\n",
    "                self.data_transformer.merged_df['Protein'].str.split(';').str[0].unique()\n",
    "            )\n",
    "        \n",
    "        # Update available grouping variables\n",
    "        if hasattr(self.data_transformer, 'group_data_dict'):\n",
    "            self.selector.available_grouping_vars = [\n",
    "                group['grouping_variable'] \n",
    "                for group in self.data_transformer.group_data_dict.values()\n",
    "            ]\n",
    "            \n",
    "            # Ensure col_order is set\n",
    "            if hasattr(self.data_transformer, 'col_order'):\n",
    "                self.selector.col_order = self.data_transformer.col_order\n",
    "        \n",
    "        # Set callback for data changes\n",
    "        self.selector._on_data_changed_callback = self._on_selector_data_change\n",
    "    \n",
    "    def _on_selector_data_change(self, change=None):\n",
    "        \"\"\"Handle changes in selector data\"\"\"\n",
    "\n",
    "        if self.app:\n",
    "            self.app.update_data(self.selector)\n",
    "    \n",
    "        # Then update the status message based on the current state\n",
    "        self._update_plot_controls_status(change)\n",
    "        \n",
    "    def _update_plot_controls_status(self, change=None):\n",
    "        \"\"\"Update the plot controls status message based on current selections\"\"\"\n",
    "        # Debounce rapid successive calls to prevent multiple displays\n",
    "        current_time = time.time()\n",
    "        if hasattr(self, '_last_status_update') and (current_time - self._last_status_update) < 0.1:\n",
    "            return\n",
    "        self._last_status_update = current_time\n",
    "        \n",
    "        # Check if a protein is selected\n",
    "        if hasattr(self.selector, 'protein_selector') and self.selector.protein_selector.value:\n",
    "            self._protein_selected = True\n",
    "        else:\n",
    "            self._protein_selected = False\n",
    "        \n",
    "        # Check if a variable is selected\n",
    "        if hasattr(self.selector, 'var_key_dropdown') and self.selector.var_key_dropdown.value:\n",
    "            self._variable_selected = True\n",
    "        else:\n",
    "            self._variable_selected = False\n",
    "        \n",
    "        # Update the status message based on current state\n",
    "        if self._protein_selected and self._variable_selected:\n",
    "            # Both protein and variable are selected\n",
    "            self.steptwo_output_html_message = \"\"\"\n",
    "                <div style='padding: 10px; background-color: #e8f5e9; border-left: 5px solid #4caf50; margin: 10px 0;'>\n",
    "                    <h3>Step 2: Plot Controls</h3>\n",
    "                    <p>Selections complete! You can now:</p>\n",
    "                    <ul style=\"list-style-type: none;\">\n",
    "                        <li> Required: Protein selected</li>\n",
    "                        <li> Required: Variable selected</li>\n",
    "                        <li> Optional: Use the Update Labels option to customize label text or remove samples (optional)</li>\n",
    "                        <li> Optional: Use the Reorder Samples option to change sample display order (optional)</li>\n",
    "                    </ul>\n",
    "                \"\"\"\n",
    "        elif self._protein_selected:\n",
    "            # Only protein is selected\n",
    "            self.steptwo_output_html_message = \"\"\"\n",
    "                <div style='padding: 10px; background-color: #fff3e0; border-left: 5px solid #ff9800; margin: 10px 0;'>\n",
    "                    <h3>Step 2: Plot Controls</h3>\n",
    "                    <p>Protein selected! Next steps:</p>\n",
    "                    <ul style=\"list-style-type: none;\">\n",
    "                        <li> Protein selected</li>\n",
    "                        <li> Required: Select a grouping variable from the dropdown</li>\n",
    "                        <li> Optional: Update Labels and Reorder Samples will be available after selecting a variable (optional)</li>\n",
    "                    </ul>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "        else:\n",
    "            # Neither protein nor variable is selected\n",
    "            self.steptwo_output_html_message = \"\"\"\n",
    "                <div style='padding: 10px; background-color: #fff3e0; border-left: 5px solid #ff9800; margin: 10px 0;'>\n",
    "                    <h3>Step 2: Plot Controls</h3>\n",
    "                    <p>Please make selections to continue:</p>\n",
    "                    <ul style=\"list-style-type: none;\">\n",
    "                        <li> Required: Select a protein from the dropdown</li>\n",
    "                        <li> Required: Then select a grouping variable</li>\n",
    "                        <li> Optional: Update Labels and Reorder Samples options will become available after selecting protein and variable</li>\n",
    "                    </ul>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "        \n",
    "        # Update the display with proper cleanup\n",
    "        if hasattr(self, 'steptwo_status_output'):\n",
    "            with self.steptwo_status_output:\n",
    "                clear_output(wait=True)\n",
    "                display(HTML(self.steptwo_output_html_message))\n",
    "     \n",
    "    def consolidate_and_display_errors(self, errors):\n",
    "        \"\"\"\n",
    "        Consolidate duplicate errors and display them in a clean, organized format.\n",
    "        \n",
    "        Args:\n",
    "            errors (list): List of error messages from plotting functions\n",
    "        \"\"\"\n",
    "        if not errors:\n",
    "            return\n",
    "            \n",
    "        # Debug: Print errors being processed (can be removed later)\n",
    "        #print(f\"[DEBUG] Processing {len(errors)} errors:\")\n",
    "        #for i, error in enumerate(errors):\n",
    "        #    print(f\"  {i+1}. {error}\")\n",
    "            \n",
    "        # Parse and categorize errors\n",
    "        error_categories = {\n",
    "            'missing_peptides': {},\n",
    "            'missing_functions': {},\n",
    "            'empty_dataframes': [],\n",
    "            'processing_errors': [],\n",
    "            'other_errors': []\n",
    "        }\n",
    "        \n",
    "        for error in errors:\n",
    "            try:\n",
    "                if 'peptide columns not found' in error.lower():\n",
    "                    # Extract variable name and missing peptides\n",
    "                    if 'variable:' in error:\n",
    "                        var_part = error.split('variable:')[1]\n",
    "                        var_name = var_part.split('.')[0].strip()\n",
    "                        \n",
    "                        # Handle both \"Missing:\" and \"Non-matching peptides:\" formats\n",
    "                        if 'Missing:' in error:\n",
    "                            missing_part = error.split('Missing:')[1].strip()\n",
    "                        elif 'Non-matching peptides:' in error:\n",
    "                            missing_part = error.split('Non-matching peptides:')[1].strip()\n",
    "                        else:\n",
    "                            continue  # Skip if we can't find the missing items part\n",
    "                            \n",
    "                        # Parse the list of missing items\n",
    "                        missing_items = missing_part.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "                        missing_items = [item.strip() for item in missing_items]\n",
    "                        \n",
    "                        if 'Some peptide columns' in error:\n",
    "                            category_key = 'partial_missing_peptides'\n",
    "                        else:\n",
    "                            category_key = 'all_missing_peptides'\n",
    "                            \n",
    "                        if category_key not in error_categories:\n",
    "                            error_categories[category_key] = {}\n",
    "                            \n",
    "                        error_categories[category_key][var_name] = missing_items\n",
    "                            \n",
    "                elif 'selected functions not found' in error.lower():\n",
    "                    # Extract variable name and missing functions\n",
    "                    if 'variable:' in error:\n",
    "                        var_part = error.split('variable:')[1]\n",
    "                        var_name = var_part.split('.')[0].strip()\n",
    "                        \n",
    "                        if 'Missing:' in error:\n",
    "                            missing_part = error.split('Missing:')[1].strip()\n",
    "                            # Parse the list of missing items\n",
    "                            missing_items = missing_part.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "                            missing_items = [item.strip() for item in missing_items]\n",
    "                            \n",
    "                            if 'Some selected functions' in error:\n",
    "                                category_key = 'partial_missing_functions'\n",
    "                            else:\n",
    "                                category_key = 'all_missing_functions'\n",
    "                                \n",
    "                            if category_key not in error_categories:\n",
    "                                error_categories[category_key] = {}\n",
    "                                \n",
    "                            error_categories[category_key][var_name] = missing_items\n",
    "                            \n",
    "                elif 'dataframe is empty' in error.lower():\n",
    "                    error_categories['empty_dataframes'].append(error)\n",
    "                elif ('error' in error.lower() and any(keyword in error.lower() for keyword in ['processing', 'plotting', 'filtering', 'function filtering'])):\n",
    "                    error_categories['processing_errors'].append(error)\n",
    "                elif any(keyword in error.lower() for keyword in ['invalid', 'reselect', 'plotting options', 'variable options', 'too few peptides', 'checkbox must be selected']):\n",
    "                    error_categories['other_errors'].append(error)\n",
    "                elif 'dataframe is empty' in error.lower() or 'empty' in error.lower():\n",
    "                    error_categories['empty_dataframes'].append(error)\n",
    "                else:\n",
    "                    error_categories['other_errors'].append(error)\n",
    "            except Exception as e:\n",
    "                #print(f\"[DEBUG] Error processing error message: {error} - Exception: {str(e)}\")\n",
    "                error_categories['other_errors'].append(error)\n",
    "        \n",
    "        # Generate consolidated display\n",
    "        html_content = []\n",
    "        \n",
    "        # Handle missing functions (most common case from your example)\n",
    "        if 'partial_missing_functions' in error_categories and error_categories['partial_missing_functions']:\n",
    "            html_content.append(self._create_missing_items_table(\n",
    "                error_categories['partial_missing_functions'], \n",
    "                \"Bioactive Functions Not Found\", \n",
    "                \"The following bioactive functions were not found in the data for the specified variables:\",\n",
    "                \"warning\"\n",
    "            ))\n",
    "            \n",
    "        if 'all_missing_functions' in error_categories and error_categories['all_missing_functions']:\n",
    "            html_content.append(self._create_missing_items_table(\n",
    "                error_categories['all_missing_functions'], \n",
    "                \"No Bioactive Functions Found\", \n",
    "                \"None of the selected bioactive functions were found in the data for these variables:\",\n",
    "                \"error\"\n",
    "            ))\n",
    "        \n",
    "        # Handle missing peptides\n",
    "        if 'partial_missing_peptides' in error_categories and error_categories['partial_missing_peptides']:\n",
    "            html_content.append(self._create_missing_items_table(\n",
    "                error_categories['partial_missing_peptides'], \n",
    "                \"Peptide Intervals Not Found\", \n",
    "                \"The following peptide intervals were not found in the data for the specified variables:\",\n",
    "                \"warning\"\n",
    "            ))\n",
    "            \n",
    "        if 'all_missing_peptides' in error_categories and error_categories['all_missing_peptides']:\n",
    "            html_content.append(self._create_missing_items_table(\n",
    "                error_categories['all_missing_peptides'], \n",
    "                \"No Peptide Intervals Found\", \n",
    "                \"None of the selected peptide intervals were found in the data for these variables:\",\n",
    "                \"error\"\n",
    "            ))\n",
    "        \n",
    "        # Handle other errors\n",
    "        if error_categories['empty_dataframes']:\n",
    "            html_content.append(self._create_simple_error_list(\n",
    "                error_categories['empty_dataframes'], \n",
    "                \"Data Issues\", \n",
    "                \"warning\"\n",
    "            ))\n",
    "            \n",
    "        if error_categories['processing_errors']:\n",
    "            html_content.append(self._create_simple_error_list(\n",
    "                error_categories['processing_errors'], \n",
    "                \"Processing Errors\", \n",
    "                \"error\"\n",
    "            ))\n",
    "            \n",
    "        if error_categories['other_errors']:\n",
    "            html_content.append(self._create_simple_error_list(\n",
    "                error_categories['other_errors'], \n",
    "                \"Other Issues\", \n",
    "                \"info\"\n",
    "            ))\n",
    "        \n",
    "        # Debug: Show categorization results\n",
    "        #print(f\"[DEBUG] Error categorization results:\")\n",
    "        #for category, items in error_categories.items():\n",
    "        #    if items:\n",
    "        #        if isinstance(items, dict):\n",
    "        #            print(f\"  {category}: {len(items)} variables with missing items\")\n",
    "        #            for var, missing in items.items():\n",
    "        #                print(f\"    {var}: {missing}\")\n",
    "        #        else:\n",
    "        #            print(f\"  {category}: {len(items)} errors\")\n",
    "        #            for error in items:\n",
    "        #                print(f\"    - {error}\")\n",
    "                        \n",
    "        # Display consolidated errors\n",
    "        if html_content:\n",
    "            final_html = \"<div style='margin: 15px 0; max-width: 1200px;'>\" + \"\".join(html_content) + \"</div>\"\n",
    "            display(HTML(final_html))\n",
    "        else:\n",
    "            print(\"[DEBUG] No HTML content generated - check if errors are being categorized correctly\")\n",
    "    \n",
    "    def _create_missing_items_table(self, missing_data, title, description, error_type):\n",
    "        \"\"\"Create a table showing missing items by variable\"\"\"\n",
    "        # Determine styling based on error type\n",
    "        if error_type == \"error\":\n",
    "            border_color = \"#dc3545\"\n",
    "            bg_color = \"#f8d7da\"\n",
    "            icon = \"\"\n",
    "        elif error_type == \"warning\":\n",
    "            border_color = \"#ffc107\"\n",
    "            bg_color = \"#fff3cd\"\n",
    "            icon = \"\"\n",
    "        else:\n",
    "            border_color = \"#17a2b8\"\n",
    "            bg_color = \"#d1ecf1\"\n",
    "            icon = \"\"\n",
    "        \n",
    "        # Get all unique missing items across all variables\n",
    "        all_missing_items = set()\n",
    "        for items in missing_data.values():\n",
    "            all_missing_items.update(items)\n",
    "        all_missing_items = sorted(list(all_missing_items))\n",
    "        \n",
    "        html = f\"\"\"\n",
    "        <div style='margin: 10px 0; padding: 15px; background-color: {bg_color}; border-left: 4px solid {border_color}; border-radius: 5px; max-width: 100%; overflow-x: auto;'>\n",
    "            <h4 style='margin: 0 0 10px 0; color: {border_color};'>{icon} {title}</h4>\n",
    "            <p style='margin: 0 0 15px 0;'>{description}</p>\n",
    "            <table style='width: auto; min-width: 60%; max-width: 100%; border-collapse: collapse; background-color: white; border-radius: 3px; margin: 0;'>\n",
    "                <thead>\n",
    "                    <tr style='background-color: #f8f9fa;'>\n",
    "                        <th style='padding: 10px 15px; text-align: left; border-bottom: 2px solid #dee2e6; font-weight: bold; width: 20%; min-width: 100px;'>Variable</th>\n",
    "                        <th style='padding: 10px 15px; text-align: left; border-bottom: 2px solid #dee2e6; font-weight: bold; width: 80%;'>Missing Items</th>\n",
    "                    </tr>\n",
    "                </thead>\n",
    "                <tbody>\n",
    "        \"\"\"\n",
    "        \n",
    "        for var_name, missing_items in missing_data.items():\n",
    "            items_str = \", \".join(missing_items)\n",
    "            html += f\"\"\"\n",
    "                    <tr>\n",
    "                        <td style='padding: 10px 15px; border-bottom: 1px solid #dee2e6; vertical-align: top; font-weight: 500; white-space: nowrap;'>{var_name}</td>\n",
    "                        <td style='padding: 10px 15px; border-bottom: 1px solid #dee2e6; line-height: 1.4; word-wrap: break-word;'>{items_str}</td>\n",
    "                    </tr>\n",
    "            \"\"\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "                </tbody>\n",
    "            </table>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        return html\n",
    "    \n",
    "    def _create_simple_error_list(self, errors, title, error_type):\n",
    "        \"\"\"Create a simple list for other types of errors\"\"\"\n",
    "        if error_type == \"error\":\n",
    "            border_color = \"#dc3545\"\n",
    "            bg_color = \"#f8d7da\"\n",
    "            icon = \"\"\n",
    "        elif error_type == \"warning\":\n",
    "            border_color = \"#ffc107\"\n",
    "            bg_color = \"#fff3cd\"\n",
    "            icon = \"\"\n",
    "        else:\n",
    "            border_color = \"#17a2b8\"\n",
    "            bg_color = \"#d1ecf1\"\n",
    "            icon = \"\"\n",
    "        \n",
    "        html = f\"\"\"\n",
    "        <div style='margin: 10px 0; padding: 15px; background-color: {bg_color}; border-left: 4px solid {border_color}; border-radius: 5px;'>\n",
    "            <h4 style='margin: 0 0 10px 0; color: {border_color};'>{icon} {title}</h4>\n",
    "            <ul style='margin: 0; padding-left: 20px;'>\n",
    "        \"\"\"\n",
    "        \n",
    "        for error in errors:\n",
    "            html += f\"<li style='margin: 5px 0;'>{error}</li>\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "            </ul>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        return html\n",
    "                   \n",
    "    def display(self):\n",
    "        \"\"\"Display the visualization interface\"\"\"\n",
    "        # Get widgets from selector - this returns a tuple of widgets\n",
    "        input_widgets_tuple = self.selector.display_widgets()\n",
    "        \n",
    "        # Create a proper VBox to contain the input widgets\n",
    "        # This ensures they render as widgets rather than as text representation\n",
    "        sel_input_widget = widgets.VBox(\n",
    "            children=input_widgets_tuple,\n",
    "            layout=widgets.Layout(\n",
    "                height='400px',\n",
    "                margin='0px',\n",
    "                overflow='hidden',\n",
    "                padding='0px',\n",
    "                width='375px'\n",
    "            )\n",
    "        )\n",
    "            \n",
    "        # Create label and update section\n",
    "        label_box = widgets.VBox([\n",
    "                widgets.HTML(value=\"<u>Update Labels (optional):</u>\"),\n",
    "                self.selector.label_widgets_container,\n",
    "                self.selector.update_label_button,\n",
    "                self.selector.message_output_label],\n",
    "            layout=widgets.Layout(\n",
    "                width='620px',\n",
    "                max_height='400px',\n",
    "                max_width = \"620px\",\n",
    "                overflow='auto',\n",
    "                padding='0px',\n",
    "                margin='0px 0'\n",
    "            )\n",
    "        )\n",
    "        \"\"\"\n",
    "        # Display Step 1: Upload Data\n",
    "        display(self.stepone_status_output)\n",
    "        display(self.data_transformer.upload_widgets)\n",
    "        \n",
    "        # Display Step 2: Plot Controls\n",
    "        display(self.steptwo_status_output)\n",
    "        display(widgets.HTML(\"<h3><u>Plot Controls:</u></h3>\"))\n",
    "        display(widgets.HBox([sel_input_widget, label_box],\n",
    "            layout=widgets.Layout(width='1000px',\n",
    "                                   height='400px',\n",
    "                                   overflow='auto',\n",
    "                                   padding='0px',\n",
    "                                   margin='0px 0px')\n",
    "        ))\n",
    "        \n",
    "        # Display reorder samples section (part of Step 2)\n",
    "        display(self.selector.update_order_initial_layout)\n",
    "        \n",
    "        # Display Step 3: Plotting Options\n",
    "        display(self.stepthree_status_output)\n",
    "        \n",
    "        # Display plot layout and output\n",
    "        display(self.app.get_layout())\n",
    "        display(self.app.plot_output)\"\"\"\n",
    "        # Create the VBox container with your widgets\n",
    "        vbox_container = widgets.VBox([\n",
    "            self.stepone_status_output,\n",
    "            self.data_transformer.upload_widgets,\n",
    "            self.steptwo_status_output,\n",
    "            widgets.HBox(\n",
    "                [sel_input_widget, label_box],\n",
    "                layout=widgets.Layout(\n",
    "                    width='1000px',\n",
    "                    height='400px',\n",
    "                    overflow='auto',\n",
    "                    padding='0px',\n",
    "                    margin='0px 0px'\n",
    "                )\n",
    "            ),\n",
    "            self.selector.update_order_initial_layout,\n",
    "            self.stepthree_status_output,\n",
    "            self.app.get_layout()\n",
    "        ], layout=widgets.Layout(\n",
    "            width='1000px',\n",
    "            max_width='1000px',\n",
    "            height='auto',\n",
    "            overflow='hidden'\n",
    "        ))\n",
    "\n",
    "        # Display the VBox container\n",
    "        display(vbox_container)\n",
    "        \n",
    "        display(self.app.plot_output)\n",
    "\n",
    "    def _check_required_data(self):\n",
    "        \"\"\"Check if we have the minimum required data to proceed\"\"\"\n",
    "        has_merged = (hasattr(self.data_transformer, 'merged_df') and \n",
    "                     isinstance(self.data_transformer.merged_df, pd.DataFrame) and \n",
    "                     not self.data_transformer.merged_df.empty)\n",
    "        \n",
    "        has_groups = (hasattr(self.data_transformer, 'group_data_dict') and \n",
    "                     isinstance(self.data_transformer.group_data_dict, dict) and \n",
    "                     len(self.data_transformer.group_data_dict) > 0)\n",
    "        \n",
    "        has_proteins = (hasattr(self.data_transformer, 'protein_dict') and \n",
    "                       isinstance(self.data_transformer.protein_dict, dict) and \n",
    "                       len(self.data_transformer.protein_dict) > 0)\n",
    "        has_fasta_files = self.data_transformer.fasta_file_uploaded_placeholder\n",
    "\n",
    "        has_uniprot_search = self.data_transformer.uniprot_search.value\n",
    "\n",
    "        return has_merged, has_groups, has_proteins, has_fasta_files, has_uniprot_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b17d3e7-714c-44ed-b3f8-e6e191cb2228",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeatmapPlotHandler:\n",
    "    def __init__(self, data_transformer):\n",
    "        self.data_transformer = data_transformer\n",
    "        self.selector = None  # Initialize to None, will be set later\n",
    "        # Initialize other attributes\n",
    "        self.ms_average_choice = 'yes'\n",
    "        self.bio_or_pep = 'no'\n",
    "        self.selected_bio_or_pep = []\n",
    "        self.selected_functions = []\n",
    "        self.selected_peptides = []\n",
    "        self.plot_heatmap = 'yes'\n",
    "        self.plot_zero = 'no'\n",
    "        self.plot_output = widgets.Output()\n",
    "\n",
    "        # Create plotting widgets\n",
    "        self.create_plotting_widgets()\n",
    "        self.display_plotting_options()\n",
    "        \n",
    "        # Attach observers to its own widgets\n",
    "        self.peptide_filter_radio.observe(self.on_filter_type_change, names='value')\n",
    "        self.ms_average_choice_dropdown.observe(self.on_dropdown_change, names='value')\n",
    "        self.specific_select_multiple.observe(self.on_dropdown_change, names='value')\n",
    "        self.bio_or_pep_dropdown.observe(self.on_selection_change, names='value')\n",
    "        self.bio_or_pep_dropdown.observe(self.on_bio_or_pep_change, names='value')\n",
    "        self.bio_or_pep_dropdown.observe(self.on_dropdown_change, names='value')\n",
    "        self.log_transform_checkbox.observe(self._on_log_transform_change, names='value')\n",
    "        # Attach button click events\n",
    "        self.update_button.on_click(self.on_update_plot_clicked)\n",
    "        self.save_button.on_click(self.on_save_plot_clicked)\n",
    "\n",
    "        self._data_change_observer_registered = False\n",
    "        \n",
    "        # Initialize callback reference\n",
    "        self._on_data_changed_callback = None\n",
    "    \n",
    "    # 2. Add this new method to HeatmapPlotHandler:\n",
    "\n",
    "    def _on_log_transform_change(self, change):\n",
    "        \"\"\"Handle log transform checkbox changes and update y-axis label automatically\"\"\"\n",
    "        if change['new']:  # Log transform enabled\n",
    "            # Update y-axis label to include log10 notation\n",
    "            if hasattr(self, 'yaxis_label_input'):\n",
    "                current_label = self.yaxis_label_input.value\n",
    "                # Only add log10 notation if it's not already there\n",
    "                if \"log\" not in current_label and \"log10\" not in current_label:\n",
    "                    self.yaxis_label_input.value = f\"log(Averaged Peptide Absorbance)\"\n",
    "        else:  # Log transform disabled\n",
    "            # Reset to default y-axis label\n",
    "            if hasattr(self, 'yaxis_label_input'):\n",
    "                self.yaxis_label_input.value = \"Averaged Peptide Absorbance\"\n",
    "                \n",
    "    def on_bio_or_pep_change(self, change):\n",
    "        \"\"\"Handle bio_or_pep dropdown changes and refresh specific options.\"\"\"\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            self.bio_or_pep = change['new']\n",
    "            # Immediately refresh the specific options when bio_or_pep changes\n",
    "            self._refresh_specific_options()    \n",
    "                \n",
    "    def _refresh_specific_options(self):\n",
    "        \"\"\"Refresh the specific options based on current data and bio_or_pep selection.\"\"\"\n",
    "        # Early return if essential components are missing\n",
    "        if (not hasattr(self, 'available_data_variables_dict') or \n",
    "            not self.available_data_variables_dict or\n",
    "            not hasattr(self, 'specific_select_multiple')):\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Store current selection to preserve it if still valid\n",
    "            current_selection = list(self.specific_select_multiple.value) if hasattr(self.specific_select_multiple, 'value') else []\n",
    "            \n",
    "            # Initialize containers for unique values\n",
    "            unique_functions = set()\n",
    "            unique_peptides = set()\n",
    "\n",
    "            # Aggregate unique functions and peptides from ALL available data variables\n",
    "            for var in self.available_data_variables_dict:\n",
    "                # Process function data for this variable\n",
    "                if 'function_heatmap_df' in self.available_data_variables_dict[var]:\n",
    "                    df = self.available_data_variables_dict[var]['function_heatmap_df']\n",
    "                    if df is not None and not df.empty:\n",
    "                        df_copy = df.copy()\n",
    "                        df_copy.replace('0', 0, inplace=True)\n",
    "                        \n",
    "                        # Extract all functions\n",
    "                        for col in df_copy.columns:\n",
    "                            for cell in df_copy[col]:\n",
    "                                if pd.notna(cell) and cell != 0:\n",
    "                                    cell_str = str(cell)\n",
    "                                    if ';' in cell_str:\n",
    "                                        unique_functions.update([f.strip() for f in cell_str.split(';')])\n",
    "                                    else:\n",
    "                                        unique_functions.add(cell_str)\n",
    "                \n",
    "                # Process heatmap data for peptide intervals\n",
    "                if 'heatmap_df' in self.available_data_variables_dict[var]:\n",
    "                    heatmap_df = self.available_data_variables_dict[var]['heatmap_df']\n",
    "                    if heatmap_df is not None and not heatmap_df.empty:\n",
    "                        columns_with_data = []\n",
    "                        for col in heatmap_df.columns:\n",
    "                            if col not in ['AA', 'count', 'average']:  # Skip metadata columns\n",
    "                                col_data = heatmap_df[col].dropna()\n",
    "                                if not col_data.empty:\n",
    "                                    try:\n",
    "                                        numeric_data = pd.to_numeric(col_data, errors='coerce').dropna()\n",
    "                                        if not numeric_data.empty and numeric_data.sum() != 0:\n",
    "                                            columns_with_data.append(col)\n",
    "                                    except Exception:\n",
    "                                        if (col_data != 0).any():\n",
    "                                            columns_with_data.append(col)\n",
    "                        unique_peptides.update(columns_with_data)\n",
    "            \n",
    "            # Get current bio_or_pep value\n",
    "            current_bio_or_pep = getattr(self, 'bio_or_pep', 'no')\n",
    "            if hasattr(self, 'bio_or_pep_dropdown'):\n",
    "                current_bio_or_pep = self.bio_or_pep_dropdown.value\n",
    "                \n",
    "            # Update widget based on current dropdown choice\n",
    "            if current_bio_or_pep == '1':  # Peptide Intervals\n",
    "                unique_peptides_list = sorted(list(unique_peptides), key=get_interval_start)\n",
    "                new_options = [(peptide, peptide) for peptide in unique_peptides_list]\n",
    "                self.specific_select_multiple.options = new_options\n",
    "                self.specific_select_multiple.disabled = False\n",
    "                \n",
    "                # Preserve valid selections\n",
    "                valid_selection = [item for item in current_selection if item in unique_peptides_list]\n",
    "                self.specific_select_multiple.value = tuple(valid_selection)\n",
    "                \n",
    "            elif current_bio_or_pep == '2':  # Bioactive Functions\n",
    "                unique_functions_list = sorted(list(unique_functions))\n",
    "                new_options = [(function, function) for function in unique_functions_list]\n",
    "                self.specific_select_multiple.options = new_options\n",
    "                self.specific_select_multiple.disabled = False\n",
    "                \n",
    "                # Preserve valid selections\n",
    "                valid_selection = [item for item in current_selection if item in unique_functions_list]\n",
    "                self.specific_select_multiple.value = tuple(valid_selection)\n",
    "                \n",
    "            else:  # 'no' option\n",
    "                self.specific_select_multiple.options = []\n",
    "                self.specific_select_multiple.value = ()\n",
    "                self.specific_select_multiple.disabled = True\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Handle any errors during option refresh\n",
    "            print(f\"Error refreshing specific options: {e}\")  # Enable for debugging\n",
    "            pass\n",
    "\n",
    "    def on_data_change_observer(self, change=None):\n",
    "        \"\"\"Observer method called when data selections change (groups/proteins).\"\"\"\n",
    "        try:\n",
    "            # Update the available data reference\n",
    "            if (hasattr(self, 'data_handler') and self.data_handler and \n",
    "                hasattr(self.data_handler, 'selector') and self.data_handler.selector and\n",
    "                hasattr(self.data_handler.selector, 'available_data_variables_dict')):\n",
    "                self.available_data_variables_dict = self.data_handler.selector.available_data_variables_dict\n",
    "            \n",
    "            # Only refresh if we have the necessary widgets and data\n",
    "            if (hasattr(self, 'specific_select_multiple') and \n",
    "                hasattr(self, 'available_data_variables_dict') and \n",
    "                self.available_data_variables_dict):\n",
    "                # Refresh the specific options based on new data\n",
    "                self._refresh_specific_options()\n",
    "        except Exception as e:\n",
    "            # Silently handle errors to prevent widget update failures\n",
    "            # You can uncomment the print below for debugging\n",
    "            # print(f\"Observer error: {e}\")\n",
    "            pass\n",
    "\n",
    "\n",
    "    def refresh_specific_options_external(self):\n",
    "        \"\"\"External method to refresh specific options from data handler\"\"\"\n",
    "        if hasattr(self, '_refresh_specific_options'):\n",
    "            self._refresh_specific_options()\n",
    "\n",
    "    def set_data_handler(self, data_handler):\n",
    "        \"\"\"Set the reference to the data handler\"\"\"\n",
    "        self.data_handler = data_handler\n",
    "        \n",
    "        # Set the callback BEFORE updating available_data_variables_dict\n",
    "        self.available_data_variables_dict = data_handler.selector.available_data_variables_dict\n",
    "        \n",
    "        # Set up bidirectional reference\n",
    "        data_handler._plot_handler = self\n",
    "        \n",
    "        # Connect to the selector\n",
    "        if hasattr(data_handler, 'selector') and data_handler.selector:\n",
    "            self.selector = data_handler.selector\n",
    "            \n",
    "            # IMPORTANT: Set up the callback for data changes\n",
    "            self.selector._on_data_changed_callback = self.refresh_specific_options_external\n",
    "            \n",
    "            # Connect observers for protein and variable selection changes\n",
    "            if hasattr(self.selector, 'protein_selector'):\n",
    "                self.selector.protein_selector.observe(self.add_group_change, names='value')\n",
    "                # ADD: Observer for specific options refresh\n",
    "                self.selector.protein_selector.observe(self.on_selection_data_change, names='value')\n",
    "                \n",
    "            if hasattr(self.selector, 'var_key_dropdown'):\n",
    "                self.selector.var_key_dropdown.observe(self.add_group_change, names='value')  \n",
    "                # ADD: Observer for specific options refresh\n",
    "                self.selector.var_key_dropdown.observe(self.on_selection_data_change, names='value')\n",
    "\n",
    "    \n",
    "    def on_selection_data_change(self, change):\n",
    "        \"\"\"Called when protein or variable selections change.\"\"\"\n",
    "        \n",
    "        # Refresh specific options after data has been updated\n",
    "        if hasattr(self, 'available_data_variables_dict') and self.available_data_variables_dict:\n",
    "            self._refresh_specific_options()\n",
    "            \n",
    "    def add_group_change(self, change=None):\n",
    "        # Only enable widgets if there are valid selections\n",
    "        if (hasattr(self.selector, 'protein_selector') and \n",
    "            hasattr(self.selector, 'var_key_dropdown') and\n",
    "            self.selector.protein_selector.value and \n",
    "            len(self.selector.protein_selector.value) > 0 and\n",
    "            self.selector.var_key_dropdown.value and \n",
    "            len(self.selector.var_key_dropdown.value) > 0):\n",
    "            \n",
    "            # Enable specific widgets\n",
    "            self.ms_average_choice_dropdown.disabled = False\n",
    "            self.bio_or_pep_dropdown.disabled = False\n",
    "            self.specific_select_multiple.disabled = False\n",
    "            self.log_transform_checkbox.disabled = False\n",
    "            self.plot_orientation.disabled = False\n",
    "            self.peptide_filter_radio.disabled = False\n",
    "            self.update_button.disabled = False\n",
    "            self.legend_title_input_1.disabled = False\n",
    "            self.legend_title_input_2.disabled = False\n",
    "            self.legend_title_input_3.disabled = False\n",
    "            self.xaxis_label_input.disabled = False\n",
    "            self.yaxis_label_input.disabled = False\n",
    "            self.yaxis_position.disabled = False\n",
    "            self.manual_y_axis_checkbox.disabled = False\n",
    "            self.hm_selected_color.disabled = False\n",
    "            self.lp_selected_color.disabled = False\n",
    "            self.avglp_selected_color.disabled = False\n",
    "\n",
    "            self.update_button.disabled = False\n",
    "\n",
    "    def on_selection_change(self, change):\n",
    "        \"\"\"Handle changes in selection with numerically sorted peptide intervals.\"\"\"\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            self.bio_or_pep = self.bio_or_pep_dropdown.value\n",
    "            self._refresh_specific_options()\n",
    "\n",
    "        \n",
    "            # Initialize containers for unique values\n",
    "            unique_functions = set()\n",
    "            unique_peptides = set()\n",
    "\n",
    "            # Aggregate unique functions and peptides from ALL available data variables\n",
    "            for var in self.available_data_variables_dict:\n",
    "                # Process function data for this variable\n",
    "                df = self.available_data_variables_dict[var]['function_heatmap_df']\n",
    "                df.replace('0', 0, inplace=True)  # Standardize zero representations\n",
    "                unique_functions.update(extract_non_zero_non_nan_values(df))\n",
    "                \n",
    "                # Process absorbance data for peptide intervals for this variable\n",
    "                abs_df = self.available_data_variables_dict[var]['heatmap_df']\n",
    "                # First, get all non-special columns\n",
    "                potential_peptide_columns = [col for col in abs_df.columns \n",
    "                                            if col not in ['AA', 'count', 'average']]\n",
    "                \n",
    "                # Convert all potential columns to numeric at once\n",
    "                numeric_df = abs_df[potential_peptide_columns].apply(pd.to_numeric, errors='coerce')\n",
    "                \n",
    "                # Find columns with any non-zero values for this variable\n",
    "                columns_with_data = numeric_df.columns[(numeric_df != 0).any()].tolist()\n",
    "                #print(f\" DEBUG: var={var}, columns_with_data: {columns_with_data}\")\n",
    "\n",
    "                # Update unique_peptides with intervals from this variable\n",
    "                unique_peptides.update(columns_with_data)    \n",
    "            \n",
    "            # Update widget based on dropdown choice\n",
    "            if self.bio_or_pep == '1':  # Peptide Intervals\n",
    "                # Convert to list and sort by the first number in the interval\n",
    "                unique_peptides_list = sorted(list(unique_peptides), key=get_interval_start)\n",
    "                #print(f\" DEBUG: unique_peptides_list: {unique_peptides_list}\")\n",
    "                self.specific_select_multiple.options = [(peptide, peptide) for peptide in unique_peptides_list]\n",
    "                self.specific_select_multiple.disabled = False  # Enable the widget\n",
    "                #self.specific_select_multiple.layout.display = 'block'  # Make it visible\n",
    "                \n",
    "            elif self.bio_or_pep == '2':  # Bioactive Functions\n",
    "                unique_functions_list = sorted(list(unique_functions))\n",
    "                self.specific_select_multiple.options = [(function, function) for function in unique_functions_list]\n",
    "                self.specific_select_multiple.disabled = False  # Enable the widget\n",
    "                #self.specific_select_multiple.layout.display = 'block'  # Make it visible\n",
    "                \n",
    "            else:  # 'no' option\n",
    "                self.specific_select_multiple.options = [\"\"]\n",
    "                self.specific_select_multiple.disabled = True  # Disable the widget\n",
    "                #self.specific_select_multiple.layout.display = 'none'  # Hide it \n",
    "\n",
    "    def display_plotting_options(self):\n",
    "        dropdown_layout = widgets.Layout(width='90%')\n",
    "        self.plot_message = widgets.HTML(\"<h3><u>Visualization Settings</u></h3>\")\n",
    "\n",
    "        # Create the description label\n",
    "        description_label = f'Plot Filter:  \\n\\n'\n",
    "\n",
    "        # Add radio buttons for peptide filtering\n",
    "        self.peptide_filter_radio = widgets.RadioButtons(\n",
    "            options=[('All Peptides', 'all-peptides'), \n",
    "                    ('All Functional Peptides', 'bioactive-only'),\n",
    "                    ('Selected Functional Peptides', 'functional-only')],\n",
    "            value='all-peptides',  # default value\n",
    "            description=description_label,\n",
    "            disabled=True,  # Start disabled\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=dropdown_layout\n",
    "        )\n",
    "\n",
    "        self.ms_average_choice_dropdown = widgets.Dropdown(\n",
    "            options=['yes', 'no', 'only'],\n",
    "            description='Plot Averaged Data:',\n",
    "            value='yes',\n",
    "            disabled=True,  # Start disabled\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=dropdown_layout,\n",
    "        )\n",
    "        \n",
    "        self.ms_average_choice = self.ms_average_choice_dropdown.value\n",
    "        \n",
    "        self.bio_or_pep_dropdown = widgets.Dropdown(\n",
    "            options=[('None', 'no'), ('Peptide Intervals', '1'), ('Bioactive Functions', '2')],\n",
    "            description='Plot Specific Peptides:',\n",
    "            disabled=True,  # Start disabled\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=dropdown_layout,\n",
    "        )\n",
    "        \n",
    "        self.specific_select_multiple = widgets.SelectMultiple(\n",
    "            options=[],\n",
    "            description='Specific Options:',\n",
    "            disabled=True,  # Start disabled\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='90%')  \n",
    "        )\n",
    "\n",
    "        self.log_transform_checkbox = widgets.Checkbox(\n",
    "            value=False,\n",
    "            description='Log Transform Y-axis:',\n",
    "            disabled=True,  # Start disabled\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='90%')  \n",
    "        )\n",
    "\n",
    "    def update_legend_widget(self):\n",
    "        # Determine which legend title to use for input 3\n",
    "        if self.bio_or_pep == '1':  # Peptide intervals\n",
    "            title_index = 3  # Use legend title for peptide intervals\n",
    "        elif self.bio_or_pep == '2':  # Bioactive functions\n",
    "            title_index = 2  # Use legend title for bioactive functions\n",
    "        else:  # bio_or_pep == 'no' or any other case\n",
    "            title_index = 4  # Use legend title for average\n",
    "        \n",
    "        # Update input 3\n",
    "        title_text = legend_title[title_index]\n",
    "        self.legend_title_input_3.value = title_text\n",
    "        self.legend_title_input_3.description = f'Legend title ({title_text})'\n",
    "\n",
    "        # Show/hide input 3 based on conditions\n",
    "        if ((self.ms_average_choice == 'yes' and self.bio_or_pep == 'no') or\n",
    "            (self.ms_average_choice == 'only')):\n",
    "            # For average only, show input 3 with average title\n",
    "            self.legend_title_input_3.value = legend_title[4]  # Average title\n",
    "            self.legend_title_input_3.description = f'Legend title ({legend_title[4]})'\n",
    "        elif (self.ms_average_choice == 'no' and self.bio_or_pep == '2'):\n",
    "            # For bioactive functions only, show input 3 with function title\n",
    "\n",
    "            self.legend_title_input_3.value = legend_title[2]  # Function title\n",
    "            self.legend_title_input_3.description = f'Legend title ({legend_title[2]})'\n",
    "        elif (self.ms_average_choice == 'no' and self.bio_or_pep == '1'):\n",
    "            # For peptide intervals only, show input 3 with interval title\n",
    "            self.legend_title_input_3.value = legend_title[3]  # Interval title\n",
    "            self.legend_title_input_3.description = f'Legend title ({legend_title[3]})'\n",
    "        elif (self.ms_average_choice == 'yes' and self.bio_or_pep == '1'):\n",
    "            # For peptide intervals with average\n",
    "            self.legend_title_input_3.value = legend_title[3]  # Interval title\n",
    "            self.legend_title_input_3.description = f'Legend title ({legend_title[3]})'\n",
    "        elif (self.ms_average_choice == 'yes' and self.bio_or_pep == '2'):\n",
    "            # For bioactive functions with average\n",
    "            self.legend_title_input_3.value = legend_title[2]  # Function title\n",
    "            self.legend_title_input_3.description = f'Legend title ({legend_title[2]})'\n",
    "\n",
    "    def _on_manual_y_axis_change(self, change):\n",
    "        \"\"\"Handle manual y-axis checkbox changes\"\"\"\n",
    "        if change['new']:  # Manual scaling enabled\n",
    "            self.y_min_input.disabled = False\n",
    "            self.y_max_input.disabled = False\n",
    "            # Set reasonable default values if available data exists\n",
    "            self._update_manual_y_axis_defaults()\n",
    "        else:  # Manual scaling disabled\n",
    "            self.y_min_input.disabled = True\n",
    "            self.y_max_input.disabled = True\n",
    "            \n",
    "    def _update_manual_y_axis_defaults(self):\n",
    "        \"\"\"Update the default values for manual y-axis inputs based on current data\"\"\"\n",
    "        import numpy as np\n",
    "        try:\n",
    "            if hasattr(self, 'available_data_variables_dict') and self.available_data_variables_dict:\n",
    "                # Extract min and max values from the current data\n",
    "                min_values = []\n",
    "                max_values = []\n",
    "                \n",
    "                for var_data in self.available_data_variables_dict.values():\n",
    "                    if 'bioactive_peptide_abs_df' in var_data:\n",
    "                        df = var_data['bioactive_peptide_abs_df']\n",
    "                        # Get numeric columns only\n",
    "                        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "                        if len(numeric_cols) > 0:\n",
    "                            df_numeric = df[numeric_cols]\n",
    "                            # Filter out zeros and negative values for better defaults\n",
    "                            df_positive = df_numeric[df_numeric > 0]\n",
    "                            if not df_positive.empty:\n",
    "                                min_values.append(df_positive.min().min())\n",
    "                                max_values.append(df_positive.max().max())\n",
    "                \n",
    "                if min_values and max_values:\n",
    "                    overall_min = min(min_values)\n",
    "                    overall_max = max(max_values)\n",
    "                    \n",
    "                    # Set defaults with some padding\n",
    "                    self.y_min_input.value = overall_min * 0.9  # 10% below minimum\n",
    "                    self.y_max_input.value = overall_max * 1.1  # 10% above maximum\n",
    "                else:\n",
    "                    # Fallback defaults\n",
    "                    self.y_min_input.value = 0.0\n",
    "                    self.y_max_input.value = 1.0\n",
    "            else:\n",
    "                # No data available, use defaults\n",
    "                self.y_min_input.value = 0.0\n",
    "                self.y_max_input.value = 1.0\n",
    "        except Exception as e:\n",
    "            # In case of any error, use safe defaults\n",
    "            self.y_min_input.value = 0.0\n",
    "            self.y_max_input.value = 1.0\n",
    "\n",
    "    def create_plotting_widgets(self):\n",
    "        # Generate filenames\n",
    "        #generate_filenames(self)\n",
    "\n",
    "        # Layouts\n",
    "        #description_layout_invisible = widgets.Layout(width='90%', overflow = 'visible')\n",
    "        description_layout = widgets.Layout(width='80%', overflow = 'visible')\n",
    "        dropdown_layout = widgets.Layout(width='50%', overflow = 'visible')\n",
    "        #dropdown_layout_large = widgets.Layout(width='90%', overflow = 'visible')\n",
    "\n",
    "        # Color Widgets\n",
    "        self.hm_selected_color = widgets.Dropdown(\n",
    "            options=valid_gradient_cmaps,\n",
    "            value=default_hm_color,\n",
    "            description='Heatmap:',\n",
    "            disabled=True,  # Start disabled\n",
    "            layout=dropdown_layout,\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "\n",
    "        self.lp_selected_color = widgets.Dropdown(\n",
    "            options=valid_discrete_cmaps,\n",
    "            value=default_lp_color,\n",
    "            description='Line Plot:',\n",
    "            disabled=True,  # Start disabled\n",
    "            layout=dropdown_layout,\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "\n",
    "        self.avglp_selected_color = widgets.Dropdown(\n",
    "            options=valid_discrete_cmaps,\n",
    "            disabled=True,  # Start disabled\n",
    "            value=default_avglp_color,\n",
    "            description='Avg Line Plot:',\n",
    "            layout=dropdown_layout,\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "\n",
    "        self.color_message = widgets.HTML(\"<h3><u>Appearance Settings:</u></h3>\")\n",
    "        \n",
    "        self.color_widget_box = widgets.VBox([\n",
    "            self.color_message,\n",
    "            self.hm_selected_color,\n",
    "            self.lp_selected_color,\n",
    "            self.avglp_selected_color\n",
    "        ])\n",
    "                \n",
    "        #  Get protein name directly from class instance\n",
    "        x_label = f\"{self.protein_name_short} Sequence\" if hasattr(self, 'protein_name_short') else \"Protein Sequence\"\n",
    "        \n",
    "        # Figure Label Widgets\n",
    "        self.xaxis_label_input = widgets.Text(\n",
    "            value=x_label,\n",
    "            description='x-axis label:',\n",
    "            disabled=True,  # Start disabled\n",
    "            layout=description_layout,\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "\n",
    "        def update_x_label():\n",
    "            if hasattr(self.data_transformer, 'protein_name_short'):\n",
    "                new_label = f\"{self.data_transformer.protein_name_short} Sequence\"\n",
    "                self.xaxis_label_input.value = new_label\n",
    "\n",
    "        # Set up observer for selector changes\n",
    "        if hasattr(self.data_transformer, 'observe'):\n",
    "            self.data_transformer.observe(lambda change: update_x_label(), names=['protein_name_short'])\n",
    "\n",
    "            \n",
    "        self.legend_title_input_1 = widgets.Text(\n",
    "            value=legend_title[0],  # Will be set dynamically\n",
    "            description=f'Legend title ({legend_title[0]}):',\n",
    "            layout=description_layout,\n",
    "            style={'description_width': 'initial'},\n",
    "            disabled=True  # Start disabled\n",
    "        )\n",
    "        \n",
    "        self.legend_title_input_2 = widgets.Text(\n",
    "            value=legend_title[1],\n",
    "            disabled=True,  # Start disabled\n",
    "            description=f'Legend title ({legend_title[1]}):',\n",
    "            layout=description_layout,\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.legend_title_input_3 = widgets.Text(\n",
    "            value=legend_title[4], # avera\n",
    "            disabled=True,  # Start disabled\n",
    "            description=f'Legend title ({legend_title[4]}):',\n",
    "            layout=description_layout,\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "\n",
    "        self.yaxis_label_input = widgets.Text(\n",
    "            value=\"Averaged Peptide Absorbance\",\n",
    "            description='y-axis label:',\n",
    "            disabled=True,  # Start disabled\n",
    "            layout=description_layout,\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "\n",
    "        self.yaxis_position = widgets.IntSlider(\n",
    "            value=0,\n",
    "            min=-10,\n",
    "            max=10,\n",
    "            step=1,\n",
    "            layout=description_layout,\n",
    "            disabled=True,  # Start disabled\n",
    "            description='y-axis title position:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Manual Y-axis scaling widgets\n",
    "        self.manual_y_axis_checkbox = widgets.Checkbox(\n",
    "            value=False,\n",
    "            description='Manual Y-axis scaling',\n",
    "            disabled=True,  # Start disabled\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.y_min_input = widgets.FloatText(\n",
    "            value=0.0,\n",
    "            description='Y-axis min:',\n",
    "            disabled=True,  # Start disabled\n",
    "            layout=description_layout,\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.y_max_input = widgets.FloatText(\n",
    "            value=1.0,\n",
    "            description='Y-axis max:',\n",
    "            disabled=True,  # Start disabled\n",
    "            layout=description_layout,\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Set up observer for manual y-axis checkbox\n",
    "        self.manual_y_axis_checkbox.observe(self._on_manual_y_axis_change, names='value')\n",
    "        \n",
    "        self.plot_port = widgets.Checkbox(\n",
    "            value=False,\n",
    "            description='Plot Portrait Graph',\n",
    "            disabled=True,\n",
    "            icon='check',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "\n",
    "        self.plot_land = widgets.Checkbox(\n",
    "            value=True,\n",
    "            description='Plot Landscape Graph',\n",
    "            disabled=False,\n",
    "            icon='check',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "            \n",
    "        self.plot_orientation = widgets.RadioButtons(\n",
    "            description='Plot Orientation:',\n",
    "            options=['Landscape', 'Portrait'],\n",
    "            value='Landscape',  # Default selection\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px', height='auto'),\n",
    "            disabled=True,\n",
    "            indent=True  # Keeps options aligned with description instead of appearing below\n",
    "        )\n",
    "        self.figure_label_box = widgets.VBox([\n",
    "            #self.figure_label_message,\n",
    "            self.xaxis_label_input,\n",
    "            self.yaxis_label_input,\n",
    "            self.yaxis_position,\n",
    "            self.manual_y_axis_checkbox,\n",
    "            self.y_min_input,\n",
    "            self.y_max_input,\n",
    "            self.legend_title_input_1,\n",
    "            self.legend_title_input_2,\n",
    "            self.legend_title_input_3,\n",
    "        ], layout=widgets.Layout(\n",
    "        width='500px',\n",
    "        #height='370px', # with plot_toggle_widget\n",
    "        height='300px',  # Increased height to accommodate new widgets\n",
    "        margin='0px')\n",
    "        )\n",
    "\n",
    "        # Add buttons for update and save plot\n",
    "        self.update_button = widgets.Button(\n",
    "            description='Generate/Update',\n",
    "            button_style='success',\n",
    "            tooltip='Click to update the plot',\n",
    "            disabled=True,\n",
    "            icon='refresh'\n",
    "        )\n",
    "\n",
    "        self.save_button = widgets.Button(\n",
    "            description='Save Plot',\n",
    "            button_style='info',\n",
    "            tooltip='Click to save the plot',\n",
    "            icon='save',\n",
    "            disabled = True\n",
    "        )\n",
    "\n",
    "        self.update_save_box = widgets.HBox([self.update_button, self.save_button], layout=widgets.Layout(width='300px'))\n",
    "\n",
    "        self.legend_title_input_1.disabled = True\n",
    "        self.legend_title_input_2.disabled = True\n",
    "        self.legend_title_input_3.disabled = True\n",
    "\n",
    "    def on_dropdown_change(self, change):\n",
    "        self.ms_average_choice = self.ms_average_choice_dropdown.value\n",
    "        self.bio_or_pep = self.bio_or_pep_dropdown.value\n",
    "        if self.bio_or_pep != 'no':\n",
    "            self.selected_bio_or_pep = self.specific_select_multiple.value\n",
    "        else:\n",
    "            self.selected_bio_or_pep = []\n",
    "\n",
    "        if self.bio_or_pep != 'no' and self.selected_bio_or_pep:\n",
    "            self.selected_peptides, self.selected_functions = proceed_with_label_specific_options(self.selected_bio_or_pep, self.bio_or_pep)\n",
    "        else:\n",
    "            self.selected_peptides, self.selected_functions = [], []\n",
    "\n",
    "        self.update_legend_widget()\n",
    "\n",
    "    def extract_non_zero_non_nan_values(df):\n",
    "        unique_functions = set()\n",
    "        # Iterate over each value in the DataFrame\n",
    "        for value in df.stack().values:  # df.stack() stacks the DataFrame into a Series\n",
    "            if value != 0 and not pd.isna(value):  # Check if value is non-zero and not NaN\n",
    "                if isinstance(value, str):\n",
    "                    # If the value is a string, it could contain multiple delimited entries\n",
    "                    entries = value.split('; ')\n",
    "                    unique_functions.update(entries)\n",
    "                else:\n",
    "                    unique_functions.add(value)\n",
    "        return unique_functions\n",
    "\n",
    "        # Return infinity for invalid formats to put them at the end\n",
    "\n",
    "    def on_filter_type_change(self, change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            # Update the selector's filter type\n",
    "            self.selector.update_filter_type(change['new'])\n",
    "        \n",
    "    def update_data(self, selector):\n",
    "        \"\"\"Update the plot handler with new data from selector\"\"\"\n",
    "        if not selector:\n",
    "            return\n",
    "                \n",
    "        # Update only the essential data structures\n",
    "        essential_attrs = [\n",
    "            'available_data_variables_dict',\n",
    "            'user_protein_id',\n",
    "            'protein_name_short',\n",
    "            'selected_protein'\n",
    "        ]\n",
    "        \n",
    "        for attr in essential_attrs:\n",
    "            if hasattr(selector, attr):\n",
    "                setattr(self, attr, getattr(selector, attr))\n",
    "                # Update x-axis label when protein name changes\n",
    "                if attr == 'protein_name_short' and hasattr(self, 'xaxis_label_input'):\n",
    "                    new_label = f\"{getattr(selector, attr)} Sequence\"\n",
    "                    self.xaxis_label_input.value = new_label\n",
    "                    #print(f\"DEBUG: Updated x-axis label to: {new_label}\")  # Debug print\n",
    "\n",
    "    def update_protein_name(self, new_name):\n",
    "        \"\"\"Update the protein name and x-axis label\"\"\"\n",
    "        self.protein_name_short = new_name\n",
    "        if hasattr(self, 'xaxis_label_input'):\n",
    "            new_label = f\"{new_name} Sequence\" if new_name else \"Protein Sequence\"\n",
    "            self.xaxis_label_input.value = new_label\n",
    "            #print(f\"DEBUG: Updated x-axis label via update_protein_name to: {new_label}\")  # Debug print\n",
    "\n",
    "    def validate_selected_options(self):\n",
    "        \"\"\"\n",
    "        Validate if selected peptide intervals or bioactive functions are available\n",
    "        for the current variable selection. Returns (is_valid, error_messages).\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'available_data_variables_dict') or not self.available_data_variables_dict:\n",
    "            return True, []  # No validation needed if no data\n",
    "        \n",
    "        error_messages = []\n",
    "        \n",
    "        # Check peptide intervals (bio_or_pep == '1')\n",
    "        if self.bio_or_pep == '1' and self.selected_peptides:\n",
    "            unavailable_peptides = []\n",
    "            \n",
    "            for var_name, var_data in self.available_data_variables_dict.items():\n",
    "                # Check which selected peptides are not available in this variable\n",
    "                if 'heatmap_df' in var_data:\n",
    "                    available_columns = var_data['heatmap_df'].columns.tolist()\n",
    "                    for peptide in self.selected_peptides:\n",
    "                        if peptide not in available_columns:\n",
    "                            if peptide not in unavailable_peptides:\n",
    "                                unavailable_peptides.append(peptide)\n",
    "            \n",
    "            if unavailable_peptides:\n",
    "                peptide_list = ', '.join([f\"<b>{p}</b>\" for p in unavailable_peptides])\n",
    "                error_messages.append(\n",
    "                    f\"<b>Peptide Interval Error:</b> The following peptide intervals are not available \"\n",
    "                    f\"for the selected variable(s): {peptide_list}.<br>\"\n",
    "                    f\"These intervals may be available for other variables but not for your current selection.\"\n",
    "                )\n",
    "        \n",
    "        # Check bioactive functions (bio_or_pep == '2')\n",
    "        elif self.bio_or_pep == '2' and self.selected_functions:\n",
    "            unavailable_functions = []\n",
    "            \n",
    "            for var_name, var_data in self.available_data_variables_dict.items():\n",
    "                # Check which selected functions are not available in this variable\n",
    "                if 'function_heatmap_df' in var_data:\n",
    "                    func_df = var_data['function_heatmap_df']\n",
    "                    if func_df is not None and not func_df.empty:\n",
    "                        # Extract all functions present in this variable\n",
    "                        present_functions = set()\n",
    "                        for col in func_df.columns:\n",
    "                            for cell in func_df[col]:\n",
    "                                if pd.notna(cell) and str(cell) != '0':\n",
    "                                    cell_str = str(cell)\n",
    "                                    if ';' in cell_str:\n",
    "                                        present_functions.update(cell_str.split(';'))\n",
    "                                    else:\n",
    "                                        present_functions.add(cell_str)\n",
    "                        \n",
    "                        # Check which selected functions are missing\n",
    "                        for function in self.selected_functions:\n",
    "                            if function not in present_functions:\n",
    "                                if function not in unavailable_functions:\n",
    "                                    unavailable_functions.append(function)\n",
    "            \n",
    "            if unavailable_functions:\n",
    "                function_list = ', '.join([f\"<b>{f}</b>\" for f in unavailable_functions])\n",
    "                error_messages.append(\n",
    "                    f\"<b>Bioactive Function Error:</b> The following bioactive functions are not available \"\n",
    "                    f\"for the selected variable(s): {function_list}.<br>\"\n",
    "                    f\"These functions may be available for other variables but not for your current selection.\"\n",
    "                )\n",
    "        \n",
    "        return len(error_messages) == 0, error_messages\n",
    "                                                    \n",
    "    def on_update_plot_clicked(self, b):\n",
    "        with self.plot_output:\n",
    "            try:\n",
    "                # Clear any existing plots and free memory\n",
    "                self.plot_output.clear_output(wait=True)\n",
    "                plt.close('all')  \n",
    "                \n",
    "                # Reset figure references\n",
    "                self.fig_port = None\n",
    "                self.fig_land = None\n",
    "                self.save_button.disabled = False\n",
    "\n",
    "                # Force garbage collection\n",
    "                if self.plot_orientation.value == 'Landscape':\n",
    "                    self.plot_land.value = True\n",
    "                    self.plot_port.value = False\n",
    "                else:\n",
    "                    self.plot_land.value = False\n",
    "                    self.plot_port.value = True\n",
    "                    \n",
    "                gc.collect()\n",
    "                \n",
    "\n",
    "                \n",
    "                # Validate selected options before plotting\n",
    "                is_valid, error_messages = self.validate_selected_options()\n",
    "                # Note: Validation errors are now handled by the plotting functions themselves\n",
    "                \n",
    "                # Debug print for all variables being passed to update_plot\n",
    "                # print(\n",
    "                #     \"DEBUG: Variables being passed to update_plot:\\n\"\n",
    "                #     f\"available_data_variables_dict: {self.available_data_variables_dict.keys()}\\n\"\n",
    "                #     f\"ms_average_choice: {self.ms_average_choice}\\n\"\n",
    "                #     f\"bio_or_pep: {self.bio_or_pep}\\n\"\n",
    "                #     f\"selected_peptides: {self.selected_peptides}\\n\"\n",
    "                #     f\"selected_functions: {self.selected_functions}\\n\"\n",
    "                #     f\"hm_selected_color: {self.hm_selected_color.value}\\n\"\n",
    "                #     f\"lp_selected_color: {self.lp_selected_color.value}\\n\"\n",
    "                #     f\"avglp_selected_color: {self.avglp_selected_color.value}\\n\"\n",
    "                #     f\"xaxis_label: {self.xaxis_label_input.value}\\n\"\n",
    "                #     f\"yaxis_label: {self.yaxis_label_input.value}\\n\"\n",
    "                #     f\"yaxis_position: {self.yaxis_position.value}\\n\"\n",
    "                #     f\"legend_title_1: {self.legend_title_input_1.value}\\n\"\n",
    "                #     f\"legend_title_2: {self.legend_title_input_2.value}\\n\"\n",
    "                #     f\"legend_title_3: {self.legend_title_input_3.value}\\n\"\n",
    "                #     f\"plot_land: {self.plot_land.value}\\n\"\n",
    "                #     f\"plot_port: {self.plot_port.value}\\n\"\n",
    "                #     f\"filter_type: {self.selector.filter_type}\"\n",
    "                # )\n",
    "                \n",
    "                # Call the update_plot function\n",
    "                self.fig_port, self.fig_land, plot_errors, missing_notifications = update_plot(\n",
    "                    self.available_data_variables_dict, \n",
    "                    self.ms_average_choice, \n",
    "                    self.bio_or_pep, \n",
    "                    self.selected_peptides, \n",
    "                    self.selected_functions, \n",
    "                    self.hm_selected_color.value, \n",
    "                    self.lp_selected_color.value, \n",
    "                    self.avglp_selected_color.value, \n",
    "                    self.xaxis_label_input.value, \n",
    "                    self.yaxis_label_input.value, \n",
    "                    self.yaxis_position.value, \n",
    "                    self.legend_title_input_1.value, \n",
    "                    self.legend_title_input_2.value, \n",
    "                    self.legend_title_input_3.value, \n",
    "                    self.plot_land.value, \n",
    "                    self.plot_port.value,\n",
    "                    self.selector.filter_type,\n",
    "                    self.log_transform_checkbox.value,\n",
    "                    self.manual_y_axis_checkbox.value,\n",
    "                    self.y_min_input.value,\n",
    "                    self.y_max_input.value\n",
    "                )\n",
    "                \n",
    "                # Display any errors that occurred during plotting using consolidated display\n",
    "                if plot_errors:\n",
    "                    # Use the data handler to access the consolidated error method\n",
    "                    if hasattr(self, 'data_handler') and hasattr(self.data_handler, 'consolidate_and_display_errors'):\n",
    "                        self.data_handler.consolidate_and_display_errors(plot_errors)\n",
    "                    else:\n",
    "                        # Fallback to original display if the method is not available\n",
    "                        for error in plot_errors:\n",
    "                            display(HTML(f'<div style=\"color: red; font-weight: bold; margin: 10px 0; padding: 10px; border: 1px solid red; border-radius: 5px; background-color: #ffe6e6;\">'\n",
    "                                        f'{error}'\n",
    "                                        f'</div>'))\n",
    "                # Display only valid figures\n",
    "                if self.fig_port is not None and len(self.fig_port.axes) > 0:\n",
    "                    display(HTML(f'<br><h2>Portrait Averaged Plot:</h2>'))\n",
    "                    display(self.fig_port)\n",
    "\n",
    "                if self.fig_land is not None and len(self.fig_land.axes) > 0:\n",
    "                    display(HTML(f'<br><h2>Landscape Averaged Plot:</h2>'))\n",
    "                    display(self.fig_land)\n",
    "                if missing_notifications:\n",
    "                    notification_html = \"<div style='margin: 15px 0; padding: 15px; background-color: #fff3cd; border: 1px solid #ffeaa7; border-radius: 5px;'>\"\n",
    "                    notification_html += \"<h4 style='color: #856404; margin: 0 0 10px 0;'> Data Availability Information</h4>\"\n",
    "                    notification_html += \"<p style='margin: 0 0 10px 0; color: #856404;'>The following data is not available for some variables but plotting will continue with available data:</p>\"\n",
    "                    notification_html += \"<ul style='margin: 0; color: #856404;'>\"\n",
    "                    for notification in missing_notifications:\n",
    "                        notification_html += f\"<li>{notification}</li>\"\n",
    "                    notification_html += \"</ul></div>\"\n",
    "                    display(HTML(notification_html))\n",
    "            except Exception as e:\n",
    "                # Display error message\n",
    "                display(HTML(f'<br><b style=\"color:red;\">Error generating plots: {str(e)}</b>'))\n",
    "                traceback.print_exc()\n",
    "                \n",
    "            finally:\n",
    "                # Always cleanup\n",
    "                plt.close('all')\n",
    "\n",
    "    def create_download_link(self, fig, filename):\n",
    "        \"\"\"Create a download button for the figure\"\"\"\n",
    "\n",
    "        \n",
    "        # Save figure to a temporary buffer.\n",
    "        buf = BytesIO()\n",
    "        fig.savefig(buf, format='png', dpi=300, bbox_inches='tight')\n",
    "        buf.seek(0)\n",
    "        \n",
    "        # Create the download button\n",
    "        download_button = widgets.Button(\n",
    "            description=f'Download {filename}',\n",
    "            button_style='info',\n",
    "            icon='download'\n",
    "        )\n",
    "        \n",
    "        # Encode the image\n",
    "        b64 = base64.b64encode(buf.read()).decode()\n",
    "        \n",
    "        def on_button_clicked(b):\n",
    "            # Create HTML with download link and click it\n",
    "            download_link = f'<a href=\"data:image/png;base64,{b64}\" download=\"{filename}\" id=\"download_link_{filename}\"></a>'\n",
    "            display(HTML(download_link))\n",
    "            display(HTML(f'''<script>\n",
    "                document.getElementById(\"download_link_{filename}\").click();\n",
    "            </script>'''))\n",
    "        \n",
    "        # Set up the button click handler\n",
    "        download_button.on_click(on_button_clicked)\n",
    "        \n",
    "        # Automatically trigger the click\n",
    "        on_button_clicked(download_button)\n",
    "        \n",
    "        return download_button\n",
    "\n",
    "    def on_save_plot_clicked(self, b):\n",
    "        # Disable the save button temporarily to prevent multiple clicks\n",
    "        b.disabled = True\n",
    "        \n",
    "        try:\n",
    "            with self.plot_output:\n",
    "                if (self.fig_port is None and self.fig_land is None) or \\\n",
    "                    (self.fig_port is not None and len(self.fig_port.axes) == 0 and \n",
    "                    self.fig_land is not None and len(self.fig_land.axes) == 0):\n",
    "                    self.plot_output.clear_output(wait=True)\n",
    "                    display(HTML(\"<div style='display: inline-block; margin: 10px 0;'><b style='color: red'>Please generate plots using the Update/Display button before saving.</b></div>\"))\n",
    "                    b.disabled = False  # Re-enable the button\n",
    "                    return\n",
    "\n",
    "                # Store existing figures before clearing\n",
    "                port_fig = self.fig_port\n",
    "                land_fig = self.fig_land\n",
    "                \n",
    "                # Clear previous output and show loading message\n",
    "                self.plot_output.clear_output(wait=True)\n",
    "                display(HTML(\"<div style='display: inline-block; margin: 10px 0;'><b style='color:blue'>Generating high resolution image for download. Please wait...</b></div>\"))\n",
    "                \n",
    "                # Create filenames\n",
    "                additional_vars = []\n",
    "                if self.plot_heatmap == 'yes':\n",
    "                    additional_vars.append('heatmap')\n",
    "                elif self.plot_heatmap == 'no':\n",
    "                    additional_vars.append('no-heatmap')\n",
    "        \n",
    "                if self.bio_or_pep == '1':\n",
    "                    additional_vars.append('intervals')\n",
    "                elif self.bio_or_pep == '2':\n",
    "                    additional_vars.append('bioactive-functions')\n",
    "                elif self.bio_or_pep == 'no':\n",
    "                    additional_vars.append('averages-only')\n",
    "        \n",
    "                additional_vars_str = '_'.join(additional_vars)\n",
    "                self.protein_filename_short = re.sub(r'[^\\w-]', '-', self.protein_name_short)\n",
    "                self.filename_port = f'portrait_{self.user_protein_id}_{self.protein_filename_short}_average-only'\n",
    "                self.filename_land = f'landscape_{self.user_protein_id}_{self.protein_filename_short}_{additional_vars_str}'\n",
    "\n",
    "                # Create and trigger downloads\n",
    "                download_buttons = []\n",
    "                if port_fig is not None and len(port_fig.axes) > 0:\n",
    "                    port_button = self.create_download_link(port_fig, f\"{self.filename_port}.png\")\n",
    "                    download_buttons.append(port_button)\n",
    "                    \n",
    "                if land_fig is not None and len(land_fig.axes) > 0:\n",
    "                    land_button = self.create_download_link(land_fig, f\"{self.filename_land}.png\")\n",
    "                    download_buttons.append(land_button)\n",
    "                \n",
    "                # Display final content\n",
    "                self.plot_output.clear_output(wait=True)\n",
    "                if download_buttons:\n",
    "                    display(HTML(\"<div style='display: inline-block; margin: 10px 0;'><b style='color:green'>Success! Your plots have been downloaded automatically.</b></div>\"))\n",
    "                    \n",
    "                    if port_fig is not None and len(port_fig.axes) > 0:\n",
    "                        #display(HTML(f'<br><h2>Portrait Averaged Plot:</h2>'))\n",
    "                        display(port_fig)\n",
    "                        \n",
    "                    if land_fig is not None and len(land_fig.axes) > 0:\n",
    "                        #display(HTML(f'<br><h2>Landscape Averaged Plot:</h2>'))\n",
    "                        display(land_fig)\n",
    "                else:\n",
    "                    display(HTML(\"<div style='display: inline-block; margin: 10px 0;'><p style='color: red;'>No plots were generated to download.</p></div>\"))\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.plot_output.clear_output(wait=True)\n",
    "            error_message = f\"An error occurred while saving plots: {str(e)}\"\n",
    "            display(HTML(f\"<div style='display: inline-block; margin: 10px 0;'><b style='color: red'>{error_message}</b></div>\"))\n",
    "        \n",
    "        finally:\n",
    "            # Always re-enable the button and cleanup\n",
    "            b.disabled = False\n",
    "            \n",
    "    def get_layout(self):\n",
    "        # Create a grid layout with 2 rows and 2 columns\n",
    "        grid = GridspecLayout(\n",
    "            1, 2,  # 2 rows, 2 columns\n",
    "            width='900px', \n",
    "            height='auto',\n",
    "            overflow='hidden',\n",
    "            grid_gap='0px',  # Already set to zero\n",
    "        )\n",
    "        \n",
    "        # Left column widgets\n",
    "        left_column = VBox([\n",
    "            self.plot_message,\n",
    "            self.peptide_filter_radio,\n",
    "            self.ms_average_choice_dropdown,\n",
    "            self.bio_or_pep_dropdown,\n",
    "            self.specific_select_multiple,\n",
    "            widgets.HTML(\"<h3><u>Display and Export</u></h3>\"),            \n",
    "            widgets.HBox([self.plot_orientation, self.log_transform_checkbox], layout=widgets.Layout(\n",
    "                max_width='300px',\n",
    "                overflow='hidden'\n",
    "            )),\n",
    "            self.update_save_box\n",
    "        ], layout=widgets.Layout(\n",
    "            width='350px',\n",
    "            margin='0px',\n",
    "            padding='0px',\n",
    "            overflow='hidden'\n",
    "        ))\n",
    "        \n",
    "        # Right column widgets\n",
    "        right_column = VBox([\n",
    "            self.color_widget_box,\n",
    "            self.figure_label_box,\n",
    "        ], layout=widgets.Layout(\n",
    "            width='450px',\n",
    "            margin='0px',\n",
    "            padding='0px',\n",
    "            overflow='hidden'\n",
    "        ))\n",
    "        \n",
    "        # Bottom row spanning both columns\n",
    "        \"\"\"\n",
    "        bottom_row = VBox([\n",
    "            widgets.HTML(\"<h3><u>Display and Export</u></h3>\"),            \n",
    "            widgets.HBox([self.plot_orientation, self.log_transform_checkbox], layout=widgets.Layout(\n",
    "                max_width='300px',\n",
    "                overflow='hidden'\n",
    "            )),\n",
    "            self.update_save_box\n",
    "        ], layout=widgets.Layout(\n",
    "            width='900px',\n",
    "            height='auto',\n",
    "            margin='0px',\n",
    "            padding='0px',\n",
    "            overflow='hidden'\n",
    "        ))\n",
    "        \"\"\"\n",
    "        # Place widgets in the grid\n",
    "        grid[0, 0] = left_column    # First row, first column\n",
    "        grid[0, 1] = right_column   # First row, second column\n",
    "        #grid[1, 0:2] = bottom_row   # Second row, span both columns\n",
    "        \n",
    "        return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a13b2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        .ellipsis-select select option {\n",
       "            text-overflow: ellipsis;\n",
       "            overflow: hidden;\n",
       "            white-space: nowrap;\n",
       "        }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        .ellipsis-select select option {\n",
       "            text-overflow: ellipsis;\n",
       "            overflow: hidden;\n",
       "            white-space: nowrap;\n",
       "        }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        .ellipsis-select select option {\n",
       "            text-overflow: ellipsis;\n",
       "            overflow: hidden;\n",
       "            white-space: nowrap;\n",
       "        }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33ed4257e64498ea0a046a87dc14290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(layout=Layout(max_width='1000px', width='100%')), VBox(children=(HTML(value='<h4><u>Uplo"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7448be094d864150bc4267ef330cd414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize the data transformer\n",
    "data_transformer = DataTransformation()\n",
    "heatmap_data_handler = HeatmapDataHandler(data_transformer)\n",
    "plot_handler = HeatmapPlotHandler(data_transformer)\n",
    "\n",
    "data_transformer.setup_data_loading_ui()\n",
    "\n",
    "# Initialize and display the visualization handler\n",
    "viz_handler = DynamicVisualizationHandler(data_transformer)\n",
    "viz_handler.display()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1Vt5dV-pTHRWngML-2nDQAR6_P_KFsIx4",
     "timestamp": 1712158917217
    },
    {
     "file_id": "1l7fpCQepyE1pJq2O5QfOHVv9a4VFpr-B",
     "timestamp": 1712094574841
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
