{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62bd34aa-691e-4d2e-ac73-b2668c0542ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json, io, base64, re, os, requests, time\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from xml.etree import ElementTree\n",
    "# Initialize settings\n",
    "import _settings as settings\n",
    "\n",
    "# Global variables from settings\n",
    "spec_translate_list = settings.SPEC_TRANSLATE_LIST\n",
    "plotly_colors = settings.plotly_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cfaad00-f6e2-48b6-9b73-07bd9559fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self):\n",
    "        self.merged_df = None\n",
    "        self.proteins_dic = {}\n",
    "        self.output_area = None\n",
    "        self.merged_uploader = None\n",
    "\n",
    "    def create_download_link(self, file_path, label):\n",
    "        \"\"\"Create a download link for a file.\"\"\"\n",
    "        if os.path.exists(file_path):\n",
    "            # Read file content and encode it as base64\n",
    "            with open(file_path, 'rb') as f:\n",
    "                content = f.read()\n",
    "            b64_content = base64.b64encode(content).decode('utf-8')\n",
    "\n",
    "            # Generate the download link HTML\n",
    "            return widgets.HTML(f\"\"\"\n",
    "                <a download=\"{os.path.basename(file_path)}\" \n",
    "                   href=\"data:application/octet-stream;base64,{b64_content}\" \n",
    "                   style=\"color: #0366d6; text-decoration: none; margin-left: 20px; font-size: 14px;\">\n",
    "                    {label}\n",
    "                </a>\n",
    "            \"\"\")\n",
    "        else:\n",
    "            # Show an error message if the file does not exist\n",
    "            return widgets.HTML(f\"\"\"\n",
    "                <span style=\"color: red; margin-left: 20px; font-size: 14px;\">\n",
    "                    File \"{file_path}\" not found!\n",
    "                </span>\n",
    "            \"\"\")\n",
    "\n",
    "    def setup_data_loading_ui(self):\n",
    "        \"\"\"Initialize and display the data loading UI.\"\"\"\n",
    "        # Create file upload widget\n",
    "        self.merged_uploader = widgets.FileUpload(\n",
    "            accept='.csv,.txt,.tsv,.xlsx',\n",
    "            multiple=False,\n",
    "            description='Upload Merged Data File',\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "\n",
    "        self.output_area = widgets.Output()\n",
    "\n",
    "        # Create upload box with example link\n",
    "        merged_box = widgets.HBox([\n",
    "            self.merged_uploader,\n",
    "            self.create_download_link(\"example_merged_dataframe.csv\", \"Example\")\n",
    "        ], layout=widgets.Layout(align_items='center'))\n",
    "\n",
    "        # Create left column with upload widgets\n",
    "        upload_widgets = widgets.VBox([\n",
    "            widgets.HTML(\"<h4>Upload Data File:</h4>\"),\n",
    "            merged_box,\n",
    "            self.output_area\n",
    "        ], layout=widgets.Layout(\n",
    "            width='300px',\n",
    "            margin='0 20px 0 0'\n",
    "        ))\n",
    "\n",
    "        # Create container for status display\n",
    "        self.status_area = widgets.Output(\n",
    "            layout=widgets.Layout(\n",
    "                width='300px',\n",
    "                margin='0 0 0 20px'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        display(upload_widgets,\n",
    "                self.status_area)\n",
    "\n",
    "        # Register observer\n",
    "        self.merged_uploader.observe(self._on_merged_upload_change, names='value')\n",
    "\n",
    "    def _validate_and_clean_data(self, df):\n",
    "        \"\"\"\n",
    "        Validate and clean the uploaded data, preserving numeric data even if stored as strings.\n",
    "        Returns tuple of (cleaned_df, warnings, errors)\n",
    "        \"\"\"\n",
    "        warnings = []\n",
    "        errors = []\n",
    "        cleaned_df = df.copy()\n",
    "    \n",
    "        # Check required columns exist\n",
    "        required_columns = [\n",
    "            'Master Protein Accessions', \n",
    "            'unique ID'\n",
    "        ]\n",
    "        \n",
    "        # Check that at least one Avg_ column exists\n",
    "        avg_columns = [col for col in df.columns if col.startswith('Avg_')]\n",
    "        if not avg_columns:\n",
    "            errors.append(\"No columns starting with 'Avg_' found in the data\")\n",
    "            return None, warnings, errors\n",
    "            \n",
    "        # Add Avg_ columns to required columns\n",
    "        required_columns.extend(avg_columns)\n",
    "        \n",
    "        missing = set(required_columns) - set(df.columns)\n",
    "        if missing:\n",
    "            errors.append(f\"Missing required columns: {', '.join(missing)}\")\n",
    "            return None, warnings, errors\n",
    "    \n",
    "        # Separate numeric and non-numeric columns\n",
    "        numeric_columns = avg_columns  # Avg_ columns should be numeric\n",
    "        text_columns = ['Master Protein Accessions', 'unique ID']\n",
    "    \n",
    "        # Handle blank values differently for numeric vs text columns\n",
    "        for column in required_columns:\n",
    "            if column in numeric_columns:\n",
    "                # For numeric columns, try to convert to numeric first\n",
    "                try:\n",
    "                    # Convert to numeric, coerce errors to NaN\n",
    "                    cleaned_df[column] = pd.to_numeric(cleaned_df[column], errors='coerce')\n",
    "                    blank_count = cleaned_df[column].isna().sum()\n",
    "                    if blank_count > 0:\n",
    "                        warnings.append(f\"Found {blank_count} invalid/blank numeric values in {column} column\")\n",
    "                except Exception as e:\n",
    "                    errors.append(f\"Error converting {column} to numeric: {str(e)}\")\n",
    "                    return None, warnings, errors\n",
    "            elif column in text_columns:\n",
    "                # For text columns, check for truly empty values\n",
    "                blank_mask = cleaned_df[column].isna() | (cleaned_df[column].astype(str).str.strip() == '')\n",
    "                blank_count = blank_mask.sum()\n",
    "                if blank_count > 0:\n",
    "                    warnings.append(f\"Dropping {blank_count} rows with blank values in {column} column\")\n",
    "                    cleaned_df = cleaned_df[~blank_mask]\n",
    "    \n",
    "        # Check for invalid characters in non-blank rows\n",
    "        if len(cleaned_df) > 0:\n",
    "            # Check Positions in Proteins\n",
    "            invalid_pos = cleaned_df['Positions in Proteins'].apply(\n",
    "                lambda x: ',' in str(x) or ':' in str(x)\n",
    "            )\n",
    "            if invalid_pos.any():\n",
    "                errors.append(\n",
    "                    \"Found invalid characters (',' or ':') in Positions in Proteins column. \"\n",
    "                    \"Please update the file and upload again.\"\n",
    "                )\n",
    "            \n",
    "            # Check Master Protein Accessions\n",
    "            invalid_acc = cleaned_df['Master Protein Accessions'].apply(\n",
    "                lambda x: ',' in str(x) or ':' in str(x)\n",
    "            )\n",
    "            if invalid_acc.any():\n",
    "                errors.append(\n",
    "                    \"Found invalid characters (',' or ':') in Master Protein Accessions column. \"\n",
    "                    \"Please update the file and upload again.\"\n",
    "                )\n",
    "    \n",
    "        return cleaned_df, warnings, errors\n",
    "\n",
    "    def _process_protein_info(self, df):\n",
    "        \"\"\"\n",
    "        Process protein information from the dataframe and store in proteins_dic.\n",
    "        Asks user whether to fetch from UniProt or use accession IDs when protein info is missing.\n",
    "        \"\"\"\n",
    "        # Initialize a cache for UniProt information to avoid redundant queries\n",
    "        self.uniprot_cache = getattr(self, 'uniprot_cache', {})\n",
    "        \n",
    "        # Check if we need to fetch any data from UniProt\n",
    "        has_protein_info = all(col in df.columns for col in ['protein_name', 'protein_species'])\n",
    "        if has_protein_info:\n",
    "            # Check if we have valid data for all entries\n",
    "            all_data_present = (\n",
    "                df['protein_name'].notna().all() and \n",
    "                df['protein_species'].notna().all() and\n",
    "                (df['protein_name'] != '').all() and\n",
    "                (df['protein_species'] != '').all()\n",
    "            )\n",
    "            if all_data_present:\n",
    "                # If we have all data, just process it silently\n",
    "                protein_info = df.groupby('Master Protein Accessions').agg({\n",
    "                    'protein_name': 'first',\n",
    "                    'protein_species': 'first'\n",
    "                }).reset_index()\n",
    "                \n",
    "                for _, row in protein_info.iterrows():\n",
    "                    protein_id = row['Master Protein Accessions']\n",
    "                    self.proteins_dic[protein_id] = {\n",
    "                        \"name\": row['protein_name'],\n",
    "                        \"species\": row['protein_species']\n",
    "                    }\n",
    "                return len(self.proteins_dic)\n",
    "\n",
    "        # Store the dataframe for later processing\n",
    "        self._protein_df_to_process = df\n",
    "        \n",
    "        # Create a flag to track if processing is complete\n",
    "        self._protein_processing_complete = False\n",
    "        \n",
    "        # If we need to fetch data, ask the user what they want to do\n",
    "        # Display in the status area\n",
    "        with self.status_area:\n",
    "            self.status_area.clear_output()\n",
    "            \n",
    "            # Create buttons for user choice\n",
    "            fetch_button = widgets.Button(\n",
    "                description='Query UniProt',\n",
    "                button_style='info',\n",
    "                tooltip='Fetch protein names from UniProt database (may take time)',\n",
    "                layout=widgets.Layout(width='250px')\n",
    "            )\n",
    "            \n",
    "            use_accession_button = widgets.Button(\n",
    "                description='Use Protein IDs',\n",
    "                button_style='warning',\n",
    "                tooltip='Use protein accession IDs as names without querying UniProt',\n",
    "                layout=widgets.Layout(width='250px')\n",
    "            )\n",
    "            \n",
    "            # Define button click handlers\n",
    "            fetch_button.on_click(lambda b: self._process_proteins_with_choice(True))\n",
    "            use_accession_button.on_click(lambda b: self._process_proteins_with_choice(False))\n",
    "            \n",
    "            display(HTML(\"\"\"\n",
    "                <div style=\"padding: 15px; margin: 10px 0; border-left: 4px solid #17a2b8; background-color: #f8f9fa;\">\n",
    "                    <h4 style=\"margin-top: 0;\">Protein Information Missing</h4>\n",
    "                    <p>Some protein names or species information is missing in your data.</p>\n",
    "                    <p>Would you like to:</p>\n",
    "                         <ul>\n",
    "                                <li>Fetch protein names from UniProt database (may take time)</li>\n",
    "                                <li>Use protein accession IDs as names without querying UniProt</li>\n",
    "                        </ul>\n",
    "                </div>\n",
    "            \"\"\"))\n",
    "            display(widgets.HBox([fetch_button, use_accession_button]))\n",
    "        \n",
    "        # Return the current count, but processing will continue when a button is clicked\n",
    "        return len(self.proteins_dic)\n",
    "\n",
    "    def _process_proteins_with_choice(self, fetch_from_uniprot):\n",
    "        \"\"\"\n",
    "        Process proteins based on user choice.\n",
    "        This is called when the user clicks one of the choice buttons.\n",
    "        \"\"\"\n",
    "        # Get the dataframe to process\n",
    "        df = self._protein_df_to_process\n",
    "        \n",
    "        # Clear the status area and show processing message\n",
    "        with self.status_area:\n",
    "            self.status_area.clear_output()\n",
    "            if fetch_from_uniprot:\n",
    "                display(HTML('<div style=\"color: #17a2b8; padding: 10px; margin: 10px 0;\">Fetching protein information from UniProt...</div>'))\n",
    "            else:\n",
    "                display(HTML('<div style=\"color: #ffc107; padding: 10px; margin: 10px 0;\">Using protein accession IDs as names...</div>'))\n",
    "        \n",
    "        # Process proteins based on user choice\n",
    "        # Use the status area for progress display\n",
    "        with self.status_area:\n",
    "            # Initialize counters\n",
    "            total_proteins = 0\n",
    "            uniprot_found = 0\n",
    "            uniprot_not_found = 0\n",
    "            multiple_entries = 0\n",
    "            cached_proteins = 0\n",
    "            \n",
    "            # Check if we need to fetch any data from UniProt\n",
    "            has_protein_info = all(col in df.columns for col in ['protein_name', 'protein_species'])\n",
    "            \n",
    "            # Group by protein accession to get unique proteins\n",
    "            protein_info = df.groupby('Master Protein Accessions').agg({\n",
    "                'protein_name': 'first' if 'protein_name' in df.columns else lambda x: None,\n",
    "                'protein_species': 'first' if 'protein_species' in df.columns else lambda x: None\n",
    "            }).reset_index()\n",
    "\n",
    "            progress_html = \"\"\"\n",
    "                <style>\n",
    "                    .fetch-status { font-family: monospace; margin: 10px 0; padding: 10px; }\n",
    "                    .fetch-progress { margin: 5px 0; padding: 5px; }\n",
    "                    .success { color: #28a745; }\n",
    "                    .warning { color: #ffc107; }\n",
    "                    .error { color: #dc3545; }\n",
    "                    .info { color: #17a2b8; }\n",
    "                    .summary { margin-top: 10px; padding: 10px;}\n",
    "                </style>\n",
    "                <div class=\"fetch-status\">\n",
    "                    <div id=\"progress-updates\"></div>\n",
    "                </div>\n",
    "            \"\"\"\n",
    "            \n",
    "            # First, collect all proteins that need fetching\n",
    "            proteins_to_fetch = []\n",
    "            \n",
    "            for _, row in protein_info.iterrows():\n",
    "                total_proteins += 1\n",
    "                protein_id = row['Master Protein Accessions']\n",
    "                \n",
    "                # Skip entries with multiple protein IDs\n",
    "                if ';' in protein_id:\n",
    "                    multiple_entries += 1\n",
    "                    self.proteins_dic[protein_id] = {\n",
    "                        \"name\": protein_id,\n",
    "                        \"species\": \"Multiple\"\n",
    "                    }\n",
    "                    continue\n",
    "                \n",
    "                # Use existing data if available and not empty\n",
    "                if (has_protein_info and \n",
    "                    pd.notna(row['protein_name']) and \n",
    "                    pd.notna(row['protein_species']) and \n",
    "                    row['protein_name'] != '' and \n",
    "                    row['protein_species'] != ''):\n",
    "                    self.proteins_dic[protein_id] = {\n",
    "                        \"name\": row['protein_name'],\n",
    "                        \"species\": row['protein_species']\n",
    "                    }\n",
    "                    continue\n",
    "                \n",
    "                # Check if we already have this protein in cache\n",
    "                if protein_id in self.uniprot_cache:\n",
    "                    cached_proteins += 1\n",
    "                    name, species = self.uniprot_cache[protein_id]\n",
    "                    self.proteins_dic[protein_id] = {\n",
    "                        \"name\": name,\n",
    "                        \"species\": species\n",
    "                    }\n",
    "                    continue\n",
    "                \n",
    "                # If we need to fetch and user chose to fetch from UniProt\n",
    "                if fetch_from_uniprot:\n",
    "                    proteins_to_fetch.append(protein_id)\n",
    "                else:\n",
    "                    # Use accession ID as name\n",
    "                    self.proteins_dic[protein_id] = {\n",
    "                        \"name\": protein_id,\n",
    "                        \"species\": \"Unknown\"\n",
    "                    }\n",
    "            \n",
    "            # Process proteins in batches if fetching from UniProt\n",
    "            if fetch_from_uniprot and proteins_to_fetch:\n",
    "                # Update progress display\n",
    "                display(HTML(progress_html + f\"\"\"\n",
    "                    <div class=\"fetch-progress info\">\n",
    "                        Preparing to fetch {len(proteins_to_fetch)} proteins from UniProt in batches...\n",
    "                    </div>\n",
    "                \"\"\"))\n",
    "                \n",
    "                # Process in batches of 50 (adjust as needed)\n",
    "                batch_size = 50\n",
    "                total_batches = (len(proteins_to_fetch) + batch_size - 1) // batch_size\n",
    "                \n",
    "                for batch_num in range(total_batches):\n",
    "                    start_idx = batch_num * batch_size\n",
    "                    end_idx = min((batch_num + 1) * batch_size, len(proteins_to_fetch))\n",
    "                    current_batch = proteins_to_fetch[start_idx:end_idx]\n",
    "                    \n",
    "                    # Update progress\n",
    "                    self.status_area.clear_output(wait=True)\n",
    "                    display(HTML(progress_html + f\"\"\"\n",
    "                        <div class=\"fetch-progress info\">\n",
    "                            Fetching batch {batch_num + 1}/{total_batches} ({len(current_batch)} proteins)...\n",
    "                        </div>\n",
    "                        <div class=\"summary\">\n",
    "                            <h4>Progress:</h4>\n",
    "                            <ul>\n",
    "                                <li>Total proteins: {total_proteins}</li>\n",
    "                                <li>Proteins from cache: {cached_proteins}</li>\n",
    "                                <li>UniProt matches found: {uniprot_found}</li>\n",
    "                                <li>UniProt matches not found: {uniprot_not_found}</li>\n",
    "                                <li>Multiple entry proteins: {multiple_entries}</li>\n",
    "                                <li>Remaining to fetch: {len(proteins_to_fetch) - start_idx}</li>\n",
    "                            </ul>\n",
    "                        </div>\n",
    "                    \"\"\"))\n",
    "                    \n",
    "                    # Fetch the batch using individual queries for now\n",
    "                    # We'll implement batch fetching later\n",
    "                    batch_results = {}\n",
    "                    for protein_id in current_batch:\n",
    "                        try:\n",
    "                            name, species = self.fetch_uniprot_info(protein_id)\n",
    "                            if name and species:\n",
    "                                batch_results[protein_id] = (name, species)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error fetching {protein_id}: {str(e)}\")\n",
    "                    \n",
    "                    # Process the results\n",
    "                    for protein_id in current_batch:\n",
    "                        if protein_id in batch_results:\n",
    "                            name, species = batch_results[protein_id]\n",
    "                            uniprot_found += 1\n",
    "                            self.proteins_dic[protein_id] = {\n",
    "                                \"name\": name,\n",
    "                                \"species\": species\n",
    "                            }\n",
    "                            # Add to cache\n",
    "                            self.uniprot_cache[protein_id] = (name, species)\n",
    "                        else:\n",
    "                            uniprot_not_found += 1\n",
    "                            self.proteins_dic[protein_id] = {\n",
    "                                \"name\": protein_id,\n",
    "                                \"species\": \"Unknown\"\n",
    "                            }\n",
    "                            # Cache the negative result too\n",
    "                            self.uniprot_cache[protein_id] = (protein_id, \"Unknown\")\n",
    "            \n",
    "            # Show final summary\n",
    "            self.status_area.clear_output(wait=True)\n",
    "            display(HTML(f\"\"\"\n",
    "                <div class=\"fetch-status\">\n",
    "                    <h4 style=\"color:green;\"><b>Protein Processing Complete!</b></h4>\n",
    "                    <div class=\"summary\">\n",
    "                        <h4>Final Summary:</h4>\n",
    "                        <ul>\n",
    "                            <li>Total proteins processed: {total_proteins}</li>\n",
    "                            <li>Proteins from cache: {cached_proteins}</li>\n",
    "                            <li>Multiple entry proteins: {multiple_entries}</li>\n",
    "                            {\"<li>UniProt matches found: \" + str(uniprot_found) + \"</li>\" if fetch_from_uniprot else \"\"}\n",
    "                            {\"<li>UniProt matches not found: \" + str(uniprot_not_found) + \"</li>\" if fetch_from_uniprot else \"\"}\n",
    "                        </ul>\n",
    "                    </div>\n",
    "                </div>\n",
    "            \"\"\"))\n",
    "        \n",
    "        # Mark processing as complete\n",
    "        self._protein_processing_complete = True\n",
    "        \n",
    "        # Update the merged_df with the protein information\n",
    "        if hasattr(self, 'merged_df') and self.merged_df is not None:\n",
    "            # Add protein_name and protein_species columns if they don't exist\n",
    "            if 'protein_name' not in self.merged_df.columns:\n",
    "                self.merged_df['protein_name'] = ''\n",
    "            if 'protein_species' not in self.merged_df.columns:\n",
    "                self.merged_df['protein_species'] = ''\n",
    "            \n",
    "            # Update the columns with the fetched information\n",
    "            for protein_id, info in self.proteins_dic.items():\n",
    "                mask = self.merged_df['Master Protein Accessions'] == protein_id\n",
    "                self.merged_df.loc[mask, 'protein_name'] = info['name']\n",
    "                self.merged_df.loc[mask, 'protein_species'] = info['species']\n",
    "        \n",
    "        # Return the number of proteins processed\n",
    "        return len(self.proteins_dic)\n",
    "\n",
    "    def fetch_uniprot_info_batch(self, protein_ids, max_retries=3, timeout=30):\n",
    "        \"\"\"\n",
    "        Fetch protein information for multiple proteins at once using UniProt's batch API.\n",
    "        Returns a dictionary mapping protein IDs to (name, species) tuples.\n",
    "        \"\"\"\n",
    "        if not protein_ids:\n",
    "            return {}\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        try:\n",
    "            # Use the batch REST API endpoint\n",
    "            batch_url = 'https://rest.uniprot.org/uniprotkb/search'\n",
    "            \n",
    "            # Create a query with OR conditions for each protein ID\n",
    "            query = ' OR '.join([f'accession:{pid}' for pid in protein_ids])\n",
    "            \n",
    "            # Parameters for the request\n",
    "            params = {\n",
    "                'query': query,\n",
    "                'format': 'json',\n",
    "                'fields': 'accession,protein_name,organism_name',\n",
    "                'size': len(protein_ids)  # Request all results in one response\n",
    "            }\n",
    "            \n",
    "            # Make the request with timeout and retry logic\n",
    "            retry_count = 0\n",
    "            while retry_count < max_retries:\n",
    "                try:\n",
    "                    response = requests.get(batch_url, params=params, timeout=timeout)\n",
    "                    \n",
    "                    # Handle rate limiting\n",
    "                    if response.status_code == 429:  # Too Many Requests\n",
    "                        retry_after = int(response.headers.get('Retry-After', 5))\n",
    "                        print(f\"Rate limited. Waiting {retry_after} seconds...\")\n",
    "                        time.sleep(retry_after + 1)  # Add 1 second buffer\n",
    "                        retry_count += 1\n",
    "                        continue\n",
    "                    \n",
    "                    # Break if successful\n",
    "                    if response.status_code == 200:\n",
    "                        break\n",
    "                    \n",
    "                    # Handle other errors\n",
    "                    response.raise_for_status()\n",
    "                    \n",
    "                except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as e:\n",
    "                    retry_count += 1\n",
    "                    wait_time = 2 ** retry_count  # Exponential backoff\n",
    "                    print(f\"Request failed: {str(e)}. Retrying in {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)\n",
    "            \n",
    "            # Process the response\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                \n",
    "                for entry in data.get('results', []):\n",
    "                    accession = entry.get('primaryAccession')\n",
    "                    \n",
    "                    # Extract protein name\n",
    "                    protein_name = None\n",
    "                    protein_data = entry.get('proteinDescription', {})\n",
    "                    \n",
    "                    # Try to find a common/short name first\n",
    "                    if 'recommendedName' in protein_data:\n",
    "                        if 'shortNames' in protein_data['recommendedName']:\n",
    "                            protein_name = protein_data['recommendedName']['shortNames'][0]['value']\n",
    "                        else:\n",
    "                            protein_name = protein_data['recommendedName'].get('fullName', {}).get('value')\n",
    "                    \n",
    "                    # Try alternative names if no recommended name found\n",
    "                    if not protein_name and 'alternativeNames' in protein_data and protein_data['alternativeNames']:\n",
    "                        if 'shortNames' in protein_data['alternativeNames'][0]:\n",
    "                            protein_name = protein_data['alternativeNames'][0]['shortNames'][0]['value']\n",
    "                        else:\n",
    "                            protein_name = protein_data['alternativeNames'][0].get('fullName', {}).get('value')\n",
    "                    \n",
    "                    # Extract species name\n",
    "                    species = None\n",
    "                    organism_data = entry.get('organism', {})\n",
    "                    organism_names = organism_data.get('names', [])\n",
    "                    \n",
    "                    # Try to find common name first\n",
    "                    for name in organism_names:\n",
    "                        if name['type'] == 'common':\n",
    "                            species = name['value']\n",
    "                            break\n",
    "                    \n",
    "                    # Fallback to scientific name\n",
    "                    if not species and organism_names:\n",
    "                        for name in organism_names:\n",
    "                            if name['type'] == 'scientific':\n",
    "                                species = name['value']\n",
    "                                break\n",
    "                    \n",
    "                    # Clean up protein name if found\n",
    "                    if protein_name:\n",
    "                        protein_name = protein_name.split(' precursor')[0].split(' (')[0]\n",
    "                    \n",
    "                    # Store the results\n",
    "                    if accession and (protein_name or species):\n",
    "                        results[accession] = (protein_name or accession, species or \"Unknown\")\n",
    "            \n",
    "            return results\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch fetch: {str(e)}\")\n",
    "            return {}\n",
    "        \n",
    "    def _load_merged_data(self, file_data):\n",
    "        \"\"\"\n",
    "        Load and validate merged data file\n",
    "        Returns tuple of (dataframe, status)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            content = bytes(file_data.content)\n",
    "            filename = file_data.name\n",
    "            extension = filename.split('.')[-1].lower()\n",
    "\n",
    "            file_stream = io.BytesIO(content)\n",
    "\n",
    "            # Load data based on file extension\n",
    "            try:\n",
    "                if extension == 'csv':\n",
    "                    df = pd.read_csv(file_stream)\n",
    "                elif extension in ['txt', 'tsv']:\n",
    "                    df = pd.read_csv(file_stream, delimiter='\\t')\n",
    "                elif extension == 'xlsx':\n",
    "                    df = pd.read_excel(file_stream)\n",
    "                else:\n",
    "                    display(HTML(f'<b style=\"color:red;\">Error: Unsupported file format</b>'))\n",
    "                    return None, 'no'\n",
    "            except Exception as e:\n",
    "                display(HTML(f'<b style=\"color:red;\">Error reading file: {str(e)}</b>'))\n",
    "                return None, 'no'\n",
    "\n",
    "            # Check for protein info columns and notify user\n",
    "            missing_columns = []\n",
    "            if 'protein_name' not in df.columns:\n",
    "                missing_columns.append('protein_name')\n",
    "                df['protein_name'] = ''\n",
    "            if 'protein_species' not in df.columns:\n",
    "                missing_columns.append('protein_species')\n",
    "                df['protein_species'] = ''\n",
    "                \n",
    "            if missing_columns:\n",
    "                notification = f\"\"\"\n",
    "                <div style=\"padding: 10px; margin: 10px 0;\">\n",
    "                    <p style=\"color: #17a2b8; margin: 0;\">\n",
    "                        <b>Notice:</b> The following columns are missing from your data:\n",
    "                        <ul style=\"color: #17a2b8; margin: 5px 0;\">\n",
    "                            {''.join(f'<li>{col}</li>' for col in missing_columns)}\n",
    "                        </ul>\n",
    "                        </p>\n",
    "                        <p style=\"color: #17a2b8; margin: 0;\">\n",
    "                        UniProt will be searched to automatically fill in this information. <br>\n",
    "                        Alternativly you can upload a standardized file from the data transomation module with the protein information. \n",
    "                    </p>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "                display(HTML(notification))\n",
    "\n",
    "            # Validate and clean data\n",
    "            cleaned_df, warnings, errors = self._validate_and_clean_data(df)\n",
    "\n",
    "            # Warnings about invalid/blank values are commented out\n",
    "            # if warnings:\n",
    "            #     warning_html = \"<br>\".join([\n",
    "            #         f'<b style=\"color:orange;\">Warning: {w}</b>'\n",
    "            #         for w in warnings\n",
    "            #     ])\n",
    "            #     display(HTML(warning_html))\n",
    "\n",
    "            # Display errors if any\n",
    "            if errors:\n",
    "                error_html = \"<br>\".join([\n",
    "                    f'<b style=\"color:red;\">Error: {e}</b>'\n",
    "                    for e in errors\n",
    "                ])\n",
    "                display(HTML(error_html))\n",
    "                return None, 'no'\n",
    "\n",
    "            if cleaned_df is not None and len(cleaned_df) > 0:\n",
    "                # Process protein information\n",
    "                num_proteins = self._process_protein_info(cleaned_df)\n",
    "                \n",
    "                # Add information about remaining rows and processed proteins\n",
    "                success_message = f\"\"\"\n",
    "                <div style=\"padding: 10px; margin: 10px 0; border-left: 4px solid #28a745; background-color: #f8f9fa;\">\n",
    "                    <p style=\"color: #28a745; margin: 0;\">\n",
    "                        <b>Data Import Complete!</b><br>\n",
    "                        • Data imported successfully with {cleaned_df.shape[0]} rows and {cleaned_df.shape[1]} columns.<br>\n",
    "                        • Processed data contains {len(cleaned_df)} rows after removing blank values.<br>\n",
    "                        • Successfully processed information for {num_proteins} unique proteins.\n",
    "                    </p>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "                #display(HTML(success_message))\n",
    "                return cleaned_df, 'yes'\n",
    "            else:\n",
    "                display(HTML('<b style=\"color:red;\">Error: No valid data rows remaining after cleaning</b>'))\n",
    "                return None, 'no'\n",
    "\n",
    "        except Exception as e:\n",
    "            display(HTML(f'<b style=\"color:red;\">Error processing file: {str(e)}</b>'))\n",
    "            return None, 'no'\n",
    "\n",
    "    def _on_merged_upload_change(self, change):\n",
    "        \"\"\"Handle merged data file upload\"\"\"\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            with self.output_area:\n",
    "                self.output_area.clear_output()\n",
    "                if change['new'] and len(change['new']) > 0:\n",
    "                    file_data = change['new'][0]\n",
    "                    df, status = self._load_merged_data(file_data)\n",
    "                    if status == 'yes' and df is not None:\n",
    "                        self.merged_df = df  # Only set merged_df if validation passed\n",
    "                        display(HTML(\n",
    "                            f'<b style=\"color:green;\">Data imported successfully with '\n",
    "                            f'{df.shape[0]} rows and {df.shape[1]} columns.</b>'\n",
    "                        ))\n",
    "\n",
    "    def fetch_uniprot_info(self, protein_id):\n",
    "        \"\"\"\n",
    "        Fetch protein information from UniProt, prioritizing common names.\n",
    "        Returns tuple of (protein_common_name, species_common_name) or (None, None) if not found.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Try REST API first\n",
    "            rest_url = f'https://rest.uniprot.org/uniprotkb/{protein_id}.json'\n",
    "            response = requests.get(rest_url)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                \n",
    "                # Get protein common name\n",
    "                try:\n",
    "                    # Look for protein names\n",
    "                    names = data['proteinDescription']\n",
    "                    protein_name = None\n",
    "                    \n",
    "                    # Try to find a common/short name\n",
    "                    if 'shortNames' in names.get('recommendedName', {}):\n",
    "                        protein_name = names['recommendedName']['shortNames'][0]['value']\n",
    "                    elif 'shortNames' in names.get('alternativeNames', [{}])[0]:\n",
    "                        protein_name = names['alternativeNames'][0]['shortNames'][0]['value']\n",
    "                    else:\n",
    "                        # Fallback to full name\n",
    "                        protein_name = names.get('recommendedName', {}).get('fullName', {}).get('value')\n",
    "                    \n",
    "                    # Get species common name\n",
    "                    organism_data = data['organism']\n",
    "                    species = None\n",
    "                    for name in organism_data.get('names', []):\n",
    "                        if name['type'] == 'common':\n",
    "                            species = name['value']\n",
    "                            break\n",
    "                    if not species:  # Fallback to scientific name\n",
    "                        species = organism_data.get('scientificName')\n",
    "                    \n",
    "                    return protein_name, species\n",
    "                    \n",
    "                except KeyError:\n",
    "                    pass  # Fall through to XML approach\n",
    "            \n",
    "            # Fall back to XML API\n",
    "            xml_url = f'https://www.uniprot.org/uniprot/{protein_id}.xml'\n",
    "            response = requests.get(xml_url)\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                return None, None\n",
    "                \n",
    "            root = ElementTree.fromstring(response.content)\n",
    "            ns = {'up': 'http://uniprot.org/uniprot'}\n",
    "            \n",
    "            # Get protein common name with fallbacks\n",
    "            protein_name = None\n",
    "            # Try short name first\n",
    "            name_element = (\n",
    "                root.find('.//up:recommendedName/up:shortName', ns) or\n",
    "                root.find('.//up:alternativeName/up:shortName', ns) or\n",
    "                root.find('.//up:recommendedName/up:fullName', ns) or\n",
    "                root.find('.//up:submittedName/up:fullName', ns)\n",
    "            )\n",
    "            protein_name = name_element.text if name_element is not None else None\n",
    "            \n",
    "            # Get species common name\n",
    "            species = None\n",
    "            # Try common name first\n",
    "            organism = root.find('.//up:organism/up:name[@type=\"common\"]', ns)\n",
    "            if organism is not None:\n",
    "                species = organism.text\n",
    "            else:\n",
    "                # Fallback to scientific name\n",
    "                organism = root.find('.//up:organism/up:name[@type=\"scientific\"]', ns)\n",
    "                species = organism.text if organism is not None else \"Unknown\"\n",
    "            \n",
    "            if protein_name:\n",
    "                # Clean up protein name - remove any \"precursor\" or similar suffixes\n",
    "                protein_name = protein_name.split(' precursor')[0].split(' (')[0]\n",
    "                return protein_name, species\n",
    "            else:\n",
    "                return None, None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching UniProt data for {protein_id}: {str(e)}\")\n",
    "            return None, None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9668b4d0-7d2a-4d54-ae01-28561699ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotState:\n",
    "    def __init__(self):\n",
    "        self.current_state = {\n",
    "            'uploadedData': None,\n",
    "            'topProteins': None,\n",
    "            'groupSelection': None,\n",
    "            'xLabel': None,\n",
    "            'yLabel': None,\n",
    "            'colorScheme': None,\n",
    "            'lastGenerated': None,\n",
    "            'buttonsLocked': True\n",
    "        }\n",
    "    \n",
    "    def update_state(self, **kwargs):\n",
    "        self.current_state.update(kwargs)\n",
    "        # Lock buttons when state changes\n",
    "        self.current_state['buttonsLocked'] = True\n",
    "    \n",
    "    def generate_completed(self):\n",
    "        self.current_state['buttonsLocked'] = False\n",
    "        self.current_state['lastGenerated'] = {\n",
    "            key: value for key, value in self.current_state.items() \n",
    "            if key not in ['lastGenerated', 'buttonsLocked']\n",
    "        }\n",
    "    \n",
    "    def get_state(self):\n",
    "        return self.current_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "377e1235-d0b5-473e-8457-e044f855a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "class ProteinPlotter:\n",
    "    def __init__(self, data_transformer):\n",
    "        self.data_transformer = data_transformer\n",
    "        self.plot_output = widgets.Output()\n",
    "        self.info_output = widgets.Output()\n",
    "        self.export_output = widgets.Output()\n",
    "        self.proteins_df = None\n",
    "        self.sum_df = None\n",
    "        \n",
    "        # Initialize state manager first\n",
    "        self.state_manager = PlotState()\n",
    "    \n",
    "        # Create widgets for protein plotting\n",
    "        self.num_proteins_widget = widgets.IntSlider(\n",
    "            value=10,\n",
    "            min=1,\n",
    "            max=50,\n",
    "            step=1,\n",
    "            description='Top Number of Proteins:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "        \n",
    "        # Create widgets for protein plotting\n",
    "        self.num_proteins_widget = widgets.IntSlider(\n",
    "            value=10,\n",
    "            min=1,\n",
    "            max=50,\n",
    "            step=1,\n",
    "            description='Top Number of Proteins:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "\n",
    "\n",
    "        self.download_plot_button = widgets.Button(\n",
    "            description='Download Interactive Plot',\n",
    "            button_style='info',\n",
    "            icon='file',\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "\n",
    "        # Create multi-select widget for groups\n",
    "        self.group_select = widgets.SelectMultiple(\n",
    "            options=[],\n",
    "            description='Groups:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px', height='100px')\n",
    "        )\n",
    "        \n",
    "        self.plot_button = widgets.Button(\n",
    "            description='Generate/Update Data',\n",
    "            button_style='success',\n",
    "            icon='refresh',\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "        \n",
    "        self.export_button = widgets.Button(\n",
    "            description='Export Data',\n",
    "            button_style='info',\n",
    "            icon='download',\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "\n",
    "        # Add label customization widgets\n",
    "        self.xlabel_widget = widgets.Text(\n",
    "            description='X Label:',\n",
    "            placeholder='Enter x-axis label',\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "        \n",
    "        self.ylabel_widget = widgets.Text(\n",
    "            description='Y Label:',\n",
    "            placeholder='Enter y-axis label',\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "        self.legend_widget = widgets.Text(\n",
    "            description='Legend Title',\n",
    "            placeholder='Enter a custom legend title',\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "        self.title_widget = widgets.Text(\n",
    "            description='Plot Title',\n",
    "            placeholder='Enter a custom plot title',\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "\n",
    "\n",
    "        # Update color scheme dropdown with categorized options\n",
    "        color_schemes = [\n",
    "            '--- DEFAULT (HSV)---',\n",
    "            'HSV',  # Default option\n",
    "            '--- QUALITATIVE (BEST FOR CATEGORIES) ---',\n",
    "            'Plotly', 'D3', 'G10', 'T10', 'Alphabet', \n",
    "            'Set1', 'Set2', 'Set3', 'Pastel1', 'Pastel2', 'Paired',\n",
    "            '--- SEQUENTIAL ---',\n",
    "            'Viridis', 'Cividis', 'Inferno', 'Magma', 'Plasma',\n",
    "            'Hot', 'Jet', 'Blues', 'Greens', 'Reds', 'Purples', 'Oranges',\n",
    "            '--- DIVERGING ---',\n",
    "            'Spectral', 'RdBu', 'RdYlBu', 'RdYlGn', 'PiYG', 'PRGn', 'BrBG', 'RdGy',\n",
    "            '--- CYCLICAL ---',\n",
    "            'IceFire', 'Edge', 'Twilight'\n",
    "        ]\n",
    "        \n",
    "        self.color_scheme = widgets.Dropdown(\n",
    "            options=color_schemes,\n",
    "            value='HSV',  # Default value\n",
    "            description='Color Scheme:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "\n",
    "        # Add an inversion toggle radio button\n",
    "        self.invert_plot = widgets.RadioButtons(\n",
    "            description='Plot Orientation:',\n",
    "            options=['By Sample', 'By Protein'],\n",
    "            value='By Sample',  # Default selection\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px', height='auto'),\n",
    "            disabled=False,\n",
    "            indent=True  # Keeps options aligned with description instead of appearing below\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Create layout\n",
    "        self.widget_box = widgets.VBox([\n",
    "            widgets.HTML(\"<h4>Plot Controls:</h4>\"),\n",
    "            self.num_proteins_widget,\n",
    "            self.group_select,\n",
    "            self.invert_plot,\n",
    "            widgets.HTML(\"<h4>Appearance Settings:</h4>\"),\n",
    "            self.xlabel_widget,\n",
    "            self.ylabel_widget,\n",
    "            self.legend_widget,\n",
    "            self.title_widget,\n",
    "            self.color_scheme,\n",
    "            widgets.HTML(\"<h4>Actions:</h4>\"),\n",
    "            self.plot_button,\n",
    "            self.export_button,\n",
    "            self.download_plot_button,\n",
    "            self.info_output,\n",
    "            self.plot_output,\n",
    "            self.export_output\n",
    "        ])\n",
    "            \n",
    "            \n",
    "        # Set initial button states\n",
    "        self.export_button.disabled = True\n",
    "        self.download_plot_button.disabled = True\n",
    "        \n",
    "        def _on_input_change(change):\n",
    "            self.state_manager.update_state()\n",
    "            self.export_button.disabled = True\n",
    "            self.download_plot_button.disabled = True\n",
    "        \n",
    "        # Add observers for input changes\n",
    "        self.num_proteins_widget.observe(_on_input_change, names='value')\n",
    "        self.group_select.observe(_on_input_change, names='value')\n",
    "        self.xlabel_widget.observe(_on_input_change, names='value')\n",
    "        self.ylabel_widget.observe(_on_input_change, names='value')\n",
    "        self.legend_widget.observe(_on_input_change, names='value')\n",
    "        self.title_widget.observe(_on_input_change, names='value')\n",
    "        self.color_scheme.observe(_on_input_change, names='value')\n",
    "\n",
    "        # Add button click handlers\n",
    "        self.plot_button.on_click(self._on_plot_button_click)\n",
    "        self.export_button.on_click(self._on_export_button_click)\n",
    "        self.download_plot_button.on_click(self._on_download_plot_click)\n",
    "        \n",
    "        # Add variable to store current figure\n",
    "        self.current_fig = None\n",
    "        # Add observer for data changes\n",
    "        self.data_transformer.merged_uploader.observe(self._update_group_options, names='value')\n",
    "\n",
    "\n",
    "\n",
    "        # In your setup_widgets method, add this line:\n",
    "        self.color_scheme.observe(self._on_color_scheme_change, names='value')\n",
    "\n",
    "    # Then add this method:\n",
    "    def _on_color_scheme_change(self, change):\n",
    "        \"\"\"Update plot when color scheme changes\"\"\"\n",
    "        if self.current_fig is not None and hasattr(self, 'plot_button'):\n",
    "            # Trigger plot update by simulating a button click\n",
    "            self._on_plot_button_click(None)\n",
    "\n",
    "    def _get_avg_columns(self):\n",
    "        \"\"\"Get all columns that start with 'Avg_' from the merged dataframe\"\"\"\n",
    "        if self.data_transformer.merged_df is not None:\n",
    "            return [col for col in self.data_transformer.merged_df.columns if col.startswith('Avg_')]\n",
    "        return []\n",
    "\n",
    "    def _update_group_options(self, change):\n",
    "        \"\"\"Update group selection options when data changes\"\"\"\n",
    "        if self.data_transformer.merged_df is not None:\n",
    "            avg_columns = self._get_avg_columns()\n",
    "            # Remove 'Avg_' prefix for display\n",
    "            group_options = [col.replace('Avg_', '') for col in avg_columns]\n",
    "            self.group_select.options = group_options\n",
    "            # Select all groups by default\n",
    "            self.group_select.value = group_options\n",
    "\n",
    "    def process_data(self, selected_groups=None):\n",
    "        \"\"\"Process data with optional group selection\"\"\"\n",
    "        if self.data_transformer.merged_df is None or not self.data_transformer.proteins_dic:\n",
    "            return False\n",
    "\n",
    "        df = self.data_transformer.merged_df.copy()\n",
    "        \n",
    "        # Get Absorbance columns based on selected groups\n",
    "        if selected_groups:\n",
    "            Absorbance_cols = [f'Avg_{var}' for var in selected_groups]\n",
    "        else:\n",
    "            Absorbance_cols = self._get_avg_columns()\n",
    "            \n",
    "        df['Total_Absorbance'] = df[Absorbance_cols].sum(axis=1).astype(int)\n",
    "        \n",
    "        # Filter out zero Absorbance entries\n",
    "        result_df = df[['unique ID', 'Total_Absorbance']]\n",
    "        result_df = result_df[result_df['Total_Absorbance'] == 0]\n",
    "        all_zero_list = list(result_df['unique ID'])\n",
    "        peptides_df = df[~df['unique ID'].isin(all_zero_list)]\n",
    "\n",
    "        # Process protein positions and create proteins DataFrame\n",
    "        additional_columns = ['Master Protein Accessions', 'unique ID']\n",
    "        selected_columns = additional_columns + Absorbance_cols\n",
    "        \n",
    "        peptides_df.loc[:, 'Master Protein Accessions'] = peptides_df['Master Protein Accessions']\n",
    "        \n",
    "        temp_df = peptides_df.copy()\n",
    "        temp_df.loc[:, 'Protein_ID'] = temp_df['Master Protein Accessions']\n",
    "        \n",
    "        # Create proteins DataFrame with selected columns\n",
    "        self.proteins_df = temp_df.groupby('Protein_ID').agg(\n",
    "            {**{col: 'first' for col in ['Master Protein Accessions']},\n",
    "             **{col: 'sum' for col in Absorbance_cols}}\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Calculate relative Absorbance for selected groups\n",
    "        for col in Absorbance_cols:\n",
    "            col_sum = self.proteins_df[col].sum()\n",
    "            if col_sum > 0:  # Avoid division by zero\n",
    "                self.proteins_df[f'Rel_{col}'] = (self.proteins_df[col] / col_sum) * 100\n",
    "            else:\n",
    "                self.proteins_df[f'Rel_{col}'] = 0\n",
    "            \n",
    "        # Create sum DataFrame for selected groups\n",
    "        self.sum_df = pd.DataFrame({\n",
    "            'Sample': Absorbance_cols,\n",
    "            'Total_Sum': [self.proteins_df[col].sum() for col in Absorbance_cols]\n",
    "        })\n",
    "        \n",
    "        # Add protein descriptions\n",
    "        name_list = []\n",
    "        for _, row in self.proteins_df.iterrows():\n",
    "            if ',' in row['Protein_ID']:\n",
    "                strrow = row['Protein_ID'].split(',')\n",
    "                named_combo = self._fetch_protein_names('; '.join(strrow))\n",
    "            else:\n",
    "                named_combo = self._fetch_protein_names(row['Protein_ID'])\n",
    "            name_list.append(named_combo)\n",
    "        \n",
    "        # Drop the 'Protein_ID' column\n",
    "        self.proteins_df = self.proteins_df.drop(columns=['Protein_ID'])    \n",
    "        \n",
    "        self.proteins_df['Description'] = name_list\n",
    "        self.proteins_df['Description'] = self.proteins_df['Description'].astype(str).str.replace(r\"['\\['\\]]\", \"\", regex=True)\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def _fetch_protein_names(self, accession_str):\n",
    "        \"\"\"\n",
    "        Fetch protein names from the proteins dictionary.\n",
    "        Returns a list of protein names, using the full protein name.\n",
    "        \"\"\"\n",
    "        names = []\n",
    "        for acc in accession_str.split('; '):\n",
    "            if acc in self.data_transformer.proteins_dic:\n",
    "                # Use the full protein name instead of splitting it\n",
    "                name = self.data_transformer.proteins_dic[acc]['name']\n",
    "                names.append(name)\n",
    "            else:\n",
    "                names.append(acc)\n",
    "        return names\n",
    "\n",
    "    def _get_color_sequence(self, n_colors):\n",
    "        \"\"\"Get color sequence based on selected scheme.\"\"\"\n",
    "        if n_colors <= 0:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            scheme = self.color_scheme.value\n",
    "            \n",
    "            # Skip header options that start with '---'\n",
    "            if scheme.startswith('---'):\n",
    "                scheme = 'HSV'  # Default to HSV if a header is selected\n",
    "            \n",
    "            # Handle special cases\n",
    "            if scheme.lower() in ['rainbow', 'hsv']:\n",
    "                return [f'hsl({h},70%,60%)' for h in np.linspace(0, 330, n_colors)]\n",
    "            \n",
    "            # Try qualitative color scales first (best for categorical data)\n",
    "            color_sequence = getattr(px.colors.qualitative, scheme, None)\n",
    "            if color_sequence is None:\n",
    "                # Try sequential color scales\n",
    "                color_sequence = getattr(px.colors.sequential, scheme, None)\n",
    "            if color_sequence is None:\n",
    "                # Try diverging color scales\n",
    "                color_sequence = getattr(px.colors.diverging, scheme, None)\n",
    "            if color_sequence is None:\n",
    "                # Try cyclical color scales\n",
    "                color_sequence = getattr(px.colors.cyclical, scheme, None)\n",
    "            \n",
    "            if color_sequence:\n",
    "                if n_colors >= len(color_sequence):\n",
    "                    # If we need more colors than available, interpolate\n",
    "                    indices = np.linspace(0, len(color_sequence)-1, n_colors)\n",
    "                    return [color_sequence[int(i)] for i in indices]\n",
    "                else:\n",
    "                    # If we need fewer colors, take a subset\n",
    "                    indices = np.linspace(0, len(color_sequence)-1, n_colors, dtype=int)\n",
    "                    return [color_sequence[i] for i in indices]\n",
    "            \n",
    "            # Default to HSV if no matching scheme found\n",
    "            return [f'hsl({h},70%,60%)' for h in np.linspace(0, 330, n_colors)]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating colors: {e}\")\n",
    "            # Fallback to HSV\n",
    "            return [f'hsl({h},70%,60%)' for h in np.linspace(0, 330, n_colors)]   \n",
    "  \n",
    "    def plot_stacked_bar_scaled(self, pro_list, title, selected_groups):\n",
    "        if self.proteins_df is None or self.sum_df is None:\n",
    "            return None\n",
    "                \n",
    "        scaled_df = self.proteins_df.copy()\n",
    "        \n",
    "        # Filter for selected groups\n",
    "        sample_orders = [f'Rel_Avg_{var}' for var in selected_groups]\n",
    "        \n",
    "        # Create sample mapping for selected groups\n",
    "        sample_mapping = {\n",
    "            f'Rel_Avg_{var}': f'Avg_{var}' for var in selected_groups\n",
    "        }\n",
    "        \n",
    "        # Convert relative absorbance columns to percentages\n",
    "        for col in sample_orders:\n",
    "            scaled_df[col] = self.proteins_df[col] * 100\n",
    "                \n",
    "        # Calculate total sums for each group first\n",
    "        total_sums = {}\n",
    "        for col in sample_orders:\n",
    "            sample_key = sample_mapping[col]\n",
    "            total_sum = self.sum_df.loc[self.sum_df['Sample'] == sample_key, 'Total_Sum'].values[0]\n",
    "            total_sums[col.replace('Rel_Avg_', '')] = total_sum  # Store with clean group name\n",
    "        \n",
    "        # Scale absolute Absorbance\n",
    "        for col in sample_orders:\n",
    "            sample_key = sample_mapping[col]\n",
    "            total_sum = self.sum_df.loc[self.sum_df['Sample'] == sample_key, 'Total_Sum'].values[0]\n",
    "            if total_sum > 0:\n",
    "                scaled_df[col] = self.proteins_df[col] * total_sum / self.proteins_df[col].sum()\n",
    "        \n",
    "        # Create a new DataFrame for the Minor Proteins\n",
    "        minor_proteins_df = pd.DataFrame()\n",
    "        \n",
    "        # For each sample, calculate the sum of proteins not in pro_list\n",
    "        for sample in sample_orders:\n",
    "            abs_col = sample_mapping[sample]\n",
    "            # Sum absorbance for proteins not in pro_list\n",
    "            minor_proteins_absorbance = scaled_df[~scaled_df['Description'].isin(pro_list)][sample].sum()\n",
    "            minor_proteins_rel_absorbance = self.proteins_df[~self.proteins_df['Description'].isin(pro_list)][sample].sum()\n",
    "            \n",
    "            # Add to the minor proteins DataFrame\n",
    "            if len(minor_proteins_df) == 0:\n",
    "                minor_proteins_df = pd.DataFrame({\n",
    "                    'Description': ['Minor Proteins'],\n",
    "                    'Master Protein Accessions': ['Minor Proteins'],\n",
    "                    sample: [minor_proteins_absorbance],\n",
    "                    abs_col: [minor_proteins_absorbance]\n",
    "                })\n",
    "            else:\n",
    "                minor_proteins_df[sample] = [minor_proteins_absorbance]\n",
    "                minor_proteins_df[abs_col] = [minor_proteins_absorbance]\n",
    "        \n",
    "        # Filter scaled_df to only include proteins in pro_list\n",
    "        scaled_df = scaled_df[scaled_df['Description'].isin(pro_list)]\n",
    "        \n",
    "        # Sort proteins_df based on pro_list\n",
    "        description_order = {desc: i for i, desc in enumerate(pro_list)}\n",
    "        scaled_df['Order'] = scaled_df['Description'].map(description_order)\n",
    "        scaled_df = scaled_df.sort_values(by='Order').reset_index(drop=True)\n",
    "        \n",
    "        # Append minor proteins to the end\n",
    "        scaled_df = pd.concat([scaled_df, minor_proteins_df], ignore_index=True)\n",
    "        \n",
    "        # Create figure object before adding traces\n",
    "        fig = go.Figure()\n",
    "\n",
    "            # Calculate total absorbance for each sample\n",
    "        total_absorbance = {}\n",
    "        for sample in sample_orders:\n",
    "            total_absorbance[sample] = scaled_df[sample].sum()\n",
    "\n",
    "\n",
    "        if self.invert_plot.value == 'By Sample':\n",
    "            # Get colors based on selected color scheme\n",
    "            colors = self._get_color_sequence(len(pro_list))\n",
    "            # Add gray color for Minor Proteins\n",
    "            colors.append('#808080')  # Gray color for Minor Proteins\n",
    "        \n",
    "\n",
    "            # Filter out zero values for plotting\n",
    "            for idx, row in scaled_df.iterrows():\n",
    "                protein_description = row['Description']\n",
    "                if protein_description in pro_list or protein_description == 'Minor Proteins':\n",
    "                    # Use gray for Minor Proteins, otherwise use the color from the sequence\n",
    "                    if protein_description == 'Minor Proteins':\n",
    "                        color = '#808080'  # Gray color\n",
    "                    else:\n",
    "                        color = colors[pro_list.index(protein_description)]\n",
    "                    \n",
    "                    # Only plot non-zero values\n",
    "                    x_values = []\n",
    "                    y_values = []\n",
    "\n",
    "                    for i, sample in enumerate(sample_orders):\n",
    "                        value = row[sample]\n",
    "                        if value > 0:  # Only include non-zero values\n",
    "                            x_values.append(sample.replace('Rel_Avg_', ''))\n",
    "                            y_values.append(value)\n",
    "                            \n",
    "                            abs_col = sample_mapping[sample]\n",
    "                            if protein_description == 'Minor Proteins':\n",
    "                                rel_value_hov = row[sample] / total_absorbance[sample] * 100 if total_absorbance[sample] > 0 else 0\n",
    "                            else:\n",
    "                                rel_value_hov = self.proteins_df.loc[self.proteins_df['Description'] == protein_description, sample].values[0]\n",
    "                            abs_value = row[abs_col]\n",
    "                            \n",
    "\n",
    "                    \n",
    "                    if y_values:  # Only add trace if there are non-zero values\n",
    "                        fig.add_trace(go.Bar(\n",
    "                            name=protein_description,\n",
    "                            x=[label.replace('Rel_Avg_', '') for label in sample_orders],  # Keep all x values for alignment\n",
    "                            y=row[sample_orders],  # Keep all y values, including zeros\n",
    "                            marker_color=color,\n",
    "                            hovertext=[\n",
    "                                f\"Protein: {row['Master Protein Accessions']}<br>\" +\n",
    "                                f\"Description: {row['Description']}<br>\" +\n",
    "                                #f\"Sample: {sample.replace('Rel_Avg_', '')}<br>\" +\n",
    "                                f\"Relative Absorbance: {self.proteins_df.loc[self.proteins_df['Description'] == protein_description, s].values[0] if protein_description != 'Minor Proteins' else row[s] / total_absorbance[s] * 100 if total_absorbance[s] > 0 else 0:.2f}%<br>\" +\n",
    "                                f\"Absolute Absorbance: {row[sample_mapping[s]]:.2e}<br>\"\n",
    "                                for s in sample_orders\n",
    "                            ],\n",
    "                            hoverinfo='text'\n",
    "                        ))\n",
    "        else:\n",
    "            # Inverted plotting logic (proteins on x-axis)\n",
    "            # Get colors based on selected color scheme\n",
    "            colors = self._get_color_sequence(len(selected_groups))\n",
    "            \n",
    "            # For each sample, create a trace\n",
    "            for i, sample in enumerate(sample_orders):\n",
    "                sample_display = sample.replace('Rel_Avg_', '')\n",
    "                abs_col = sample_mapping[sample]\n",
    "                \n",
    "                # Prepare data for this sample\n",
    "                x_values = []  # Protein names\n",
    "                y_values = []  # Values for this sample\n",
    "\n",
    "                for _, row in scaled_df.iterrows():\n",
    "                    protein_description = row['Description']\n",
    "                    if protein_description in pro_list or protein_description == 'Minor Proteins':\n",
    "                        value = row[sample]\n",
    "                        if value > 0:  # Only include non-zero values\n",
    "                            x_values.append(protein_description)\n",
    "                            y_values.append(value)\n",
    "                            \n",
    "                            # Create hover text\n",
    "                            if protein_description == 'Minor Proteins':\n",
    "                                rel_value_hov = row[sample] / total_absorbance[sample] * 100 if total_absorbance[sample] > 0 else 0\n",
    "                            else:\n",
    "                                rel_value_hov = self.proteins_df.loc[self.proteins_df['Description'] == protein_description, sample].values[0]\n",
    "                            \n",
    "\n",
    "                if y_values:  # Only add trace if there are non-zero values\n",
    "                    fig.add_trace(go.Bar(\n",
    "                        name=sample_display,  # Use sample name for legend\n",
    "                        x=pro_list + (['Minor Proteins'] if 'Minor Proteins' in scaled_df['Description'].values else []),\n",
    "                        y=scaled_df[sample],  # Use all values to maintain alignment\n",
    "                        marker_color=colors[i],\n",
    "                        hovertext=[\n",
    "                            #f\"Protein: {row['Master Protein Accessions']}<br>\" +\n",
    "                            #f\"Description: {row['Description']}<br>\" +\n",
    "                            f\"Sample: {sample_display}<br>\" +\n",
    "                            f\"Relative Absorbance: {self.proteins_df.loc[self.proteins_df['Description'] == row['Description'], sample].values[0] if row['Description'] != 'Minor Proteins' else row[sample] / total_absorbance[sample] * 100 if total_absorbance[sample] > 0 else 0:.2f}%<br>\" +\n",
    "                            f\"Absolute Absorbance: {row[abs_col]:.2e}<br>\"\n",
    "                            for _, row in scaled_df.iterrows()\n",
    "                        ],\n",
    "                        hoverinfo='text'\n",
    "                    ))\n",
    "\n",
    "        \n",
    "        # Get custom labels\n",
    "        x_label = self.xlabel_widget.value or ('Proteins' if self.invert_plot.value == 'By Protein' else 'Samples')\n",
    "        y_label = self.ylabel_widget.value or 'Summed Absorbance'\n",
    "        plot_title = self.title_widget.value or title or 'Protein Distribution Analysis'\n",
    "        legend_title = self.legend_widget.value or ('Samples' if self.invert_plot.value == 'By Protein' else 'Protein Origins')\n",
    "\n",
    "        fig.update_layout(\n",
    "            barmode='stack',\n",
    "            title={\n",
    "                'text': plot_title,\n",
    "                'y': 0.95,\n",
    "                'x': 0.5,\n",
    "                'xanchor': 'center',\n",
    "                'yanchor': 'top',\n",
    "                'font': {\"size\": 18, 'color': 'black'}\n",
    "            },\n",
    "        xaxis_title=x_label,\n",
    "        yaxis_title=y_label,\n",
    "\n",
    "        #yaxis_type='log',  # Set y-axis to log scale\n",
    "        yaxis=dict(\n",
    "            showline=True,\n",
    "            gridcolor='lightgray',\n",
    "            showgrid=True,\n",
    "            showticklabels=True,  # Hide tick labels on y-axis\n",
    "            linewidth=1,\n",
    "            linecolor='black',\n",
    "            mirror=False,\n",
    "            zeroline=False  # Don't show zero line\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            showline=True,\n",
    "            linewidth=1,\n",
    "            linecolor='black',\n",
    "            mirror=False,\n",
    "            tickangle=-90 if self.invert_plot.value == 'By Sample' else 45  # Adjust tick angle based on orientation\n",
    "        ),\n",
    "        legend_title=legend_title,\n",
    "        legend={\n",
    "            'yanchor': \"top\",\n",
    "            'y': 0.95,\n",
    "            'xanchor': \"left\",\n",
    "            'x': 1.05,\n",
    "            'traceorder': 'normal',\n",
    "            'font': {\"size\": 16, 'color': 'black'},\n",
    "            'bgcolor': 'rgba(255, 255, 255, 0.9)'\n",
    "        },\n",
    "        showlegend=True,\n",
    "        template='plotly_white',\n",
    "        height=820,\n",
    "        width=1200,\n",
    "        margin=dict(\n",
    "            t=100,\n",
    "            l=100,\n",
    "            r=100,\n",
    "            b=100\n",
    "        ),\n",
    "        hoverlabel=dict(\n",
    "            bgcolor=\"white\",\n",
    "            font_size=14,\n",
    "            font_family=\"Arial\"\n",
    "        ))\n",
    "        \n",
    "        fig.update_xaxes(\n",
    "            tickangle=45,\n",
    "            title_font={\"size\": 18},\n",
    "            tickfont={\"size\": 16},\n",
    "            tickfont_color=\"black\",  # Black tick labels\n",
    "            title_font_color=\"black\",  # Black axis title                \n",
    "        )\n",
    "        \n",
    "        fig.update_yaxes(\n",
    "            title_font={\"size\": 18},\n",
    "            tickfont={\"size\": 16},\n",
    "            tickfont_color=\"black\",  # Black tick labels\n",
    "            title_font_color=\"black\",  # Black axis title\n",
    "            gridcolor=\"lightgray\",  # Light gray grid lines\n",
    "            showgrid=True,  # Show grid lines\n",
    "            zeroline=False,  # Hide zero line\n",
    "            exponentformat='E',\n",
    "            showexponent='all',\n",
    "            tickformat=\".1e\"\n",
    "        )\n",
    "        # Always add scatter trace for totals, but calculate differently based on orientation\n",
    "        if self.invert_plot.value == 'By Sample':\n",
    "            # Original sample-wise totals calculation\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[label.replace('Rel_Avg_', '') for label in sample_orders],\n",
    "                y=[total_sums[group.replace('Rel_Avg_', '')] for group in sample_orders],\n",
    "                mode='text',\n",
    "                text=[f\"{total_sums[group.replace('Rel_Avg_', '')]:.2e}\" for group in sample_orders],\n",
    "                textposition='top center',\n",
    "                textfont=dict(size=12, color='black'),\n",
    "                showlegend=True,\n",
    "                name='Show Summed Absorbance',\n",
    "                hoverinfo='none',  # Remove hover info for summed absorbance\n",
    "                texttemplate='%{text}'\n",
    "            ))\n",
    "        else:\n",
    "            # Calculate protein-wise totals\n",
    "            protein_sums = {}\n",
    "            for protein in pro_list + (['Minor Proteins'] if 'Minor Proteins' in scaled_df['Description'].values else []):\n",
    "                # Sum all sample values for this protein\n",
    "                protein_values = scaled_df[scaled_df['Description'] == protein][sample_orders].values[0]\n",
    "                protein_total = sum(protein_values)\n",
    "                protein_sums[protein] = protein_total\n",
    "\n",
    "            # Add the protein totals trace\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=list(protein_sums.keys()),\n",
    "                y=list(protein_sums.values()),\n",
    "                mode='text',\n",
    "                text=[f\"{value:.2e}\" for value in protein_sums.values()],\n",
    "                textposition='top center',\n",
    "                textfont=dict(size=12, color='black'),\n",
    "                showlegend=True,\n",
    "                name='Show Summed Absorbance',\n",
    "                hoverinfo='none',  # Remove hover info for summed absorbance\n",
    "                texttemplate='%{text}'\n",
    "            ))       \n",
    "            \n",
    "        # Mark generation as complete\n",
    "        self.state_manager.generate_completed()\n",
    "        self.export_button.disabled = False\n",
    "        self.download_plot_button.disabled = False\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def _on_plot_button_click(self, b):\n",
    "        if self.current_fig is not None:\n",
    "            self.state_manager.generate_completed()\n",
    "            self.export_button.disabled = False\n",
    "            self.download_plot_button.disabled = False\n",
    "        with self.plot_output:\n",
    "            self.plot_output.clear_output(wait=True)\n",
    "            \n",
    "            if not self.group_select.value:\n",
    "                print(\"Please select at least one group to plot.\")\n",
    "                return\n",
    "            \n",
    "            selected_groups = list(self.group_select.value)\n",
    "            if self.process_data(selected_groups):\n",
    "                # Calculate average Absorbance for sorting using only selected groups\n",
    "                selected_avg_columns = [f'Avg_{var}' for var in selected_groups]\n",
    "                #self.proteins_df['avg_absorbance_all'] = self.proteins_df[selected_avg_columns].mean(axis=1)\n",
    "                                \n",
    "                # Calculate sum of all selected columns\n",
    "                total_sum =  self.proteins_df[selected_avg_columns].sum().sum()\n",
    "                \n",
    "                # Calculate row sums\n",
    "                row_sums =  self.proteins_df[selected_avg_columns].sum(axis=1)\n",
    "                \n",
    "                # Calculate relative percentage contribution\n",
    "                self.proteins_df['avg_absorbance_all'] = (row_sums / total_sum * 100).round(2)\n",
    "                \n",
    "                # Sort and get top N proteins\n",
    "                self.proteins_df = self.proteins_df.sort_values('avg_absorbance_all', ascending=False)\n",
    "                \n",
    "                # Sort and get top N proteins\n",
    "                pro_list = list(self.proteins_df ['Description'].head(self.num_proteins_widget.value))\n",
    "                \n",
    "                # Create and store plot\n",
    "                self.current_fig = self.plot_stacked_bar_scaled(\n",
    "                    pro_list=pro_list,\n",
    "                    title='Protein Distribution Analysis',  # Add a default title here\n",
    "                    selected_groups=selected_groups\n",
    "                )\n",
    "                if self.current_fig is not None:\n",
    "                    self.current_fig.show()\n",
    "            else:\n",
    "                print(\"Please upload all required files first.\")\n",
    "                print(\"Error creating plot. Please check your data.\")\n",
    "    \n",
    "    def generate_download_link(self, content, filename, filetype='text/csv'):\n",
    "        \"\"\"Generate a download link for any content\"\"\"\n",
    "        if isinstance(content, pd.DataFrame):\n",
    "            if filetype == 'text/csv':\n",
    "                content = content.to_csv(index=False)\n",
    "            else:\n",
    "                content = content.to_csv(index=True)\n",
    "        if isinstance(content, str):\n",
    "            content = content.encode()\n",
    "        b64 = base64.b64encode(content).decode()\n",
    "        return f\"\"\"\n",
    "            <a id=\"download_link\" href=\"data:{filetype};base64,{b64}\" \n",
    "               download=\"{filename}\"\n",
    "               style=\"display: none;\">\n",
    "                Download {filename}\n",
    "            </a>\n",
    "            <script>\n",
    "                document.getElementById('download_link').click();\n",
    "            </script>\n",
    "            \"\"\"\n",
    "    \n",
    "    def _on_download_plot_click(self, b):\n",
    "        \"\"\"Handle plot download button click with automatic download\"\"\"\n",
    "        if self.current_fig is not None:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            plot_filename = f'protein_plot_{timestamp}.html'\n",
    "            \n",
    "            with self.export_output:\n",
    "                self.export_output.clear_output(wait=True)\n",
    "                display(HTML(self.generate_download_link(\n",
    "                    self.current_fig.to_html(),\n",
    "                    plot_filename,\n",
    "                    'text/html'\n",
    "                )))\n",
    "        else:\n",
    "            print(\"Please generate a plot first.\")\n",
    "    \n",
    "    def _on_export_button_click(self, b):\n",
    "        \"\"\"Handle data export with automatic download\"\"\"\n",
    "        if self.proteins_df is not None:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            data_filename = f'protein_absorbance_analysis_{timestamp}.csv'\n",
    "            \n",
    "            with self.export_output:\n",
    "                self.export_output.clear_output(wait=True)\n",
    "                display(HTML(self.generate_download_link(\n",
    "                    self.proteins_df,\n",
    "                    data_filename,\n",
    "                    'text/csv'\n",
    "                )))\n",
    "        else:\n",
    "            print(\"Please generate the analysis first.\")\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Display the protein analysis interface\"\"\"\n",
    "        display(self.widget_box)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1775dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the interface\n",
    "data_transformer = DataTransformation()\n",
    "data_transformer.setup_data_loading_ui()\n",
    "\n",
    "# Create protein plotter\n",
    "protein_plotter = ProteinPlotter(data_transformer)\n",
    "protein_plotter.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (newenv)",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
