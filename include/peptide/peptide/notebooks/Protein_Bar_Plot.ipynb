{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62bd34aa-691e-4d2e-ac73-b2668c0542ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json, io, base64, re, os, requests, time, traceback\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from xml.etree import ElementTree\n",
    "# Initialize settings\n",
    "import _settings as settings\n",
    "\n",
    "# Global variables from settings\n",
    "spec_translate_list = settings.SPEC_TRANSLATE_LIST\n",
    "plotly_colors = settings.plotly_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cfaad00-f6e2-48b6-9b73-07bd9559fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self):\n",
    "        self.merged_df = None\n",
    "        self.proteins_dic = {}\n",
    "        self.output_area = None\n",
    "        self.merged_uploader = None\n",
    "\n",
    "    def create_download_link(self, file_path, label):\n",
    "        \"\"\"Create a download link for a file.\"\"\"\n",
    "        if os.path.exists(file_path):\n",
    "            # Read file content and encode it as base64\n",
    "            with open(file_path, 'rb') as f:\n",
    "                content = f.read()\n",
    "            b64_content = base64.b64encode(content).decode('utf-8')\n",
    "\n",
    "            # Generate the download link HTML\n",
    "            return widgets.HTML(f\"\"\"\n",
    "                <a download=\"{os.path.basename(file_path)}\" \n",
    "                   href=\"data:application/octet-stream;base64,{b64_content}\" \n",
    "                   style=\"color: #0366d6; text-decoration: none; margin-left: 20px; font-size: 14px;\">\n",
    "                    {label}\n",
    "                </a>\n",
    "            \"\"\")\n",
    "        else:\n",
    "            # Show an error message if the file does not exist\n",
    "            return widgets.HTML(f\"\"\"\n",
    "                <span style=\"color: red; margin-left: 20px; font-size: 14px;\">\n",
    "                    File \"{file_path}\" not found!\n",
    "                </span>\n",
    "            \"\"\")\n",
    "\n",
    "    def setup_data_loading_ui(self):\n",
    "        \"\"\"Initialize and display the data loading UI.\"\"\"\n",
    "        # Create file upload widget\n",
    "        self.merged_uploader = widgets.FileUpload(\n",
    "            accept='.csv,.txt,.tsv,.xlsx',\n",
    "            multiple=False,\n",
    "            description='Upload Merged Data File',\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "\n",
    "        self.output_area = widgets.Output()\n",
    "\n",
    "        # Create upload box with example link\n",
    "        merged_box = widgets.HBox([\n",
    "            self.merged_uploader,\n",
    "            self.create_download_link(\"example_merged_dataframe.csv\", \"Example\")\n",
    "        ], layout=widgets.Layout(align_items='center'))\n",
    "\n",
    "        # Create left column with upload widgets\n",
    "        upload_widgets = widgets.VBox([\n",
    "            widgets.HTML(\"<h4>Upload Data File:</h4>\"),\n",
    "            merged_box,\n",
    "            self.output_area\n",
    "        ], layout=widgets.Layout(\n",
    "            width='300px',\n",
    "            margin='0 20px 0 0'\n",
    "        ))\n",
    "\n",
    "        # Create container for status display\n",
    "        self.status_area = widgets.Output(\n",
    "            layout=widgets.Layout(\n",
    "                width='300px',\n",
    "                margin='0 0 0 20px'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        display(upload_widgets,\n",
    "                self.status_area)\n",
    "\n",
    "        # Register observer\n",
    "        self.merged_uploader.observe(self._on_merged_upload_change, names='value')\n",
    "\n",
    "    def _validate_and_clean_data(self, df):\n",
    "        \"\"\"\n",
    "        Validate and clean the uploaded data, preserving numeric data even if stored as strings.\n",
    "        Returns tuple of (cleaned_df, warnings, errors)\n",
    "        \"\"\"\n",
    "        warnings = []\n",
    "        errors = []\n",
    "        cleaned_df = df.copy()\n",
    "    \n",
    "        # Check required columns exist\n",
    "        required_columns = [\n",
    "            'Master Protein Accessions', \n",
    "            'unique ID'\n",
    "        ]\n",
    "        \n",
    "        # Check that at least one Avg_ column exists\n",
    "        avg_columns = [col for col in df.columns if col.startswith('Avg_')]\n",
    "        if not avg_columns:\n",
    "            errors.append(\"No columns starting with 'Avg_' found in the data\")\n",
    "            return None, warnings, errors\n",
    "            \n",
    "        # Add Avg_ columns to required columns\n",
    "        required_columns.extend(avg_columns)\n",
    "        \n",
    "        missing = set(required_columns) - set(df.columns)\n",
    "        if missing:\n",
    "            errors.append(f\"Missing required columns: {', '.join(missing)}\")\n",
    "            return None, warnings, errors\n",
    "    \n",
    "        # Separate numeric and non-numeric columns\n",
    "        numeric_columns = avg_columns  # Avg_ columns should be numeric\n",
    "        text_columns = ['Master Protein Accessions', 'unique ID']\n",
    "    \n",
    "        # Handle blank values differently for numeric vs text columns\n",
    "        for column in required_columns:\n",
    "            if column in numeric_columns:\n",
    "                # For numeric columns, try to convert to numeric first\n",
    "                try:\n",
    "                    # Convert to numeric, coerce errors to NaN\n",
    "                    cleaned_df[column] = pd.to_numeric(cleaned_df[column], errors='coerce')\n",
    "                    blank_count = cleaned_df[column].isna().sum()\n",
    "                    if blank_count > 0:\n",
    "                        warnings.append(f\"Found {blank_count} invalid/blank numeric values in {column} column\")\n",
    "                except Exception as e:\n",
    "                    errors.append(f\"Error converting {column} to numeric: {str(e)}\")\n",
    "                    return None, warnings, errors\n",
    "            elif column in text_columns:\n",
    "                # For text columns, check for truly empty values\n",
    "                blank_mask = cleaned_df[column].isna() | (cleaned_df[column].astype(str).str.strip() == '')\n",
    "                blank_count = blank_mask.sum()\n",
    "                if blank_count > 0:\n",
    "                    warnings.append(f\"Dropping {blank_count} rows with blank values in {column} column\")\n",
    "                    cleaned_df = cleaned_df[~blank_mask]\n",
    "    \n",
    "        # Check for invalid characters in non-blank rows\n",
    "        if len(cleaned_df) > 0:\n",
    "            # Check Positions in Proteins\n",
    "            invalid_pos = cleaned_df['Positions in Proteins'].apply(\n",
    "                lambda x: ',' in str(x) or ':' in str(x)\n",
    "            )\n",
    "            if invalid_pos.any():\n",
    "                errors.append(\n",
    "                    \"Found invalid characters (',' or ':') in Positions in Proteins column. \"\n",
    "                    \"Please update the file and upload again.\"\n",
    "                )\n",
    "            \n",
    "            # Check Master Protein Accessions\n",
    "            invalid_acc = cleaned_df['Master Protein Accessions'].apply(\n",
    "                lambda x: ',' in str(x) or ':' in str(x)\n",
    "            )\n",
    "            if invalid_acc.any():\n",
    "                errors.append(\n",
    "                    \"Found invalid characters (',' or ':') in Master Protein Accessions column. \"\n",
    "                    \"Please update the file and upload again.\"\n",
    "                )\n",
    "    \n",
    "        return cleaned_df, warnings, errors\n",
    "\n",
    "    def _process_protein_info(self, df):\n",
    "        \"\"\"\n",
    "        Process protein information from the dataframe and store in proteins_dic.\n",
    "        Asks user whether to fetch from UniProt or use accession IDs when protein info is missing.\n",
    "        \"\"\"\n",
    "        # Initialize a cache for UniProt information to avoid redundant queries\n",
    "        self.uniprot_cache = getattr(self, 'uniprot_cache', {})\n",
    "        \n",
    "        # Check if we need to fetch any data from UniProt\n",
    "        has_protein_info = all(col in df.columns for col in ['protein_name', 'protein_species'])\n",
    "        if has_protein_info:\n",
    "            # Check if we have valid data for all entries\n",
    "            all_data_present = (\n",
    "                df['protein_name'].notna().all() and \n",
    "                df['protein_species'].notna().all() and\n",
    "                (df['protein_name'] != '').all() and\n",
    "                (df['protein_species'] != '').all()\n",
    "            )\n",
    "            if all_data_present:\n",
    "                # If we have all data, just process it silently\n",
    "                protein_info = df.groupby('Master Protein Accessions').agg({\n",
    "                    'protein_name': 'first',\n",
    "                    'protein_species': 'first'\n",
    "                }).reset_index()\n",
    "                \n",
    "                for _, row in protein_info.iterrows():\n",
    "                    protein_id = row['Master Protein Accessions']\n",
    "                    self.proteins_dic[protein_id] = {\n",
    "                        \"name\": row['protein_name'],\n",
    "                        \"species\": row['protein_species']\n",
    "                    }\n",
    "                return len(self.proteins_dic)\n",
    "\n",
    "        # Store the dataframe for later processing\n",
    "        self._protein_df_to_process = df\n",
    "        \n",
    "        # Create a flag to track if processing is complete\n",
    "        self._protein_processing_complete = False\n",
    "        \n",
    "        # If we need to fetch data, ask the user what they want to do\n",
    "        # Display in the status area\n",
    "        with self.status_area:\n",
    "            self.status_area.clear_output()\n",
    "            \n",
    "            # Create buttons for user choice\n",
    "            fetch_button = widgets.Button(\n",
    "                description='Query UniProt',\n",
    "                button_style='info',\n",
    "                tooltip='Fetch protein names from UniProt database (may take time)',\n",
    "                layout=widgets.Layout(width='250px')\n",
    "            )\n",
    "            \n",
    "            use_accession_button = widgets.Button(\n",
    "                description='Use Protein IDs',\n",
    "                button_style='warning',\n",
    "                tooltip='Use protein accession IDs as names without querying UniProt',\n",
    "                layout=widgets.Layout(width='250px')\n",
    "            )\n",
    "            \n",
    "            # Define button click handlers\n",
    "            fetch_button.on_click(lambda b: self._process_proteins_with_choice(True))\n",
    "            use_accession_button.on_click(lambda b: self._process_proteins_with_choice(False))\n",
    "            \n",
    "            display(HTML(\"\"\"\n",
    "                <div style=\"padding: 15px; margin: 10px 0; border-left: 4px solid #17a2b8; background-color: #f8f9fa;\">\n",
    "                    <h4 style=\"margin-top: 0;\">Protein Information Missing</h4>\n",
    "                    <p>Some protein names or species information is missing in your data.</p>\n",
    "                    <p>Would you like to:</p>\n",
    "                         <ul>\n",
    "                                <li>Fetch protein names from UniProt database (may take time)</li>\n",
    "                                <li>Use protein accession IDs as names without querying UniProt</li>\n",
    "                        </ul>\n",
    "                </div>\n",
    "            \"\"\"))\n",
    "            display(widgets.HBox([fetch_button, use_accession_button]))\n",
    "        \n",
    "        # Return the current count, but processing will continue when a button is clicked\n",
    "        return len(self.proteins_dic)\n",
    "\n",
    "    def _process_proteins_with_choice(self, fetch_from_uniprot):\n",
    "        \"\"\"\n",
    "        Process proteins based on user choice.\n",
    "        This is called when the user clicks one of the choice buttons.\n",
    "        \"\"\"\n",
    "        # Get the dataframe to process\n",
    "        df = self._protein_df_to_process\n",
    "        \n",
    "        # Clear the status area and show processing message\n",
    "        with self.status_area:\n",
    "            self.status_area.clear_output()\n",
    "            if fetch_from_uniprot:\n",
    "                display(HTML('<div style=\"color: #17a2b8; padding: 10px; margin: 10px 0;\">Fetching protein information from UniProt...</div>'))\n",
    "            else:\n",
    "                display(HTML('<div style=\"color: #ffc107; padding: 10px; margin: 10px 0;\">Using protein accession IDs as names...</div>'))\n",
    "        \n",
    "        # Process proteins based on user choice\n",
    "        # Use the status area for progress display\n",
    "        with self.status_area:\n",
    "            # Initialize counters\n",
    "            total_proteins = 0\n",
    "            uniprot_found = 0\n",
    "            uniprot_not_found = 0\n",
    "            multiple_entries = 0\n",
    "            cached_proteins = 0\n",
    "            \n",
    "            # Check if we need to fetch any data from UniProt\n",
    "            has_protein_info = all(col in df.columns for col in ['protein_name', 'protein_species'])\n",
    "            \n",
    "            # Group by protein accession to get unique proteins\n",
    "            protein_info = df.groupby('Master Protein Accessions').agg({\n",
    "                'protein_name': 'first' if 'protein_name' in df.columns else lambda x: None,\n",
    "                'protein_species': 'first' if 'protein_species' in df.columns else lambda x: None\n",
    "            }).reset_index()\n",
    "\n",
    "            progress_html = \"\"\"\n",
    "                <style>\n",
    "                    .fetch-status { font-family: monospace; margin: 10px 0; padding: 10px; }\n",
    "                    .fetch-progress { margin: 5px 0; padding: 5px; }\n",
    "                    .success { color: #28a745; }\n",
    "                    .warning { color: #ffc107; }\n",
    "                    .error { color: #dc3545; }\n",
    "                    .info { color: #17a2b8; }\n",
    "                    .summary { margin-top: 10px; padding: 10px;}\n",
    "                </style>\n",
    "                <div class=\"fetch-status\">\n",
    "                    <div id=\"progress-updates\"></div>\n",
    "                </div>\n",
    "            \"\"\"\n",
    "            \n",
    "            # First, collect all proteins that need fetching\n",
    "            proteins_to_fetch = []\n",
    "            \n",
    "            for _, row in protein_info.iterrows():\n",
    "                total_proteins += 1\n",
    "                protein_id = row['Master Protein Accessions']\n",
    "                \n",
    "                # Skip entries with multiple protein IDs\n",
    "                if ';' in protein_id:\n",
    "                    multiple_entries += 1\n",
    "                    self.proteins_dic[protein_id] = {\n",
    "                        \"name\": protein_id,\n",
    "                        \"species\": \"Multiple\"\n",
    "                    }\n",
    "                    continue\n",
    "                \n",
    "                # Use existing data if available and not empty\n",
    "                if (has_protein_info and \n",
    "                    pd.notna(row['protein_name']) and \n",
    "                    pd.notna(row['protein_species']) and \n",
    "                    row['protein_name'] != '' and \n",
    "                    row['protein_species'] != ''):\n",
    "                    self.proteins_dic[protein_id] = {\n",
    "                        \"name\": row['protein_name'],\n",
    "                        \"species\": row['protein_species']\n",
    "                    }\n",
    "                    continue\n",
    "                \n",
    "                # Check if we already have this protein in cache\n",
    "                if protein_id in self.uniprot_cache:\n",
    "                    cached_proteins += 1\n",
    "                    name, species = self.uniprot_cache[protein_id]\n",
    "                    self.proteins_dic[protein_id] = {\n",
    "                        \"name\": name,\n",
    "                        \"species\": species\n",
    "                    }\n",
    "                    continue\n",
    "                \n",
    "                # If we need to fetch and user chose to fetch from UniProt\n",
    "                if fetch_from_uniprot:\n",
    "                    proteins_to_fetch.append(protein_id)\n",
    "                else:\n",
    "                    # Use accession ID as name\n",
    "                    self.proteins_dic[protein_id] = {\n",
    "                        \"name\": protein_id,\n",
    "                        \"species\": \"Unknown\"\n",
    "                    }\n",
    "            \n",
    "            # Process proteins in batches if fetching from UniProt\n",
    "            if fetch_from_uniprot and proteins_to_fetch:\n",
    "                # Update progress display\n",
    "                display(HTML(progress_html + f\"\"\"\n",
    "                    <div class=\"fetch-progress info\">\n",
    "                        Preparing to fetch {len(proteins_to_fetch)} proteins from UniProt in batches...\n",
    "                    </div>\n",
    "                \"\"\"))\n",
    "                \n",
    "                # Process in batches of 50 (adjust as needed)\n",
    "                batch_size = 50\n",
    "                total_batches = (len(proteins_to_fetch) + batch_size - 1) // batch_size\n",
    "                \n",
    "                for batch_num in range(total_batches):\n",
    "                    start_idx = batch_num * batch_size\n",
    "                    end_idx = min((batch_num + 1) * batch_size, len(proteins_to_fetch))\n",
    "                    current_batch = proteins_to_fetch[start_idx:end_idx]\n",
    "                    \n",
    "                    # Update progress\n",
    "                    self.status_area.clear_output(wait=True)\n",
    "                    display(HTML(progress_html + f\"\"\"\n",
    "                        <div class=\"fetch-progress info\">\n",
    "                            Fetching batch {batch_num + 1}/{total_batches} ({len(current_batch)} proteins)...\n",
    "                        </div>\n",
    "                        <div class=\"summary\">\n",
    "                            <h4>Progress:</h4>\n",
    "                            <ul>\n",
    "                                <li>Total proteins: {total_proteins}</li>\n",
    "                                <li>Proteins from cache: {cached_proteins}</li>\n",
    "                                <li>UniProt matches found: {uniprot_found}</li>\n",
    "                                <li>UniProt matches not found: {uniprot_not_found}</li>\n",
    "                                <li>Multiple entry proteins: {multiple_entries}</li>\n",
    "                                <li>Remaining to fetch: {len(proteins_to_fetch) - start_idx}</li>\n",
    "                            </ul>\n",
    "                        </div>\n",
    "                    \"\"\"))\n",
    "                    \n",
    "                    # Fetch the batch using individual queries for now\n",
    "                    # We'll implement batch fetching later\n",
    "                    batch_results = {}\n",
    "                    for protein_id in current_batch:\n",
    "                        try:\n",
    "                            name, species = self.fetch_uniprot_info(protein_id)\n",
    "                            if name and species:\n",
    "                                batch_results[protein_id] = (name, species)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error fetching {protein_id}: {str(e)}\")\n",
    "                    \n",
    "                    # Process the results\n",
    "                    for protein_id in current_batch:\n",
    "                        if protein_id in batch_results:\n",
    "                            name, species = batch_results[protein_id]\n",
    "                            uniprot_found += 1\n",
    "                            self.proteins_dic[protein_id] = {\n",
    "                                \"name\": name,\n",
    "                                \"species\": species\n",
    "                            }\n",
    "                            # Add to cache\n",
    "                            self.uniprot_cache[protein_id] = (name, species)\n",
    "                        else:\n",
    "                            uniprot_not_found += 1\n",
    "                            self.proteins_dic[protein_id] = {\n",
    "                                \"name\": protein_id,\n",
    "                                \"species\": \"Unknown\"\n",
    "                            }\n",
    "                            # Cache the negative result too\n",
    "                            self.uniprot_cache[protein_id] = (protein_id, \"Unknown\")\n",
    "            \n",
    "            # Show final summary\n",
    "            self.status_area.clear_output(wait=True)\n",
    "            display(HTML(f\"\"\"\n",
    "                <div class=\"fetch-status\">\n",
    "                    <h4 style=\"color:green;\"><b>Protein Processing Complete!</b></h4>\n",
    "                    <div class=\"summary\">\n",
    "                        <h4>Final Summary:</h4>\n",
    "                        <ul>\n",
    "                            <li>Total proteins processed: {total_proteins}</li>\n",
    "                            <li>Proteins from cache: {cached_proteins}</li>\n",
    "                            <li>Multiple entry proteins: {multiple_entries}</li>\n",
    "                            {\"<li>UniProt matches found: \" + str(uniprot_found) + \"</li>\" if fetch_from_uniprot else \"\"}\n",
    "                            {\"<li>UniProt matches not found: \" + str(uniprot_not_found) + \"</li>\" if fetch_from_uniprot else \"\"}\n",
    "                        </ul>\n",
    "                    </div>\n",
    "                </div>\n",
    "            \"\"\"))\n",
    "        \n",
    "        # Mark processing as complete\n",
    "        self._protein_processing_complete = True\n",
    "        \n",
    "        # Update the merged_df with the protein information\n",
    "        if hasattr(self, 'merged_df') and self.merged_df is not None:\n",
    "            # Add protein_name and protein_species columns if they don't exist\n",
    "            if 'protein_name' not in self.merged_df.columns:\n",
    "                self.merged_df['protein_name'] = ''\n",
    "            if 'protein_species' not in self.merged_df.columns:\n",
    "                self.merged_df['protein_species'] = ''\n",
    "            \n",
    "            # Update the columns with the fetched information\n",
    "            for protein_id, info in self.proteins_dic.items():\n",
    "                mask = self.merged_df['Master Protein Accessions'] == protein_id\n",
    "                self.merged_df.loc[mask, 'protein_name'] = info['name']\n",
    "                self.merged_df.loc[mask, 'protein_species'] = info['species']\n",
    "        \n",
    "        # Return the number of proteins processed\n",
    "        return len(self.proteins_dic)\n",
    "\n",
    "    def fetch_uniprot_info_batch(self, protein_ids, max_retries=3, timeout=30):\n",
    "        \"\"\"\n",
    "        Fetch protein information for multiple proteins at once using UniProt's batch API.\n",
    "        Returns a dictionary mapping protein IDs to (name, species) tuples.\n",
    "        \"\"\"\n",
    "        if not protein_ids:\n",
    "            return {}\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        try:\n",
    "            # Use the batch REST API endpoint\n",
    "            batch_url = 'https://rest.uniprot.org/uniprotkb/search'\n",
    "            \n",
    "            # Create a query with OR conditions for each protein ID\n",
    "            query = ' OR '.join([f'accession:{pid}' for pid in protein_ids])\n",
    "            \n",
    "            # Parameters for the request\n",
    "            params = {\n",
    "                'query': query,\n",
    "                'format': 'json',\n",
    "                'fields': 'accession,protein_name,organism_name',\n",
    "                'size': len(protein_ids)  # Request all results in one response\n",
    "            }\n",
    "            \n",
    "            # Make the request with timeout and retry logic\n",
    "            retry_count = 0\n",
    "            while retry_count < max_retries:\n",
    "                try:\n",
    "                    response = requests.get(batch_url, params=params, timeout=timeout)\n",
    "                    \n",
    "                    # Handle rate limiting\n",
    "                    if response.status_code == 429:  # Too Many Requests\n",
    "                        retry_after = int(response.headers.get('Retry-After', 5))\n",
    "                        print(f\"Rate limited. Waiting {retry_after} seconds...\")\n",
    "                        time.sleep(retry_after + 1)  # Add 1 second buffer\n",
    "                        retry_count += 1\n",
    "                        continue\n",
    "                    \n",
    "                    # Break if successful\n",
    "                    if response.status_code == 200:\n",
    "                        break\n",
    "                    \n",
    "                    # Handle other errors\n",
    "                    response.raise_for_status()\n",
    "                    \n",
    "                except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as e:\n",
    "                    retry_count += 1\n",
    "                    wait_time = 2 ** retry_count  # Exponential backoff\n",
    "                    print(f\"Request failed: {str(e)}. Retrying in {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)\n",
    "            \n",
    "            # Process the response\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                \n",
    "                for entry in data.get('results', []):\n",
    "                    accession = entry.get('primaryAccession')\n",
    "                    \n",
    "                    # Extract protein name\n",
    "                    protein_name = None\n",
    "                    protein_data = entry.get('proteinDescription', {})\n",
    "                    \n",
    "                    # Try to find a common/short name first\n",
    "                    if 'recommendedName' in protein_data:\n",
    "                        if 'shortNames' in protein_data['recommendedName']:\n",
    "                            protein_name = protein_data['recommendedName']['shortNames'][0]['value']\n",
    "                        else:\n",
    "                            protein_name = protein_data['recommendedName'].get('fullName', {}).get('value')\n",
    "                    \n",
    "                    # Try alternative names if no recommended name found\n",
    "                    if not protein_name and 'alternativeNames' in protein_data and protein_data['alternativeNames']:\n",
    "                        if 'shortNames' in protein_data['alternativeNames'][0]:\n",
    "                            protein_name = protein_data['alternativeNames'][0]['shortNames'][0]['value']\n",
    "                        else:\n",
    "                            protein_name = protein_data['alternativeNames'][0].get('fullName', {}).get('value')\n",
    "                    \n",
    "                    # Extract species name\n",
    "                    species = None\n",
    "                    organism_data = entry.get('organism', {})\n",
    "                    organism_names = organism_data.get('names', [])\n",
    "                    \n",
    "                    # Try to find common name first\n",
    "                    for name in organism_names:\n",
    "                        if name['type'] == 'common':\n",
    "                            species = name['value']\n",
    "                            break\n",
    "                    \n",
    "                    # Fallback to scientific name\n",
    "                    if not species and organism_names:\n",
    "                        for name in organism_names:\n",
    "                            if name['type'] == 'scientific':\n",
    "                                species = name['value']\n",
    "                                break\n",
    "                    \n",
    "                    # Clean up protein name if found\n",
    "                    if protein_name:\n",
    "                        protein_name = protein_name.split(' precursor')[0].split(' (')[0]\n",
    "                    \n",
    "                    # Store the results\n",
    "                    if accession and (protein_name or species):\n",
    "                        results[accession] = (protein_name or accession, species or \"Unknown\")\n",
    "            \n",
    "            return results\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch fetch: {str(e)}\")\n",
    "            return {}\n",
    "        \n",
    "    def _load_merged_data(self, file_data):\n",
    "        \"\"\"\n",
    "        Load and validate merged data file\n",
    "        Returns tuple of (dataframe, status)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            content = bytes(file_data.content)\n",
    "            filename = file_data.name\n",
    "            extension = filename.split('.')[-1].lower()\n",
    "\n",
    "            file_stream = io.BytesIO(content)\n",
    "\n",
    "            # Load data based on file extension\n",
    "            try:\n",
    "                if extension == 'csv':\n",
    "                    df = pd.read_csv(file_stream)\n",
    "                elif extension in ['txt', 'tsv']:\n",
    "                    df = pd.read_csv(file_stream, delimiter='\\t')\n",
    "                elif extension == 'xlsx':\n",
    "                    df = pd.read_excel(file_stream)\n",
    "                else:\n",
    "                    display(HTML(f'<b style=\"color:red;\">Error: Unsupported file format</b>'))\n",
    "                    return None, 'no'\n",
    "            except Exception as e:\n",
    "                display(HTML(f'<b style=\"color:red;\">Error reading file: {str(e)}</b>'))\n",
    "                return None, 'no'\n",
    "\n",
    "            # Check for protein info columns and notify user\n",
    "            missing_columns = []\n",
    "            if 'protein_name' not in df.columns:\n",
    "                missing_columns.append('protein_name')\n",
    "                df['protein_name'] = ''\n",
    "            if 'protein_species' not in df.columns:\n",
    "                missing_columns.append('protein_species')\n",
    "                df['protein_species'] = ''\n",
    "                \n",
    "            if missing_columns:\n",
    "                notification = f\"\"\"\n",
    "                <div style=\"padding: 10px; margin: 10px 0;\">\n",
    "                    <p style=\"color: #17a2b8; margin: 0;\">\n",
    "                        <b>Notice:</b> The following columns are missing from your data:\n",
    "                        <ul style=\"color: #17a2b8; margin: 5px 0;\">\n",
    "                            {''.join(f'<li>{col}</li>' for col in missing_columns)}\n",
    "                        </ul>\n",
    "                        </p>\n",
    "                        <p style=\"color: #17a2b8; margin: 0;\">\n",
    "                        UniProt will be searched to automatically fill in this information. <br>\n",
    "                        Alternativly you can upload a standardized file from the data transomation module with the protein information. \n",
    "                    </p>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "                display(HTML(notification))\n",
    "\n",
    "            # Validate and clean data\n",
    "            cleaned_df, warnings, errors = self._validate_and_clean_data(df)\n",
    "\n",
    "            # Warnings about invalid/blank values are commented out\n",
    "            # if warnings:\n",
    "            #     warning_html = \"<br>\".join([\n",
    "            #         f'<b style=\"color:orange;\">Warning: {w}</b>'\n",
    "            #         for w in warnings\n",
    "            #     ])\n",
    "            #     display(HTML(warning_html))\n",
    "\n",
    "            # Display errors if any\n",
    "            if errors:\n",
    "                error_html = \"<br>\".join([\n",
    "                    f'<b style=\"color:red;\">Error: {e}</b>'\n",
    "                    for e in errors\n",
    "                ])\n",
    "                display(HTML(error_html))\n",
    "                return None, 'no'\n",
    "\n",
    "            if cleaned_df is not None and len(cleaned_df) > 0:\n",
    "                # Process protein information\n",
    "                num_proteins = self._process_protein_info(cleaned_df)\n",
    "                \n",
    "                # Add information about remaining rows and processed proteins\n",
    "                success_message = f\"\"\"\n",
    "                <div style=\"padding: 10px; margin: 10px 0; border-left: 4px solid #28a745; background-color: #f8f9fa;\">\n",
    "                    <p style=\"color: #28a745; margin: 0;\">\n",
    "                        <b>Data Import Complete!</b><br>\n",
    "                        • Data imported successfully with {cleaned_df.shape[0]} rows and {cleaned_df.shape[1]} columns.<br>\n",
    "                        • Processed data contains {len(cleaned_df)} rows after removing blank values.<br>\n",
    "                        • Successfully processed information for {num_proteins} unique proteins.\n",
    "                    </p>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "                #display(HTML(success_message))\n",
    "                return cleaned_df, 'yes'\n",
    "            else:\n",
    "                display(HTML('<b style=\"color:red;\">Error: No valid data rows remaining after cleaning</b>'))\n",
    "                return None, 'no'\n",
    "\n",
    "        except Exception as e:\n",
    "            display(HTML(f'<b style=\"color:red;\">Error processing file: {str(e)}</b>'))\n",
    "            return None, 'no'\n",
    "\n",
    "    def _on_merged_upload_change(self, change):\n",
    "        \"\"\"Handle merged data file upload\"\"\"\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            with self.output_area:\n",
    "                self.output_area.clear_output()\n",
    "                if change['new'] and len(change['new']) > 0:\n",
    "                    file_data = change['new'][0]\n",
    "                    df, status = self._load_merged_data(file_data)\n",
    "                    if status == 'yes' and df is not None:\n",
    "                        self.merged_df = df  # Only set merged_df if validation passed\n",
    "                        display(HTML(\n",
    "                            f'<b style=\"color:green;\">Data imported successfully with '\n",
    "                            f'{df.shape[0]} rows and {df.shape[1]} columns.</b>'\n",
    "                        ))\n",
    "\n",
    "    def fetch_uniprot_info(self, protein_id):\n",
    "        \"\"\"\n",
    "        Fetch protein information from UniProt, prioritizing common names.\n",
    "        Returns tuple of (protein_common_name, species_common_name) or (None, None) if not found.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Try REST API first\n",
    "            rest_url = f'https://rest.uniprot.org/uniprotkb/{protein_id}.json'\n",
    "            response = requests.get(rest_url)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                \n",
    "                # Get protein common name\n",
    "                try:\n",
    "                    # Look for protein names\n",
    "                    names = data['proteinDescription']\n",
    "                    protein_name = None\n",
    "                    \n",
    "                    # Try to find a common/short name\n",
    "                    if 'shortNames' in names.get('recommendedName', {}):\n",
    "                        protein_name = names['recommendedName']['shortNames'][0]['value']\n",
    "                    elif 'shortNames' in names.get('alternativeNames', [{}])[0]:\n",
    "                        protein_name = names['alternativeNames'][0]['shortNames'][0]['value']\n",
    "                    else:\n",
    "                        # Fallback to full name\n",
    "                        protein_name = names.get('recommendedName', {}).get('fullName', {}).get('value')\n",
    "                    \n",
    "                    # Get species common name\n",
    "                    organism_data = data['organism']\n",
    "                    species = None\n",
    "                    for name in organism_data.get('names', []):\n",
    "                        if name['type'] == 'common':\n",
    "                            species = name['value']\n",
    "                            break\n",
    "                    if not species:  # Fallback to scientific name\n",
    "                        species = organism_data.get('scientificName')\n",
    "                    \n",
    "                    return protein_name, species\n",
    "                    \n",
    "                except KeyError:\n",
    "                    pass  # Fall through to XML approach\n",
    "            \n",
    "            # Fall back to XML API\n",
    "            xml_url = f'https://www.uniprot.org/uniprot/{protein_id}.xml'\n",
    "            response = requests.get(xml_url)\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                return None, None\n",
    "                \n",
    "            root = ElementTree.fromstring(response.content)\n",
    "            ns = {'up': 'http://uniprot.org/uniprot'}\n",
    "            \n",
    "            # Get protein common name with fallbacks\n",
    "            protein_name = None\n",
    "            # Try short name first\n",
    "            name_element = (\n",
    "                root.find('.//up:recommendedName/up:shortName', ns) or\n",
    "                root.find('.//up:alternativeName/up:shortName', ns) or\n",
    "                root.find('.//up:recommendedName/up:fullName', ns) or\n",
    "                root.find('.//up:submittedName/up:fullName', ns)\n",
    "            )\n",
    "            protein_name = name_element.text if name_element is not None else None\n",
    "            \n",
    "            # Get species common name\n",
    "            species = None\n",
    "            # Try common name first\n",
    "            organism = root.find('.//up:organism/up:name[@type=\"common\"]', ns)\n",
    "            if organism is not None:\n",
    "                species = organism.text\n",
    "            else:\n",
    "                # Fallback to scientific name\n",
    "                organism = root.find('.//up:organism/up:name[@type=\"scientific\"]', ns)\n",
    "                species = organism.text if organism is not None else \"Unknown\"\n",
    "            \n",
    "            if protein_name:\n",
    "                # Clean up protein name - remove any \"precursor\" or similar suffixes\n",
    "                protein_name = protein_name.split(' precursor')[0].split(' (')[0]\n",
    "                return protein_name, species\n",
    "            else:\n",
    "                return None, None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching UniProt data for {protein_id}: {str(e)}\")\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9668b4d0-7d2a-4d54-ae01-28561699ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotState:\n",
    "    def __init__(self):\n",
    "        self.current_state = {\n",
    "            'uploadedData': None,\n",
    "            'topProteins': None,\n",
    "            'groupSelection': None,\n",
    "            'xLabel': None,\n",
    "            'yLabel': None,\n",
    "            'colorScheme': None,\n",
    "            'lastGenerated': None,\n",
    "            'buttonsLocked': True\n",
    "        }\n",
    "    \n",
    "    def update_state(self, **kwargs):\n",
    "        self.current_state.update(kwargs)\n",
    "        # Lock buttons when state changes\n",
    "        self.current_state['buttonsLocked'] = True\n",
    "    \n",
    "    def generate_completed(self):\n",
    "        self.current_state['buttonsLocked'] = False\n",
    "        self.current_state['lastGenerated'] = {\n",
    "            key: value for key, value in self.current_state.items() \n",
    "            if key not in ['lastGenerated', 'buttonsLocked']\n",
    "        }\n",
    "    \n",
    "    def get_state(self):\n",
    "        return self.current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "377e1235-d0b5-473e-8457-e044f855a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "class ProteinPlotter:\n",
    "    def __init__(self, data_transformer):\n",
    "        self.data_transformer = data_transformer\n",
    "        self.plot_output = widgets.Output()\n",
    "        self.info_output = widgets.Output()\n",
    "        self.export_output = widgets.Output()\n",
    "        self.proteins_df = None\n",
    "        self.sum_df = None\n",
    "        \n",
    "        # Initialize state manager first\n",
    "        self.state_manager = PlotState()\n",
    "\n",
    "        self.download_plot_button = widgets.Button(\n",
    "            description='Download Interactive Plot',\n",
    "            button_style='info',\n",
    "            icon='file',\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "\n",
    "        # Create multi-select widget for groups\n",
    "        self.group_select = widgets.SelectMultiple(\n",
    "            options=[],\n",
    "            description='Groups:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px', height='100px')\n",
    "        )\n",
    "        \n",
    "        self.plot_button = widgets.Button(\n",
    "            description='Generate/Update Data',\n",
    "            button_style='success',\n",
    "            icon='refresh',\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "        \n",
    "        self.export_button = widgets.Button(\n",
    "            description='Export Data',\n",
    "            button_style='info',\n",
    "            icon='download',\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "\n",
    "        # Add label customization widgets\n",
    "        self.xlabel_widget = widgets.Text(\n",
    "            description='X Label:',\n",
    "            placeholder='Enter x-axis label',\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "        \n",
    "        self.ylabel_widget = widgets.Text(\n",
    "            description='Y Label:',\n",
    "            placeholder='Enter y-axis label',\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "        self.legend_widget = widgets.Text(\n",
    "            description='Legend Title',\n",
    "            placeholder='Enter a custom legend title',\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "        self.title_widget = widgets.Text(\n",
    "            description='Plot Title',\n",
    "            placeholder='Enter a custom plot title',\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "\n",
    "\n",
    "        # Update color scheme dropdown with categorized options\n",
    "        color_schemes = [\n",
    "            '--- DEFAULT (HSV)---',\n",
    "            'HSV',  # Default option\n",
    "            '--- QUALITATIVE (BEST FOR CATEGORIES) ---',\n",
    "            'Plotly', 'D3', 'G10', 'T10', 'Alphabet', \n",
    "            'Set1', 'Set2', 'Set3', 'Pastel1', 'Pastel2', 'Paired',\n",
    "            '--- SEQUENTIAL ---',\n",
    "            'Viridis', 'Cividis', 'Inferno', 'Magma', 'Plasma',\n",
    "            'Hot', 'Jet', 'Blues', 'Greens', 'Reds', 'Purples', 'Oranges',\n",
    "            '--- DIVERGING ---',\n",
    "            'Spectral', 'RdBu', 'RdYlBu', 'RdYlGn', 'PiYG', 'PRGn', 'BrBG', 'RdGy',\n",
    "            '--- CYCLICAL ---',\n",
    "            'IceFire', 'Edge', 'Twilight'\n",
    "        ]\n",
    "        \n",
    "        self.color_scheme = widgets.Dropdown(\n",
    "            options=color_schemes,\n",
    "            value='HSV',  # Default value\n",
    "            description='Color Scheme:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "\n",
    "        # Add an inversion toggle radio button\n",
    "        self.invert_plot = widgets.RadioButtons(\n",
    "            description='Plot Orientation:',\n",
    "            options=['By Sample', 'By Protein'],\n",
    "            value='By Sample',  # Default selection\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px', height='auto'),\n",
    "            disabled=False,\n",
    "            indent=True  # Keeps options aligned with description instead of appearing below\n",
    "        )\n",
    "\n",
    "        # Change the protein_selector initialization to not have a default selection\n",
    "        self.protein_selector = widgets.SelectMultiple(\n",
    "            options=[],\n",
    "            value=(),  # Empty tuple - no selection by default\n",
    "            description='Proteins:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(\n",
    "                width='300px',\n",
    "                height='100px',\n",
    "            )\n",
    "        )\n",
    "        # Selecte between relative and absolute plots\n",
    "        self.metric_type = widgets.RadioButtons(\n",
    "            description='Scale Absorbance:',\n",
    "            options=['Relative', 'Absolute'],\n",
    "            value='Relative',  # Default selection\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px', height='auto'),\n",
    "            disabled=False,\n",
    "            indent=True  # Keeps options aligned with description instead of appearing below\n",
    "        )                   \n",
    "        # Create the checkbox with improved description\n",
    "        self.plot_minor_proteins = widgets.Checkbox(\n",
    "            description='Show Minor Proteins',\n",
    "            value=True,\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px', height='30px')\n",
    "        )\n",
    "\n",
    "        # Use the existing create_help_icon function style\n",
    "        def create_help_icon(tooltip_text):\n",
    "            \"\"\"Create a help icon widget with tooltip\"\"\"\n",
    "            help_icon = widgets.HTML(\n",
    "                value='<i class=\"fa fa-question-circle\" style=\"color: #007bff;\"></i>',\n",
    "                layout=widgets.Layout(width='25px', margin='2px 5px')\n",
    "            )\n",
    "            help_icon.add_class('jupyter-widgets')\n",
    "            help_icon.add_class('widget-html')\n",
    "            return widgets.HTML(\n",
    "                f'<div title=\"{tooltip_text}\" style=\"display: inline-block;\">{help_icon.value}</div>'\n",
    "            )\n",
    "\n",
    "        # Create a help icon with explanatory tooltip\n",
    "        help_tooltip = \"Groups all unselected proteins into a single 'Minor Proteins' category in the plot\"\n",
    "        minor_proteins_help = create_help_icon(help_tooltip)\n",
    "\n",
    "        # Combine checkbox and help icon into a horizontal layout\n",
    "        self.minor_proteins_row = widgets.HBox([\n",
    "            self.plot_minor_proteins, \n",
    "            minor_proteins_help\n",
    "        ], layout=widgets.Layout(align_items='center'))\n",
    "\n",
    "        # Add after creating the protein_selector widget\n",
    "        self._populate_protein_selector()\n",
    "\n",
    "\n",
    "        # Update plot type selection to remove 'All Plots'\n",
    "        self.plot_type = widgets.RadioButtons(\n",
    "            options=['Stacked Bar Plots', 'Grouped Bar Plots', 'Pie Charts'],\n",
    "            value='Stacked Bar Plots',\n",
    "            description='Plot Type:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Add bar plot type selection\n",
    "        self.abs_or_count = widgets.RadioButtons(\n",
    "            options=['Absorbance', 'Count'],\n",
    "            value='Absorbance', \n",
    "            description='Data Type:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "\n",
    "        # Create help icons\n",
    "        def create_help_icon(tooltip_text):\n",
    "            \"\"\"Create a help icon widget with tooltip\"\"\"\n",
    "            help_icon = widgets.HTML(\n",
    "                value='<i class=\"fa fa-question-circle\" style=\"color: #007bff;\"></i>',\n",
    "                layout=widgets.Layout(width='25px', margin='2px 5px')\n",
    "            )\n",
    "            help_icon.add_class('jupyter-widgets')\n",
    "            help_icon.add_class('widget-html')\n",
    "            return widgets.HTML(\n",
    "                f'<div title=\"{tooltip_text}\" style=\"display: inline-block;\">{help_icon.value}</div>'\n",
    "            )\n",
    "\n",
    "        # Add help tooltips\n",
    "        plot_type_help = create_help_icon(\"Select whether to display data as a bar plot or pie chart\")\n",
    "        bar_plot_type_help = create_help_icon(\"Choose the type of values to display in the bar plot\")\n",
    "        plot_orientation_help = create_help_icon(\"Group data by sample or by protein\")\n",
    "\n",
    "        self.plot_type_row = widgets.HBox([self.plot_type,\n",
    "                                           self.metric_type],\n",
    "                                           layout=widgets.Layout(width='300px')\n",
    "                                          )\n",
    "        self.plot_type_row_two= widgets.HBox([self.abs_or_count,\n",
    "                                           self.invert_plot],\n",
    "                                           layout=widgets.Layout(width='300px')\n",
    "                                          )\n",
    "        # Create layout\n",
    "        self.widget_box = widgets.VBox([\n",
    "            widgets.HTML(\"<h4>Plot Controls:</h4>\"),\n",
    "            self.group_select,\n",
    "            self.protein_selector,\n",
    "            self.plot_type_row,\n",
    "            self.plot_type_row_two,\n",
    "            self.minor_proteins_row,\n",
    "            widgets.HTML(\"<h4>Appearance Settings:</h4>\"),\n",
    "            self.xlabel_widget,\n",
    "            self.ylabel_widget,\n",
    "            self.legend_widget,\n",
    "            self.title_widget,\n",
    "            self.color_scheme,\n",
    "            widgets.HTML(\"<h4>Actions:</h4>\"),\n",
    "            self.plot_button,\n",
    "            self.export_button,\n",
    "            self.download_plot_button,\n",
    "            self.info_output,\n",
    "            self.plot_output,\n",
    "            self.export_output\n",
    "        ])\n",
    "            \n",
    "            \n",
    "        # Set initial button states\n",
    "        self.export_button.disabled = True\n",
    "        self.download_plot_button.disabled = True\n",
    "        \n",
    "        def _on_input_change(change):\n",
    "            self.state_manager.update_state()\n",
    "            self.export_button.disabled = True\n",
    "            self.download_plot_button.disabled = True\n",
    "\n",
    "        \n",
    "        # Add observers for input changes\n",
    "        self.group_select.observe(_on_input_change, names='value')\n",
    "        self.xlabel_widget.observe(_on_input_change, names='value')\n",
    "        self.ylabel_widget.observe(_on_input_change, names='value')\n",
    "        self.legend_widget.observe(_on_input_change, names='value')\n",
    "        self.title_widget.observe(_on_input_change, names='value')\n",
    "        self.color_scheme.observe(_on_input_change, names='value')\n",
    "\n",
    "        # Add button click handlers\n",
    "        self.plot_button.on_click(self._on_plot_button_click)\n",
    "        self.export_button.on_click(self._on_export_button_click)\n",
    "        self.download_plot_button.on_click(self._on_download_plot_click)\n",
    "        \n",
    "        # Add variable to store current figure\n",
    "        self.current_fig = None\n",
    "        # Add observer for data changes\n",
    "        self.data_transformer.merged_uploader.observe(self._update_group_options, names='value')\n",
    "\n",
    "        # Register an explicit callback to populate proteins when merged data changes\n",
    "        self.data_transformer.merged_uploader.observe(self._populate_protein_selector, names='value')\n",
    "        \n",
    "        # In your setup_widgets method, add this line:\n",
    "        self.color_scheme.observe(self._on_color_scheme_change, names='value')\n",
    "  \n",
    "    def _update_group_options(self, change):\n",
    "        \"\"\"Update group selection options when data changes\"\"\"\n",
    "        if self.data_transformer.merged_df is not None:\n",
    "            # Get all Avg_ columns\n",
    "            avg_columns = [col.replace('Avg_', '') for col in self.data_transformer.merged_df.columns \n",
    "                         if col.startswith('Avg_')]\n",
    "            \n",
    "            # Update group selection options\n",
    "            self.group_select.options = avg_columns\n",
    "            # Select all groups by default\n",
    "            self.group_select.value = avg_columns\n",
    "\n",
    "    def _populate_protein_selector(self, change=None):\n",
    "        \"\"\"Populate the protein selector with proteins ordered by their relative abundance across all samples\"\"\"\n",
    "        \n",
    "        # Check if data_transformer is available\n",
    "        if not hasattr(self, 'data_transformer') or self.data_transformer is None:\n",
    "            return\n",
    "            \n",
    "        # Use proteins_dic (with 's') instead of protein_dic\n",
    "        if not hasattr(self.data_transformer, 'proteins_dic') or not self.data_transformer.proteins_dic:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            # Calculate protein abundance across all samples\n",
    "            protein_abundance = {}\n",
    "            \n",
    "            if hasattr(self.data_transformer, 'merged_df') and self.data_transformer.merged_df is not None:\n",
    "                df = self.data_transformer.merged_df\n",
    "                \n",
    "                # Find all Avg_ columns for abundance data\n",
    "                abundance_cols = [col for col in df.columns if col.startswith('Avg_')]\n",
    "                protein_col = 'Master Protein Accessions'\n",
    "                \n",
    "                if abundance_cols and protein_col in df.columns:\n",
    "                    \n",
    "                    # Process each row in the dataframe\n",
    "                    for _, row in df.iterrows():\n",
    "                        # Skip rows without protein information\n",
    "                        if pd.isna(row[protein_col]) or row[protein_col] == '':\n",
    "                            continue\n",
    "                            \n",
    "                        # Get proteins for this peptide\n",
    "                        proteins = [p.strip() for p in str(row[protein_col]).split(';') if p.strip()]\n",
    "                        \n",
    "                        # Calculate total abundance across all samples for this peptide\n",
    "                        total_abundance = 0\n",
    "                        for col in abundance_cols:\n",
    "                            try:\n",
    "                                if pd.notna(row.get(col)):\n",
    "                                    total_abundance += float(row.get(col, 0))\n",
    "                            except (ValueError, TypeError) as e:\n",
    "                                print(f\"Error converting abundance value in column {col}: {str(e)}\")\n",
    "                                print(f\"Value: {row.get(col)}, Type: {type(row.get(col))}\")\n",
    "                        \n",
    "                        # If there are multiple proteins, divide the abundance equally among them\n",
    "                        per_protein_abundance = total_abundance / len(proteins) if proteins else 0\n",
    "                        \n",
    "                        # Add to each protein's total\n",
    "                        for protein in proteins:\n",
    "                            if protein in protein_abundance:\n",
    "                                protein_abundance[protein] += per_protein_abundance\n",
    "                            else:\n",
    "                                protein_abundance[protein] = per_protein_abundance\n",
    "                    \n",
    "            \n",
    "            # Get the list of all proteins from proteins_dic\n",
    "            all_proteins = list(self.data_transformer.proteins_dic.keys())\n",
    "            \n",
    "            # Sort proteins by abundance (highest first)\n",
    "            if protein_abundance:\n",
    "                # Get proteins sorted by abundance\n",
    "                sorted_proteins = sorted(all_proteins, \n",
    "                                        key=lambda p: protein_abundance.get(p, 0), \n",
    "                                        reverse=True)\n",
    "\n",
    "                # Create options with protein ID and name\n",
    "                options = []\n",
    "                options.append('All')  # Add 'All' option first\n",
    "                \n",
    "                # Add each protein with its ID, name and abundance\n",
    "                for protein_id in sorted_proteins:\n",
    "                    protein_info = self.data_transformer.proteins_dic.get(protein_id, {})\n",
    "                    protein_name = protein_info.get('name', protein_id)\n",
    "                    abundance = protein_abundance.get(protein_id, 0)\n",
    "\n",
    "                    options.append(protein_name)\n",
    "                    \n",
    "                # Update the protein selector with all options\n",
    "                self.protein_selector.options = options\n",
    "                \n",
    "                # Automatically select the top 10 proteins (or fewer if less are available)\n",
    "                num_proteins = min(10, len(options) - 1)  # -1 to account for 'All'\n",
    "                if num_proteins > 0:\n",
    "                    # Select top proteins (options[1:] to skip 'All')\n",
    "                    self.protein_selector.value = tuple(options[1:num_proteins+1])\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error populating protein selector: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def _get_proteins_to_plot(self):\n",
    "        \"\"\"Get the list of proteins to plot based on user selection\"\"\"\n",
    "        try:\n",
    "            # 'Select Specific Proteins'\n",
    "            # Get selection from multi-select widget\n",
    "            if hasattr(self, 'protein_selector'):\n",
    "                selected = self.protein_selector.value\n",
    "                \n",
    "                # Handle 'All' selection\n",
    "                if 'All' in selected:\n",
    "                    # Use all proteins in the dataframe\n",
    "                    if hasattr(self, 'proteins_df'):\n",
    "                        self.pro_list = list(set(self.proteins_df['Description']))\n",
    "                    else:\n",
    "                        self.pro_list = []\n",
    "                    return self.pro_list\n",
    "                else:\n",
    "                    # Use selected proteins\n",
    "                    self.pro_list = list(selected)\n",
    "                    return self.pro_list\n",
    "            else:\n",
    "                print(\"Protein selector widget not found\")\n",
    "                self.pro_list = []\n",
    "                return []\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting proteins to plot: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "            # Set empty list on error for compatibility\n",
    "            self.pro_list = []\n",
    "            return []\n",
    "\n",
    "    def _on_color_scheme_change(self, change):\n",
    "        \"\"\"Update plot when color scheme changes\"\"\"\n",
    "        if self.current_fig is not None and hasattr(self, 'plot_button'):\n",
    "            # Trigger plot update by simulating a button click\n",
    "            self._on_plot_button_click(None)\n",
    "\n",
    "    def _get_avg_columns(self):\n",
    "        \"\"\"Get all columns that start with 'Avg_' from the merged dataframe\"\"\"\n",
    "        if self.data_transformer.merged_df is not None:\n",
    "            return [col for col in self.data_transformer.merged_df.columns if col.startswith('Avg_')]\n",
    "        return []\n",
    "\n",
    "    def _update_group_options(self, change):\n",
    "        \"\"\"Update group selection options when data changes\"\"\"\n",
    "        if self.data_transformer.merged_df is not None:\n",
    "            avg_columns = self._get_avg_columns()\n",
    "            # Remove 'Avg_' prefix for display\n",
    "            group_options = [col.replace('Avg_', '') for col in avg_columns]\n",
    "            self.group_select.options = group_options\n",
    "            # Select all groups by default\n",
    "            self.group_select.value = group_options\n",
    "                    \n",
    "    def process_data(self, selected_groups=None):\n",
    "        from collections import defaultdict\n",
    "        \n",
    "        if self.data_transformer.merged_df is None or not self.data_transformer.proteins_dic:\n",
    "            return False\n",
    "\n",
    "        # First, update the protein list to plot\n",
    "        self._get_proteins_to_plot()\n",
    "        \n",
    "        df = self.data_transformer.merged_df.copy()\n",
    "        self.merged_df = df.copy()  # Store a reference to merged_df for later use\n",
    "        \n",
    "        # Get Absorbance columns based on selected groups\n",
    "        if selected_groups:\n",
    "            Absorbance_cols = [f'Avg_{var}' for var in selected_groups]\n",
    "        else:\n",
    "            Absorbance_cols = self._get_avg_columns()\n",
    "            \n",
    "        df['Total_Absorbance'] = df[Absorbance_cols].sum(axis=1).astype(int)\n",
    "        \n",
    "        # Filter out zero Absorbance entries\n",
    "        result_df = df[['unique ID', 'Total_Absorbance']]\n",
    "        result_df = result_df[result_df['Total_Absorbance'] == 0]\n",
    "        all_zero_list = list(result_df['unique ID'])\n",
    "        peptides_df = df[~df['unique ID'].isin(all_zero_list)]\n",
    "\n",
    "        # Process protein positions and create proteins DataFrame\n",
    "        additional_columns = ['Master Protein Accessions', 'unique ID']\n",
    "        selected_columns = additional_columns + Absorbance_cols\n",
    "        \n",
    "        peptides_df.loc[:, 'Master Protein Accessions'] = peptides_df['Master Protein Accessions']\n",
    "        \n",
    "        temp_df = peptides_df.copy()\n",
    "        temp_df.loc[:, 'Protein_ID'] = temp_df['Master Protein Accessions']\n",
    "        \n",
    "        # Create proteins DataFrame with selected columns\n",
    "        self.proteins_df = temp_df.groupby('Protein_ID').agg(\n",
    "            {**{col: 'first' for col in ['Master Protein Accessions']},\n",
    "            **{col: 'sum' for col in Absorbance_cols}}\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Calculate relative Absorbance for selected groups\n",
    "        for col in Absorbance_cols:\n",
    "            col_sum = self.proteins_df[col].sum()\n",
    "            if col_sum > 0:  # Avoid division by zero\n",
    "                self.proteins_df[f'Rel_{col}'] = (self.proteins_df[col] / col_sum) * 100\n",
    "            else:\n",
    "                self.proteins_df[f'Rel_{col}'] = 0\n",
    "                \n",
    "        # Create sum DataFrame for selected groups\n",
    "        self.sum_df = pd.DataFrame({\n",
    "            'Sample': Absorbance_cols,\n",
    "            'Total_Sum': [self.proteins_df[col].sum() for col in Absorbance_cols]\n",
    "        })\n",
    "        \n",
    "        # Add protein descriptions\n",
    "        name_list = []\n",
    "        for _, row in self.proteins_df.iterrows():\n",
    "            if ',' in row['Protein_ID']:\n",
    "                strrow = row['Protein_ID'].split(',')\n",
    "                named_combo = self._fetch_protein_names('; '.join(strrow))\n",
    "            else:\n",
    "                named_combo = self._fetch_protein_names(row['Protein_ID'])\n",
    "            name_list.append(named_combo)\n",
    "        \n",
    "        # Drop the 'Protein_ID' column\n",
    "        self.proteins_df = self.proteins_df.drop(columns=['Protein_ID'])    \n",
    "        \n",
    "        self.proteins_df['Description'] = name_list\n",
    "        self.proteins_df['Description'] = self.proteins_df['Description'].astype(str).str.replace(r\"['\\['\\]]\", \"\", regex=True)\n",
    "        \n",
    "        # Calculate average Absorbance for sorting using only selected groups\n",
    "       \n",
    "        # Calculate sum of all selected columns\n",
    "        total_sum = self.proteins_df[Absorbance_cols].sum().sum()\n",
    "        \n",
    "        # Calculate row sums\n",
    "        row_sums = self.proteins_df[Absorbance_cols].sum(axis=1)\n",
    "        \n",
    "        # Calculate relative percentage contribution\n",
    "        self.proteins_df['avg_absorbance_all'] = (row_sums / total_sum * 100).round(2)\n",
    "        \n",
    "        # Sort proteins by abundance for consistent ordering\n",
    "        self.proteins_df = self.proteins_df.sort_values('avg_absorbance_all', ascending=False)\n",
    "                                \n",
    "        # Create a dictionary to store the actual peptide counts per group\n",
    "        self.peptide_count_totals = {}\n",
    "        \n",
    "        # Dictionary to store unique peptide counts per protein\n",
    "        self.protein_peptide_counts = {}\n",
    "        \n",
    "        # Track which peptides belong to which proteins\n",
    "        protein_to_peptides = defaultdict(set)\n",
    "        \n",
    "        # Track which peptides belong to which proteins in each group\n",
    "        protein_to_group_peptides = defaultdict(lambda: defaultdict(set))\n",
    "        \n",
    "        # Determine counts based on merged_df and add to proteins_df\n",
    "        if selected_groups and self.proteins_df is not None and df is not None:\n",
    "            # Add count columns to the proteins_df (initialize with zeros)\n",
    "            for group in selected_groups:\n",
    "                count_col = f'Count_{group}'\n",
    "                rel_count_col = f'Rel_Count_{group}'\n",
    "                # Initialize with float64 dtype\n",
    "                self.proteins_df[count_col] = pd.Series(dtype='float64')\n",
    "                self.proteins_df[rel_count_col] = pd.Series(dtype='float64')\n",
    "                # Set initial values to 0.0\n",
    "                self.proteins_df[count_col] = 0.0\n",
    "                self.proteins_df[rel_count_col] = 0.0\n",
    "            \n",
    "            # Create a mapping from accession to protein index in proteins_df\n",
    "            accession_to_idx = {}\n",
    "            accession_to_description = {}  # Map accessions to descriptions for counting\n",
    "            for idx, row in self.proteins_df.iterrows():\n",
    "                if 'Master Protein Accessions' in row and pd.notna(row['Master Protein Accessions']):\n",
    "                    accession_to_idx[row['Master Protein Accessions']] = idx\n",
    "                    accession_to_description[row['Master Protein Accessions']] = row['Description']\n",
    "                elif 'Accession' in row and pd.notna(row['Accession']):\n",
    "                    accession_to_idx[row['Accession']] = idx\n",
    "                    accession_to_description[row['Accession']] = row['Description']\n",
    "            \n",
    "            # For each group, count peptides per protein\n",
    "            for group in selected_groups:\n",
    "                # Filter peptides that are present in this group\n",
    "                group_peptides = df[df[f'Avg_{group}'] > 0]\n",
    "                \n",
    "                # Store the total number of peptides for this group\n",
    "                self.peptide_count_totals[group] = len(group_peptides)\n",
    "                \n",
    "                # Track which peptides have already been counted\n",
    "                counted_peptides = set()\n",
    "                \n",
    "                # Track warning stats\n",
    "                peptides_with_no_accession = 0\n",
    "                peptides_with_no_id = 0\n",
    "                peptides_already_counted = 0\n",
    "                peptides_with_multi_accessions = set()\n",
    "                peptides_with_no_protein_match = 0\n",
    "                \n",
    "                # Count peptides for each protein\n",
    "                for _, peptide in group_peptides.iterrows():\n",
    "                    if 'Master Protein Accessions' not in peptide or pd.isna(peptide['Master Protein Accessions']):\n",
    "                        peptides_with_no_accession += 1\n",
    "                        continue\n",
    "                        \n",
    "                    # Get unique peptide ID to track counting\n",
    "                    peptide_id = peptide.get('unique ID', None)\n",
    "                    if peptide_id is None or pd.isna(peptide_id):\n",
    "                        peptides_with_no_id += 1\n",
    "                        continue  # Skip if no unique ID\n",
    "                    \n",
    "                    # Skip if we've already counted this peptide for this group\n",
    "                    if peptide_id in counted_peptides:\n",
    "                        peptides_already_counted += 1\n",
    "                        continue\n",
    "                    \n",
    "                    accession = peptide['Master Protein Accessions']\n",
    "                    found_match = False\n",
    "                    \n",
    "                    # Check if this peptide maps to multiple proteins\n",
    "                    if ';' in accession:\n",
    "                        peptides_with_multi_accessions.add(peptide_id)\n",
    "                        accessions = [acc.strip() for acc in accession.split(';') if acc.strip()]\n",
    "                        \n",
    "                        # Only count for the first valid protein in the list\n",
    "                        for acc in accessions:\n",
    "                            if acc in accession_to_idx:\n",
    "                                idx = accession_to_idx[acc]\n",
    "                                count_col = f'Count_{group}'\n",
    "                                self.proteins_df.at[idx, count_col] += 1\n",
    "                                \n",
    "                                # Add this peptide to the protein's set for protein-specific counting\n",
    "                                protein_desc = accession_to_description.get(acc, acc)\n",
    "                                protein_to_peptides[protein_desc].add(peptide_id)\n",
    "                                protein_to_group_peptides[protein_desc][group].add(peptide_id)\n",
    "                                \n",
    "                                counted_peptides.add(peptide_id)  # Mark as counted\n",
    "                                found_match = True\n",
    "                                break  # Count only once\n",
    "                    else:\n",
    "                        # Handle direct match - only single protein\n",
    "                        if accession in accession_to_idx:\n",
    "                            idx = accession_to_idx[accession]\n",
    "                            count_col = f'Count_{group}'\n",
    "                            self.proteins_df.at[idx, count_col] += 1\n",
    "                            \n",
    "                            # Add this peptide to the protein's set for protein-specific counting\n",
    "                            protein_desc = accession_to_description.get(accession, accession)\n",
    "                            protein_to_peptides[protein_desc].add(peptide_id)\n",
    "                            protein_to_group_peptides[protein_desc][group].add(peptide_id)\n",
    "                            \n",
    "                            counted_peptides.add(peptide_id)  # Mark as counted\n",
    "                            found_match = True\n",
    "                    \n",
    "                    # Track peptides that didn't match any protein in our list\n",
    "                    if not found_match:\n",
    "                        peptides_with_no_protein_match += 1\n",
    "                        \n",
    "                # After counting all peptides for this group, calculate relative counts\n",
    "                count_col = f'Count_{group}'\n",
    "                rel_count_col = f'Rel_Count_{group}'\n",
    "                total_value = self.peptide_count_totals[group]\n",
    "                \n",
    "                # Calculate relative counts as percentages of total peptides\n",
    "                # When calculating relative counts\n",
    "                if total_value > 0:\n",
    "                    for idx in range(len(self.proteins_df)):\n",
    "                        protein_count = float(self.proteins_df.at[idx, count_col])  # Ensure float\n",
    "                        rel_value = (protein_count / total_value) * 100\n",
    "                        self.proteins_df.at[idx, rel_count_col] = rel_value\n",
    "\n",
    "                \n",
    "                # Display warning about peptides mapping to multiple proteins\n",
    "                warning_html = '<div style=\"color: orange; margin: 5px 0;\"><b>Warning:</b> Peptide counting stats for group {0}:<br>'\n",
    "                \n",
    "                if peptides_with_no_accession > 0:\n",
    "                    warning_html += f'• Skipped {peptides_with_no_accession} peptides with no accession<br>'\n",
    "                    \n",
    "                if peptides_with_no_id > 0:\n",
    "                    warning_html += f'• Skipped {peptides_with_no_id} peptides with no unique ID<br>'\n",
    "                    \n",
    "                if peptides_already_counted > 0:\n",
    "                    warning_html += f'• Skipped {peptides_already_counted} duplicate peptides (already counted)<br>'\n",
    "                    \n",
    "                if len(peptides_with_multi_accessions) > 0:\n",
    "                    warning_html += f'• Found {len(peptides_with_multi_accessions)} peptides mapping to multiple proteins<br>'\n",
    "                    warning_html += f'  (Each counted only once for the first matching protein)<br>'\n",
    "                    \n",
    "                if peptides_with_no_protein_match > 0:\n",
    "                    warning_html += f'• {peptides_with_no_protein_match} peptides had no matching protein in the protein list<br>'\n",
    "                    \n",
    "                total_peptides = len(group_peptides)\n",
    "                warning_html += f'• Total peptides processed: {total_peptides}, successfully counted: {len(counted_peptides)}'\n",
    "                warning_html += '</div>'\n",
    "                \n",
    "                #display(HTML(warning_html.format(group)))\n",
    "\n",
    "        # Calculate the number of unique peptides per protein\n",
    "        for protein, peptides in protein_to_peptides.items():\n",
    "            self.protein_peptide_counts[protein] = len(peptides)\n",
    "\n",
    "        # Create a copy of the proteins DataFrame for protein sample distribution calculation\n",
    "        working_df = self.proteins_df.copy()\n",
    "        \n",
    "        # Calculate protein distributions across samples (for both counts and absorbance)\n",
    "        self.protein_sample_distribution = {}\n",
    "        \n",
    "        # Calculate data for major proteins (based on pro_list)\n",
    "        major_proteins = []\n",
    "        if hasattr(self, 'pro_list') and self.pro_list:\n",
    "            major_proteins = self.pro_list\n",
    "            \n",
    "        # Add \"Minor Proteins\" data structures to hold aggregated values\n",
    "        minor_proteins_data = {\n",
    "            'counts': {group: 0 for group in selected_groups},\n",
    "            'count_relative': {group: 0 for group in selected_groups},\n",
    "            'absorbance': {group: 0 for group in selected_groups},\n",
    "            'absorbance_relative': {group: 0 for group in selected_groups},\n",
    "            'unique_peptide_count': 0,\n",
    "            'total_value': 0,\n",
    "            'total_absorbance': 0,\n",
    "            'total_count': 0\n",
    "        }\n",
    "        \n",
    "        # Counts to track minor proteins' peptides\n",
    "        minor_proteins_peptides = set()\n",
    "        \n",
    "        # Process each protein\n",
    "        for _, row in working_df.iterrows():\n",
    "            protein_name = row['Description']\n",
    "            \n",
    "            # Skip if protein name is empty or NaN\n",
    "            if pd.isna(protein_name) or not protein_name:\n",
    "                continue\n",
    "            \n",
    "            # Initialize data structure for this protein\n",
    "            protein_data = {\n",
    "                'counts': {},\n",
    "                'count_relative': {},\n",
    "                'absorbance': {},\n",
    "                'absorbance_relative': {},\n",
    "                'unique_peptide_count': 0\n",
    "            }\n",
    "            \n",
    "            # Get count values for each group\n",
    "            count_values = {}\n",
    "            absorbance_values = {}\n",
    "            \n",
    "            for group in selected_groups:\n",
    "                # Get count values from proteins_df\n",
    "                count_col = f'Count_{group}'\n",
    "                if count_col in row:\n",
    "                    count_values[group] = row[count_col]\n",
    "                else:\n",
    "                    count_values[group] = 0\n",
    "                \n",
    "                # Get absorbance values\n",
    "                absorbance_col = f'Avg_{group}'\n",
    "                if absorbance_col in row:\n",
    "                    absorbance_values[group] = row[absorbance_col]\n",
    "                else:\n",
    "                    absorbance_values[group] = 0\n",
    "            \n",
    "            # Get the actual count of unique peptides for this protein (across all groups)\n",
    "            if protein_name in protein_to_peptides:\n",
    "                protein_data['unique_peptide_count'] = len(protein_to_peptides[protein_name])\n",
    "            \n",
    "            # Store the count and absorbance values\n",
    "            protein_data['counts'] = count_values\n",
    "            protein_data['absorbance'] = absorbance_values\n",
    "            \n",
    "            # Calculate totals as sums across groups\n",
    "            protein_total_count = sum(count_values.values())\n",
    "            protein_total_absorbance = sum(absorbance_values.values())\n",
    "            \n",
    "            protein_data['total_count'] = protein_total_count\n",
    "            protein_data['total_absorbance'] = protein_total_absorbance\n",
    "            \n",
    "            # Calculate relative distributions\n",
    "            # Count relative distribution - percentage of this protein's total count in each group\n",
    "            if protein_total_count > 0:\n",
    "                for group, count in count_values.items():\n",
    "                    protein_data['count_relative'][group] = (count / protein_total_count) * 100\n",
    "            else:\n",
    "                for group in selected_groups:\n",
    "                    protein_data['count_relative'][group] = 0\n",
    "            \n",
    "            # Absorbance relative distribution\n",
    "            if protein_total_absorbance > 0:\n",
    "                for group, absorbance in absorbance_values.items():\n",
    "                    protein_data['absorbance_relative'][group] = (absorbance / protein_total_absorbance) * 100\n",
    "            else:\n",
    "                for group in selected_groups:\n",
    "                    protein_data['absorbance_relative'][group] = 0\n",
    "            \n",
    "            # Add backward compatibility\n",
    "            use_count = hasattr(self, 'abs_or_count') and ('count' in getattr(self, 'abs_or_count').value.lower() \n",
    "                                                        if hasattr(getattr(self, 'abs_or_count'), 'value') else True)\n",
    "            \n",
    "            if use_count:\n",
    "                protein_data['total'] = protein_total_count\n",
    "                protein_data['values'] = count_values\n",
    "                protein_data['relative'] = protein_data['count_relative']\n",
    "            else:\n",
    "                protein_data['total'] = protein_total_absorbance\n",
    "                protein_data['values'] = absorbance_values\n",
    "                protein_data['relative'] = protein_data['absorbance_relative']\n",
    "            \n",
    "            # Check if this is a major or minor protein\n",
    "            if major_proteins and protein_name not in major_proteins:\n",
    "                # This is a minor protein - add its data to the minor proteins aggregated data\n",
    "                for group in selected_groups:\n",
    "                    minor_proteins_data['counts'][group] += count_values[group]\n",
    "                    minor_proteins_data['absorbance'][group] += absorbance_values[group]\n",
    "                \n",
    "                # For minor proteins, track both the sum and the unique peptide count\n",
    "                if protein_name in protein_to_peptides:\n",
    "                    minor_proteins_peptides.update(protein_to_peptides[protein_name])\n",
    "                \n",
    "                minor_proteins_data['total_count'] += protein_total_count\n",
    "                minor_proteins_data['total_absorbance'] += protein_total_absorbance\n",
    "            else:\n",
    "                # This is a major protein - store its individual data\n",
    "                self.protein_sample_distribution[protein_name] = protein_data\n",
    "        \n",
    "        # Set unique peptide count for minor proteins\n",
    "        minor_proteins_data['unique_peptide_count'] = len(minor_proteins_peptides)\n",
    "        \n",
    "        # Calculate relative distributions for minor proteins\n",
    "        if minor_proteins_data['total_count'] > 0:\n",
    "            for group in selected_groups:\n",
    "                minor_proteins_data['count_relative'][group] = (minor_proteins_data['counts'][group] / minor_proteins_data['total_count'] * 100)\n",
    "        \n",
    "        if minor_proteins_data['total_absorbance'] > 0:\n",
    "            for group in selected_groups:\n",
    "                minor_proteins_data['absorbance_relative'][group] = (minor_proteins_data['absorbance'][group] / minor_proteins_data['total_absorbance'] * 100)\n",
    "        \n",
    "        # Add backward compatibility for minor proteins\n",
    "        if use_count:\n",
    "            minor_proteins_data['total'] = minor_proteins_data['total_count']\n",
    "            minor_proteins_data['values'] = minor_proteins_data['counts']\n",
    "            minor_proteins_data['relative'] = minor_proteins_data['count_relative']\n",
    "        else:\n",
    "            minor_proteins_data['total'] = minor_proteins_data['total_absorbance']\n",
    "            minor_proteins_data['values'] = minor_proteins_data['absorbance']\n",
    "            minor_proteins_data['relative'] = minor_proteins_data['absorbance_relative']\n",
    "        \n",
    "        # Add minor proteins to the distribution dictionary and peptide counts\n",
    "        self.protein_sample_distribution['Minor Proteins'] = minor_proteins_data\n",
    "        self.protein_peptide_counts['Minor Proteins'] = minor_proteins_data['unique_peptide_count']\n",
    "        \n",
    "        # Add a row for \"Minor Proteins\" to the proteins_df if not already present\n",
    "        if 'Minor Proteins' not in self.proteins_df['Description'].values and major_proteins:\n",
    "            minor_proteins_row = {\n",
    "                'Description': 'Minor Proteins', \n",
    "                'Master Protein Accessions': 'Minor Proteins'\n",
    "            }\n",
    "            # Add counts and relative counts\n",
    "            for group in selected_groups:\n",
    "                count_col = f'Count_{group}'\n",
    "                rel_count_col = f'Rel_Count_{group}'\n",
    "                avg_col = f'Avg_{group}'\n",
    "                rel_avg_col = f'Rel_{avg_col}'\n",
    "                \n",
    "                # Use float values\n",
    "                minor_proteins_row[count_col] = float(minor_proteins_data['counts'][group])\n",
    "                minor_proteins_row[rel_count_col] = 0.0  # Will be recalculated\n",
    "                minor_proteins_row[avg_col] = float(minor_proteins_data['absorbance'][group])\n",
    "                \n",
    "                if rel_avg_col in self.proteins_df.columns:\n",
    "                    total_absorbance = self.sum_df[self.sum_df['Sample'] == avg_col]['Total_Sum'].values[0]\n",
    "                    if total_absorbance > 0:\n",
    "                        minor_proteins_row[rel_avg_col] = float((minor_proteins_data['absorbance'][group] / total_absorbance) * 100)\n",
    "                    else:\n",
    "                        minor_proteins_row[rel_avg_col] = 0.0\n",
    "            \n",
    "            # Add the row\n",
    "            self.proteins_df = pd.concat([self.proteins_df, pd.DataFrame([minor_proteins_row])], ignore_index=True)\n",
    "            \n",
    "            # Recalculate relative counts for all proteins\n",
    "            for group in selected_groups:\n",
    "                count_col = f'Count_{group}'\n",
    "                rel_count_col = f'Rel_Count_{group}'\n",
    "                total_count = self.peptide_count_totals[group]\n",
    "                \n",
    "                if total_count > 0:\n",
    "                    for idx in range(len(self.proteins_df)):\n",
    "                        protein_count = self.proteins_df.at[idx, count_col]\n",
    "                        self.proteins_df.at[idx, rel_count_col] = (protein_count / total_count) * 100\n",
    "        \n",
    "        # Print debug info for key proteins\n",
    "        #debug_proteins = ['Beta-casein', 'Alpha-S1-casein', 'Minor Proteins']\n",
    "        #for protein in debug_proteins:\n",
    "        #    if protein in self.protein_sample_distribution:\n",
    "        #        print(f\"\\nProtein: {protein}\")\n",
    "        #        data = self.protein_sample_distribution[protein]\n",
    "        #        print(f\"Total count across all groups: {data['total_count']}\")\n",
    "        #        print(f\"Unique peptide count: {data.get('unique_peptide_count', 'N/A')}\")\n",
    "        #        print(f\"Total absorbance: {data['total_absorbance']:.2e}\")\n",
    "        #        print(f\"Sample distribution (% of protein's total):\")\n",
    "        #        print(f\"Count: {', '.join([f'{g}: {v:.1f}%' for g, v in data['count_relative'].items()])}\")\n",
    "        #        print(f\"Absorbance: {', '.join([f'{g}: {v:.1f}%' for g, v in data['absorbance_relative'].items()])}\")\n",
    "        #        print(f\"Sum of count percentages: {sum(data['count_relative'].values()):.1f}%\")\n",
    "                \n",
    "        return True\n",
    "    \n",
    "    def _fetch_protein_names(self, accession_str):\n",
    "        \"\"\"\n",
    "        Fetch protein names from the proteins dictionary.\n",
    "        Returns a list of protein names, using the full protein name.\n",
    "        \"\"\"\n",
    "        names = []\n",
    "        for acc in accession_str.split('; '):\n",
    "            if acc in self.data_transformer.proteins_dic:\n",
    "                # Use the full protein name instead of splitting it\n",
    "                name = self.data_transformer.proteins_dic[acc]['name']\n",
    "                names.append(name)\n",
    "            else:\n",
    "                names.append(acc)\n",
    "        return names\n",
    "\n",
    "    def _get_color_sequence(self, n_colors):\n",
    "        \"\"\"Get color sequence based on selected scheme.\"\"\"\n",
    "        if n_colors <= 0:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Get the selected color scheme\n",
    "            scheme = 'HSV'  # Default scheme\n",
    "            if hasattr(self, 'color_scheme') and self.color_scheme.value:\n",
    "                scheme = self.color_scheme.value\n",
    "            \n",
    "            # Skip header options that start with '---'\n",
    "            if scheme.startswith('---'):\n",
    "                scheme = 'HSV'  # Default to HSV if a header is selected\n",
    "            \n",
    "            # Handle special cases\n",
    "            if scheme.lower() in ['rainbow', 'hsv']:\n",
    "                return [f'hsl({h},70%,60%)' for h in np.linspace(0, 330, n_colors)]\n",
    "            \n",
    "            # Try qualitative color scales first (best for categorical data)\n",
    "            color_sequence = getattr(px.colors.qualitative, scheme, None)\n",
    "            if color_sequence is None:\n",
    "                # Try sequential color scales\n",
    "                color_sequence = getattr(px.colors.sequential, scheme, None)\n",
    "            if color_sequence is None:\n",
    "                # Try diverging color scales\n",
    "                color_sequence = getattr(px.colors.diverging, scheme, None)\n",
    "            if color_sequence is None:\n",
    "                # Try cyclical color scales\n",
    "                color_sequence = getattr(px.colors.cyclical, scheme, None)\n",
    "            \n",
    "            if color_sequence:\n",
    "                if n_colors >= len(color_sequence):\n",
    "                    # If we need more colors than available, interpolate\n",
    "                    indices = np.linspace(0, len(color_sequence)-1, n_colors)\n",
    "                    return [color_sequence[int(i)] for i in indices]\n",
    "                else:\n",
    "                    # If we need fewer colors, take a subset\n",
    "                    indices = np.linspace(0, len(color_sequence)-1, n_colors, dtype=int)\n",
    "                    return [color_sequence[i] for i in indices]\n",
    "            \n",
    "            # Default to HSV if no matching scheme found\n",
    "            return [f'hsl({h},70%,60%)' for h in np.linspace(0, 330, n_colors)]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating colors: {e}\")\n",
    "            # Fallback to HSV\n",
    "            return [f'hsl({h},70%,60%)' for h in np.linspace(0, 330, n_colors)]\n",
    "\n",
    "    def create_grouped_bar_plot(self, title, selected_groups, use_count=False):\n",
    "        \"\"\"Generate interactive Plotly grouped bar plots for proteins\n",
    "        \n",
    "        Uses pre-calculated data from process_data to create grouped bar plots.\n",
    "        \n",
    "        Args:\n",
    "            title: Title for the plot\n",
    "            selected_groups: Groups to include in the plot\n",
    "            use_count: Whether to use counts instead of abundance values\n",
    "            \n",
    "        Returns:\n",
    "            Plotly figure object\n",
    "        \"\"\"\n",
    "        if self.proteins_df is None or len(self.proteins_df) == 0:\n",
    "            print(\"No data available for plotting.\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Check if we're using relative metrics\n",
    "            is_relative_metric = hasattr(self, 'metric_type') and 'relative' in self.metric_type.value.lower()\n",
    "            \n",
    "            # Create figure\n",
    "            fig = go.Figure()\n",
    "            \n",
    "            # Determine orientation - sync with invert_plot for consistency\n",
    "            if hasattr(self, 'invert_plot'):\n",
    "                orientation = self.invert_plot.value\n",
    "            else:\n",
    "                orientation = 'By Sample'  # Default\n",
    "            \n",
    "            # Set up proteins to display\n",
    "            if hasattr(self, 'pro_list') and self.pro_list:\n",
    "                display_proteins = self.pro_list.copy()\n",
    "                if hasattr(self, 'plot_minor_proteins') and self.plot_minor_proteins.value:\n",
    "                    if 'Minor Proteins' in self.protein_sample_distribution:\n",
    "                        display_proteins.append('Minor Proteins')\n",
    "            else:\n",
    "                # Fallback to top proteins\n",
    "                proteins_to_show = int(self.minor_proteins_input.value) if hasattr(self, 'minor_proteins_input') else 10\n",
    "                display_proteins = self.proteins_df['Description'].tolist()[:proteins_to_show]\n",
    "            \n",
    "            # Filter to only include proteins that have data\n",
    "            display_proteins = [p for p in display_proteins if p in self.protein_sample_distribution]\n",
    "            \n",
    "            if not selected_groups or not display_proteins:\n",
    "                print(\"No valid groups or proteins selected for plotting.\")\n",
    "                return None\n",
    "            \n",
    "            # Based on orientation, determine which will be the categories and which will be the bars\n",
    "            if orientation == 'By Protein':\n",
    "                # By Protein: Proteins on x-axis, samples as different colored bars\n",
    "                categories = display_proteins\n",
    "                bar_groups = selected_groups\n",
    "                \n",
    "                # Create consistent color mapping for samples\n",
    "                color_sequence = self._get_color_sequence(len(selected_groups))\n",
    "                color_mapping = {group: color_sequence[i] for i, group in enumerate(selected_groups)}\n",
    "            else:  # 'By Sample'\n",
    "                # By Sample: Samples on x-axis, proteins as different colored bars\n",
    "                categories = selected_groups\n",
    "                bar_groups = display_proteins\n",
    "                color_sequence = self._get_color_sequence(len(display_proteins))\n",
    "                color_mapping = {protein: color_sequence[i] for i, protein in enumerate(display_proteins)}\n",
    "                # Special color for Minor Proteins\n",
    "                if 'Minor Proteins' in bar_groups:\n",
    "                    color_mapping['Minor Proteins'] = '#808080'  # Grey\n",
    "            \n",
    "            # Calculate bar positions\n",
    "            n_bar_groups = len(bar_groups)\n",
    "            bar_width = 0.8 / n_bar_groups  # Adjust total width of group\n",
    "            \n",
    "            # For each bar group, create a trace\n",
    "            for idx, bar_group in enumerate(bar_groups):\n",
    "                # Calculate x positions for this group's bars\n",
    "                x_positions = [i + (idx - n_bar_groups/2 + 0.5) * bar_width for i in range(len(categories))]\n",
    "                \n",
    "                values = []\n",
    "                hover_text = []\n",
    "                \n",
    "                for i, category in enumerate(categories):\n",
    "                    if orientation == 'By Protein':\n",
    "                        # By Protein: category = protein, bar_group = sample\n",
    "                        protein = category\n",
    "                        group = bar_group\n",
    "                        \n",
    "                        # Skip if protein doesn't have data\n",
    "                        if protein not in self.protein_sample_distribution:\n",
    "                            values.append(0)\n",
    "                            hover_text.append(f\"Protein: {protein}<br>Sample: {group}<br>Value: 0\")\n",
    "                            continue\n",
    "                        \n",
    "                        # Get data from protein_sample_distribution\n",
    "                        protein_data = self.protein_sample_distribution[protein]\n",
    "                        \n",
    "                        # Get the appropriate values based on metric type\n",
    "                        if use_count:\n",
    "                            abs_value = protein_data['counts'].get(group, 0)\n",
    "                            total_value = protein_data['total_count']\n",
    "                            unique_count = protein_data['unique_peptide_count']\n",
    "                            rel_percentage = protein_data['count_relative'].get(group, 0)\n",
    "                        else:\n",
    "                            abs_value = protein_data['absorbance'].get(group, 0)\n",
    "                            total_value = protein_data['total_absorbance']\n",
    "                            unique_count = protein_data['unique_peptide_count']\n",
    "                            rel_percentage = protein_data['absorbance_relative'].get(group, 0)\n",
    "                        \n",
    "                        # Determine y-value based on metric type\n",
    "                        if is_relative_metric:\n",
    "                            # For relative metrics: use percentage contribution\n",
    "                            y_value = rel_percentage\n",
    "                            hover = (f\"Protein: {protein}<br>\" +\n",
    "                                    f\"Sample: {group}<br>\" +\n",
    "                                    f\"Relative Contribution: {rel_percentage:.1f}%<br>\" +\n",
    "                                    f\"{self.metric_name}: {abs_value:{self.num_format}}\")\n",
    "                        else:\n",
    "                            # For absolute metrics: use actual count/abundance\n",
    "                            y_value = abs_value\n",
    "                            hover = (f\"Protein: {protein}<br>\" +\n",
    "                                    f\"Sample: {group}<br>\" +\n",
    "                                    f\"{self.metric_name}: {abs_value:{self.num_format}}<br>\" +\n",
    "                                    f\"Relative Contribution: {rel_percentage:.1f}%\")\n",
    "                        \n",
    "                    else:  # 'By Sample'\n",
    "                        # By Sample: category = sample, bar_group = protein\n",
    "                        protein = bar_group\n",
    "                        group = category\n",
    "                        \n",
    "                        # Skip if protein doesn't have data\n",
    "                        if protein not in self.protein_sample_distribution:\n",
    "                            values.append(0)\n",
    "                            hover_text.append(f\"Protein: {protein}<br>Sample: {group}<br>Value: 0\")\n",
    "                            continue\n",
    "                        \n",
    "                        # Get data from protein_sample_distribution\n",
    "                        protein_data = self.protein_sample_distribution[protein]\n",
    "                        \n",
    "                        # Get the appropriate values based on metric type\n",
    "                        if use_count:\n",
    "                            abs_value = protein_data['counts'].get(group, 0)\n",
    "                            total_count = self.peptide_count_totals.get(group, 0)\n",
    "                            rel_percentage = (abs_value / total_count * 100) if total_count > 0 else 0\n",
    "                            protein_specific_rel = protein_data['count_relative'].get(group, 0)\n",
    "                        else:\n",
    "                            abs_value = protein_data['absorbance'].get(group, 0)\n",
    "                            # Get total absorbance for this group from sum_df\n",
    "                            sample_col = f'Avg_{group}'\n",
    "                            total_value = self.sum_df.loc[self.sum_df['Sample'] == sample_col, 'Total_Sum'].values[0] if sample_col in self.sum_df['Sample'].values else 0\n",
    "                            rel_percentage = (abs_value / total_value * 100) if total_value > 0 else 0\n",
    "                            protein_specific_rel = protein_data['absorbance_relative'].get(group, 0)\n",
    "                        \n",
    "                        # Determine y-value based on metric type\n",
    "                        if is_relative_metric:\n",
    "                            # For relative metrics: use percentage of sample total\n",
    "                            y_value = rel_percentage\n",
    "                            hover = (f\"Protein: {protein}<br>\" +\n",
    "                                    f\"Sample: {group}<br>\" +\n",
    "                                    f\"Relative Contribution: {rel_percentage:.1f}%<br>\" +\n",
    "                                    f\"{self.metric_name}: {abs_value:{self.num_format}}\")\n",
    "                        else:\n",
    "                            # For absolute metrics: use actual count/abundance\n",
    "                            y_value = abs_value\n",
    "                            hover = (f\"Protein: {protein}<br>\" +\n",
    "                                    f\"Sample: {group}<br>\" +\n",
    "                                    f\"{self.metric_name}: {abs_value:{self.num_format}}<br>\" +\n",
    "                                    f\"Relative Contribution: {rel_percentage:.1f}%\")\n",
    "                    \n",
    "                    values.append(y_value)\n",
    "                    hover_text.append(hover)\n",
    "                \n",
    "                # Only add trace if we have valid values\n",
    "                if any(v > 0 for v in values):\n",
    "                    fig.add_trace(go.Bar(\n",
    "                        name=bar_group,\n",
    "                        x=x_positions,\n",
    "                        y=values,\n",
    "                        width=bar_width * 0.9,  # Slight gap between bars\n",
    "                        marker_color=color_mapping.get(bar_group, 'gray'),\n",
    "                        hovertext=hover_text,\n",
    "                        hoverinfo='text'\n",
    "                    ))\n",
    "            \n",
    "            # Determine plot title and axis labels\n",
    "            plot_title = title or f\"Protein Distribution - {orientation} ({self.metric_name})\"\n",
    "            \n",
    "            # Determine y-axis title based on metric type\n",
    "            if use_count:\n",
    "                metric_base = \"Peptide Count\"\n",
    "            else:\n",
    "                metric_base = \"Abundance\"\n",
    "                \n",
    "            if is_relative_metric:\n",
    "                yaxis_title = f\"Relative {metric_base} (%)\"\n",
    "            else:\n",
    "                yaxis_title = f\"Absolute {metric_base}\"\n",
    "            \n",
    "            # Determine x-axis title based on orientation\n",
    "            xaxis_title = 'Proteins' if orientation == 'By Protein' else 'Sample Categories'\n",
    "            \n",
    "            # Determine legend title based on orientation\n",
    "            legend_title = 'Samples' if orientation == 'By Protein' else 'Protein Origins'\n",
    "            \n",
    "            # Update titles from widgets if available\n",
    "            if hasattr(self, 'legend_widget') and self.legend_widget.value:\n",
    "                legend_title = self.legend_widget.value\n",
    "            \n",
    "            if hasattr(self, 'xlabel_widget') and self.xlabel_widget.value:\n",
    "                xaxis_title = self.xlabel_widget.value\n",
    "\n",
    "            if hasattr(self, 'ylabel_widget') and self.ylabel_widget.value:\n",
    "                yaxis_title = self.ylabel_widget.value\n",
    "\n",
    "            # Update layout\n",
    "            fig.update_layout(\n",
    "                title={\n",
    "                    'text': plot_title,\n",
    "                    'y': .975,\n",
    "                    'x': 0.5,\n",
    "                    'xanchor': 'center',\n",
    "                    'yanchor': 'top',\n",
    "                    'font': {'size': 18, 'color': 'black'}\n",
    "                },\n",
    "                xaxis_title=xaxis_title,\n",
    "                yaxis_title=yaxis_title,\n",
    "                legend_title=legend_title,\n",
    "                legend={'yanchor': \"top\", 'y': 1.0, 'xanchor': \"left\", 'x': 1.05, 'traceorder': 'normal', 'font': {'size': 12, 'color': 'black'}},\n",
    "                showlegend=True,\n",
    "                template='plotly_white',\n",
    "                height=750,\n",
    "                width=1100,\n",
    "                margin=dict(t=100, l=100, r=200),\n",
    "                hoverlabel=dict(\n",
    "                    bgcolor=\"white\",\n",
    "                    font_size=12,\n",
    "                    font_family=\"Arial\"\n",
    "                ),\n",
    "                barmode='group',\n",
    "                xaxis=dict(\n",
    "                    showline=True,\n",
    "                    linewidth=1,\n",
    "                    linecolor='black',\n",
    "                    mirror=False\n",
    "                ),\n",
    "                yaxis=dict(\n",
    "                    showline=True,\n",
    "                    linewidth=1,\n",
    "                    linecolor='black',\n",
    "                    mirror=False\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Update axis properties\n",
    "            fig.update_xaxes(\n",
    "                ticktext=categories,\n",
    "                tickvals=list(range(len(categories))),\n",
    "                tickangle=45,\n",
    "                title_font={\"size\": 18},\n",
    "                tickfont={\"size\": 16},\n",
    "                tickfont_color=\"black\",\n",
    "                title_font_color=\"black\",\n",
    "            )\n",
    "            \n",
    "            # Set y-axis format based on plot type\n",
    "            if use_count and not is_relative_metric:\n",
    "                # Absolute count\n",
    "                fig.update_yaxes(\n",
    "                    type='linear',\n",
    "                    tickformat=\",d\",  # Format with commas for thousands\n",
    "                    title_font={\"size\": 18},\n",
    "                    tickfont={\"size\": 16},\n",
    "                    tickfont_color=\"black\",\n",
    "                    title_font_color=\"black\",\n",
    "                    gridcolor=\"lightgray\",\n",
    "                    showgrid=True,\n",
    "                    zeroline=False,\n",
    "                )\n",
    "            elif not use_count and not is_relative_metric:\n",
    "                # Absolute abundance\n",
    "                fig.update_yaxes(\n",
    "                    type='log',\n",
    "                    exponentformat='E',\n",
    "                    showexponent='all',\n",
    "                    title_font={\"size\": 18},\n",
    "                    tickfont={\"size\": 16},\n",
    "                    tickfont_color=\"black\",\n",
    "                    title_font_color=\"black\",\n",
    "                    gridcolor=\"lightgray\",\n",
    "                    showgrid=True,\n",
    "                    zeroline=False,\n",
    "                )\n",
    "            else:\n",
    "                # Relative metrics (both count and abundance)\n",
    "                fig.update_yaxes(\n",
    "                    type='linear',\n",
    "                    range=[0, 100],\n",
    "                    title_font={\"size\": 18},\n",
    "                    tickfont={\"size\": 16},\n",
    "                    tickfont_color=\"black\",\n",
    "                    title_font_color=\"black\",\n",
    "                    gridcolor=\"lightgray\",\n",
    "                    showgrid=True,\n",
    "                    zeroline=False,\n",
    "                )\n",
    "                \n",
    "            # Mark generation as complete\n",
    "            self.state_manager.generate_completed()\n",
    "            self.export_button.disabled = False\n",
    "            self.download_plot_button.disabled = False\n",
    "            \n",
    "            return fig\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating grouped bar plot: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "   \n",
    "    def generate_download_link(self, content, filename, filetype='text/csv'):\n",
    "        \"\"\"Generate a download link for any content\"\"\"\n",
    "        if isinstance(content, pd.DataFrame):\n",
    "            if filetype == 'text/csv':\n",
    "                content = content.to_csv(index=False)\n",
    "            else:\n",
    "                content = content.to_csv(index=True)\n",
    "        if isinstance(content, str):\n",
    "            content = content.encode()\n",
    "        b64 = base64.b64encode(content).decode()\n",
    "        return f\"\"\"\n",
    "            <a id=\"download_link\" href=\"data:{filetype};base64,{b64}\" \n",
    "               download=\"{filename}\"\n",
    "               style=\"display: none;\">\n",
    "                Download {filename}\n",
    "            </a>\n",
    "            <script>\n",
    "                document.getElementById('download_link').click();\n",
    "            </script>\n",
    "            \"\"\"\n",
    "    \n",
    "    def _on_download_plot_click(self, b):\n",
    "        \"\"\"Handle plot download button click with automatic download\"\"\"\n",
    "        if self.current_fig is not None:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            plot_filename = f'protein_plot_{timestamp}.html'\n",
    "            \n",
    "            with self.export_output:\n",
    "                self.export_output.clear_output(wait=True)\n",
    "                display(HTML(self.generate_download_link(\n",
    "                    self.current_fig.to_html(),\n",
    "                    plot_filename,\n",
    "                    'text/html'\n",
    "                )))\n",
    "        else:\n",
    "            print(\"Please generate a plot first.\")\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the protein analysis interface\"\"\"\n",
    "        display(self.widget_box)\n",
    "\n",
    "    def _on_export_button_click(self, b):\n",
    "        \"\"\"Handle data export with automatic download\"\"\"\n",
    "        if self.proteins_df is not None:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            data_filename = f'protein_absorbance_analysis_{timestamp}.csv'\n",
    "            \n",
    "            with self.export_output:\n",
    "                self.export_output.clear_output(wait=True)\n",
    "                display(HTML(self.generate_download_link(\n",
    "                    self.proteins_df,\n",
    "                    data_filename,\n",
    "                    'text/csv'\n",
    "                )))\n",
    "        else:\n",
    "            print(\"Please generate the analysis first.\")\n",
    "\n",
    "    def _on_plot_button_click(self, b):\n",
    "        if self.current_fig is not None:\n",
    "            self.state_manager.generate_completed()\n",
    "            self.export_button.disabled = False\n",
    "            self.download_plot_button.disabled = False\n",
    "        with self.plot_output:\n",
    "            self.plot_output.clear_output(wait=True)\n",
    "            \n",
    "            if not self.group_select.value:\n",
    "                print(\"Please select at least one group to plot.\")\n",
    "                return\n",
    "            \n",
    "            selected_groups = list(self.group_select.value)\n",
    "            if self.process_data(selected_groups):\n",
    "\n",
    "                # Check if using count metric\n",
    "                use_count = False\n",
    "                self.metric_name = \"Abundance\"\n",
    "                if hasattr(self, 'abs_or_count'):\n",
    "                    if self.abs_or_count.value == 'Count':\n",
    "                        use_count = True\n",
    "                        self.metric_name = \"Peptide Count\"\n",
    "                        self.value_prefix = \"Count_\"\n",
    "                        self.rel_prefix = \"Rel_Count_\"\n",
    "                        self.num_format = \",.0f\"  # Integer format for counts\n",
    "                        \n",
    "                    else: #abundance\n",
    "                        self.metric_name = \"Abundance\"\n",
    "                        self.value_prefix = \"Avg_\"\n",
    "                        self.rel_prefix = \"Rel_Avg_\"\n",
    "                        self.num_format = \",.2e\"  # Scientific notation for abundance\n",
    "            \n",
    "                # Create mapping from sample name to column names\n",
    "                self.value_cols = {var: f'{self.value_prefix}{var}' for var in selected_groups}\n",
    "                self.rel_cols = {var: f'{self.rel_prefix}{var}' for var in selected_groups}\n",
    "                    \n",
    "                # Get the selected plot type (Bar or Pie)\n",
    "                if hasattr(self, 'plot_type'):\n",
    "                    plot_type = self.plot_type.value\n",
    "                else:\n",
    "                    plot_type = 'Stacked Bar Plots'  # Default to bar plot if widget doesn't exist\n",
    "                \n",
    "                # Create and display the appropriate plot based on selection and metric\n",
    "                if plot_type == 'Stacked Bar Plots':\n",
    "                    # Create and store bar plot (existing functionality)\n",
    "                    title = self.title_widget.value or f'Protein Distribution Analysis ({self.metric_name})'\n",
    "                    \n",
    "                    # Modified plot_stacked_bar_scaled to use count columns if needed\n",
    "                    self.current_fig = self.plot_stacked_bar_scaled(\n",
    "                        title=title,\n",
    "                        selected_groups=selected_groups,\n",
    "                        use_count=use_count\n",
    "                    )\n",
    "                    if self.current_fig is not None:\n",
    "                        self.current_fig.show()\n",
    "                \n",
    "                elif plot_type == \"Grouped Bar Plots\":\n",
    "                    # Get the group column - you might want to add a dropdown for this\n",
    "                    title = self.title_widget.value or f'Protein Distribution Analysis ({self.metric_name})'\n",
    "\n",
    "                    self.current_fig = self.create_grouped_bar_plot(\n",
    "                            title=title,\n",
    "                            selected_groups=selected_groups,\n",
    "                            use_count=use_count\n",
    "                        )\n",
    "                    if self.current_fig is not None:\n",
    "                        self.current_fig.show()\n",
    "                elif plot_type == 'Pie Charts':  # Pie Chart\n",
    "                    # Create and store pie plot\n",
    "                    try:\n",
    "                        # Call the pie chart function with count flag\n",
    "                        orientation = self.invert_plot.value\n",
    "                        title = self.title_widget.value or f\"Protein Distribution - {orientation} ({self.metric_name})\"\n",
    "\n",
    "                        self.current_fig = self.create_pie_charts(\n",
    "                            selected_groups=selected_groups, \n",
    "                            title=title,\n",
    "                            use_count=use_count\n",
    "                        )\n",
    "                        \n",
    "                        if self.current_fig is not None:\n",
    "                            self.current_fig.show()\n",
    "                        else:\n",
    "                            print(\"Error: Could not generate pie charts.\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error creating pie charts: {str(e)}\")\n",
    "                        import traceback\n",
    "                        traceback.print_exc()\n",
    "            else:\n",
    "                print(\"Please upload all required files first.\")\n",
    "                print(\"Error creating plot. Please check your data.\")\n",
    "                 \n",
    "    def create_pie_charts(self, selected_groups, title, use_count=False):\n",
    "        \"\"\"Create pie charts for protein data with pre-calculated counts or abundance\"\"\"\n",
    "        try:\n",
    "            # Check if we have data\n",
    "            if not hasattr(self, 'proteins_df') or self.proteins_df is None or self.proteins_df.empty:\n",
    "                print(\"No protein data available to plot\")\n",
    "                return None\n",
    "                        \n",
    "            # Determine orientation - sync with invert_plot for consistency\n",
    "            if hasattr(self, 'invert_plot'):\n",
    "                orientation = self.invert_plot.value\n",
    "            else:\n",
    "                orientation = 'By Sample'  # Default\n",
    "            \n",
    "            \n",
    "            # Create figure and subplots with maximum 3 columns\n",
    "            if orientation == 'By Sample':\n",
    "                # One pie chart per sample\n",
    "                # Create a working copy of the DataFrame named scaled_df\n",
    "                scaled_df = self.proteins_df.copy()\n",
    "                \n",
    "                # Get the list of groups/samples to plot\n",
    "                if hasattr(self, 'selected_groups'):\n",
    "                    selected_groups = self.selected_groups\n",
    "                else:\n",
    "                    # Fallback if selected_groups is not available\n",
    "                    selected_groups = list(self.value_cols.keys()) if isinstance(self.value_cols, dict) else [col.replace(self.value_prefix, '') for col in self.value_cols]\n",
    "                \n",
    "                # Map group names to actual column names\n",
    "                sample_columns = []\n",
    "                sample_names = []\n",
    "                \n",
    "                if isinstance(self.value_cols, dict):\n",
    "                    # If value_cols is a dictionary (group -> column)\n",
    "                    for group in selected_groups:\n",
    "                        if group in self.value_cols:\n",
    "                            sample_columns.append(self.value_cols[group])\n",
    "                            sample_names.append(group)\n",
    "                else:\n",
    "                    # If value_cols is a list of columns\n",
    "                    sample_columns = self.value_cols\n",
    "                    sample_names = [col.replace(self.value_prefix, '') for col in sample_columns]\n",
    "                \n",
    "                # Ensure we have data after mapping\n",
    "                if not sample_columns:\n",
    "                    print(\"No samples available for plotting\")\n",
    "                    return None\n",
    "                \n",
    "                # Filter to only selected proteins (including minor proteins if enabled)\n",
    "                if hasattr(self, 'pro_list') and self.pro_list:\n",
    "                    display_proteins = self.pro_list.copy()\n",
    "                    if hasattr(self, 'plot_minor_proteins') and self.plot_minor_proteins.value:\n",
    "                        if 'Minor Proteins' in scaled_df['Description'].values:\n",
    "                            display_proteins.append('Minor Proteins')\n",
    "                    \n",
    "                    scaled_df = scaled_df[scaled_df['Description'].isin(display_proteins)]\n",
    "                \n",
    "                # Debug info\n",
    "                print(f\"Sample columns to plot: {sample_columns}\")\n",
    "                print(f\"Sample names for display: {sample_names}\")\n",
    "                \n",
    "                # Check if columns exist in DataFrame\n",
    "                for col in sample_columns:\n",
    "                    if col not in scaled_df.columns:\n",
    "                        print(f\"Warning: Column '{col}' not found in DataFrame. Available columns: {scaled_df.columns.tolist()}\")\n",
    "                \n",
    "                # Calculate grid layout\n",
    "                num_samples = len(sample_columns)\n",
    "                num_cols = min(3, num_samples)  # Maximum 3 columns\n",
    "                num_rows = (num_samples + num_cols - 1) // num_cols  # Ceiling division\n",
    "                \n",
    "                # Create figure with grid layout - using sample_names as subplot_titles\n",
    "                fig = make_subplots(\n",
    "                    rows=num_rows, \n",
    "                    cols=num_cols,\n",
    "                    specs=[[{'type': 'pie'} for _ in range(num_cols)] for _ in range(num_rows)],\n",
    "                    subplot_titles=sample_names\n",
    "                )\n",
    "                \n",
    "                # Get unique proteins for coloring\n",
    "                unique_proteins = scaled_df['Description'].unique().tolist()\n",
    "                if 'Minor Proteins' in unique_proteins:\n",
    "                    unique_proteins.remove('Minor Proteins')\n",
    "                \n",
    "                # Use the existing color sequence function for proteins\n",
    "                protein_colors = self._get_color_sequence(len(unique_proteins))\n",
    "                \n",
    "                # Create a color map, setting Minor Proteins to grey\n",
    "                color_map = {protein: color for protein, color in zip(unique_proteins, protein_colors)}\n",
    "                if 'Minor Proteins' in scaled_df['Description'].values:\n",
    "                    color_map['Minor Proteins'] = '#808080'  # Grey color for minor proteins\n",
    "                \n",
    "                # First pie chart will set the legend for all\n",
    "                first_chart = True\n",
    "                \n",
    "                # Create a pie chart for each sample\n",
    "                for i, col_name in enumerate(sample_columns):\n",
    "                    # Skip if column doesn't exist in DataFrame\n",
    "                    if col_name not in scaled_df.columns:\n",
    "                        continue\n",
    "                        \n",
    "                    # Calculate which row and column this chart belongs in\n",
    "                    row_idx = i // num_cols + 1  # 1-based indexing for plotly\n",
    "                    col_idx = i % num_cols + 1   # 1-based indexing for plotly\n",
    "                    \n",
    "                    sample_name = sample_names[i]\n",
    "                    \n",
    "                    # Get data for this sample\n",
    "                    try:\n",
    "                        sample_data = scaled_df[['Description', col_name]].copy()\n",
    "                        \n",
    "                        # Filter out zero values\n",
    "                        sample_data = sample_data[sample_data[col_name] > 0]\n",
    "                        \n",
    "                        # Skip if no data\n",
    "                        if sample_data.empty:\n",
    "                            continue\n",
    "                        \n",
    "                        # Sort by value but ensure Minor Proteins is at the end\n",
    "                        if 'Minor Proteins' in sample_data['Description'].values:\n",
    "                            # Extract Minor Proteins row\n",
    "                            minor_row = sample_data[sample_data['Description'] == 'Minor Proteins']\n",
    "                            # Get the rest sorted by value\n",
    "                            other_rows = sample_data[sample_data['Description'] != 'Minor Proteins']\n",
    "                            other_rows = other_rows.sort_values(by=col_name, ascending=False)\n",
    "                            # Combine with Minor Proteins at the end\n",
    "                            sample_data = pd.concat([other_rows, minor_row], ignore_index=True)\n",
    "                        else:\n",
    "                            sample_data = sample_data.sort_values(by=col_name, ascending=False)\n",
    "                        \n",
    "                        # Get colors for the current sample's proteins\n",
    "                        colors = [color_map.get(protein, '#CCCCCC') for protein in sample_data['Description']]\n",
    "                        \n",
    "                        # Create the pie chart\n",
    "                        fig.add_trace(\n",
    "                            go.Pie(\n",
    "                                labels=sample_data['Description'],\n",
    "                                values=sample_data[col_name],\n",
    "                                name=sample_name,\n",
    "                                marker_colors=colors,\n",
    "                                textposition='inside',\n",
    "                                textinfo='percent',\n",
    "                                hovertemplate=(\n",
    "                                    f\"Protein: %{{label}}<br>\"\n",
    "                                    f\"{self.metric_name}: %{{value:{self.num_format}}}<br>\"\n",
    "                                    f\"Percentage: %{{percent}}<br>\"\n",
    "                                    f\"Sample: {sample_name}<br>\"\n",
    "                                    f\"<extra></extra>\"\n",
    "                                ),\n",
    "                                hole=0.3,\n",
    "                                showlegend=first_chart  # Only show legend for the first chart\n",
    "                            ),\n",
    "                            row=row_idx, col=col_idx\n",
    "                        )\n",
    "                        \n",
    "                        # After first chart, don't show labels in legend again\n",
    "                        first_chart = False\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error creating pie chart for {sample_name}: {str(e)}\")\n",
    "                        continue\n",
    "\n",
    "           # pie plot\n",
    "            else:  # 'By Protein'\n",
    "                # One pie chart for each protein showing distribution across samples\n",
    "                # Convert dict_keys to a list to make it subscriptable\n",
    "                unique_proteins = list(self.protein_sample_distribution.keys())\n",
    "                \n",
    "                # Filter to only include proteins we want to plot\n",
    "                if hasattr(self, 'pro_list') and self.pro_list:\n",
    "                    # Include both selected proteins and Minor Proteins if enabled\n",
    "                    filtered_proteins = []\n",
    "                    for protein in self.pro_list:\n",
    "                        if protein in self.protein_sample_distribution:\n",
    "                            filtered_proteins.append(protein)\n",
    "                    \n",
    "                    if self.plot_minor_proteins.value and 'Minor Proteins' in self.protein_sample_distribution:\n",
    "                        filtered_proteins.append('Minor Proteins')\n",
    "                        \n",
    "                    unique_proteins = filtered_proteins\n",
    "                \n",
    "                # Ensure we have proteins to plot\n",
    "                if not unique_proteins:\n",
    "                    print(\"No proteins available with distribution data\")\n",
    "                    return None\n",
    "                    \n",
    "                num_proteins = len(unique_proteins)\n",
    "                \n",
    "                num_cols = min(3, num_proteins)  # Maximum 3 columns\n",
    "                num_rows = (num_proteins + num_cols - 1) // num_cols  # Ceiling division\n",
    "                \n",
    "                # Create figure with grid layout\n",
    "                fig = make_subplots(\n",
    "                    rows=num_rows, \n",
    "                    cols=num_cols,\n",
    "                    specs=[[{'type': 'pie'} for _ in range(num_cols)] for _ in range(num_rows)],\n",
    "                    subplot_titles=unique_proteins\n",
    "                )\n",
    "                \n",
    "                # Use the existing color sequence function for samples\n",
    "                sample_colors = self._get_color_sequence(len(selected_groups))\n",
    "                \n",
    "                # Create a color map for samples\n",
    "                color_map = {group: color for group, color in zip(selected_groups, sample_colors)}\n",
    "                \n",
    "                # First pie chart will set the legend for all\n",
    "                first_chart = True\n",
    "                \n",
    "                # Create a pie chart for each protein\n",
    "                for i, protein in enumerate(unique_proteins):\n",
    "                    # Calculate which row and column this chart belongs in\n",
    "                    row_idx = i // num_cols + 1  # 1-based indexing for plotly\n",
    "                    col_idx = i % num_cols + 1   # 1-based indexing for plotly\n",
    "                    \n",
    "                    # Get the pre-calculated data from the dictionary\n",
    "                    protein_data = self.protein_sample_distribution[protein]\n",
    "                    \n",
    "                    # Choose the appropriate data based on metric type\n",
    "                    if use_count:\n",
    "                        values_dict = protein_data['counts']\n",
    "                        total = protein_data['total_count']\n",
    "                    else:\n",
    "                        values_dict = protein_data['absorbance'] \n",
    "                        total = protein_data['total_absorbance']\n",
    "                        \n",
    "                    # Get values and labels, filtering out zero values\n",
    "                    values = []\n",
    "                    labels = []\n",
    "                    colors_list = []\n",
    "                    \n",
    "                    for group in selected_groups:\n",
    "                        value = values_dict.get(group, 0)\n",
    "                        if value > 0:  # Only include non-zero values\n",
    "                            values.append(value)\n",
    "                            labels.append(group)\n",
    "                            colors_list.append(color_map[group])\n",
    "                    \n",
    "                    # Skip if no non-zero values\n",
    "                    if not values:\n",
    "                        continue\n",
    "                        \n",
    "                    # Create the pie chart\n",
    "                    fig.add_trace(\n",
    "                        go.Pie(\n",
    "                            labels=labels,\n",
    "                            values=values,\n",
    "                            name=protein,\n",
    "                            marker_colors=colors_list,\n",
    "                            textposition='inside',\n",
    "                            textinfo='percent',\n",
    "                            hovertemplate=(\n",
    "                                f\"Sample: %{{label}}<br>\"\n",
    "                                f\"{self.metric_name}: %{{value:{self.num_format}}}<br>\"\n",
    "                                f\"Percentage: %{{percent}}<br>\"\n",
    "                                f\"Total {self.metric_name}: {total:{self.num_format}}<br>\"\n",
    "                                f\"<extra></extra>\"\n",
    "                            ),\n",
    "                            hole=0.3,\n",
    "                            showlegend=first_chart  # Only show legend for the first chart\n",
    "                        ),\n",
    "                        row=row_idx, col=col_idx\n",
    "                    )\n",
    "                    \n",
    "                    # After first chart, don't show labels in legend again\n",
    "                    first_chart = False\n",
    "            \n",
    "            # Update layout with adjusted height for multiple rows\n",
    "            legend_title = self.legend_widget.value or ('Samples' if self.invert_plot.value == 'By Protein' else 'Protein Origins')\n",
    "\n",
    "            \n",
    "            fig.update_layout(\n",
    "                height=500 * num_rows,  # Scale height based on number of rows\n",
    "                width=min(1400, 450 * num_cols),  # Adjust width for maximum 3 columns\n",
    "                title_text=title,\n",
    "                title={\n",
    "                    'y': 0.98,\n",
    "                    'x': 0.5,\n",
    "                    'xanchor': 'center',\n",
    "                    'yanchor': 'top',\n",
    "                    'font': {\"size\": 20, 'color': 'black'}\n",
    "                },\n",
    "                showlegend=True,  # Show the legend\n",
    "                legend={\n",
    "                    'title': legend_title,\n",
    "                    'yanchor': \"top\",\n",
    "                    'y': 0.99,\n",
    "                    'xanchor': \"left\",\n",
    "                    'x': 1.02,\n",
    "                    'font': {\"size\": 12},\n",
    "                    #'bgcolor': 'rgba(255, 255, 255, 0.8)',\n",
    "                    #'bordercolor': 'rgba(0, 0, 0, 0.5)',\n",
    "                    #'borderwidth': 1\n",
    "                },\n",
    "                margin=dict(t=100, b=50, l=50, r=150),  # Increased right margin for legend\n",
    "                paper_bgcolor='rgba(255,255,255,1)',\n",
    "                plot_bgcolor='rgba(255,255,255,1)',\n",
    "                font=dict(\n",
    "                    family=\"Arial, sans-serif\",\n",
    "                    size=14,\n",
    "                    color=\"black\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            return fig\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating pie charts: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None   \n",
    "\n",
    "    def plot_stacked_bar_scaled(self, title, selected_groups, use_count=False):\n",
    "        if self.proteins_df is None or self.sum_df is None:\n",
    "            return None\n",
    "                    \n",
    "        # Create figure object before adding traces\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Check if we're using relative metrics\n",
    "        is_relative_metric = hasattr(self, 'metric_type') and 'relative' in self.metric_type.value.lower()\n",
    "        \n",
    "\n",
    "        if self.invert_plot.value == 'By Sample':\n",
    "\n",
    "            scaled_df = self.proteins_df.copy()\n",
    "        \n",
    "            # Calculate total values for each sample (needed for hover info)\n",
    "            total_absorbance = {}\n",
    "            for group in selected_groups:\n",
    "                col = self.value_cols[group]\n",
    "                total_absorbance[group] = self.proteins_df[col].sum()\n",
    "            \n",
    "            # For relative metric, ensure all relative columns are properly calculated\n",
    "            if is_relative_metric: # 'relative'\n",
    "                for group in selected_groups:\n",
    "                    value_col = self.value_cols[group]\n",
    "                    rel_col = self.rel_cols[group]\n",
    "                    \n",
    "                    # If relative column doesn't exist, calculate it\n",
    "                    if rel_col not in scaled_df.columns:\n",
    "                        total = scaled_df[value_col].sum()\n",
    "                        if total > 0:\n",
    "                            scaled_df[rel_col] = scaled_df[value_col] / total * 100\n",
    "                        else:\n",
    "                            scaled_df[rel_col] = 0\n",
    "            \n",
    "            # Calculate total sums for each group first (for absolute values)\n",
    "            total_sums = {}\n",
    "            for group in selected_groups:\n",
    "                if use_count:\n",
    "                    # For count values, use the pre-calculated totals from process_data\n",
    "                    if hasattr(self, 'peptide_count_totals') and group in self.peptide_count_totals:\n",
    "                        total_sum = self.peptide_count_totals[group]\n",
    "                    else:\n",
    "                        # Fallback: directly sum the Count_ columns\n",
    "                        count_col = f'Count_{group}'\n",
    "                        if count_col in self.proteins_df.columns:\n",
    "                            total_sum = self.proteins_df[count_col].sum()\n",
    "                        else:\n",
    "                            total_sum = 0\n",
    "                            print(f\"Warning: Count column {count_col} not found in proteins_df\")\n",
    "                else: # abundance\n",
    "                    # For abundance values, use the existing logic\n",
    "                    sample_key = self.value_cols[group]\n",
    "                    if sample_key in self.sum_df['Sample'].values:\n",
    "                        # Direct match\n",
    "                        total_sum = self.sum_df.loc[self.sum_df['Sample'] == sample_key, 'Total_Sum'].values[0]\n",
    "                    else:\n",
    "                        # Calculate from proteins_df\n",
    "                        total_sum = self.proteins_df[sample_key].sum()\n",
    "                \n",
    "                # Store with clean group name\n",
    "                total_sums[group] = total_sum\n",
    "                \n",
    "\n",
    "            # Create a new DataFrame for the Minor Proteins\n",
    "            minor_proteins_df = pd.DataFrame()\n",
    "\n",
    "            # Calculate minor proteins data for each sample\n",
    "            for group in selected_groups:\n",
    "                # Get the value and relative columns\n",
    "                value_col = self.value_cols[group]\n",
    "                rel_col = self.rel_cols[group]\n",
    "                \n",
    "                # Sum values for proteins not in pro_list\n",
    "                minor_proteins_value = scaled_df[~scaled_df['Description'].isin(self.pro_list)][value_col].sum()\n",
    "                \n",
    "                # Calculate relative value for minor proteins\n",
    "                if is_relative_metric:\n",
    "                    # When using relative metrics, calculate percentage directly\n",
    "                    total_value = scaled_df[value_col].sum()\n",
    "                    minor_proteins_rel_value = minor_proteins_value / total_value * 100 if total_value > 0 else 0\n",
    "                else:\n",
    "                    # For absolute metrics, use the pre-calculated relative column if it exists\n",
    "                    if rel_col in scaled_df.columns:\n",
    "                        minor_proteins_rel_value = scaled_df[~scaled_df['Description'].isin(self.pro_list)][rel_col].sum()\n",
    "                    else:\n",
    "                        # If it doesn't exist, calculate it directly\n",
    "                        minor_proteins_rel_value = 0\n",
    "                \n",
    "                # Add to the minor proteins DataFrame\n",
    "                if len(minor_proteins_df) == 0:\n",
    "                    minor_proteins_df = pd.DataFrame({\n",
    "                        'Description': ['Minor Proteins'],\n",
    "                        'Master Protein Accessions': ['Minor Proteins'],\n",
    "                        rel_col: [minor_proteins_rel_value],\n",
    "                        value_col: [minor_proteins_value]\n",
    "                    })\n",
    "                else:\n",
    "                    minor_proteins_df[rel_col] = minor_proteins_rel_value\n",
    "                    minor_proteins_df[value_col] = minor_proteins_value\n",
    "\n",
    "            # Filter scaled_df to only include proteins in pro_list\n",
    "            scaled_df = scaled_df[scaled_df['Description'].isin(self.pro_list)]\n",
    "            \n",
    "            # Sort proteins_df based on pro_list\n",
    "            description_order = {desc: i for i, desc in enumerate(self.pro_list)}\n",
    "            scaled_df['Order'] = scaled_df['Description'].map(description_order)\n",
    "            scaled_df = scaled_df.sort_values(by='Order').reset_index(drop=True)\n",
    "                                \n",
    "            # Now only append if the checkbox is checked\n",
    "            if self.plot_minor_proteins.value:\n",
    "                # Append minor proteins to the end of the main dataframe\n",
    "                scaled_df = pd.concat([scaled_df, minor_proteins_df], ignore_index=True)\n",
    "\n",
    "\n",
    "            # Get colors based on selected color scheme\n",
    "            colors = self._get_color_sequence(len(self.pro_list))\n",
    "            # Add gray color for Minor Proteins\n",
    "            colors.append('#808080')  # Gray color for Minor Proteins\n",
    "            \n",
    "            # For each sample, calculate the relative proportions and scale by the actual count\n",
    "            for group in selected_groups:\n",
    "                # Get the total count for this sample\n",
    "                sample_total = total_sums[group]\n",
    "                \n",
    "                # Create a DataFrame with just this sample's data for scaling\n",
    "                sample_data = scaled_df.copy()\n",
    "                \n",
    "                # Get column to use (rel column for relative metrics, value column for absolute)  \n",
    "                col = self.rel_cols[group] if is_relative_metric else self.value_cols[group]\n",
    "                \n",
    "                # Calculate the raw percentage for each protein in this sample\n",
    "                if not is_relative_metric: # absolute\n",
    "                    # For absolute metrics, calculate percentage\n",
    "                    sample_col_total = sample_data[col].sum()\n",
    "                    if sample_col_total > 0:\n",
    "                        sample_data[f'percentage_{group}'] = sample_data[col] / sample_col_total * 100\n",
    "                    else:\n",
    "                        sample_data[f'percentage_{group}'] = 0\n",
    "                else: # relative\n",
    "                    # For relative metrics, use the relative column directly\n",
    "                    sample_data[f'percentage_{group}'] = sample_data[col]\n",
    "                \n",
    "                # Calculate the scaled height for each protein in this sample\n",
    "                if use_count:\n",
    "                    # For count data, scale by the total count\n",
    "                    sample_data[f'scaled_{group}'] = sample_data[f'percentage_{group}'] * sample_total / 100\n",
    "                    if is_relative_metric:\n",
    "                        sample_data[f'scaled_{group}'] = sample_data[f'percentage_{group}']\n",
    "                else:\n",
    "                    # For abundance data, use the original values\n",
    "                    sample_data[f'scaled_{group}'] = sample_data[col]\n",
    "                \n",
    "                # Filter out zero values for plotting\n",
    "                for idx, row in sample_data.iterrows():\n",
    "                    protein_description = row['Description']\n",
    "                    if protein_description in self.pro_list or protein_description == 'Minor Proteins':\n",
    "                        # Use gray for Minor Proteins, otherwise use the color from the sequence\n",
    "                        if protein_description == 'Minor Proteins':\n",
    "                            color = '#808080'  # Gray color\n",
    "                        else:\n",
    "                            color = colors[self.pro_list.index(protein_description)]\n",
    "                        \n",
    "                        # Get the scaled value for this protein in this sample\n",
    "                        value = row[f'scaled_{group}']\n",
    "                        \n",
    "                        # Create hover text\n",
    "                        abs_value = row[f'{self.value_prefix}{group}']\n",
    "                        rel_value = row[f'{self.rel_prefix}{group}'] \n",
    "                        \n",
    "\n",
    "                        hover_text = (\n",
    "                            f\"Protein: {row['Master Protein Accessions']}<br>\" +\n",
    "                            f\"Description: {row['Description']}<br>\" +\n",
    "                            f\"Sample: {group}<br>\" +\n",
    "                            f\"Relative {self.metric_name}: {rel_value:.2f}%<br>\" +\n",
    "                            f\"Absolute {self.metric_name}: {abs_value:{self.num_format}}<br>\"\n",
    "                        )\n",
    "                        \n",
    "                        # Add trace for this protein in this sample\n",
    "                        fig.add_trace(go.Bar(\n",
    "                            name=protein_description,\n",
    "                            x=[group],  # Just this sample\n",
    "                            y=[value],  # Scaled value\n",
    "                            marker_color=color,\n",
    "                            hovertext=[hover_text],\n",
    "                            hoverinfo='text',\n",
    "                            showlegend=(group == selected_groups[0])  # Only show in legend for first sample\n",
    "                        ))\n",
    "                                \n",
    "        else:  # 'By Protein'\n",
    "            # Inverted plotting logic (proteins on x-axis)\n",
    "            # Get colors based on selected color scheme\n",
    "            colors = self._get_color_sequence(len(selected_groups))\n",
    "\n",
    "            # Define protein_totals dictionary to store totals for each protein\n",
    "            protein_totals = {}\n",
    "\n",
    "            # For each protein, get data from the protein_sample_distribution dictionary\n",
    "            for protein in self.pro_list + (['Minor Proteins'] if self.plot_minor_proteins.value else []):\n",
    "                # Get total from protein_sample_distribution if available\n",
    "                protein_data = self.protein_sample_distribution[protein]\n",
    "                if use_count:\n",
    "                    protein_totals[protein] = protein_data['unique_peptide_count']\n",
    "                else:\n",
    "                    protein_totals[protein] = protein_data['total']\n",
    "\n",
    "            # Now plot each protein with data from protein_sample_distribution\n",
    "            for protein in self.pro_list + (['Minor Proteins'] if self.plot_minor_proteins.value else []):\n",
    "                # Skip if protein not found in data\n",
    "                if protein not in self.protein_sample_distribution.keys():\n",
    "                    continue\n",
    "                \n",
    "                # Check if we have data in the protein_sample_distribution dictionary\n",
    "                protein_distribution_available = (hasattr(self, 'protein_sample_distribution') and \n",
    "                                                    protein in self.protein_sample_distribution)\n",
    "                \n",
    "                if not protein_distribution_available:\n",
    "                    print(f\"Warning: No distribution data available for {protein}\")\n",
    "                    continue\n",
    "                \n",
    "                # Get the pre-calculated data from the dictionary\n",
    "                protein_data = self.protein_sample_distribution[protein]\n",
    "                \n",
    "                # Get the appropriate values based on metric type\n",
    "                sample_values = protein_data['values']\n",
    "                sample_percentages = protein_data['relative']\n",
    "                total_value = protein_data['total']\n",
    "                unique_peptide_count = protein_data['unique_peptide_count']\n",
    "                \n",
    "                # Only proceed if we have a valid total\n",
    "                if total_value <= 0:\n",
    "                    continue\n",
    "                \n",
    "                # Debug output for key proteins\n",
    "                #if protein in ['Beta-casein', 'Alpha-S1-casein', 'Alpha-S2-casein']:\n",
    "                #    print(f\"Protein: {protein}\")\n",
    "                #    print(f\"Total {self.metric_name}: {total_value}\")\n",
    "                #    print(f\"Sample percentages: {sample_percentages}\")\n",
    "                \n",
    "                # For each sample, add a bar segment\n",
    "                for i, group in enumerate(selected_groups):\n",
    "                    # Skip if no contribution\n",
    "                    if group not in sample_values or sample_values[group] <= 0:\n",
    "                        continue\n",
    "                    \n",
    "                    abs_value = sample_values[group]  # Actual count/abundance in this sample\n",
    "                    rel_percentage = sample_percentages.get(group, 0)  # Sample's percentage contribution\n",
    "                    \n",
    "                    # Calculate y-value based on metric type\n",
    "                    if is_relative_metric: #Relative\n",
    "                        # For relative metrics: always plot relative percentages (0-100 scale)\n",
    "                        y_value = rel_percentage\n",
    "\n",
    "                    else: #Absolute\n",
    "                        # For absolute metrics: scale each segment to maintain the correct total height\n",
    "                        # This ensures segments add up to the total count/abundance\n",
    "                        if use_count:\n",
    "                            y_value = unique_peptide_count * (rel_percentage / 100)\n",
    "\n",
    "                        else:\n",
    "                            y_value = total_value * (rel_percentage / 100)\n",
    "\n",
    "                    # Format for hover\n",
    "                    if use_count:\n",
    "                        self.num_format = \",.0f\"  # Integer format for counts\n",
    "                        abs_count_label = \"Count\"\n",
    "                    else:\n",
    "                        self.num_format = \".2e\"   # Scientific notation for abundance\n",
    "                        abs_count_label = \"Abundance\"\n",
    "                    \n",
    "                    # Create hover text with correct information\n",
    "                    hover_text = (\n",
    "                        f\"Protein: {protein}<br>\" +\n",
    "                        f\"Sample: {group}<br>\" +\n",
    "                        f\"Sample's contribution to protein: {rel_percentage:.2f}%<br>\" +\n",
    "                        f\"{abs_count_label} in sample: {abs_value:{self.num_format}}<br>\" \n",
    "                        #f\"Total protein {abs_count_label}: {total_value:{self.num_format}}\"\n",
    "                    )\n",
    "                    \n",
    "                    # Add trace for this sample in this protein\n",
    "                    fig.add_trace(go.Bar(\n",
    "                        name=group,\n",
    "                        x=[protein],\n",
    "                        y=[y_value],\n",
    "                        marker_color=colors[i],\n",
    "                        hovertext=[hover_text],\n",
    "                        hoverinfo='text',\n",
    "                        showlegend=(protein == (self.pro_list[0] if self.pro_list else 'Minor Proteins'))\n",
    "                    ))\n",
    "\n",
    "            # Set Y-axis range to 0-100 for relative metrics\n",
    "            if is_relative_metric:\n",
    "                fig.update_layout(yaxis_range=[0, 100])\n",
    "        \n",
    "        # Get custom labels\n",
    "        x_label = self.xlabel_widget.value or ('Proteins' if self.invert_plot.value == 'By Protein' else 'Samples')\n",
    "        y_label = self.ylabel_widget.value or (f\"Relative {self.metric_name} within {'protein' if self.invert_plot.value == 'By Protein' else 'sample'} (%)\" if is_relative_metric else self.metric_name)\n",
    "        plot_title = title\n",
    "        legend_title = self.legend_widget.value or ('Samples' if self.invert_plot.value == 'By Protein' else 'Protein Origins')\n",
    "\n",
    "        fig.update_layout(\n",
    "            barmode='stack',\n",
    "            title={\n",
    "                'text': plot_title,\n",
    "                'y': 0.95,\n",
    "                'x': 0.5,\n",
    "                'xanchor': 'center',\n",
    "                'yanchor': 'top',\n",
    "                'font': {\"size\": 18, 'color': 'black'}\n",
    "            },\n",
    "            xaxis_title=x_label,\n",
    "            yaxis_title=y_label,\n",
    "            yaxis=dict(\n",
    "                showline=True,\n",
    "                gridcolor='lightgray',\n",
    "                showgrid=True,\n",
    "                showticklabels=True,\n",
    "                linewidth=1,\n",
    "                linecolor='black',\n",
    "                mirror=False,\n",
    "                zeroline=False,  # Don't show zero line\n",
    "                range=[0, 100] if is_relative_metric else None  # Set range to [0,100] for relative metrics\n",
    "            ),\n",
    "            xaxis=dict(\n",
    "                showline=True,\n",
    "                linewidth=1,\n",
    "                linecolor='black',\n",
    "                mirror=False,\n",
    "                tickangle=-90 if self.invert_plot.value == 'By Sample' else 45  # Adjust tick angle based on orientation\n",
    "            ),\n",
    "            legend_title=legend_title,\n",
    "            legend={\n",
    "                'yanchor': \"top\",\n",
    "                'y': 0.95,\n",
    "                'xanchor': \"left\",\n",
    "                'x': 1.05,\n",
    "                'traceorder': 'normal',\n",
    "                'font': {\"size\": 16, 'color': 'black'},\n",
    "                'bgcolor': 'rgba(255, 255, 255, 0.9)'\n",
    "            },\n",
    "            showlegend=True,\n",
    "            template='plotly_white',\n",
    "            height=820,\n",
    "            width=1200,\n",
    "            margin=dict(\n",
    "                t=100,\n",
    "                l=100,\n",
    "                r=100,\n",
    "                b=100\n",
    "            ),\n",
    "            hoverlabel=dict(\n",
    "                bgcolor=\"white\",\n",
    "                font_size=14,\n",
    "                font_family=\"Arial\"\n",
    "            ))\n",
    "        \n",
    "        fig.update_xaxes(\n",
    "            tickangle=45,\n",
    "            title_font={\"size\": 18},\n",
    "            tickfont={\"size\": 16},\n",
    "            tickfont_color=\"black\",  # Black tick labels\n",
    "            title_font_color=\"black\",  # Black axis title                \n",
    "        )\n",
    "        \n",
    "        # Update Y axis formatting based on metric\n",
    "        if is_relative_metric:\n",
    "            tick_format = \".1f\"  # Format as percentage with one decimal place for relative metrics\n",
    "            showticklabels_tf = True\n",
    "        else:\n",
    "            if use_count:\n",
    "                tick_format = \"\"  # Regular integers for counts\n",
    "            else:\n",
    "                tick_format = \".1e\"  # Scientific notation for abundance\n",
    "            showticklabels_tf = False\n",
    "        fig.update_yaxes(\n",
    "            title_font={\"size\": 18},\n",
    "            tickfont={\"size\": 16},\n",
    "            tickfont_color=\"black\",  # Black tick labels\n",
    "            title_font_color=\"black\",  # Black axis title\n",
    "            gridcolor=\"lightgray\",  # Light gray grid lines\n",
    "            showgrid=True,  # Show grid lines\n",
    "            zeroline=False,  # Hide zero line\n",
    "            exponentformat='E',\n",
    "            showexponent='all',\n",
    "            tickformat=tick_format,\n",
    "            showticklabels=showticklabels_tf\n",
    "        )\n",
    "        \n",
    "        # Always add scatter trace for totals, but calculate differently based on orientation\n",
    "        if not is_relative_metric:  # Only show totals for absolute metrics\n",
    "            if self.invert_plot.value == 'By Sample':\n",
    "                # Sample-wise totals calculation\n",
    "                # Format based on metric\n",
    "                if use_count:\n",
    "                    text_format = [f\"{int(total_sums[group])}\" for group in selected_groups]\n",
    "                else: #abundance\n",
    "                    text_format = [f\"{total_sums[group]:.2e}\" for group in selected_groups]\n",
    "                    \n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=selected_groups,\n",
    "                    y=[total_sums[group] for group in selected_groups],\n",
    "                    mode='text',\n",
    "                    text=text_format,\n",
    "                    textposition='top center',\n",
    "                    textfont=dict(size=12, color='black'),\n",
    "                    showlegend=True,\n",
    "                    name=f'Show Total {self.metric_name}',\n",
    "                    hoverinfo='none',\n",
    "                    texttemplate='%{text}'\n",
    "                ))\n",
    "            else: #By Protein\n",
    "                # Protein-wise totals\n",
    "                # Format for display based on metric\n",
    "                if use_count:\n",
    "                    text_format = [f\"{int(protein_totals.get(protein, 0))}\" for protein in self.pro_list + (['Minor Proteins'] if self.plot_minor_proteins.value else [])]\n",
    "                else: #abundance\n",
    "                    # For abundance, calculate the sum across all samples\n",
    "                    text_format = [f\"{protein_totals.get(protein, 0):.2e}\" for protein in self.pro_list + (['Minor Proteins'] if self.plot_minor_proteins.value else [])]\n",
    "                y_values = [protein_totals.get(protein, 0) for protein in self.pro_list + (['Minor Proteins'] if self.plot_minor_proteins.value else [])]\n",
    "                \n",
    "                # Add the protein totals trace\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=self.pro_list + (['Minor Proteins'] if self.plot_minor_proteins.value else []),\n",
    "                    y=y_values,\n",
    "                    mode='text',\n",
    "                    text=text_format,\n",
    "                    textposition='top center',\n",
    "                    textfont=dict(size=12, color='black'),\n",
    "                    showlegend=True,\n",
    "                    name=f'Show Total {self.metric_name}',\n",
    "                    hoverinfo='none',\n",
    "                    texttemplate='%{text}'\n",
    "                ))       \n",
    "                    \n",
    "        # Mark generation as complete\n",
    "        self.state_manager.generate_completed()\n",
    "        self.export_button.disabled = False\n",
    "        self.download_plot_button.disabled = False\n",
    "        \n",
    "        return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1775dd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09bf89af122440d999f0fd534273ef61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4>Upload Data File:</h4>'), HBox(children=(FileUpload(value=(), accept='.csv,.txt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951ccdcd4ae04ee0917de9749453aad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(margin='0 0 0 20px', width='300px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30eb68eb08b84f6792bc47f0acf72a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4>Plot Controls:</h4>'), SelectMultiple(description='Groups:', layout=Layout(heig…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize the interface\n",
    "data_transformer = DataTransformation()\n",
    "data_transformer.setup_data_loading_ui()\n",
    "\n",
    "# Create protein plotter\n",
    "protein_plotter = ProteinPlotter(data_transformer)\n",
    "\n",
    "protein_plotter.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (newenv)",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
