{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62bd34aa-691e-4d2e-ac73-b2668c0542ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json, io, base64, re, os\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Initialize settings\n",
    "import _settings as settings\n",
    "\n",
    "# Global variables from settings\n",
    "spec_translate_list = settings.SPEC_TRANSLATE_LIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cfaad00-f6e2-48b6-9b73-07bd9559fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self):\n",
    "        self.merged_df = None\n",
    "        self.group_data = None\n",
    "        self.proteins_dic = {}\n",
    "        self.output_area = None\n",
    "        self.merged_uploader = None\n",
    "        self.group_uploader = None\n",
    "        self.fasta_uploader = None\n",
    "        \n",
    "    def create_download_link(self, file_path, label):\n",
    "        \"\"\"Create a download link for a file.\"\"\"\n",
    "        if os.path.exists(file_path):\n",
    "            # Read file content and encode it as base64\n",
    "            with open(file_path, 'rb') as f:\n",
    "                content = f.read()\n",
    "            b64_content = base64.b64encode(content).decode('utf-8')\n",
    "\n",
    "            # Generate the download link HTML\n",
    "            return widgets.HTML(f\"\"\"\n",
    "                <a download=\"{os.path.basename(file_path)}\" \n",
    "                   href=\"data:application/octet-stream;base64,{b64_content}\" \n",
    "                   style=\"color: #0366d6; text-decoration: none; margin-left: 20px; font-size: 14px;\">\n",
    "                    {label}\n",
    "                </a>\n",
    "            \"\"\")\n",
    "        else:\n",
    "            # Show an error message if the file does not exist\n",
    "            return widgets.HTML(f\"\"\"\n",
    "                <span style=\"color: red; margin-left: 20px; font-size: 14px;\">\n",
    "                    File \"{file_path}\" not found!\n",
    "                </span>\n",
    "            \"\"\")\n",
    "\n",
    "    def setup_data_loading_ui(self):\n",
    "        \"\"\"Initialize and display the data loading UI.\"\"\"\n",
    "        # Create file upload widgets\n",
    "        self.merged_uploader = widgets.FileUpload(\n",
    "            accept='.csv,.txt,.tsv,.xlsx',\n",
    "            multiple=False,\n",
    "            description='Upload Merged Data File',\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "\n",
    "        self.group_uploader = widgets.FileUpload(\n",
    "            accept='.json',\n",
    "            multiple=False,\n",
    "            description='Upload Group Definition',\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "\n",
    "        self.fasta_uploader = widgets.FileUpload(\n",
    "            accept='.fasta',\n",
    "            multiple=True,\n",
    "            description='Upload FASTA Files',\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "\n",
    "        # Reset button\n",
    "        self.reset_button = widgets.Button(\n",
    "            description='Reset',\n",
    "            button_style='warning'\n",
    "        )\n",
    "\n",
    "        self.output_area = widgets.Output()\n",
    "\n",
    "        # Create individual upload boxes with example links\n",
    "        merged_box = widgets.HBox([\n",
    "            self.merged_uploader,\n",
    "            self.create_download_link(\"example_merged_dataframe.csv\", \"Example\")\n",
    "        ], layout=widgets.Layout(align_items='center'))\n",
    "\n",
    "        group_box = widgets.HBox([\n",
    "            self.group_uploader,\n",
    "            self.create_download_link(\"example_group_definition.json\", \"Example\")\n",
    "        ], layout=widgets.Layout(align_items='center'))\n",
    "\n",
    "        fasta_box = widgets.HBox([\n",
    "            self.fasta_uploader,\n",
    "            self.create_download_link(\"example_fasta.fasta\", \"Example\")\n",
    "        ], layout=widgets.Layout(align_items='center'))\n",
    "\n",
    "        # Create left column with upload widgets\n",
    "        upload_widgets = widgets.VBox([\n",
    "            widgets.HTML(\"<h3><u>Upload Data Files:</u></h3>\"),\n",
    "            merged_box,\n",
    "            widgets.HTML(\"<h3><u>Upload Group Definition:</u></h3>\"),\n",
    "            group_box,\n",
    "            widgets.HTML(\"<h3><u>Upload Protein FASTA Files:</u></h3>\"),\n",
    "            fasta_box,\n",
    "            self.output_area\n",
    "        ], layout=widgets.Layout(\n",
    "            width='400px',\n",
    "            margin='0 20px 0 0'\n",
    "        ))\n",
    "\n",
    "        # Create container for status display\n",
    "        self.status_area = widgets.Output(\n",
    "            layout=widgets.Layout(\n",
    "                width='400px',\n",
    "                margin='0 0 0 20px'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Create grid layout\n",
    "        grid = widgets.GridBox(\n",
    "            [upload_widgets, self.status_area],\n",
    "            layout=widgets.Layout(\n",
    "                grid_template_columns='auto auto',\n",
    "                grid_gap='20px',\n",
    "                width='900px'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Register observers\n",
    "        self.merged_uploader.observe(self._on_merged_upload_change, names='value')\n",
    "        self.group_uploader.observe(self._on_group_upload_change, names='value')\n",
    "        self.fasta_uploader.observe(self._on_fasta_upload_change, names='value')\n",
    "        self.reset_button.on_click(self._reset_ui)\n",
    "\n",
    "        # Display the grid\n",
    "        display(grid)\n",
    "        \n",
    "    def _reset_ui(self, b):\n",
    "        \"\"\"Reset the UI state\"\"\"\n",
    "        self.merged_uploader._counter = 0\n",
    "        self.group_uploader._counter = 0\n",
    "        self.fasta_uploader._counter = 0\n",
    "        self.merged_uploader.value = ()\n",
    "        self.group_uploader.value = ()\n",
    "        self.fasta_uploader.value = ()\n",
    "        self.merged_df = None\n",
    "        self.group_data = None\n",
    "        self.proteins_dic = {}\n",
    "        with self.output_area:\n",
    "            self.output_area.clear_output()\n",
    "            display(HTML('<b style=\"color:blue;\">All uploads cleared.</b>'))\n",
    "\n",
    "\n",
    "    def _on_group_upload_change(self, change):\n",
    "        \"\"\"Handle group definition JSON file upload\"\"\"\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            with self.output_area:\n",
    "                self.output_area.clear_output()\n",
    "                if change['new'] and len(change['new']) > 0:\n",
    "                    file_data = change['new'][0]\n",
    "                    try:\n",
    "                        # Convert bytes content to string\n",
    "                        content = file_data.content.tobytes().decode('utf-8')\n",
    "                        self.group_data = json.loads(content)\n",
    "                        \n",
    "                        # Validate the group data structure\n",
    "                        if not isinstance(self.group_data, dict):\n",
    "                            raise ValueError(\"Group definition must be a dictionary\")\n",
    "                        \n",
    "                        for group_key, group_info in self.group_data.items():\n",
    "                            required_keys = {'grouping_variable', 'abundance_columns'}\n",
    "                            if not required_keys.issubset(group_info.keys()):\n",
    "                                raise ValueError(f\"Group {group_key} missing required keys: {required_keys - group_info.keys()}\")\n",
    "                            if not isinstance(group_info['abundance_columns'], list):\n",
    "                                raise ValueError(f\"Group {group_key} abundance_columns must be a list\")\n",
    "                        \n",
    "                        # Create list of group variables\n",
    "                        group_vars = [group_info['grouping_variable'] for group_info in self.group_data.values()]\n",
    "                        \n",
    "                        display(HTML(\n",
    "                            f'<b style=\"color:green;\">Group definition file imported successfully with {len(self.group_data)} groups.</b><br>' + \n",
    "                            f'<b>Groups loaded: {\", \".join(group_vars)}</b>'\n",
    "                        ))\n",
    "                        \n",
    "                    except json.JSONDecodeError as e:\n",
    "                        display(HTML(f'<b style=\"color:red;\">Invalid JSON format: {str(e)}</b>'))\n",
    "                    except ValueError as e:\n",
    "                        display(HTML(f'<b style=\"color:red;\">Invalid group definition format: {str(e)}</b>'))\n",
    "                    except Exception as e:\n",
    "                        display(HTML(f'<b style=\"color:red;\">Error loading group definition file: {str(e)}</b>'))\n",
    "\n",
    "    def _on_fasta_upload_change(self, change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            with self.output_area:\n",
    "                self.output_area.clear_output()\n",
    "                if change['new'] and len(change['new']) > 0:\n",
    "                    for file_data in change['new']:\n",
    "                        try:\n",
    "                            file_name = getattr(file_data, 'name', None)\n",
    "                            if file_name and file_name.endswith('.fasta'):\n",
    "                                new_proteins = self._parse_uploaded_fasta(file_data)\n",
    "                                self.proteins_dic.update(new_proteins)\n",
    "                                display(HTML(f'<b style=\"color:green;\">Successfully imported FASTA file: {file_name} ({len(new_proteins)} proteins)</b>'))\n",
    "                            else:\n",
    "                                display(HTML(f'<b style=\"color:red;\">Invalid file format. Please upload FASTA files only.</b>'))\n",
    "                        except Exception as e:\n",
    "                            display(HTML(f'<b style=\"color:red;\">Error processing FASTA file: {str(e)}</b>'))\n",
    "    \n",
    "        \n",
    "    def _validate_and_clean_data(self, df):\n",
    "        \"\"\"\n",
    "        Validate and clean the uploaded data, dropping rows with blank values in key columns.\n",
    "        Returns tuple of (cleaned_df, warnings, errors)\n",
    "        \"\"\"\n",
    "        warnings = []\n",
    "        errors = []\n",
    "        \n",
    "        # Check required columns exist\n",
    "        required_columns = ['Master Protein Accessions', 'Positions in Proteins']\n",
    "        missing = set(required_columns) - set(df.columns)\n",
    "        if missing:\n",
    "            errors.append(f\"Missing required columns: {', '.join(missing)}\")\n",
    "            return None, warnings, errors\n",
    "    \n",
    "        cleaned_df = df.copy()\n",
    "        \n",
    "        # Handle blank values by dropping rows and issuing warnings\n",
    "        for column in required_columns:\n",
    "            blank_count = cleaned_df[column].isna().sum()\n",
    "            if blank_count > 0:\n",
    "                warnings.append(f\"Dropping {blank_count} rows with blank values in {column} column\")\n",
    "                cleaned_df = cleaned_df.dropna(subset=[column])\n",
    "        \n",
    "        # Check for invalid characters in non-blank rows\n",
    "        if len(cleaned_df) > 0:\n",
    "            # Check Positions in Proteins\n",
    "            invalid_pos = cleaned_df['Positions in Proteins'].apply(\n",
    "                lambda x: ',' in str(x) or ':' in str(x)\n",
    "            )\n",
    "            if invalid_pos.any():\n",
    "                errors.append(\n",
    "                    \"Found invalid characters (',' or ':') in Positions in Proteins column. \"\n",
    "                    \"Please update the file and upload again.\"\n",
    "                )\n",
    "            \n",
    "            # Check Master Protein Accessions\n",
    "            invalid_acc = cleaned_df['Master Protein Accessions'].apply(\n",
    "                lambda x: ',' in str(x) or ':' in str(x)\n",
    "            )\n",
    "            if invalid_acc.any():\n",
    "                errors.append(\n",
    "                    \"Found invalid characters (',' or ':') in Master Protein Accessions column. \"\n",
    "                    \"Please update the file and upload again.\"\n",
    "                )\n",
    "        \n",
    "        return cleaned_df, warnings, errors\n",
    "    \n",
    "    def _load_merged_data(self, file_data):\n",
    "        \"\"\"\n",
    "        Load and validate merged data file\n",
    "        Returns tuple of (dataframe, status)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            content = bytes(file_data.content)\n",
    "            filename = file_data.name\n",
    "            extension = filename.split('.')[-1].lower()\n",
    "            \n",
    "            file_stream = io.BytesIO(content)\n",
    "            \n",
    "            # Load data based on file extension\n",
    "            try:\n",
    "                if extension == 'csv':\n",
    "                    df = pd.read_csv(file_stream)\n",
    "                elif extension in ['txt', 'tsv']:\n",
    "                    df = pd.read_csv(file_stream, delimiter='\\t')\n",
    "                elif extension == 'xlsx':\n",
    "                    df = pd.read_excel(file_stream)\n",
    "                else:\n",
    "                    display(HTML(f'<b style=\"color:red;\">Error: Unsupported file format</b>'))\n",
    "                    return None, 'no'\n",
    "            except Exception as e:\n",
    "                display(HTML(f'<b style=\"color:red;\">Error reading file: {str(e)}</b>'))\n",
    "                return None, 'no'\n",
    "                \n",
    "            # Validate and clean data\n",
    "            cleaned_df, warnings, errors = self._validate_and_clean_data(df)\n",
    "            \n",
    "            # Display warnings about dropped rows\n",
    "            if warnings:\n",
    "                warning_html = \"<br>\".join([\n",
    "                    f'<b style=\"color:orange;\">Warning: {w}</b>' \n",
    "                    for w in warnings\n",
    "                ])\n",
    "                display(HTML(warning_html))\n",
    "            \n",
    "            # Display errors if any\n",
    "            if errors:\n",
    "                error_html = \"<br>\".join([\n",
    "                    f'<b style=\"color:red;\">Error: {e}</b>' \n",
    "                    for e in errors\n",
    "                ])\n",
    "                display(HTML(error_html))\n",
    "                return None, 'no'\n",
    "            \n",
    "            if cleaned_df is not None and len(cleaned_df) > 0:\n",
    "                # Add information about remaining rows\n",
    "                display(HTML(\n",
    "                    f'<b style=\"color:green;\">Processed data contains {len(cleaned_df)} rows '\n",
    "                    f'after removing blank values.</b>'\n",
    "                ))\n",
    "                return cleaned_df, 'yes'\n",
    "            else:\n",
    "                display(HTML('<b style=\"color:red;\">Error: No valid data rows remaining after cleaning</b>'))\n",
    "                return None, 'no'\n",
    "                \n",
    "        except Exception as e:\n",
    "            display(HTML(f'<b style=\"color:red;\">Error processing file: {str(e)}</b>'))\n",
    "            return None, 'no'\n",
    "    \n",
    "    def _on_merged_upload_change(self, change):\n",
    "        \"\"\"Handle merged data file upload\"\"\"\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            with self.output_area:\n",
    "                self.output_area.clear_output()\n",
    "                if change['new'] and len(change['new']) > 0:\n",
    "                    file_data = change['new'][0]\n",
    "                    df, status = self._load_merged_data(file_data)\n",
    "                    if status == 'yes' and df is not None:\n",
    "                        self.merged_df = df  # Only set merged_df if validation passed\n",
    "                        display(HTML(\n",
    "                            f'<b style=\"color:green;\">Merged data imported successfully with '\n",
    "                            f'{df.shape[0]} rows and {df.shape[1]} columns.</b>'\n",
    "                        ))\n",
    "\n",
    "    def _find_species(self, header):\n",
    "        \"\"\"Find species in FASTA header\"\"\"\n",
    "        header_lower = header.lower()\n",
    "        for spec_group in spec_translate_list:\n",
    "            for term in spec_group[1:]:\n",
    "                if term.lower() in header_lower:\n",
    "                    return spec_group[0]\n",
    "        return \"unknown\"\n",
    "\n",
    "    def _parse_uploaded_fasta(self, file_data):\n",
    "        \"\"\"Parse uploaded FASTA file content\"\"\"\n",
    "        fasta_dict = {}\n",
    "        fasta_text = bytes(file_data.content).decode('utf-8')\n",
    "        lines = fasta_text.split('\\n')\n",
    "        \n",
    "        protein_id = \"\"\n",
    "        protein_name = \"\"\n",
    "        sequence = \"\"\n",
    "        species = \"\"\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                if protein_id:\n",
    "                    fasta_dict[protein_id] = {\n",
    "                        \"name\": protein_name,\n",
    "                        \"sequence\": sequence,\n",
    "                        \"species\": species\n",
    "                    }\n",
    "                sequence = \"\"\n",
    "                header_parts = line[1:].split('|')\n",
    "                if len(header_parts) > 2:\n",
    "                    protein_id = header_parts[1]\n",
    "                    protein_name_full = re.split(r' OS=', header_parts[2])[0]\n",
    "                    protein_name = protein_name_full if ' ' in protein_name_full else protein_name_full\n",
    "                    species = self._find_species(line)\n",
    "            else:\n",
    "                sequence += line\n",
    "                \n",
    "        if protein_id:\n",
    "            fasta_dict[protein_id] = {\n",
    "                \"name\": protein_name,\n",
    "                \"sequence\": sequence,\n",
    "                \"species\": species\n",
    "            }\n",
    "        \n",
    "        return fasta_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "377e1235-d0b5-473e-8457-e044f855a37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e50a6f4ee2849d3bcb70f913849b962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(VBox(children=(HTML(value='<h3><u>Upload Data Files:</u></h3>'), HBox(children=(FileUpload(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79ca160bf304fcba7b6df7c95c53680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Protein Absorbance Analysis</h3>'), IntSlider(value=10, description='Top Number…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ProteinPlotter:\n",
    "    def __init__(self, data_transformer):\n",
    "        self.data_transformer = data_transformer\n",
    "        self.plot_output = widgets.Output()\n",
    "        self.info_output = widgets.Output()\n",
    "        self.export_output = widgets.Output()\n",
    "        self.proteins_df = None\n",
    "        self.sum_df = None\n",
    "        \n",
    "        # Create widgets for protein plotting\n",
    "        self.num_proteins_widget = widgets.IntSlider(\n",
    "            value=10,\n",
    "            min=1,\n",
    "            max=50,\n",
    "            step=1,\n",
    "            description='Top Number of Proteins:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "        \n",
    "        # Create multi-select widget for groups\n",
    "        self.group_select = widgets.SelectMultiple(\n",
    "            options=[],\n",
    "            description='Select Groups:',\n",
    "            style={'description_width': 'initial'},\n",
    "\n",
    "            layout=widgets.Layout(width='400px', height='100px')\n",
    "        )\n",
    "        \n",
    "        self.plot_button = widgets.Button(\n",
    "            description='Generate Plot',\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "        \n",
    "        self.export_button = widgets.Button(\n",
    "            description='Export Data',\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "        # Add label customization widgets\n",
    "        self.xlabel_widget = widgets.Text(\n",
    "            description='X Label:',\n",
    "            placeholder='Enter x-axis label',\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "        \n",
    "        self.ylabel_widget = widgets.Text(\n",
    "            description='Y Label:',\n",
    "            placeholder='Enter y-axis label',\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "\n",
    "        self.color_scheme = widgets.Dropdown(\n",
    "            options=[\n",
    "                # Sequential\n",
    "                ('Viridis', 'Viridis'),\n",
    "                ('Cividis', 'Cividis'),\n",
    "                ('Inferno', 'Inferno'),\n",
    "                ('Magma', 'Magma'),\n",
    "                ('Plasma', 'Plasma'),\n",
    "                ('Warm', 'Warm'),\n",
    "                ('Cool', 'Cool'),\n",
    "                ('Hot', 'Hot'),\n",
    "                ('Jet', 'Jet'),\n",
    "                # Sequential (Blues)\n",
    "                ('Blues', 'Blues'),\n",
    "                ('Bluered', 'Bluered'),\n",
    "                ('Blugrn', 'Blugrn'),\n",
    "                # Sequential (Greens)\n",
    "                ('Greens', 'Greens'),\n",
    "                ('Gnbu', 'GnBu'),\n",
    "                # Sequential (Purples)\n",
    "                ('Purples', 'Purples'),\n",
    "                ('Pubu', 'PuBu'),\n",
    "                ('Purd', 'PuRd'),\n",
    "                ('Purp', 'Purp'),\n",
    "                # Sequential (Oranges/Reds)\n",
    "                ('Oranges', 'Oranges'),\n",
    "                ('Reds', 'Reds'),\n",
    "                ('Orrd', 'OrRd'),\n",
    "                # Diverging\n",
    "                ('Spectral', 'Spectral'),\n",
    "                ('RdBu', 'RdBu'),\n",
    "                ('RdYlBu', 'RdYlBu'),\n",
    "                ('RdYlGn', 'RdYlGn'),\n",
    "                ('PiYG', 'PiYG'),\n",
    "                ('PRGn', 'PRGn'),\n",
    "                ('BrBG', 'BrBG'),\n",
    "                ('RdGy', 'RdGy'),\n",
    "                # Cyclical\n",
    "                ('Rainbow', 'Rainbow'),\n",
    "                ('IceFire', 'IceFire'),\n",
    "                ('Edge', 'Edge'),\n",
    "                ('HSV', 'HSV'),\n",
    "                ('Twilight', 'Twilight'),\n",
    "                ('Mrybm', 'Mrybm'),\n",
    "                ('Mygbm', 'Mygbm'),\n",
    "            ],\n",
    "            value='HSV',\n",
    "            description='Color Scheme:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "\n",
    "        # Create layout\n",
    "        self.widget_box = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>Protein Absorbance Analysis</h3>\"),\n",
    "            self.num_proteins_widget,\n",
    "            self.group_select,\n",
    "            self.xlabel_widget,\n",
    "            self.ylabel_widget,\n",
    "            self.color_scheme,\n",
    "            widgets.HBox([self.plot_button, self.export_button]),\n",
    "            self.info_output,\n",
    "            self.plot_output,\n",
    "            self.export_output\n",
    "        ])\n",
    "\n",
    "        # Add button click handlers\n",
    "        self.plot_button.on_click(self._on_plot_button_click)\n",
    "        self.export_button.on_click(self._on_export_button_click)\n",
    "\n",
    "        # Add observer for data changes\n",
    "        self.data_transformer.group_uploader.observe(self._update_group_options, names='value')\n",
    "\n",
    "    def process_data(self, selected_groups=None):\n",
    "        \"\"\"Process data with optional group selection\"\"\"\n",
    "        if not all([self.data_transformer.merged_df is not None,\n",
    "                   self.data_transformer.group_data != {},\n",
    "                   self.data_transformer.proteins_dic is not None]):\n",
    "            return False\n",
    "\n",
    "        df = self.data_transformer.merged_df.copy()\n",
    "        \n",
    "        # Get Absorbance columns based on selected groups\n",
    "        if selected_groups:\n",
    "            Absorbance_cols = [f'Avg_{var}' for var in selected_groups]\n",
    "        else:\n",
    "            Absorbance_cols = [col for col in df.columns if 'Avg_' in col]\n",
    "            \n",
    "        df['Total_Absorbance'] = df[Absorbance_cols].sum(axis=1).astype(int)\n",
    "        \n",
    "        # Filter out zero Absorbance entries\n",
    "        result_df = df[['unique ID', 'Total_Absorbance']]\n",
    "        result_df = result_df[result_df['Total_Absorbance'] == 0]\n",
    "        all_zero_list = list(result_df['unique ID'])\n",
    "        peptides_df = df[~df['unique ID'].isin(all_zero_list)]\n",
    "\n",
    "        # Process protein positions and create proteins DataFrame\n",
    "        additional_columns = ['Master Protein Accessions', 'Positions in Proteins', 'unique ID']\n",
    "        selected_columns = additional_columns + Absorbance_cols\n",
    "        \n",
    "        peptides_df.loc[:, 'Positions in Proteins'] = peptides_df['Positions in Proteins'].apply(\n",
    "            lambda x: re.sub(r'\\[\\d+-\\d+\\]', '', x).replace(';', ',').strip(',').strip()\n",
    "        )\n",
    "        \n",
    "        temp_df = peptides_df.copy()\n",
    "        temp_df.loc[:, 'Protein_ID'] = temp_df['Positions in Proteins']\n",
    "        \n",
    "        # Create proteins DataFrame with selected columns\n",
    "        self.proteins_df = temp_df.groupby('Protein_ID').agg(\n",
    "            {**{col: 'first' for col in ['Master Protein Accessions']},\n",
    "             **{col: 'sum' for col in Absorbance_cols}}\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Calculate relative Absorbance for selected groups\n",
    "        for col in Absorbance_cols:\n",
    "            col_sum = self.proteins_df[col].sum()\n",
    "            if col_sum > 0:  # Avoid division by zero\n",
    "                self.proteins_df[f'Rel_{col}'] = (self.proteins_df[col] / col_sum) * 100\n",
    "            else:\n",
    "                self.proteins_df[f'Rel_{col}'] = 0\n",
    "            \n",
    "        # Create sum DataFrame for selected groups\n",
    "        self.sum_df = pd.DataFrame({\n",
    "            'Sample': Absorbance_cols,\n",
    "            'Total_Sum': [self.proteins_df[col].sum() for col in Absorbance_cols]\n",
    "        })\n",
    "        \n",
    "        # Add protein descriptions\n",
    "        name_list = []\n",
    "        for _, row in self.proteins_df.iterrows():\n",
    "            if ',' in row['Protein_ID']:\n",
    "                strrow = row['Protein_ID'].split(',')\n",
    "                named_combo = self._fetch_protein_names('; '.join(strrow))\n",
    "            else:\n",
    "                named_combo = self._fetch_protein_names(row['Protein_ID'])\n",
    "            name_list.append(named_combo)\n",
    "        \n",
    "        # Drop the 'Protein_ID' column\n",
    "        self.proteins_df = self.proteins_df.drop(columns=['Protein_ID'])    \n",
    "        \n",
    "        self.proteins_df['Description'] = name_list\n",
    "        self.proteins_df['Description'] = self.proteins_df['Description'].astype(str).str.replace(r\"['\\['\\]]\", \"\", regex=True)\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def _fetch_protein_names(self, accession_str):\n",
    "        names = []\n",
    "        for acc in accession_str.split('; '):\n",
    "            if acc in self.data_transformer.proteins_dic:\n",
    "                name = self.data_transformer.proteins_dic[acc]['name'].split()[1]\n",
    "                names.append(name)\n",
    "            else:\n",
    "                names.append(acc)\n",
    "        return names\n",
    "\n",
    "    def _update_group_options(self, change):\n",
    "        \"\"\"Update group selection options when data changes\"\"\"\n",
    "        if self.data_transformer.group_data is not None:\n",
    "            grouping_vars = [group_info['grouping_variable'] \n",
    "                           for group_info in self.data_transformer.group_data.values()]\n",
    "            self.group_select.options = grouping_vars\n",
    "            # Select all groups by default\n",
    "            self.group_select.value = grouping_vars\n",
    "         \n",
    "    def plot_stacked_bar_scaled(self, pro_list, title, selected_groups):\n",
    "            if self.proteins_df is None or self.sum_df is None:\n",
    "                return None\n",
    "                \n",
    "            scaled_df = self.proteins_df.copy()\n",
    "            \n",
    "            # Filter for selected groups\n",
    "            sample_orders = [f'Rel_Avg_{var}' for var in selected_groups]\n",
    "            \n",
    "            # Create sample mapping for selected groups\n",
    "            sample_mapping = {\n",
    "                f'Rel_Avg_{var}': f'Avg_{var}' for var in selected_groups\n",
    "            }\n",
    "            \n",
    "            # Convert relative absorbance columns to percentages\n",
    "            for col in sample_orders:\n",
    "                scaled_df[col] = self.proteins_df[col] * 100\n",
    "                \n",
    "            # Scale absolute Absorbance\n",
    "            for col in sample_orders:\n",
    "                sample_key = sample_mapping[col]\n",
    "                total_sum = self.sum_df.loc[self.sum_df['Sample'] == sample_key, 'Total_Sum'].values[0]\n",
    "                if total_sum > 0:\n",
    "                    scaled_df[col] = self.proteins_df[col] * total_sum / self.proteins_df[col].sum()\n",
    "            \n",
    "            # Sort proteins_df based on pro_list\n",
    "            description_order = {desc: i for i, desc in enumerate(pro_list)}\n",
    "            scaled_df['Order'] = scaled_df['Description'].map(description_order)\n",
    "            scaled_df = scaled_df.sort_values(by='Order').reset_index(drop=True)\n",
    "            \n",
    "            fig = go.Figure()\n",
    "                \n",
    "            def get_color_sequence(scheme, n_colors):\n",
    "                \"\"\"Get color sequence based on selected scheme.\"\"\"\n",
    "                try:\n",
    "                    # Get the color sequence from plotly's built-in sequences\n",
    "                    if scheme.lower() in ['rainbow', 'hsv']:\n",
    "                        return [f'hsl({h},70%,60%)' for h in np.linspace(0, 330, n_colors)]\n",
    "                    \n",
    "                    # Get the corresponding plotly color sequence\n",
    "                    color_sequence = getattr(px.colors.sequential, scheme, None)\n",
    "                    if color_sequence is None:\n",
    "                        color_sequence = getattr(px.colors.diverging, scheme, None)\n",
    "                    if color_sequence is None:\n",
    "                        color_sequence = getattr(px.colors.cyclical, scheme, None)\n",
    "                    \n",
    "                    if color_sequence:\n",
    "                        # Ensure we get the right number of colors\n",
    "                        if n_colors >= len(color_sequence):\n",
    "                            # If we need more colors than available, interpolate\n",
    "                            indices = np.linspace(0, len(color_sequence)-1, n_colors)\n",
    "                            return [color_sequence[int(i)] for i in indices]\n",
    "                        else:\n",
    "                            # If we need fewer colors, take evenly spaced samples\n",
    "                            indices = np.linspace(0, len(color_sequence)-1, n_colors, dtype=int)\n",
    "                            return [color_sequence[i] for i in indices]\n",
    "                    \n",
    "                    # Fallback to rainbow if scheme not found\n",
    "                    return [f'hsl({h},70%,60%)' for h in np.linspace(0, 330, n_colors)]\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating colors: {e}\")\n",
    "                    # Fallback to basic rainbow\n",
    "                    return [f'hsl({h},70%,60%)' for h in np.linspace(0, 330, n_colors)]\n",
    "    \n",
    "            # Get colors based on selected scheme\n",
    "            colors = get_color_sequence(self.color_scheme.value, len(pro_list))\n",
    "            \n",
    "            for idx, row in scaled_df.iterrows():\n",
    "                protein_description = row['Description']\n",
    "                if protein_description in pro_list:\n",
    "                    color = colors[pro_list.index(protein_description)]\n",
    "                    \n",
    "                    hover_text = []\n",
    "                    for sample in sample_orders:\n",
    "                        abs_col = sample_mapping[sample]\n",
    "                        rel_value = self.proteins_df.loc[idx, sample]\n",
    "                        rel_value_hov = self.proteins_df.loc[self.proteins_df['Description'] == protein_description, sample].values[0]\n",
    "                        abs_value = row[abs_col]\n",
    "                        hover_text.append(\n",
    "                            f\"Protein: {row['Master Protein Accessions']}<br>\" +\n",
    "                            f\"Description: {row['Description']}<br>\" +\n",
    "                            f\"Sample: {sample.replace('Rel_Avg_', '')}<br>\" +\n",
    "                            f\"Relative Absorbance: {rel_value_hov:.2f}%<br>\" +\n",
    "                            f\"Absolute Absorbance: {abs_value:.2e}\"\n",
    "                        )\n",
    "                    \n",
    "                    fig.add_trace(go.Bar(\n",
    "                        name=protein_description,\n",
    "                        x=[label.replace('Rel_Avg_', '') for label in sample_orders],\n",
    "                        y=row[sample_orders],\n",
    "                        marker_color=color,\n",
    "                        hovertext=hover_text,\n",
    "                        hoverinfo='text'\n",
    "                    ))\n",
    "    \n",
    "            # Get custom labels\n",
    "            x_label = self.xlabel_widget.value or 'Sample Type'\n",
    "            y_label = self.ylabel_widget.value or 'Scaled Absolute Absorbance'\n",
    "            \n",
    "            fig.update_layout(\n",
    "                barmode='stack',\n",
    "                title={\n",
    "                    'text': title,\n",
    "                    'y': 0.95,\n",
    "                    'x': 0.5,\n",
    "                    'xanchor': 'center',\n",
    "                    'yanchor': 'top'\n",
    "                },\n",
    "                xaxis_title=x_label,\n",
    "                yaxis_title=y_label,\n",
    "                legend_title=\"Protein\",\n",
    "                legend={'yanchor': \"top\", 'y': 1, 'xanchor': \"left\", 'x': 1.05},\n",
    "                showlegend=True,\n",
    "                template='plotly_white',\n",
    "                height=600,\n",
    "                width=1000,\n",
    "                margin=dict(t=100, l=100, r=200),\n",
    "                hoverlabel=dict(\n",
    "                    bgcolor=\"white\",\n",
    "                    font_size=12,\n",
    "                    font_family=\"Arial\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            fig.update_xaxes(\n",
    "                tickangle=45,\n",
    "                title_font={\"size\": 14},\n",
    "                tickfont={\"size\": 12}\n",
    "            )\n",
    "            \n",
    "            fig.update_yaxes(\n",
    "                title_font={\"size\": 14},\n",
    "                tickfont={\"size\": 12},\n",
    "                exponentformat='E',\n",
    "                showexponent='all'\n",
    "            )\n",
    "            \n",
    "            return fig\n",
    "\n",
    "\n",
    "    def _on_plot_button_click(self, b):\n",
    "        with self.plot_output:\n",
    "            self.plot_output.clear_output(wait=True)\n",
    "            \n",
    "            if not self.group_select.value:\n",
    "                print(\"Please select at least one group to plot.\")\n",
    "                return\n",
    "            \n",
    "            selected_groups = list(self.group_select.value)\n",
    "            if self.process_data(selected_groups):\n",
    "                # Calculate average Absorbance for sorting using only selected groups\n",
    "                selected_rel_columns = [f'Rel_Avg_{var}' for var in selected_groups]\n",
    "                self.proteins_df['avg_absorbance_all'] = self.proteins_df[selected_rel_columns].mean(axis=1)\n",
    "                \n",
    "                # Sort and get top N proteins\n",
    "                sorted_proteins = self.proteins_df.sort_values('avg_absorbance_all', ascending=False)\n",
    "                pro_list = list(sorted_proteins['Description'].head(self.num_proteins_widget.value))\n",
    "                \n",
    "                # Create and display plot\n",
    "                fig = self.plot_stacked_bar_scaled(\n",
    "                    pro_list=pro_list,\n",
    "                    title=f'',#Top {self.num_proteins_widget.value} Proteins - Relative Absorbance',\n",
    "                    selected_groups=selected_groups\n",
    "                )\n",
    "                if fig is not None:\n",
    "                    fig.show()\n",
    "            else:\n",
    "                print(\"Please upload all required files first.\")\n",
    "                print(\"Error creating plot. Please check your data.\")\n",
    "\n",
    "    def _on_export_button_click(self, b):\n",
    "        with self.export_output:\n",
    "            self.export_output.clear_output(wait=True)\n",
    "            \n",
    "            if self.proteins_df is not None:\n",
    "                # Export to CSV\n",
    "                csv_data = self.proteins_df.to_csv(index=False).encode('utf-8')\n",
    "                b64 = base64.b64encode(csv_data).decode()\n",
    "                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "                filename = f'protein_Absorbance_analysis_{timestamp}.csv'\n",
    "                \n",
    "                # Create download link\n",
    "                html_str = f'''\n",
    "                    <a download=\"{filename}\" \n",
    "                       href=\"data:text/csv;base64,{b64}\" \n",
    "                       class=\"download-link\" \n",
    "                       style=\"background-color: #4CAF50;\n",
    "                              border: none;\n",
    "                              color: white;\n",
    "                              padding: 10px 20px;\n",
    "                              text-align: center;\n",
    "                              text-decoration: none;\n",
    "                              display: inline-block;\n",
    "                              font-size: 14px;\n",
    "                              margin: 4px 2px;\n",
    "                              cursor: pointer;\n",
    "                              border-radius: 4px;\">\n",
    "                        Download {filename}\n",
    "                    </a>\n",
    "                '''\n",
    "                display(HTML(html_str))\n",
    "            else:\n",
    "                print(\"Please generate the analysis first.\")\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Display the protein analysis interface\"\"\"\n",
    "        display(self.widget_box)\n",
    "\n",
    "\n",
    "# Initialize the interface\n",
    "data_transformer = DataTransformation()\n",
    "data_transformer.setup_data_loading_ui()\n",
    "\n",
    "# Create protein plotter\n",
    "protein_plotter = ProteinPlotter(data_transformer)\n",
    "protein_plotter.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "259a9095-a5f9-48a6-b51e-f3c49e277024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = protein_plotter.proteins_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50c82415-e65e-4386-9f1b-9a404b2af28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Master Protein Accessions</th>\n",
       "      <th>Avg_Acid_Low_DH</th>\n",
       "      <th>Avg_Sweet_Low_DH1</th>\n",
       "      <th>Avg_Sweet_Low_DH2</th>\n",
       "      <th>Avg_Acid_Mid_DH</th>\n",
       "      <th>Avg_Sweet_Mid_DH</th>\n",
       "      <th>Avg_Sweet_High_DH1</th>\n",
       "      <th>Avg_Sweet_High_DH2</th>\n",
       "      <th>Rel_Avg_Acid_Low_DH</th>\n",
       "      <th>Rel_Avg_Sweet_Low_DH1</th>\n",
       "      <th>Rel_Avg_Sweet_Low_DH2</th>\n",
       "      <th>Rel_Avg_Acid_Mid_DH</th>\n",
       "      <th>Rel_Avg_Sweet_Mid_DH</th>\n",
       "      <th>Rel_Avg_Sweet_High_DH1</th>\n",
       "      <th>Rel_Avg_Sweet_High_DH2</th>\n",
       "      <th>Description</th>\n",
       "      <th>avg_absorbance_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P00711</td>\n",
       "      <td>1.916545e+10</td>\n",
       "      <td>2.757990e+10</td>\n",
       "      <td>1.524829e+10</td>\n",
       "      <td>1.305600e+10</td>\n",
       "      <td>7.224882e+09</td>\n",
       "      <td>4.097130e+09</td>\n",
       "      <td>2.626658e+09</td>\n",
       "      <td>8.710411</td>\n",
       "      <td>6.810010</td>\n",
       "      <td>6.557491</td>\n",
       "      <td>5.061462</td>\n",
       "      <td>6.077251</td>\n",
       "      <td>13.023648</td>\n",
       "      <td>12.397124</td>\n",
       "      <td>Alpha-lactalbumin</td>\n",
       "      <td>8.376771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P00711</td>\n",
       "      <td>3.083917e+09</td>\n",
       "      <td>5.912715e+09</td>\n",
       "      <td>1.043788e+09</td>\n",
       "      <td>6.371839e+08</td>\n",
       "      <td>6.875720e+07</td>\n",
       "      <td>1.226151e+08</td>\n",
       "      <td>1.018042e+08</td>\n",
       "      <td>1.401594</td>\n",
       "      <td>1.459964</td>\n",
       "      <td>0.448878</td>\n",
       "      <td>0.247019</td>\n",
       "      <td>0.057836</td>\n",
       "      <td>0.389760</td>\n",
       "      <td>0.480489</td>\n",
       "      <td>Alpha-lactalbumin</td>\n",
       "      <td>0.640791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Master Protein Accessions  Avg_Acid_Low_DH  Avg_Sweet_Low_DH1  \\\n",
       "13                    P00711     1.916545e+10       2.757990e+10   \n",
       "14                    P00711     3.083917e+09       5.912715e+09   \n",
       "\n",
       "    Avg_Sweet_Low_DH2  Avg_Acid_Mid_DH  Avg_Sweet_Mid_DH  Avg_Sweet_High_DH1  \\\n",
       "13       1.524829e+10     1.305600e+10      7.224882e+09        4.097130e+09   \n",
       "14       1.043788e+09     6.371839e+08      6.875720e+07        1.226151e+08   \n",
       "\n",
       "    Avg_Sweet_High_DH2  Rel_Avg_Acid_Low_DH  Rel_Avg_Sweet_Low_DH1  \\\n",
       "13        2.626658e+09             8.710411               6.810010   \n",
       "14        1.018042e+08             1.401594               1.459964   \n",
       "\n",
       "    Rel_Avg_Sweet_Low_DH2  Rel_Avg_Acid_Mid_DH  Rel_Avg_Sweet_Mid_DH  \\\n",
       "13               6.557491             5.061462              6.077251   \n",
       "14               0.448878             0.247019              0.057836   \n",
       "\n",
       "    Rel_Avg_Sweet_High_DH1  Rel_Avg_Sweet_High_DH2        Description  \\\n",
       "13               13.023648               12.397124  Alpha-lactalbumin   \n",
       "14                0.389760                0.480489  Alpha-lactalbumin   \n",
       "\n",
       "    avg_absorbance_all  \n",
       "13            8.376771  \n",
       "14            0.640791  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Description'] ==  'Alpha-lactalbumin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7079941a-123a-48e3-a0ad-ccce6ef780bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types for Alpha-lactalbumin rows:\n",
      "=====================================\n",
      "Master Protein Accessions: object\n",
      "Avg_Acid_Low_DH: float64\n",
      "Avg_Sweet_Low_DH1: float64\n",
      "Avg_Sweet_Low_DH2: float64\n",
      "Avg_Acid_Mid_DH: float64\n",
      "Avg_Sweet_Mid_DH: float64\n",
      "Avg_Sweet_High_DH1: float64\n",
      "Avg_Sweet_High_DH2: float64\n",
      "Rel_Avg_Acid_Low_DH: float64\n",
      "Rel_Avg_Sweet_Low_DH1: float64\n",
      "Rel_Avg_Sweet_Low_DH2: float64\n",
      "Rel_Avg_Acid_Mid_DH: float64\n",
      "Rel_Avg_Sweet_Mid_DH: float64\n",
      "Rel_Avg_Sweet_High_DH1: float64\n",
      "Rel_Avg_Sweet_High_DH2: float64\n",
      "Description: object\n",
      "avg_absorbance_all: float64\n",
      "\n",
      "Sample values from first row:\n",
      "=============================\n",
      "Master Protein Accessions: P00711 (type: str)\n",
      "Avg_Acid_Low_DH: 19165450188.351444 (type: float64)\n",
      "Avg_Sweet_Low_DH1: 27579897816.42547 (type: float64)\n",
      "Avg_Sweet_Low_DH2: 15248293760.257385 (type: float64)\n",
      "Avg_Acid_Mid_DH: 13056001540.235628 (type: float64)\n",
      "Avg_Sweet_Mid_DH: 7224882374.315495 (type: float64)\n",
      "Avg_Sweet_High_DH1: 4097130192.282995 (type: float64)\n",
      "Avg_Sweet_High_DH2: 2626657854.991533 (type: float64)\n",
      "Rel_Avg_Acid_Low_DH: 8.71041098439508 (type: float64)\n",
      "Rel_Avg_Sweet_Low_DH1: 6.810010266521081 (type: float64)\n",
      "Rel_Avg_Sweet_Low_DH2: 6.55749084153833 (type: float64)\n",
      "Rel_Avg_Acid_Mid_DH: 5.061461830154075 (type: float64)\n",
      "Rel_Avg_Sweet_Mid_DH: 6.077251326217876 (type: float64)\n",
      "Rel_Avg_Sweet_High_DH1: 13.023647800223886 (type: float64)\n",
      "Rel_Avg_Sweet_High_DH2: 12.397123985927951 (type: float64)\n",
      "Description: Alpha-lactalbumin (type: str)\n",
      "avg_absorbance_all: 8.376771004996897 (type: float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print data types for all columns\n",
    "alpha_df = df[df['Description'] == 'Alpha-lactalbumin']\n",
    "print(\"Data types for Alpha-lactalbumin rows:\")\n",
    "print(\"=====================================\")\n",
    "for column, dtype in alpha_df.dtypes.items():\n",
    "    print(f\"{column}: {dtype}\")\n",
    "\n",
    "# Print some example values to verify\n",
    "print(\"\\nSample values from first row:\")\n",
    "print(\"=============================\")\n",
    "first_row = alpha_df.iloc[0]\n",
    "for column, value in first_row.items():\n",
    "    print(f\"{column}: {value} (type: {type(value).__name__})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
