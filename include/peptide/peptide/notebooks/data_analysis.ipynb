{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62bd34aa-691e-4d2e-ac73-b2668c0542ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json, io, base64, re, os, requests, time, traceback\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from collections import defaultdict\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from itertools import combinations\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import (\n",
    "    interact, interactive, fixed, interact_manual,\n",
    "    GridspecLayout, VBox, HBox, Layout, Output\n",
    ")\n",
    "from xml.etree import ElementTree\n",
    "from utils.uniprot_client import UniProtClient\n",
    "# Initialize settings\n",
    "import _settings as settings\n",
    "\n",
    "# Global variables from settings\n",
    "spec_translate_list = settings.SPEC_TRANSLATE_LIST\n",
    "#plotly_colors = settings.plotly_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ad8804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_concat(dfs, **kwargs):\n",
    "    \"\"\"Safely concatenate DataFrames handling empty/NA columns\"\"\"\n",
    "    if not dfs:  # If empty list\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    # Remove any all-NA columns from each DataFrame\n",
    "    cleaned_dfs = []\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "            # Drop all-NA columns\n",
    "            df = df.dropna(axis=1, how='all')\n",
    "            cleaned_dfs.append(df)\n",
    "    \n",
    "    if not cleaned_dfs:  # If no valid DataFrames after cleaning\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Find common columns across all DataFrames\n",
    "    common_cols = set.intersection(*[set(df.columns) for df in cleaned_dfs])\n",
    "    \n",
    "    # Filter to common columns before concatenation\n",
    "    filtered_dfs = [df[list(common_cols)] for df in cleaned_dfs]\n",
    "    \n",
    "    # Perform concatenation\n",
    "    return pd.concat(filtered_dfs, **kwargs)\n",
    "\n",
    "# Use the existing create_help_icon function style\n",
    "def create_help_icon(tooltip_text):\n",
    "    \"\"\"Create a help icon widget with tooltip\"\"\"\n",
    "    help_icon = widgets.HTML(\n",
    "        value='<i class=\"fa fa-question-circle\" style=\"color: #007bff;\"></i>',\n",
    "        layout=widgets.Layout(width='5px', margin='0 0 0 2px')  # Reduced margin, only on left side\n",
    "    )\n",
    "    help_icon.add_class('jupyter-widgets')\n",
    "    help_icon.add_class('widget-html')\n",
    "    return widgets.HTML(\n",
    "        f'<div title=\"{tooltip_text}\" style=\"display: inline-block; margin-left: 2px;\">{help_icon.value}</div>'\n",
    "    )\n",
    "\n",
    "# General warning display function \n",
    "def display_warning( message):\n",
    "    \"\"\"Display a standardized warning message\"\"\"\n",
    "    warning_html = f\"\"\"\n",
    "    <div style='color: #856404; background-color: #fff3cd; border: 1px solid #ffeeba; border-radius: 4px; padding: 10px; margin: 10px 0;'>\n",
    "        <strong>Warning:</strong> {message}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(warning_html))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfaad00-f6e2-48b6-9b73-07bd9559fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self):\n",
    "        self.merged_df = None\n",
    "        self.protein_dict = {}\n",
    "        self.group_data_dict = {}\n",
    "        self.output_area = None\n",
    "        self.merged_uploader = None\n",
    "        self.uniprot_client = UniProtClient()  # Add this line\n",
    "        \n",
    "        # Create the checkbox with improved description\n",
    "        self.plot_lock = widgets.Checkbox(value=True)\n",
    "        self._initialize_instructions()\n",
    "                        \n",
    "    def _initialize_instructions(self):\n",
    "        self.stepone_output_html_message = \"\"\"\n",
    "        <div style='padding: 10px; background-color: #f8f9fa; border-left: 5px solid #007bff; margin: 10px 0;'>\n",
    "            <h3>Step 1: Upload Data</h3>\n",
    "            <p>Please upload your data files to begin visualization:</p>\n",
    "            <ul style='list-style-type: circle;'>\n",
    "                <li>Upload a merged data file exported from the Data Transformation module</li>\n",
    "                <li>File must contain Master Protein Accessions, unique ID, and Avg_* columns</li>\n",
    "                <li>Protein information will be automatically retrieved from UniProt or FASTA files</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        self.stepone_status_output = widgets.Output(\n",
    "            layout=widgets.Layout(\n",
    "                max_width='1000px',\n",
    "                width='100%'\n",
    "            )\n",
    "        )\n",
    "        with self.stepone_status_output:\n",
    "            display(HTML(self.stepone_output_html_message))\n",
    "\n",
    "    def _on_file_change(self, change):\n",
    "        \"\"\"Handle file upload changes without recreating the UI\"\"\"\n",
    "        # Check if we now have all required data\n",
    "        self.has_merged = (hasattr(self, 'merged_df') and \n",
    "                    isinstance(self.merged_df, pd.DataFrame) and \n",
    "                    not self.merged_df.empty)\n",
    "        \n",
    "        self.has_groups = (hasattr(self, 'group_data_dict') and \n",
    "                    isinstance(self.group_data_dict, dict) and \n",
    "                    len(self.group_data_dict) > 0)\n",
    "        \n",
    "        self.has_proteins = (hasattr(self, 'protein_dict') and \n",
    "                    isinstance(self.protein_dict, dict) and \n",
    "                    len(self.protein_dict) > 0)\n",
    "                \n",
    "        # Check if we have all required data\n",
    "        has_required_data = self.has_merged and self.has_groups and self.has_proteins\n",
    "        \n",
    "        # Prepare status info section with current data summary\n",
    "        status_info = \"\"\n",
    "        if self.has_merged and hasattr(self, 'merged_df'):\n",
    "            df = self.merged_df\n",
    "            status_info += f\"<div>Data loaded: {df.shape[0]} rows, {df.shape[1]} columns</div>\"\n",
    "        \n",
    "        if self.has_groups and hasattr(self, 'group_data_dict'):\n",
    "            groups = len(self.group_data_dict)\n",
    "            status_info += f\"<div>Groups detected: {groups}</div>\"\n",
    "        \n",
    "        if self.has_proteins and hasattr(self, 'protein_dict'):\n",
    "            proteins = len(self.protein_dict)\n",
    "            status_info += f\"<div>Proteins loaded: {proteins}</div>\"\n",
    "        \n",
    "        if has_required_data:\n",
    "            # We have all necessary data, so populate the selectors and enable widgets\n",
    "            self.stepone_output_html_message = f\"\"\"\n",
    "            <div style='padding: 10px; background-color: #e8f5e9; border-left: 5px solid #4caf50; margin: 10px 0;'>\n",
    "                <h3>Step 1: Upload Data</h3>\n",
    "                <p>Data successfully loaded:</p>\n",
    "                <ul style=\"list-style-type: none;\">\n",
    "                    <li>✅ <b>{self.filename}</b> successfully upload as a merged data file with {df.shape[0]} rows of data</li> \n",
    "                    <li>✅ {len(self.group_data_dict) if self.group_data_dict else 0} Valid sample groups detected</li> \n",
    "                    <li>✅ {len(self.protein_dict) if self.protein_dict else 0} unique proteins loaded from data file</li>\n",
    "                    <li>✅ {len(df['function'].unique()) if 'function' in df.columns else 0} unique function combinations loaded from datafile</li>\n",
    "                </ul>\n",
    "                <p>You can now proceed to Step 2: variable selection.</p>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        else:\n",
    "            # Still missing data, update the message\n",
    "            missing_data = self._get_missing_data_message()\n",
    "            background_color = \"#fff3e0\"  # Light orange for warning\n",
    "            border_color = \"#ff9800\"      # Orange for warning\n",
    "            \n",
    "            self.stepone_output_html_message = f\"\"\"\n",
    "            <div style='padding: 10px; background-color: {background_color}; border-left: 5px solid {border_color}; margin: 10px 0;'>\n",
    "                <h3>Step 1: Upload Data</h3>\n",
    "                <div style='background-color: #f5f5f5; padding: 8px; border-radius: 4px; margin-bottom: 10px;'>\n",
    "                    <strong>Current Status:</strong> <span style='color: #ff9800;'>Waiting for required data</span>\n",
    "                    {status_info}\n",
    "                </div>\n",
    "                <p>Please complete the data upload:</p>\n",
    "                {missing_data}\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        # Always update the display at the end of the method\n",
    "        with self.stepone_status_output:\n",
    "            clear_output(wait=True)\n",
    "            display(HTML(self.stepone_output_html_message))\n",
    "\n",
    "    def _get_missing_data_message(self):\n",
    "        message = \"<ul style='list-style-type: none;'>\"\n",
    "        if not self.has_merged:\n",
    "            message += \"<li>❌ Missing merged data file</li>\"\n",
    "        else:\n",
    "            message += \"<li>✅ Merged data file uploaded</li>\"\n",
    "            \n",
    "        if not self.has_groups:\n",
    "            message += \"<li>❌ Missing valid abundance columns (Avg_*)</li>\"\n",
    "        else:\n",
    "            message += \"<li>✅ Valid abundance columns detected</li>\"\n",
    "        \n",
    "        if not self.has_proteins:\n",
    "            message += \"<li>❌ Missing protein information</li>\"\n",
    "        else:\n",
    "            message += \"<li>✅ Protein information loaded</li>\"\n",
    "        \n",
    "        message += \"</ul>\"\n",
    "        return message\n",
    "   \n",
    "    def create_download_link(self, file_path, label):\n",
    "        \"\"\"Create a download link for a file.\"\"\"\n",
    "        if os.path.exists(file_path):\n",
    "            # Read file content and encode it as base64\n",
    "            with open(file_path, 'rb') as f:\n",
    "                content = f.read()\n",
    "            b64_content = base64.b64encode(content).decode('utf-8')\n",
    "\n",
    "            # Generate the download link HTML\n",
    "            return widgets.HTML(f\"\"\"\n",
    "                <a download=\"{os.path.basename(file_path)}\" \n",
    "                   href=\"data:application/octet-stream;base64,{b64_content}\" \n",
    "                   style=\"color: #0366d6; text-decoration: none; margin-left: 20px; font-size: 14px;\">\n",
    "                    {label}\n",
    "                </a>\n",
    "            \"\"\")\n",
    "        else:\n",
    "            # Show an error message if the file does not exist\n",
    "            return widgets.HTML(f\"\"\"\n",
    "                <span style=\"color: red; margin-left: 20px; font-size: 14px;\">\n",
    "                    File \"{file_path}\" not found!\n",
    "                </span>\n",
    "            \"\"\")\n",
    "\n",
    "    def setup_data_loading_ui(self):\n",
    "        \"\"\"Initialize and display the data loading UI.\"\"\"\n",
    "        # Create file upload widget\n",
    "        self.merged_uploader = widgets.FileUpload(\n",
    "            accept='.csv,.txt,.tsv,.xlsx',\n",
    "            multiple=False,\n",
    "            description='Upload Merged Data File',\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "\n",
    "        self.output_area = widgets.Output()\n",
    "\n",
    "        # Create upload box with example link\n",
    "        merged_box = widgets.HBox([\n",
    "            self.merged_uploader,\n",
    "            self.create_download_link(\"examples/example_merged_dataframe.csv\", \"Example\")\n",
    "        ], layout=widgets.Layout(align_items='center'))\n",
    "\n",
    "        # Create container for status display\n",
    "        self.status_area = widgets.Output(\n",
    "            layout=widgets.Layout(\n",
    "                width='650px',\n",
    "                margin='0 0 0 20px',\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Create left column with upload widgets\n",
    "        upload_widgets = widgets.VBox([\n",
    "            self.stepone_status_output,\n",
    "            widgets.HTML(\"<u>Upload Data File:</u>\"),\n",
    "            merged_box,\n",
    "            self.status_area,\n",
    "        ], layout=widgets.Layout(\n",
    "            width='1000px',\n",
    "            margin='0 20px 0 0',\n",
    "            overflow='hidden'  # or 'auto' or 'scroll' depending on your needs\n",
    "        ))\n",
    "        \n",
    "        display(upload_widgets)\n",
    "\n",
    "        # Register observer\n",
    "        self.merged_uploader.observe(self.on_merged_upload_change, names='value')\n",
    "    \n",
    "    def process_group_data_from_dataframe(self, df):\n",
    "        \"\"\"\n",
    "        Process and extract group data from DataFrame columns that have grouping information.\n",
    "        This function parses column names in the format \"ColumnName 'Grouped: (Group1; Group2; ...)'\"\n",
    "        and organizes them into a dictionary structure.\n",
    "        \n",
    "        Returns:\n",
    "        {\n",
    "            \"Group1\": [\"Column1\", \"Column2\", ...],\n",
    "            \"Group2\": [\"Column3\", \"Column4\", ...],\n",
    "            ...\n",
    "        }\n",
    "        \"\"\"\n",
    "        try:\n",
    "            group_data_dict = {}\n",
    "            renamed_columns = {}\n",
    "            \n",
    "            # Find all columns that have the 'Grouped:' pattern\n",
    "            grouped_columns = [col for col in df.columns if \" 'Grouped:\" in str(col)]\n",
    "            \n",
    "            if not grouped_columns:\n",
    "                display(HTML('<b style=\"color:orange;\">No valid group data could be extracted.</b>'))\n",
    "                try:\n",
    "                    # Extract group information from Avg_ columns\n",
    "                    avg_columns = [col for col in df.columns if col.startswith('Avg_')]\n",
    "                    if not avg_columns:\n",
    "                        raise ValueError(\"No Avg_ columns found in the data file\")\n",
    "\n",
    "                    # Create group data dictionary from Avg_ columns\n",
    "                    for col in avg_columns:\n",
    "                        group_name = col.replace('Avg_', '')\n",
    "                        # Find all abundance columns that correspond to this group\n",
    "                        group_data_dict[group_name] = col\n",
    "\n",
    "                    if not group_data_dict:\n",
    "                        raise ValueError(\"Could not identify any groups from Avg_ columns\")\n",
    "                        \n",
    "\n",
    "                    display(HTML(\n",
    "                        f'<b style=\"color:green;\">Group definition imported from Peptide Data File with {len(group_data_dict)} groups and no replicate data.</b><br>'\n",
    "                    ))\n",
    "                    display_warning(\"Some plot and data export features will be limited without replicate data. Limited features include: \\n\" +\n",
    "                                    \"• Error bars\\n\" +\n",
    "                                    \"• Replicate correlative analysis\")\n",
    "                    return group_data_dict, df\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    display(HTML(f'<b style=\"color:red;\">Error loading group definition from Peptide Data File: {str(e)}</b>'))\n",
    "                    return group_data_dict, df\n",
    "            \n",
    "            \n",
    "            # Extract grouping information from each column\n",
    "            for col in grouped_columns:\n",
    "                # Extract the base column name (before the grouping info)\n",
    "                base_col_name = col.split(\" 'Grouped:\")[0].strip()\n",
    "                \n",
    "                # Extract the groups from the format \"(Group1; Group2; ...)\"\n",
    "                match = re.search(r\"\\((.*?)\\)\", col)\n",
    "                if match:\n",
    "                    groups_str = match.group(1)\n",
    "                    groups = [g.strip() for g in groups_str.split(\";\")]\n",
    "                    \n",
    "                    # Add the column to each group it belongs to\n",
    "                    for group in groups:\n",
    "                        if group not in group_data_dict:\n",
    "                            group_data_dict[group] = []\n",
    "                        group_data_dict[group].append(base_col_name)\n",
    "                    \n",
    "                    # Create mapping for column renaming (strip the 'Grouped:' part)\n",
    "                    renamed_columns[col] = base_col_name\n",
    "            \n",
    "            # Rename the columns in the DataFrame to remove the 'Grouped:' part\n",
    "            df_renamed = df.rename(columns=renamed_columns)\n",
    "            \n",
    "            # Validate the structure\n",
    "            if not group_data_dict:\n",
    "                #display(HTML('<b style=\"color:orange;\">No valid group data could be extracted.</b>'))\n",
    "                return group_data_dict, df\n",
    "            \n",
    "            #display(HTML('<b style=\"color:green;\">Group data successfully extracted and column names cleaned.</b>'))\n",
    "            return group_data_dict, df_renamed\n",
    "        \n",
    "        except Exception as e:\n",
    "            display(HTML(f\"<b style='color:red;'>Error processing group data from DataFrame: {str(e)}</b>\"))\n",
    "            return group_data_dict, df\n",
    "\n",
    "    def _validate_and_clean_data(self, df):\n",
    "        \"\"\"\n",
    "        Validate and clean the uploaded data, preserving numeric data even if stored as strings.\n",
    "        Returns tuple of (cleaned_df, warnings, errors)\n",
    "        \"\"\"\n",
    "        warnings = []\n",
    "        errors = []\n",
    "        cleaned_df = df.copy()\n",
    "    \n",
    "        # Check required columns exist\n",
    "        required_columns = [\n",
    "            'Master Protein Accessions', \n",
    "            'unique ID'\n",
    "        ]\n",
    "        \n",
    "        # Check that at least one Avg_ column exists\n",
    "        avg_columns = [col for col in df.columns if col.startswith('Avg_')]\n",
    "        if not avg_columns:\n",
    "            errors.append(\"No columns starting with 'Avg_' found in the data\")\n",
    "            return None, warnings, errors\n",
    "            \n",
    "        # Function to function\n",
    "        cleaned_df = cleaned_df.rename(columns={'Function': 'function'})\n",
    "            \n",
    "        # Add Avg_ columns to required columns\n",
    "        required_columns.extend(avg_columns)\n",
    "        \n",
    "        missing = set(required_columns) - set(df.columns)\n",
    "        if missing:\n",
    "            errors.append(f\"Missing required columns: {', '.join(missing)}\")\n",
    "            return None, warnings, errors\n",
    "    \n",
    "        # Separate numeric and non-numeric columns\n",
    "        numeric_columns = avg_columns  # Avg_ columns should be numeric\n",
    "        text_columns = ['Master Protein Accessions', 'unique ID']\n",
    "    \n",
    "        # Handle blank values differently for numeric vs text columns\n",
    "        for column in required_columns:\n",
    "            if column in numeric_columns:\n",
    "                # For numeric columns, try to convert to numeric first\n",
    "                try:\n",
    "                    # Convert to numeric, coerce errors to NaN\n",
    "                    cleaned_df[column] = pd.to_numeric(cleaned_df[column], errors='coerce')\n",
    "                    blank_count = cleaned_df[column].isna().sum()\n",
    "                    if blank_count > 0:\n",
    "                        warnings.append(f\"Found {blank_count} invalid/blank numeric values in {column} column\")\n",
    "                except Exception as e:\n",
    "                    errors.append(f\"Error converting {column} to numeric: {str(e)}\")\n",
    "                    return None, warnings, errors\n",
    "            elif column in text_columns:\n",
    "                # For text columns, check for truly empty values\n",
    "                blank_mask = cleaned_df[column].isna() | (cleaned_df[column].astype(str).str.strip() == '')\n",
    "                blank_count = blank_mask.sum()\n",
    "                if blank_count > 0:\n",
    "                    warnings.append(f\"Dropping {blank_count} rows with blank values in {column} column\")\n",
    "                    cleaned_df = cleaned_df[~blank_mask]\n",
    "    \n",
    "        # Check for invalid characters in non-blank rows\n",
    "        if len(cleaned_df) > 0:\n",
    "            # Check Positions in Proteins\n",
    "            invalid_pos = cleaned_df['Positions in Proteins'].apply(\n",
    "                lambda x: ',' in str(x) or ':' in str(x)\n",
    "            )\n",
    "            if invalid_pos.any():\n",
    "                errors.append(\n",
    "                    \"Found invalid characters (',' or ':') in Positions in Proteins column. \"\n",
    "                    \"Please update the file and upload again.\"\n",
    "                )\n",
    "            \n",
    "            # Check Master Protein Accessions\n",
    "            invalid_acc = cleaned_df['Master Protein Accessions'].apply(\n",
    "                lambda x: ',' in str(x) or ':' in str(x)\n",
    "            )\n",
    "            if invalid_acc.any():\n",
    "                errors.append(\n",
    "                    \"Found invalid characters (',' or ':') in Master Protein Accessions column. \"\n",
    "                    \"Please update the file and upload again.\"\n",
    "                )\n",
    "    \n",
    "        return cleaned_df, warnings, errors\n",
    "\n",
    "    def process_protein_info(self, df, fetch_sequence=False):\n",
    "        \"\"\"\n",
    "        Process protein information from the dataframe and store in protein_dict.\n",
    "        Asks user whether to fetch from UniProt or use accession IDs when protein info is missing.\n",
    "        \n",
    "        Args:\n",
    "            df (DataFrame): DataFrame containing protein data\n",
    "            fetch_sequence (bool): Whether to fetch protein sequences. Defaults to False.\n",
    "        \"\"\"\n",
    "        # Initialize a cache for UniProt information to avoid redundant queries\n",
    "        if not hasattr(self, 'uniprot_client'):\n",
    "            self.uniprot_client = UniProtClient()\n",
    "        if not hasattr(self, 'uniprot_cache'):\n",
    "            self.uniprot_cache = getattr(self, 'uniprot_client').cache if hasattr(self, 'uniprot_client') else {}\n",
    "        \n",
    "\n",
    "        # Check if we need to fetch any data from UniProt\n",
    "        has_protein_info = all(col in df.columns for col in ['protein_name', 'protein_species'])\n",
    "        if has_protein_info:\n",
    "            # Check if we have valid data for all entries\n",
    "            all_data_present = (\n",
    "                df['protein_name'].notna().all() and \n",
    "                df['protein_species'].notna().all() and\n",
    "                (df['protein_name'] != '').all() and\n",
    "                (df['protein_species'] != '').all()\n",
    "            )\n",
    "            if all_data_present:\n",
    "                # If we have all data, just process it silently\n",
    "                protein_info = df.groupby('Master Protein Accessions').agg({\n",
    "                    'protein_name': 'first',\n",
    "                    'protein_species': 'first'\n",
    "                }).reset_index()\n",
    "                \n",
    "                for _, row in protein_info.iterrows():\n",
    "                    protein_id = row['Master Protein Accessions']\n",
    "                    self.protein_dict[protein_id] = {\n",
    "                        \"name\": row['protein_name'],\n",
    "                        \"species\": row['protein_species']\n",
    "                    }\n",
    "                self._protein_processing_complete = True\n",
    "\n",
    "                return len(self.protein_dict)\n",
    "\n",
    "        # Store the dataframe for later processing\n",
    "        self._protein_df_to_process = df\n",
    "\n",
    "        if not all_data_present:\n",
    "            # Store sequence fetch preference\n",
    "            self._fetch_sequence = fetch_sequence\n",
    "            \n",
    "            # Create a flag to track if processing is complete\n",
    "\n",
    "            self._protein_processing_complete = False\n",
    "            \n",
    "            # If we need to fetch data, ask the user what they want to do\n",
    "            # Display in the status area\n",
    "            with self.status_area:\n",
    "                self.status_area.clear_output()\n",
    "                \n",
    "                # Create buttons for user choice\n",
    "                fetch_button = widgets.Button(\n",
    "                    description='Query UniProt',\n",
    "                    button_style='info',\n",
    "                    tooltip='Fetch protein names from UniProt database (may take time)',\n",
    "                    layout=widgets.Layout(width='250px')\n",
    "                )\n",
    "                \n",
    "                use_accession_button = widgets.Button(\n",
    "                    description='Use Protein IDs',\n",
    "                    button_style='warning',\n",
    "                    tooltip='Use protein accession IDs as names without querying UniProt',\n",
    "                    layout=widgets.Layout(width='250px')\n",
    "                )\n",
    "                \n",
    "                # Define button click handlers\n",
    "                fetch_button.on_click(lambda b: self.process_proteins_with_choice(True))\n",
    "                use_accession_button.on_click(lambda b: self.process_proteins_with_choice(False))\n",
    "                \n",
    "                display(HTML(\"\"\"\n",
    "                    <div style=\"padding: 15px; margin: 10px 0; border-left: 4px solid #17a2b8; background-color: #f8f9fa;\">\n",
    "                        <h4 style=\"margin-top: 0;\">Protein Information Missing</h4>\n",
    "                        <p>Some protein names or species information is missing in your data.</p>\n",
    "                        <p>Would you like to:</p>\n",
    "                            <ul>\n",
    "                                    <li>Fetch protein names from UniProt database (may take time)</li>\n",
    "                                    <li>Use protein accession IDs as names without querying UniProt</li>\n",
    "                            </ul>\n",
    "                    </div>\n",
    "                \"\"\"))\n",
    "                display(widgets.HBox([fetch_button, use_accession_button]))\n",
    "            # Mark processing as complete\n",
    "            self._protein_processing_complete = True\n",
    "\n",
    "        # Process _pending_merged_df if it exists rather than merged_df\n",
    "        if hasattr(self, '_pending_merged_df') and self._pending_merged_df is not None:\n",
    "            df_to_update = self._pending_merged_df\n",
    "            \n",
    "            # Add protein_name and protein_species columns if they don't exist\n",
    "            if 'protein_name' not in df_to_update.columns:\n",
    "                df_to_update['protein_name'] = ''\n",
    "            if 'protein_species' not in df_to_update.columns:\n",
    "                df_to_update['protein_species'] = ''\n",
    "            \n",
    "            # Update the columns with the fetched information\n",
    "            for protein_id, info in self.protein_dict.items():\n",
    "                mask = df_to_update['Master Protein Accessions'] == protein_id\n",
    "                df_to_update.loc[mask, 'protein_name'] = info['name']\n",
    "                df_to_update.loc[mask, 'protein_species'] = info['species']\n",
    "            \n",
    "            # Finalize the data import now that processing is complete\n",
    "            self._finalize_data_import()\n",
    "        # Return the current count, but processing will continue when a button is clicked\n",
    "        return len(self.protein_dict)\n",
    "\n",
    "    def process_proteins_with_choice(self, fetch_from_uniprot):\n",
    "        \"\"\"\n",
    "        Process proteins based on user choice.\n",
    "        This is called when the user clicks one of the choice buttons.\n",
    "        \"\"\"\n",
    "        # Get the dataframe to process\n",
    "        df = self._protein_df_to_process\n",
    "        # Get sequence fetch preference (default to False if not set)\n",
    "        fetch_sequence = getattr(self, '_fetch_sequence', False)\n",
    "        \n",
    "        # Clear the status area and show processing message\n",
    "        with self.status_area:\n",
    "            self.status_area.clear_output()\n",
    "            if fetch_from_uniprot:\n",
    "                display(HTML('<div style=\"color: #17a2b8; padding: 10px; margin: 10px 0;\">Fetching protein information from UniProt...</div>'))\n",
    "            else:\n",
    "                display(HTML('<div style=\"color: #ffc107; padding: 10px; margin: 10px 0;\">Using protein accession IDs as names...</div>'))\n",
    "        \n",
    "        # Process proteins based on user choice\n",
    "        # Use the status area for progress display\n",
    "        with self.status_area:\n",
    "            # Initialize counters\n",
    "            total_proteins = 0\n",
    "            uniprot_found = 0\n",
    "            uniprot_not_found = 0\n",
    "            multiple_entries = 0\n",
    "            cached_proteins = 0\n",
    "            \n",
    "            # Check if we need to fetch any data from UniProt\n",
    "            has_protein_info = all(col in df.columns for col in ['protein_name', 'protein_species'])\n",
    "            \n",
    "            # Group by protein accession to get unique proteins\n",
    "            protein_info = df.groupby('Master Protein Accessions').agg({\n",
    "                'protein_name': 'first' if 'protein_name' in df.columns else lambda x: None,\n",
    "                'protein_species': 'first' if 'protein_species' in df.columns else lambda x: None\n",
    "            }).reset_index()\n",
    "\n",
    "            progress_html = \"\"\"\n",
    "                <style>\n",
    "                    .fetch-status { font-family: monospace; margin: 10px 0; padding: 10px; }\n",
    "                    .fetch-progress { margin: 5px 0; padding: 5px; }\n",
    "                    .success { color: #28a745; }\n",
    "                    .warning { color: #ffc107; }\n",
    "                    .error { color: #dc3545; }\n",
    "                    .info { color: #17a2b8; }\n",
    "                    .summary { margin-top: 10px; padding: 10px;}\n",
    "                </style>\n",
    "                <div class=\"fetch-status\">\n",
    "                    <div id=\"progress-updates\"></div>\n",
    "                </div>\n",
    "            \"\"\"\n",
    "            # First, collect all proteins that need fetching\n",
    "            proteins_to_fetch = []\n",
    "            \n",
    "            for _, row in protein_info.iterrows():\n",
    "                total_proteins += 1\n",
    "                protein_id = row['Master Protein Accessions']\n",
    "                \n",
    "                # Skip entries with multiple protein IDs\n",
    "                if ';' in protein_id:\n",
    "                    multiple_entries += 1\n",
    "                    self.protein_dict[protein_id] = {\n",
    "                        \"name\": protein_id,\n",
    "                        \"species\": \"Multiple\"\n",
    "                    }\n",
    "                    continue\n",
    "                \n",
    "                # Use existing data if available and not empty\n",
    "                if (has_protein_info and \n",
    "                    pd.notna(row['protein_name']) and \n",
    "                    pd.notna(row['protein_species']) and \n",
    "                    row['protein_name'] != '' and \n",
    "                    row['protein_species'] != ''):\n",
    "                    self.protein_dict[protein_id] = {\n",
    "                        \"name\": row['protein_name'],\n",
    "                        \"species\": row['protein_species']\n",
    "                    }\n",
    "                    continue\n",
    "                \n",
    "                # Check if we already have this protein in cache\n",
    "                if hasattr(self, 'uniprot_client') and protein_id in self.uniprot_client.cache:\n",
    "                    cached_proteins += 1\n",
    "                    name, species = self.uniprot_client.cache[protein_id]\n",
    "                    self.protein_dict[protein_id] = {\n",
    "                        \"name\": name if name else protein_id,\n",
    "                        \"species\": species if species else \"Unknown\"\n",
    "                    }\n",
    "                    continue\n",
    "                elif hasattr(self, 'uniprot_cache') and protein_id in self.uniprot_cache:\n",
    "                    cached_proteins += 1\n",
    "                    name, species = self.uniprot_cache[protein_id]\n",
    "                    self.protein_dict[protein_id] = {\n",
    "                        \"name\": name if name else protein_id,\n",
    "                        \"species\": species if species else \"Unknown\"\n",
    "                    }\n",
    "                    continue\n",
    "                \n",
    "                # If we need to fetch and user chose to fetch from UniProt\n",
    "                if fetch_from_uniprot:\n",
    "                    proteins_to_fetch.append(protein_id)\n",
    "                else:\n",
    "                    # Use accession ID as name\n",
    "                    self.protein_dict[protein_id] = {\n",
    "                        \"name\": protein_id,\n",
    "                        \"species\": \"Unknown\"\n",
    "                    }\n",
    "            \n",
    "            # Process proteins in batches if fetching from UniProt\n",
    "            if fetch_from_uniprot and proteins_to_fetch:\n",
    "                # Update progress display\n",
    "                display(HTML(progress_html + f\"\"\"\n",
    "                    <div class=\"fetch-progress info\">\n",
    "                        Preparing to fetch {len(proteins_to_fetch)} proteins from UniProt in batches...\n",
    "                    </div>\n",
    "                \"\"\"))\n",
    "                \n",
    "                # Process in batches of 50 (adjust as needed)\n",
    "                batch_size = 50\n",
    "                total_batches = (len(proteins_to_fetch) + batch_size - 1) // batch_size\n",
    "                \n",
    "                for batch_num in range(total_batches):\n",
    "                    start_idx = batch_num * batch_size\n",
    "                    end_idx = min((batch_num + 1) * batch_size, len(proteins_to_fetch))\n",
    "                    current_batch = proteins_to_fetch[start_idx:end_idx]\n",
    "                    \n",
    "                    # Update progress\n",
    "                    self.status_area.clear_output(wait=True)\n",
    "                    display(HTML(progress_html + f\"\"\"\n",
    "                        <div class=\"fetch-progress info\">\n",
    "                            Fetching batch {batch_num + 1}/{total_batches} ({len(current_batch)} proteins)...\n",
    "                        </div>\n",
    "                        <div class=\"summary\">\n",
    "                            <h4>Progress:</h4>\n",
    "                            <ul>\n",
    "                                <li>Total proteins: {total_proteins}</li>\n",
    "                                <li>Proteins from cache: {cached_proteins}</li>\n",
    "                                <li>UniProt matches found: {uniprot_found}</li>\n",
    "                                <li>UniProt matches not found: {uniprot_not_found}</li>\n",
    "                                <li>Multiple entry proteins: {multiple_entries}</li>\n",
    "                                <li>Remaining to fetch: {len(proteins_to_fetch) - start_idx}</li>\n",
    "                            </ul>\n",
    "                        </div>\n",
    "                    \"\"\"))\n",
    "                    \n",
    "                    # Fetch the batch\n",
    "                    batch_results = {}\n",
    "                    for protein_id in current_batch:\n",
    "                        try:\n",
    "                            # Use the appropriate method based on whether we want to fetch sequence\n",
    "                            if fetch_sequence:\n",
    "                                name, species, sequence = self.uniprot_client.fetch_protein_info_with_sequence(protein_id)\n",
    "                                if name or species:\n",
    "                                    batch_results[protein_id] = (name, species, sequence)\n",
    "                            else:\n",
    "                                name, species = self.uniprot_client.fetch_protein_info(protein_id)\n",
    "                                if name or species:\n",
    "                                    batch_results[protein_id] = (name, species)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error fetching {protein_id}: {str(e)}\")\n",
    "                    \n",
    "                    # Process the results\n",
    "                    for protein_id in current_batch:\n",
    "                        if protein_id in batch_results:\n",
    "                            if fetch_sequence:\n",
    "                                name, species, sequence = batch_results[protein_id]\n",
    "                            else:\n",
    "                                name, species = batch_results[protein_id]\n",
    "                                sequence = None\n",
    "                                \n",
    "                            # Use the protein_id as name if name is None or empty\n",
    "                            if not name:\n",
    "                                name = protein_id\n",
    "                                \n",
    "                            # Use \"Unknown\" for species if it's None or empty\n",
    "                            if not species:\n",
    "                                species = \"Unknown\"\n",
    "                                \n",
    "                            uniprot_found += 1\n",
    "                            self.protein_dict[protein_id] = {\n",
    "                                \"name\": name,\n",
    "                                \"species\": species\n",
    "                            }\n",
    "                            \n",
    "                            # Add sequence if we have it\n",
    "                            if sequence:\n",
    "                                self.protein_dict[protein_id][\"sequence\"] = sequence\n",
    "                                \n",
    "                            # Add to cache\n",
    "                            if hasattr(self, 'uniprot_client'):\n",
    "                                if fetch_sequence:\n",
    "                                    self.uniprot_client.sequence_cache[protein_id] = (name, species, sequence)\n",
    "                                self.uniprot_client.cache[protein_id] = (name, species)\n",
    "                            else:\n",
    "                                if not hasattr(self, 'uniprot_cache'):\n",
    "                                    self.uniprot_cache = {}\n",
    "                                self.uniprot_cache[protein_id] = (name, species)\n",
    "                        else:\n",
    "                            uniprot_not_found += 1\n",
    "                            self.protein_dict[protein_id] = {\n",
    "                                \"name\": protein_id,\n",
    "                                \"species\": \"Unknown\"\n",
    "                            }\n",
    "                            # Cache the negative result too\n",
    "                            if hasattr(self, 'uniprot_cache'):\n",
    "                                self.uniprot_cache[protein_id] = (protein_id, \"Unknown\")\n",
    "            \n",
    "            # Show final summary\n",
    "            self.status_area.clear_output(wait=True)\n",
    "            display(HTML(f\"\"\"\n",
    "                <div class=\"fetch-status\">\n",
    "                    <h4 style=\"color:green;\"><b>Protein Processing Complete!</b></h4>\n",
    "                    <div class=\"summary\">\n",
    "                        <h4>Final Summary:</h4>\n",
    "                        <ul>\n",
    "                            <li>Total proteins processed: {total_proteins}</li>\n",
    "                            <li>Proteins from cache: {cached_proteins}</li>\n",
    "                            <li>Multiple entry proteins: {multiple_entries}</li>\n",
    "                            {\"<li>UniProt matches found: \" + str(uniprot_found) + \"</li>\" if fetch_from_uniprot else \"\"}\n",
    "                            {\"<li>UniProt matches not found: \" + str(uniprot_not_found) + \"</li>\" if fetch_from_uniprot else \"\"}\n",
    "                        </ul>\n",
    "                    </div>\n",
    "                </div>\n",
    "            \"\"\"))\n",
    "        \n",
    "        # Mark processing as complete\n",
    "        self._protein_processing_complete = True\n",
    "        \n",
    "        # Process _pending_merged_df if it exists rather than merged_df\n",
    "        if hasattr(self, '_pending_merged_df') and self._pending_merged_df is not None:\n",
    "            df_to_update = self._pending_merged_df\n",
    "            \n",
    "            # Add protein_name and protein_species columns if they don't exist\n",
    "            if 'protein_name' not in df_to_update.columns:\n",
    "                df_to_update['protein_name'] = ''\n",
    "            if 'protein_species' not in df_to_update.columns:\n",
    "                df_to_update['protein_species'] = ''\n",
    "            \n",
    "            # Update the columns with the fetched information\n",
    "            for protein_id, info in self.protein_dict.items():\n",
    "                mask = df_to_update['Master Protein Accessions'] == protein_id\n",
    "                df_to_update.loc[mask, 'protein_name'] = info['name']\n",
    "                df_to_update.loc[mask, 'protein_species'] = info['species']\n",
    "            \n",
    "            # Finalize the data import now that processing is complete\n",
    "            self._finalize_data_import()\n",
    "        \n",
    "        # Otherwise update the existing merged_df if it exists\n",
    "        elif hasattr(self, 'merged_df') and self.merged_df is not None:\n",
    "            # Add protein_name and protein_species columns if they don't exist\n",
    "            if 'protein_name' not in self.merged_df.columns:\n",
    "                self.merged_df['protein_name'] = ''\n",
    "            if 'protein_species' not in self.merged_df.columns:\n",
    "                self.merged_df['protein_species'] = ''\n",
    "            \n",
    "            # Update the columns with the fetched information\n",
    "            for protein_id, info in self.protein_dict.items():\n",
    "                mask = self.merged_df['Master Protein Accessions'] == protein_id\n",
    "                self.merged_df.loc[mask, 'protein_name'] = info['name']\n",
    "                self.merged_df.loc[mask, 'protein_species'] = info['species']\n",
    "        \n",
    "        # Check if we can enable the plot button\n",
    "        self.check_and_update_plot_button_state()\n",
    "        # Return the number of proteins processed\n",
    "        return len(self.protein_dict)\n",
    "\n",
    "    def _finalize_data_import(self):\n",
    "        \"\"\"Finalize data import after protein processing is complete\"\"\"\n",
    "        if hasattr(self, '_pending_merged_df') and self._pending_merged_df is not None:\n",
    "            # Set the merged_df property\n",
    "            self.merged_df = self._pending_merged_df\n",
    "\n",
    "            # Display success message in output area\n",
    "            with self.status_area:\n",
    "                display(HTML(\n",
    "                    f'<b style=\"color:green;\">Data imported successfully with '\n",
    "                    f'{self.merged_df.shape[0]} rows and {self.merged_df.shape[1]} columns.</b>'\n",
    "                ))\n",
    "            \n",
    "            # Clear the pending data\n",
    "            self._pending_merged_df = None\n",
    "\n",
    "    def on_merged_upload_change(self, change):\n",
    "        \"\"\"Handle merged data file upload\"\"\"\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            self.merged_df = pd.DataFrame()\n",
    "            self.group_data_dict = {}\n",
    "            with self.status_area:\n",
    "                self.status_area.clear_output()\n",
    "                if change['new'] and len(change['new']) > 0:\n",
    "                    file_data = change['new'][0]\n",
    "                    df, status = self._load_data(file_data)\n",
    "                    if status == 'yes' and df is not None:\n",
    "                        # Set a property to track that we have pending data\n",
    "                        self._pending_merged_df = df\n",
    "                        \n",
    "                        # Only update UI and set merged_df when protein processing is complete\n",
    "                        if hasattr(self, '_protein_processing_complete') and self._protein_processing_complete:\n",
    "                            self._finalize_data_import()\n",
    "\n",
    "                        # Otherwise, the process_proteins_with_choice method will call _finalize_data_import\n",
    "                        else:\n",
    "                            display(HTML(\n",
    "                                f'<b style=\"color:orange;\">Protein information processing in progress... '\n",
    "                                f'Please complete protein information selection.</b>'\n",
    "                            ))\n",
    "\n",
    "                        # Process group data\n",
    "                        self.group_data_dict, self.merged_df = self.process_group_data_from_dataframe(df)\n",
    "                        # Check if we can enable the plot button\n",
    "                        self._on_file_change(change)\n",
    "                        self.check_and_update_plot_button_state()\n",
    "    \n",
    "    def _load_data(self, file_data):\n",
    "        \"\"\"\n",
    "        Load and validate merged data file\n",
    "        Returns tuple of (dataframe, status)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            content = bytes(file_data.content)\n",
    "            filename = file_data.name\n",
    "            extension = filename.split('.')[-1].lower()\n",
    "            self.filename = filename\n",
    "            file_stream = io.BytesIO(content)\n",
    "\n",
    "            # Load data based on file extension\n",
    "            try:\n",
    "                if extension == 'csv':\n",
    "                    df = pd.read_csv(file_stream)\n",
    "                elif extension in ['txt', 'tsv']:\n",
    "                    df = pd.read_csv(file_stream, delimiter='\\t')\n",
    "                elif extension == 'xlsx':\n",
    "                    df = pd.read_excel(file_stream)\n",
    "                else:\n",
    "                    display(HTML(f'<b style=\"color:red;\">Error: Unsupported file format</b>'))\n",
    "                    return None, 'no'\n",
    "            except Exception as e:\n",
    "                display(HTML(f'<b style=\"color:red;\">Error reading file: {str(e)}</b>'))\n",
    "                return None, 'no'\n",
    "\n",
    "            # Check for protein info columns and notify user\n",
    "            missing_columns = []\n",
    "            if 'protein_name' not in df.columns:\n",
    "                missing_columns.append('protein_name')\n",
    "                df['protein_name'] = ''\n",
    "            if 'protein_species' not in df.columns:\n",
    "                missing_columns.append('protein_species')\n",
    "                df['protein_species'] = ''\n",
    "                \n",
    "            if missing_columns:\n",
    "                notification = f\"\"\"\n",
    "                <div style=\"padding: 10px; margin: 10px 0;\">\n",
    "                    <p style=\"color: #17a2b8; margin: 0;\">\n",
    "                        <b>Notice:</b> The following columns are missing from your data:\n",
    "                        <ul style=\"color: #17a2b8; margin: 5px 0;\">\n",
    "                            {''.join(f'<li>{col}</li>' for col in missing_columns)}\n",
    "                        </ul>\n",
    "                        </p>\n",
    "                        <p style=\"color: #17a2b8; margin: 0;\">\n",
    "                        UniProt will be searched to automatically fill in this information. <br>\n",
    "                        Alternativly you can upload a standardized file from the data transomation module with the protein information. \n",
    "                    </p>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "                display(HTML(notification))\n",
    "\n",
    "            # Validate and clean data\n",
    "            cleaned_df, warnings, errors = self._validate_and_clean_data(df)\n",
    "\n",
    "            # Warnings about invalid/blank values are commented out\n",
    "            # if warnings:\n",
    "            #     warning_html = \"<br>\".join([\n",
    "            #         f'<b style=\"color:orange;\">Warning: {w}</b>'\n",
    "            #         for w in warnings\n",
    "            #     ])\n",
    "            #     display(HTML(warning_html))\n",
    "\n",
    "            # Display errors if any\n",
    "            if errors:\n",
    "                error_html = \"<br>\".join([\n",
    "                    f'<b style=\"color:red;\">Error: {e}</b>'\n",
    "                    for e in errors\n",
    "                ])\n",
    "                display(HTML(error_html))\n",
    "                return None, 'no'\n",
    "\n",
    "            if cleaned_df is not None and len(cleaned_df) > 0:\n",
    "                # Process protein information\n",
    "                num_proteins = self.process_protein_info(cleaned_df)\n",
    "                \n",
    "                # Add information about remaining rows and processed proteins\n",
    "                success_message = f\"\"\"\n",
    "                <div style=\"padding: 10px; margin: 10px 0; border-left: 4px solid #28a745; background-color: #f8f9fa;\">\n",
    "                    <p style=\"color: #28a745; margin: 0;\">\n",
    "                        <b>Data Import Complete!</b><br>\n",
    "                        • Data imported successfully with {cleaned_df.shape[0]} rows and {cleaned_df.shape[1]} columns.<br>\n",
    "                        • Processed data contains {len(cleaned_df)} rows after removing blank values.<br>\n",
    "                        • Successfully processed information for {num_proteins} unique proteins.\n",
    "                    </p>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "                #display(HTML(success_message))\n",
    "                return cleaned_df, 'yes'\n",
    "            else:\n",
    "                display(HTML('<b style=\"color:red;\">Error: No valid data rows remaining after cleaning</b>'))\n",
    "                return None, 'no'\n",
    "\n",
    "        except Exception as e:\n",
    "            display(HTML(f'<b style=\"color:red;\">Error processing file: {str(e)}</b>'))\n",
    "            return None, 'no'\n",
    "\n",
    "    def check_and_update_plot_button_state(self):\n",
    "        \"\"\"\n",
    "        Check if all requirements are met to enable the plot button:\n",
    "        1. Merged data is available\n",
    "        2. Protein info is successfully processed\n",
    "        3. Group data is available\n",
    "        \"\"\"\n",
    "\n",
    "        # Check if we have merged data\n",
    "        has_merged_data = hasattr(self, 'merged_df') and self.merged_df is not None\n",
    "\n",
    "        # Check if protein info is processed\n",
    "        protein_info_processed = hasattr(self, '_protein_processing_complete') and self._protein_processing_complete\n",
    "\n",
    "        # Check if we have group data\n",
    "        has_group_data_dict = hasattr(self, 'group_data_dict') and self.group_data_dict is not None\n",
    "\n",
    "        \n",
    "        # Enable plot button only if all conditions are met\n",
    "        if has_merged_data and protein_info_processed and has_group_data_dict:\n",
    "            self.plot_lock.value=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a47f2735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "    def __init__(self, data_transformer):\n",
    "        self.data_transformer = data_transformer\n",
    "        self.selected_proteins = []\n",
    "        self.selected_functions = []\n",
    "        # Add variable to store current figure\n",
    "        self.current_fig = None\n",
    "        self.merged_df = self.data_transformer.merged_df\n",
    "        self.group_data_dict = self.data_transformer.group_data_dict\n",
    "        self.protein_dict = self.data_transformer.protein_dict\n",
    "        self.set_up_self_widget()   \n",
    "        self._initialize_instructions() \n",
    "        \n",
    "        self.data_transformer.merged_uploader.observe(self.update_group_options, names='value')\n",
    "\n",
    "        # Register an explicit callback to populate proteins when merged data changes\n",
    "        self.data_transformer.merged_uploader.observe(self.populate_protein_selector, names='value')\n",
    "\n",
    "        # Observe for data loading to update functions and color generation\n",
    "        self.data_transformer.merged_uploader.observe(self.on_data_loaded_func_and_color_gen, names='value')\n",
    "               \n",
    "        self.data_transformer.plot_lock.observe(self._on_plot_lock_change_handler, names='value')\n",
    "        # In your setup_widgets method, add this line:\n",
    "        self.color_scheme.observe(self.on_color_scheme_change, names='value')\n",
    "\n",
    "        self.plot_func_or_pro.observe(self.on_plot_type_change, names='value')\n",
    "        #self.on_plot_func_or_pro_change(type('Change', (), {'new': 'No Filter'})())\n",
    "   \n",
    "        self.plot_type.observe(self.on_plot_type_change, names='value')\n",
    "  \n",
    "    def _on_plot_lock_change_handler(self, change):\n",
    "        \"\"\"Handle changes in Plot_lock state\"\"\"\n",
    "        if change.new == False and change.old == True:\n",
    "            self.merged_df = self.data_transformer.merged_df\n",
    "            self.group_data_dict = self.data_transformer.group_data_dict\n",
    "            self.protein_dict = self.data_transformer.protein_dict\n",
    "\n",
    "            self.group_selector.disabled = False\n",
    "            self.protein_selector.disabled = False\n",
    "            self.function_selector.disabled = False\n",
    "            self.plot_func_or_pro.disabled = False\n",
    "            self.plot_minor.disabled = False\n",
    "            self.xlabel_widget.disabled = False\n",
    "            self.ylabel_widget.disabled = False\n",
    "            self.legend_widget.disabled = False\n",
    "            self.title_widget.disabled = False\n",
    "            self.color_scheme.disabled = False\n",
    "            self.plot_type.disabled = False\n",
    "            self.metric_type.disabled = False\n",
    "            self.abs_or_count.disabled = False\n",
    "            self.invert_plot.disabled = False\n",
    "            self.log_transform.disabled = False\n",
    "\n",
    "            self.update_group_options(change)       \n",
    "            self.populate_protein_selector()  \n",
    "            self.on_data_loaded_func_and_color_gen()\n",
    "\n",
    "    def update_group_options(self, change=None):\n",
    "        \"\"\"Update group selection options when data changes\"\"\"\n",
    "        if self.merged_df is not None:\n",
    "            # Get all Avg_ columns\n",
    "            self.avg_columns = [col for col in self.merged_df.columns \n",
    "                        if col.startswith('Avg_')]\n",
    "            # Use the stripped names but maintain original order\n",
    "            self.stripped_columns = [col.replace('Avg_', '')  for col in self.avg_columns]\n",
    "            # Update group selection options\n",
    "            self.group_selector.options = self.stripped_columns\n",
    "            # Select all groups by default\n",
    "            self.group_selector.value = self.stripped_columns\n",
    "    \n",
    "    def on_data_loaded_func_and_color_gen(self, change=None):\n",
    "        \"\"\"Handle data loading and generate function colors\"\"\"\n",
    "        # Process bioactive data and get both dictionaries\n",
    "        self.calculate_bioactivt_count_and_dict()\n",
    "\n",
    "        if self.unique_function_absorbance_dict:\n",
    "            # Get all unique functions and their total absorbance\n",
    "            function_totals_dict = {}\n",
    "            for group_data_dict in self.unique_function_absorbance_dict.values():\n",
    "                for function, absorbance in group_data_dict.items():\n",
    "                    if function not in function_totals_dict:\n",
    "                        function_totals_dict[function] = 0\n",
    "                    function_totals_dict[function] += absorbance\n",
    "            \n",
    "            # Sort functions by total absorbance in descending order\n",
    "            self.all_functions = [\n",
    "                function for function, _ in sorted(\n",
    "                    function_totals_dict.items(),\n",
    "                    key=lambda x: x[1],\n",
    "                    reverse=True\n",
    "                )\n",
    "            ]\n",
    "            \n",
    "            # Update function selector options first\n",
    "            all_functions = [func for func in self.all_functions if func != 'Minor Functions' and func != 'Functional Peptides' and func != 'Non-Functional Peptides']\n",
    "            self.function_selector.options = ['All Functional Peptides'] + all_functions\n",
    "            # Then set the default value to 'All'\n",
    "            self.function_selector.value = ('All Functional Peptides',)\n",
    "            \n",
    "            # Generate colors for functions\n",
    "            self.function_colors = self.get_color_sequence(len(self.all_functions))\n",
    "            \n",
    "            # Create color mapping\n",
    "            self.function_color_map = {\n",
    "                function: color \n",
    "                for function, color in zip(self.all_functions, self.function_colors)\n",
    "            }\n",
    "            # Check if we should plot minor functions\n",
    "            plot_minor = self.plot_minor.value\n",
    "            if plot_minor:\n",
    "                # Always set Minor Functions to grey\n",
    "                if 'Minor Functions' not in self.function_color_map:\n",
    "                    self.function_color_map['Minor Functions'] = '#808080'  # Grey color\n",
    "        \n",
    "    def populate_protein_selector(self, change=None):\n",
    "        \"\"\"Populate the protein selector with proteins ordered by their relative abundance across all samples\"\"\"\n",
    "        \n",
    "        # Check if data_transformer is available\n",
    "        if not hasattr(self, 'data_transformer') or self.data_transformer is None:\n",
    "            return\n",
    "            \n",
    "        # Use protein_dict (with 's') instead of protein_dic\n",
    "        if not self.protein_dict:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            # Calculate protein abundance across all samples\n",
    "            protein_abundance = {}\n",
    "            \n",
    "            if self.merged_df  is not None:\n",
    "                df = self.merged_df.copy()\n",
    "                \n",
    "                # Find all Avg_ columns for abundance data\n",
    "                abundance_cols = self.avg_columns\n",
    "                protein_col = 'Master Protein Accessions'\n",
    "                \n",
    "                if abundance_cols and protein_col in df.columns:\n",
    "                    \n",
    "                    # Process each row in the dataframe\n",
    "                    for _, row in df.iterrows():\n",
    "                        # Skip rows without protein information\n",
    "                        if pd.isna(row[protein_col]) or row[protein_col] == '':\n",
    "                            continue\n",
    "                            \n",
    "                        # Get proteins for this peptide\n",
    "                        proteins = [p.strip() for p in str(row[protein_col]).split(';') if p.strip()]\n",
    "                        \n",
    "                        # Calculate total abundance across all samples for this peptide\n",
    "                        total_abundance = 0\n",
    "                        for col in abundance_cols:\n",
    "                            try:\n",
    "                                if pd.notna(row.get(col)):\n",
    "                                    total_abundance += float(row.get(col, 0))\n",
    "                            except (ValueError, TypeError) as e:\n",
    "                                print(f\"Error converting abundance value in column {col}: {str(e)}\")\n",
    "                                print(f\"Value: {row.get(col)}, Type: {type(row.get(col))}\")\n",
    "                        \n",
    "                        # If there are multiple proteins, divide the abundance equally among them\n",
    "                        per_protein_abundance = total_abundance / len(proteins) if proteins else 0\n",
    "                        \n",
    "                        # Add to each protein's total\n",
    "                        for protein in proteins:\n",
    "                            if protein in protein_abundance:\n",
    "                                protein_abundance[protein] += per_protein_abundance\n",
    "                            else:\n",
    "                                protein_abundance[protein] = per_protein_abundance\n",
    "                    \n",
    "            \n",
    "            # Get the list of all proteins from protein_dict\n",
    "            all_proteins = list(self.protein_dict.keys())\n",
    "            self.all_proteins = []\n",
    "            # Sort proteins by abundance (highest first)\n",
    "\n",
    "            if protein_abundance:\n",
    "                # Get proteins sorted by abundance\n",
    "                sorted_proteins = sorted(all_proteins, \n",
    "                                        key=lambda p: protein_abundance.get(p, 0), \n",
    "                                        reverse=True)\n",
    "\n",
    "                # Create options with protein ID and name\n",
    "                options = []\n",
    "                options.append('All Proteins (No Filter)')  # Add 'All' option first\n",
    "                \n",
    "                # Add each protein with its ID, name and abundance\n",
    "                for protein_id in sorted_proteins:\n",
    "                    protein_info = self.protein_dict.get(protein_id, {})\n",
    "                    protein_name = protein_info.get('name', protein_id)\n",
    "                    self.all_proteins.append(protein_name)\n",
    "                    abundance = protein_abundance.get(protein_id, 0)\n",
    "\n",
    "                    options.append(protein_name)\n",
    "                # Update the protein selector with all options\n",
    "                self.protein_selector.options = options\n",
    "\n",
    "                self.all_proteins \n",
    "                # Automatically select the top 10 proteins (or fewer if less are available)\n",
    "                num_proteins = min(10, len(options) - 1)  # -1 to account for 'All'\n",
    "                if num_proteins > 0:\n",
    "                    # Select top proteins (options[1:] to skip 'All')\n",
    "                    self.protein_selector.value = tuple(options[1:num_proteins+1])\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error populating protein selector: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            \n",
    "    def set_up_self_widget(self):\n",
    "        \n",
    "        # Create multi-select widget for groups\n",
    "        self.group_selector = widgets.SelectMultiple(\n",
    "            options=[],\n",
    "            #description='Groups:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px', height='100px'),\n",
    "            disabled=True\n",
    "        )\n",
    "\n",
    "\n",
    "        # Add Correlation specific widgets\n",
    "        self.correlation_type = widgets.RadioButtons(\n",
    "            options=['Pearson', 'Spearman'],\n",
    "            description='Correlation Type:',\n",
    "            value='Pearson',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            disabled=True\n",
    "        )\n",
    "        self.log_transform = widgets.Checkbox(\n",
    "            value=True,\n",
    "            description='Apply log10 transformation to the y-axis',\n",
    "            layout=widgets.Layout(width='350px'),\n",
    "            indent=False,\n",
    "            style={'description_width': 'initial'},\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        # Add label customization widgets\n",
    "        self.xlabel_widget = widgets.Text(\n",
    "            description='X Label:',\n",
    "            placeholder='Enter x-axis label',\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            disabled=True\n",
    "        )\n",
    "        self.ylabel_widget = widgets.Text(\n",
    "            description='Y Label:',\n",
    "            placeholder='Enter y-axis label',\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            disabled=True\n",
    "        )\n",
    "        self.legend_widget = widgets.Text(\n",
    "            description='Legend Title',\n",
    "            placeholder='Enter a custom legend title',\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            disabled=True\n",
    "        )\n",
    "        self.title_widget = widgets.Text(\n",
    "            description='Plot Title',\n",
    "            placeholder='Enter a custom plot title',\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            disabled=True\n",
    "        )\n",
    "\n",
    "\n",
    "        self.single_color_scheme = [\n",
    "            '--- SINGLE COLORS OPTIONS ---',\n",
    "            'red', 'green', 'blue', 'yellow', 'purple', 'orange', 'cyan', \n",
    "            'magenta', 'pink', 'brown', 'black', 'white', 'gray', 'darkblue',\n",
    "            'darkgreen', 'darkred', 'darkorange', 'darkpurple', 'lightblue',\n",
    "            'lightgreen', 'lightred', 'gold', 'silver', 'teal', 'navy', 'maroon',\n",
    "            'olive', 'lime', 'aqua', 'indigo', 'violet', 'turquoise', 'coral',\n",
    "            'crimson', 'salmon', 'sienna', 'tan', 'khaki', 'plum', 'orchid'\n",
    "        ]\n",
    "        # Update color scheme dropdown with categorized options\n",
    "        color_palet = [\n",
    "            '--- DEFAULT PALETTE(HSV) ---',\n",
    "            'HSV',  # Default option\n",
    "            '--- QUALITATIVE PALETTES (RECOMENDED) ---',\n",
    "            'Plotly', 'D3', 'G10', 'T10', 'Alphabet', \n",
    "            'Set1', 'Set2', 'Set3', 'Pastel1', 'Pastel2', 'Paired',\n",
    "            '--- SEQUENTIAL PALETTES ---',\n",
    "            'Viridis', 'Cividis', 'Inferno', 'Magma', 'Plasma',\n",
    "            'Hot', 'Jet', 'Blues', 'Greens', 'Reds', 'Purples', 'Oranges',\n",
    "            '--- DIVERGING PALETTES ---',\n",
    "            'Spectral', 'RdBu', 'RdYlBu', 'RdYlGn', 'PiYG', 'PRGn', 'BrBG', 'RdGy',\n",
    "            '--- CYCLICAL PALETTES ---',\n",
    "            'IceFire', 'Edge', 'Twilight',\n",
    "\n",
    "        ]\n",
    "        color_schemes = color_palet + self.single_color_scheme\n",
    "\n",
    "        self.color_scheme = widgets.Dropdown(\n",
    "            options=color_schemes,\n",
    "            value='HSV',  # Default value\n",
    "            description='Color Scheme:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            disabled=True\n",
    "        )\n",
    "\n",
    "        # Add an inversion toggle radio button\n",
    "        self.invert_plot = widgets.RadioButtons(\n",
    "            description='Plot Orientation:',\n",
    "            options=['By Sample', 'By Protein', 'By Function'],\n",
    "            value='By Sample',  # Default selection\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px', height='auto'),\n",
    "            disabled=True,\n",
    "            indent=True  # Keeps options aligned with description instead of appearing below\n",
    "        )\n",
    "\n",
    "        # Create a custom class for SelectMultiple with text-overflow ellipsis\n",
    "        class EllipsisSelectMultiple(widgets.SelectMultiple):\n",
    "            def __init__(self, **kwargs):\n",
    "                super().__init__(**kwargs)\n",
    "                self._dom_classes = ['ellipsis-select']\n",
    "                \n",
    "        # Apply CSS styling for ellipsis\n",
    "        display(HTML(\"\"\"\n",
    "        <style>\n",
    "        .ellipsis-select select option {\n",
    "            text-overflow: ellipsis;\n",
    "            overflow: hidden;\n",
    "            white-space: nowrap;\n",
    "        }\n",
    "        </style>\n",
    "        \"\"\"))\n",
    "        \n",
    "        self.protein_selector = EllipsisSelectMultiple(\n",
    "            options=['All Proteins (No Filter)'],\n",
    "            value=['All Proteins (No Filter)'],  # Empty tuple - no selection by default\n",
    "            #description='Proteins:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(\n",
    "                width='300px',\n",
    "                height='100px',\n",
    "            ),\n",
    "            disabled=True\n",
    "        )\n",
    "\n",
    "                     \n",
    "       # Plot type selection\n",
    "        self.plot_func_or_pro = widgets.Dropdown(\n",
    "            options=['No Filter', 'Selected Protein(s)', 'Selected Function(s)', 'Both', 'Functional vs Non-Functional Peptides'],\n",
    "            value='Both',\n",
    "            description='Plot Filter:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        # Replace Dropdown with SelectMultiple for functions\n",
    "        self.function_selector = widgets.SelectMultiple(\n",
    "            options=['All Functional Peptides'],\n",
    "            value=['All Functional Peptides'],\n",
    "            #description='Functions:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(\n",
    "                width='300px',                # Use 100% to take up entire allocated width\n",
    "                height='100px',              # Fixed height\n",
    "                overflow_y='hidden',           # Enable vertical scrollbar when needed\n",
    "                overflow_x='hidden'          # Hide horizontal scrollbar\n",
    "            ),\n",
    "            disabled=True\n",
    "        )\n",
    "        self.function_selector.disabled = True\n",
    "\n",
    "        self.profunc_grid = widgets.GridBox(\n",
    "            [\n",
    "                widgets.VBox(\n",
    "                    [widgets.HTML(\"<u>Select Proteins:</u>\"), self.protein_selector],\n",
    "                    layout=widgets.Layout(width='100%', height='150px')\n",
    "                ),\n",
    "                widgets.VBox(\n",
    "                    [widgets.HTML(\"<u>Select Functions:</u>\"), self.function_selector],\n",
    "                    layout=widgets.Layout(width='100%', height='150px')\n",
    "                )\n",
    "            ],\n",
    "            layout=widgets.Layout(\n",
    "                grid_template_columns=\"1fr 1fr\",\n",
    "                gap=\"10px\",\n",
    "                width=\"650px\",\n",
    "                height=\"auto\",\n",
    "                overflow=\"hidden\"\n",
    "            )\n",
    "        )    \n",
    "        \n",
    "        self.groups_grid = widgets.GridBox(\n",
    "            [\n",
    "                widgets.VBox(\n",
    "                    [widgets.HTML(\"<u>Select Groups:</u>\"), self.group_selector],\n",
    "                    layout=widgets.Layout(width='100%', height='150px')\n",
    "                )\n",
    "            ],\n",
    "            layout=widgets.Layout(\n",
    "                grid_template_columns=\"1fr 1fr\",\n",
    "                gap=\"10px\",\n",
    "                width=\"650px\",\n",
    "                height=\"auto\",\n",
    "                overflow=\"hidden\"\n",
    "            )\n",
    "        )    \n",
    "        \n",
    "        # Selecte between relative and absolute plots\n",
    "        self.metric_type = widgets.RadioButtons(\n",
    "            description='Scale Absorbance:',\n",
    "            options=['Absolute', 'Relative'],\n",
    "            value='Absolute',  # Default selection\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px', height='auto'),\n",
    "            disabled=True,\n",
    "            indent=True  # Keeps options aligned with description instead of appearing below\n",
    "        )                   \n",
    "       \n",
    "\n",
    "    \n",
    "        # Create the checkbox with improved description\n",
    "        self.plot_minor = widgets.Checkbox(\n",
    "            description='Group Unselected Proteins or Functions',\n",
    "            value=True,\n",
    "            indent=False,\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px', height='30px'),\n",
    "            disabled=True\n",
    "        )\n",
    "\n",
    "\n",
    "        # Create a help icon with explanatory tooltip\n",
    "        \n",
    "\n",
    "        # Combine checkbox and help icon into a horizontal layout\n",
    "        self.minor_row = widgets.HBox([\n",
    "            self.plot_minor, \n",
    "        ], layout=widgets.Layout(align_items='center'))\n",
    "\n",
    "        # Add after creating the protein_selector widget\n",
    "        self.populate_protein_selector()\n",
    "\n",
    "\n",
    "        # Update plot type selection to remove 'All Plots'\n",
    "        self.plot_type = widgets.RadioButtons(\n",
    "            options=['Grouped Bar Plots','Stacked Bar Plots', 'Pie Charts', 'Corr. Scatter Plots'],\n",
    "            value='Grouped Bar Plots',\n",
    "            description='Plot Type:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        # Add bar plot type selection\n",
    "        self.abs_or_count = widgets.RadioButtons(\n",
    "            options=['Absorbance', 'Count'],\n",
    "            value='Absorbance', \n",
    "            description='Data Type:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            disabled=True\n",
    "        )\n",
    "\n",
    "       \n",
    "        # Add help tooltips\n",
    "        plot_type_help = create_help_icon(\"Select whether to display data as a bar plot or pie chart\")\n",
    "        bar_plot_type_help = create_help_icon(\"Choose the type of values to display in the bar plot\")\n",
    "        plot_orientation_help = create_help_icon(\"Group data by sample or by protein\")\n",
    "\n",
    "        self.plot_type_row = widgets.HBox([self.plot_type,\n",
    "                                           self.metric_type],\n",
    "                                           layout=widgets.Layout(width='300px')\n",
    "                                          )\n",
    "        self.plot_type_row_two= widgets.HBox([self.abs_or_count,\n",
    "                                           self.invert_plot],\n",
    "                                           layout=widgets.Layout(width='300px')\n",
    "                                          )\n",
    "\n",
    "        self.corr_box = widgets.VBox([\n",
    "                                    #widgets.HTML(\"<u>Correlation Settings:</u>\"), \n",
    "                                    self.log_transform,\n",
    "                                    self.correlation_type],\n",
    "                                    layout=widgets.Layout(width='360px', height='100px', overflow='hidden', margin='0')\n",
    "                                   )\n",
    "\n",
    "    def populate_function_selector(self, change=None):\n",
    "        \"\"\"Populate the function selector with functions ordered by their total absorbance across all samples\"\"\"\n",
    "\n",
    "        if self.all_functions is None:\n",
    "            self.function_selector.options = ['All Functional Peptides']\n",
    "            self.function_selector.value = ('All Functional Peptides',)\n",
    "            return\n",
    "        else:\n",
    "            function_selector = ['All Functional Peptides'] + self.all_functions\n",
    "            self.function_selector.options = [func for func in function_selector if func != 'Minor Functions' and func != 'Functional Peptides' and func != 'Non-Functional Peptides']\n",
    "            self.function_selector.value = ('All Functional Peptides',)\n",
    "\n",
    "    def on_plot_type_change(self, change):\n",
    "        try:\n",
    "            new_value = change.new\n",
    "            old_value = change.old if hasattr(change, 'old') else None\n",
    "            \n",
    "            # Reset disabled states when switching from 'No Filter' to any other option\n",
    "            if old_value == 'No Filter' or old_value == 'Functional vs Non-Functional Peptides':\n",
    "                self.protein_selector.disabled = True\n",
    "                self.function_selector.disabled = True\n",
    "                if self.plot_type.value != 'Pie Charts':\n",
    "                    self.metric_type.disabled = False\n",
    "                self.plot_type.disabled = False\n",
    "                self.invert_plot.disabled = False\n",
    "                self.plot_minor.disabled = False\n",
    "            \n",
    "            # First handle Correlation Scatter Plots case which has special settings\n",
    "            if self.plot_type.value == 'Corr. Scatter Plots':\n",
    "                # Always disable these widgets for correlation plots\n",
    "                self.invert_plot.disabled = True\n",
    "                self.plot_minor.disabled = True\n",
    "                self.plot_minor.value = False\n",
    "                self.metric_type.disabled = True\n",
    "                self.metric_type.value = 'Absolute'\n",
    "                self.abs_or_count.disabled = True\n",
    "                self.abs_or_count.value = 'Absorbance'\n",
    "                self.log_transform.disabled = False\n",
    "                self.correlation_type.disabled = False     \n",
    "\n",
    "                \n",
    "                # Enable appropriate selectors based on filter type\n",
    "                if new_value == 'Both':\n",
    "                    self.protein_selector.disabled = False\n",
    "                    self.function_selector.disabled = False\n",
    "                elif new_value == 'Selected Function(s)':\n",
    "                    self.protein_selector.disabled = True\n",
    "                    self.function_selector.disabled = False\n",
    "                elif new_value == 'Selected Protein(s)':\n",
    "                    self.protein_selector.disabled = False\n",
    "                    self.function_selector.disabled = True\n",
    "                elif new_value == 'No Filter':\n",
    "                    self.protein_selector.disabled = True\n",
    "                    self.function_selector.disabled = True\n",
    "                    self.plot_minor.disabled = True\n",
    "                elif new_value == 'Functional vs Non-Functional Peptides':\n",
    "                    self.protein_selector.disabled = True\n",
    "                    self.plot_minor.disabled = True\n",
    "                    self.plot_minor.value = False\n",
    "                    self.function_selector.disabled = True\n",
    "            elif new_value == 'Pie Charts':\n",
    "                self.log_transform.disabled = True\n",
    "                self.log_transform.value = False\n",
    "                self.correlation_type.disabled = True\n",
    "                self.plot_minor.disabled = False\n",
    "                self.plot_minor.value = False\n",
    "                self.abs_or_count.disabled = False\n",
    "                self.invert_plot.disabled = False\n",
    "\n",
    "\n",
    "            else:                \n",
    "                # For non-correlation plots, enable these controls\n",
    "                self.invert_plot.disabled = False\n",
    "                self.plot_minor.disabled = False\n",
    "                if self.plot_type.value != 'Pie Charts':\n",
    "                    self.metric_type.disabled = False\n",
    "                self.log_transform.disabled = False                      \n",
    "                self.correlation_type.disabled = True\n",
    "                self.abs_or_count.disabled = False\n",
    "                self.plot_minor.disabled = False\n",
    "                self.plot_type.disabled = False\n",
    "\n",
    "                # For non-correlation plots\n",
    "                if new_value == 'Both':\n",
    "                    # Enable both selectors\n",
    "                    self.protein_selector.disabled = False\n",
    "                    self.function_selector.disabled = False\n",
    "                    \n",
    "                    self.populate_protein_selector()\n",
    "                    self.populate_function_selector()\n",
    "\n",
    "                    # Ensure both selectors are enabled and visible\n",
    "                    self.protein_selector.style.text_color = 'black'\n",
    "                    self.function_selector.style.text_color = 'black'\n",
    "                elif new_value == 'Functional vs Non-Functional Peptides':\n",
    "                    self.protein_selector.disabled = True\n",
    "                    self.function_selector.disabled = True\n",
    "                    self.plot_minor.disabled = True\n",
    "                    self.plot_minor.value = False\n",
    "                elif new_value == 'Selected Function(s)':\n",
    "                    # Clear and disable protein selector\n",
    "                    self.protein_selector.value = ['All Proteins (No Filter)']\n",
    "                    self.protein_selector.disabled = True\n",
    "                    # Enable function selector\n",
    "                    self.function_selector.disabled = False\n",
    "\n",
    "\n",
    "                    self.populate_function_selector()\n",
    "                    if self.invert_plot.value == 'By Protein':\n",
    "                        self.invert_plot.value = 'By Function'\n",
    "                        \n",
    "                elif new_value == 'Selected Protein(s)':\n",
    "                    # Clear and disable function selector\n",
    "                    self.function_selector.value = ['All Functional Peptides']\n",
    "                    self.function_selector.disabled = True\n",
    "                    # Enable protein selector\n",
    "                    self.protein_selector.disabled = False\n",
    "                    \n",
    "                    self.populate_protein_selector()\n",
    "                    \n",
    "                    if self.invert_plot.value == 'By Function':\n",
    "                        self.invert_plot.value = 'By Protein'\n",
    "\n",
    "                elif new_value == 'No Filter':\n",
    "                    self.protein_selector.disabled = True\n",
    "                    self.function_selector.disabled = True\n",
    "                    self.plot_minor.value = False\n",
    "                    self.plot_minor.disabled = True\n",
    "                    self.plot_minor.value = False\n",
    "\n",
    "                elif new_value == 'Functional vs Non-Functional Peptides':\n",
    "                    self.plot_minor.disabled = True\n",
    "                    self.plot_minor.value = False\n",
    "                \n",
    "\n",
    "\n",
    "            # Update the widget appearances\n",
    "            self.protein_selector.style.text_color = 'grey' if self.protein_selector.disabled else 'black'\n",
    "            self.function_selector.style.text_color = 'grey' if self.function_selector.disabled else 'black'\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in on_plot_func_or_pro_change: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "                    \n",
    "    def contains_function(self, func_string, target_function):\n",
    "        if not isinstance(func_string, str) or pd.isna(func_string):\n",
    "            return False\n",
    "        funcs = [f.strip() for f in func_string.split(';')]\n",
    "        return target_function in funcs      \n",
    "\n",
    "    def calculate_bioactivt_count_and_dict(self):\n",
    "        \"\"\"Calculate basic function metrics (counts and absorbance) from the dataframe\"\"\"\n",
    "        unique_function_absorbance_dict = {}\n",
    "        unique_function_counts_dict = {}\n",
    "        # Track total bioactivitiesper group\n",
    "        total_functional_peptides_dict = {}\n",
    "        # Track non-bioactive peptides (blank or NA functions)\n",
    "        non_bioactive_absorbance_dict = {}\n",
    "        non_bioactive_counts_dict = {}\n",
    "        # Track total bioactive values for each group\n",
    "        all_bioactives_absorbance_dict = {}\n",
    "        all_bioactives_counts_dict = {}\n",
    "\n",
    "        selected_groups = []\n",
    "        for group in self.group_selector.value:\n",
    "            if group not in selected_groups:\n",
    "                selected_groups.append(group)\n",
    "\n",
    "        # For other modes, use the merged dataframe\n",
    "        df = self.merged_df.copy() if self.merged_df is not None else None\n",
    "       \n",
    "        if df is None:\n",
    "            return\n",
    "        else:\n",
    "             self.full_merged_df = df.copy()            \n",
    "        # Process group data\n",
    "        for column, grouping_variable in zip(self.avg_columns, self.stripped_columns):\n",
    "            \n",
    "            # Initialize counters for this group\n",
    "            total_functional_peptides_dict[grouping_variable] = 0\n",
    "            non_bioactive_absorbance_dict[grouping_variable] = 0\n",
    "            non_bioactive_counts_dict[grouping_variable] = 0\n",
    "            all_bioactives_absorbance_dict[grouping_variable] = 0\n",
    "            all_bioactives_counts_dict[grouping_variable] = 0\n",
    "            \n",
    "            # Filter all data with valid abundance values\n",
    "            temp_df = df[['unique ID', 'function', column]].copy()\n",
    "            temp_df = temp_df[\n",
    "                (temp_df[column] != 0) & \n",
    "                temp_df[column].notna()\n",
    "            ]\n",
    "            \n",
    "            if temp_df.empty:\n",
    "                continue\n",
    "                    \n",
    "            # Identify non-bioactive peptides (blank or NA functions)\n",
    "            non_bioactive_mask = temp_df['function'].isna() | (temp_df['function'] == '')\n",
    "            non_bioactive_df = temp_df[non_bioactive_mask]\n",
    "            \n",
    "            # Calculate non-bioactive metrics\n",
    "            if not non_bioactive_df.empty:\n",
    "                non_bioactive_absorbance_dict[grouping_variable] = non_bioactive_df[column].sum()\n",
    "                non_bioactive_counts_dict[grouping_variable] = non_bioactive_df['unique ID'].nunique()\n",
    "            \n",
    "            # Filter for bioactive (valid function) peptides\n",
    "            bioactive_df = temp_df[~non_bioactive_mask & temp_df['function'].notna()]\n",
    "            \n",
    "            if bioactive_df.empty:\n",
    "                continue\n",
    "                    \n",
    "            # Calculate total bioactive metrics for the group (before handling individual functions)\n",
    "            all_bioactives_absorbance_dict[grouping_variable] = bioactive_df[column].sum()\n",
    "            all_bioactives_counts_dict[grouping_variable] = bioactive_df['unique ID'].nunique()\n",
    "            \n",
    "            # Drop duplicates to get unique peptide counts\n",
    "            unique_peptides_df = bioactive_df.drop_duplicates(subset='unique ID')\n",
    "            \n",
    "            # Count total unique bioactivitiesfor this group\n",
    "            total_functional_peptides_dict[grouping_variable] = unique_peptides_df['unique ID'].nunique()\n",
    "            \n",
    "            # Process functions for both absorbance and counts\n",
    "            for df_to_process, result_dict in [\n",
    "                (bioactive_df, unique_function_absorbance_dict),\n",
    "                (unique_peptides_df, unique_function_counts_dict)\n",
    "            ]:\n",
    "            \n",
    "                # Get all unique functions from the dataset\n",
    "                all_functions = set()\n",
    "                for func_str in df_to_process['function'].dropna():\n",
    "                    if isinstance(func_str, str):\n",
    "                        funcs = [f.strip() for f in func_str.split(';') if f.strip()]\n",
    "                        all_functions.update(funcs)\n",
    "                \n",
    "                # For each function, find peptides that contain it using contains_function\n",
    "                for func in all_functions:\n",
    "                    matching_rows = df_to_process[df_to_process['function'].apply(\n",
    "                        lambda x: self.contains_function(x, func)\n",
    "                    )]\n",
    "                    \n",
    "                    if not matching_rows.empty:\n",
    "                        if result_dict is unique_function_absorbance_dict:\n",
    "                            # Sum absorbance values\n",
    "                            total_absorbance = matching_rows[column].sum()\n",
    "                            if grouping_variable not in result_dict:\n",
    "                                result_dict[grouping_variable] = {}\n",
    "                            result_dict[grouping_variable][func] = total_absorbance\n",
    "                        else:\n",
    "                            # Count unique peptides per function\n",
    "                            unique_count = matching_rows['unique ID'].nunique()\n",
    "                            if grouping_variable not in result_dict:\n",
    "                                result_dict[grouping_variable] = {}\n",
    "                            result_dict[grouping_variable][func] = unique_count\n",
    "        \n",
    "        # Add non_bioactive and all_bioactives to the dictionaries\n",
    "        for group in selected_groups:\n",
    "            # Non-bioactive\n",
    "            if group in non_bioactive_absorbance_dict:\n",
    "                if group not in unique_function_absorbance_dict:\n",
    "                    unique_function_absorbance_dict[group] = {}\n",
    "                unique_function_absorbance_dict[group]['Non-Functional Peptides'] = non_bioactive_absorbance_dict[group]\n",
    "                \n",
    "            if group in non_bioactive_counts_dict:\n",
    "                if group not in unique_function_counts_dict:\n",
    "                    unique_function_counts_dict[group] = {}\n",
    "                unique_function_counts_dict[group]['Non-Functional Peptides'] = non_bioactive_counts_dict[group]\n",
    "            \n",
    "            # All bioactives\n",
    "            if group in all_bioactives_absorbance_dict:\n",
    "                if group not in unique_function_absorbance_dict:\n",
    "                    unique_function_absorbance_dict[group] = {}\n",
    "                unique_function_absorbance_dict[group]['Functional Peptides'] = all_bioactives_absorbance_dict[group]\n",
    "                \n",
    "            if group in all_bioactives_counts_dict:\n",
    "                if group not in unique_function_counts_dict:\n",
    "                    unique_function_counts_dict[group] = {}\n",
    "                unique_function_counts_dict[group]['Functional Peptides'] = all_bioactives_counts_dict[group]\n",
    "                    \n",
    "        # Sort the functions within each group in descending order\n",
    "        for group, functions in unique_function_counts_dict.items():\n",
    "            unique_function_counts_dict[group] = dict(sorted(functions.items(), key=lambda x: x[1], reverse=True))\n",
    "        \n",
    "        for group, functions in unique_function_absorbance_dict.items():\n",
    "            unique_function_absorbance_dict[group] = dict(sorted(functions.items(), key=lambda x: x[1], reverse=True))\n",
    "                \n",
    "        # Store the results\n",
    "        self.unique_function_absorbance_dict = unique_function_absorbance_dict\n",
    "        self.unique_function_counts_dict = unique_function_counts_dict\n",
    "        self.total_functional_peptides_dict = total_functional_peptides_dict\n",
    "\n",
    "    def get_single_color(self):\n",
    "        \"\"\"Get the first color from the selected scheme.\"\"\"\n",
    "        try:\n",
    "            # Get the selected color scheme\n",
    "            if hasattr(self, 'color_scheme') and self.color_scheme.value:\n",
    "                scheme = self.color_scheme.value\n",
    "\n",
    "          \n",
    "            # Carolina Blue\n",
    "            carolina_blue = '#7BAFD4'\n",
    "            \n",
    "            # Check for single color schemes\n",
    "            if scheme.lower() not in self.single_color_scheme:\n",
    "                # Display error message to notify user to choose new options\n",
    "                warning_html = f\"\"\"\n",
    "                <div style='color: #856404; background-color: #fff3cd; border: 1px solid #ffeeba; border-radius: 4px; padding: 10px; margin: 10px 0;'>\n",
    "                    <strong>Warning:</strong> Please choose a single color scheme otherwise Carolina Blue will be used by defualt.<br>\n",
    "                </div>\n",
    "                \"\"\"  \n",
    "                display(HTML(warning_html))\n",
    "                return carolina_blue\n",
    "            else:\n",
    "                return scheme\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting color: {e}\")\n",
    "            # Fallback to Carolina Blue\n",
    "            return '#7BAFD4'  # Carolina Blue\n",
    "    \n",
    "    def get_color_sequence(self, n_colors, ncolor=None):\n",
    "        \"\"\"Get color sequence based on selected scheme.\n",
    "        \n",
    "        Args:\n",
    "            n_colors: Number of colors to generate\n",
    "            ncolor: Alternative parameter name for backward compatibility\n",
    "            \n",
    "        Returns:\n",
    "            List of color strings in the selected scheme\n",
    "        \"\"\"\n",
    "        # Use ncolor parameter if provided (for backward compatibility)\n",
    "        n_colors = ncolor if ncolor is not None else n_colors\n",
    "        \n",
    "        if n_colors <= 0:\n",
    "            return []\n",
    "            \n",
    "        try:\n",
    "            # Get the selected color scheme\n",
    "            scheme = 'HSV'  # Default scheme\n",
    "            if hasattr(self, 'color_scheme') and self.color_scheme.value:\n",
    "                scheme = self.color_scheme.value\n",
    "            \n",
    "            if scheme.lower() in self.single_color_scheme:\n",
    "                # Display error message to notify user to choose new options\n",
    "                warning_html = f\"\"\"\n",
    "                <div style='color: #856404; background-color: #fff3cd; border: 1px solid #ffeeba; border-radius: 4px; padding: 10px; margin: 10px 0;'>\n",
    "                    <strong>Warning:</strong> Please choose from a color pallette not a single color. Otherwise 'HSV' pallette will be used by defualt.<br>\n",
    "                </div>\n",
    "                \"\"\"  \n",
    "                display(HTML(warning_html))\n",
    "\n",
    "            # Skip header options that start with '---'\n",
    "            if scheme.startswith('---'):\n",
    "                scheme = 'HSV'  # Default to HSV if a header is selected\n",
    "            \n",
    "            # Handle special cases\n",
    "            if scheme.lower() in ['rainbow', 'hsv']:\n",
    "                return [f'hsl({h},70%,60%)' for h in np.linspace(0, 330, n_colors)]\n",
    "            \n",
    "            # Try qualitative color scales first (best for categorical data)\n",
    "            color_sequence = getattr(px.colors.qualitative, scheme, None)\n",
    "            if color_sequence is None:\n",
    "                # Try sequential color scales\n",
    "                color_sequence = getattr(px.colors.sequential, scheme, None)\n",
    "            if color_sequence is None:\n",
    "                # Try diverging color scales\n",
    "                color_sequence = getattr(px.colors.diverging, scheme, None)\n",
    "            if color_sequence is None:\n",
    "                # Try cyclical color scales\n",
    "                color_sequence = getattr(px.colors.cyclical, scheme, None)\n",
    "            \n",
    "            if color_sequence:\n",
    "                if n_colors >= len(color_sequence):\n",
    "                    # If we need more colors than available, interpolate\n",
    "                    indices = np.linspace(0, len(color_sequence)-1, n_colors)\n",
    "                    return [color_sequence[int(i)] for i in indices]\n",
    "                else:\n",
    "                    # If we need fewer colors, take a subset\n",
    "                    indices = np.linspace(0, len(color_sequence)-1, n_colors, dtype=int)\n",
    "                    return [color_sequence[i] for i in indices]\n",
    "            \n",
    "            # Default to HSV if no matching scheme found\n",
    "\n",
    "            return [f'hsl({h},70%,60%)' for h in np.linspace(0, 330, n_colors)]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating colors: {e}\")\n",
    "            # Fallback to HSV\n",
    "\n",
    "            return [f'hsl({h},70%,60%)' for h in np.linspace(0, 330, n_colors)]\n",
    "    \n",
    "    def calculate_group_metrics(self):\n",
    "        \"\"\"Calculate summed and relative metrics for each group in the filtered dataframe.\"\"\"\n",
    "       \n",
    "        if self.plot_func_or_pro.value == 'No Filter':\n",
    "            self.filtered_df = self.merged_df.copy()\n",
    "        try:\n",
    "            # Identify group columns (they start with 'Avg_')\n",
    "            group_cols = [col for col in self.filtered_df.columns if col.startswith('Avg_')]\n",
    "            if not group_cols:\n",
    "                print(\"No group columns (Avg_*) found in dataframe\")\n",
    "                return None\n",
    "                \n",
    "            # Initialize results dictionary\n",
    "            group_metrics = {}\n",
    "            \n",
    "            # Calculate total abundance and counts for each group\n",
    "            for col in group_cols:\n",
    "                group_name = col.replace('Avg_', '')  # Remove 'Avg_' prefix\n",
    "                \n",
    "                # Calculate abundance metrics\n",
    "                total_abundance = self.filtered_df[col].sum()\n",
    "                non_zero_peptides = self.filtered_df[\n",
    "                    (self.filtered_df[col].notna()) & \n",
    "                    (self.filtered_df[col] > 0)\n",
    "                ]['unique ID'].nunique()\n",
    "                \n",
    "                # Store metrics\n",
    "                group_metrics[group_name] = {\n",
    "                    'total_abundance': total_abundance,\n",
    "                    'unique_peptides': non_zero_peptides\n",
    "                }\n",
    "            \n",
    "            # Calculate relative metrics\n",
    "            total_abundance_all = sum(m['total_abundance'] for m in group_metrics.values())\n",
    "            total_peptides_all = sum(m['unique_peptides'] for m in group_metrics.values())\n",
    "            \n",
    "            # Add relative metrics to each group\n",
    "            for group_name, metrics in group_metrics.items():\n",
    "                metrics['relative_abundance'] = (metrics['total_abundance'] / total_abundance_all * 100 \n",
    "                                            if total_abundance_all > 0 else 0)\n",
    "                metrics['relative_peptides'] = (metrics['unique_peptides'] / total_peptides_all * 100 \n",
    "                                            if total_peptides_all > 0 else 0)\n",
    "            \n",
    "            # Debug output\n",
    "            #print(\"\\nGroup Metrics Summary:\")\n",
    "            #print(f\"Total abundance across all groups: {total_abundance_all:.2e}\")\n",
    "            #print(f\"Total unique peptides across all groups: {total_peptides_all}\")\n",
    "            #print(\"\\nPer-group metrics:\")\n",
    "            #for group, metrics in group_metrics.items():\n",
    "                #print(f\"\\n{group}:\")\n",
    "                #print(f\"  Total abundance: {metrics['total_abundance']:.2e}\")\n",
    "                #print(f\"  Unique peptides: {metrics['unique_peptides']}\")\n",
    "                #print(f\"  Relative abundance: {metrics['relative_abundance']:.2f}%\")\n",
    "                #print(f\"  Relative peptides: {metrics['relative_peptides']:.2f}%\")\n",
    "                \n",
    "            return group_metrics\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating group metrics: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "    def create_function_df(self):\n",
    "        \"\"\"\n",
    "        Creates a DataFrame for functions similar to protein_df when by_sample is selected.\n",
    "        Updates self.function_df with the results.\n",
    "        \"\"\"\n",
    "        # Get all unique functions and groups\n",
    "\n",
    "        selected_groups = self.group_selector.value\n",
    "\n",
    "        \n",
    "        # Create initial data structure for DataFrame\n",
    "        data = []\n",
    "        \n",
    "        if self.plot_func_or_pro.value == 'Functional vs Non-Functional Peptides':\n",
    "            all_functions = ['Functional Peptides', 'Non-Functional Peptides']           \n",
    "        else:\n",
    "            all_functions = [func for func in self.all_functions if func != 'Functional Peptides' and func != 'Non-Functional Peptides']\n",
    "        # Process each function\n",
    "        for function in all_functions:\n",
    "            row_data = {\n",
    "                'Description': function  # Similar to Protein_ID in protein_df\n",
    "            }\n",
    "            \n",
    "            # Add absorbance columns and their relative values\n",
    "            for group in selected_groups:\n",
    "                # Absorbance columns\n",
    "                avg_col = f'Avg_{group}'\n",
    "                rel_avg_col = f'Rel_Avg_{group}'\n",
    "                # Get absorbance value\n",
    "                absorbance = self.unique_function_absorbance_dict.get(group, {}).get(function, 0)\n",
    "                \n",
    "                row_data[avg_col] = absorbance\n",
    "                \n",
    "                # Calculate relative absorbance (will update after collecting all data)\n",
    "                row_data[rel_avg_col] = 0.0\n",
    "                \n",
    "                # Count columns\n",
    "                count_col = f'Count_{group}'\n",
    "                rel_count_col = f'Rel_Count_{group}'\n",
    "                \n",
    "                # Get count value\n",
    "                count = self.unique_function_counts_dict.get(group, {}).get(function, 0)\n",
    "                row_data[count_col] = count\n",
    "                \n",
    "                # Calculate relative count (will update after collecting all data)\n",
    "                row_data[rel_count_col] = 0.0\n",
    "            \n",
    "            data.append(row_data)\n",
    "        # Create DataFrame\n",
    "        self.function_df = pd.DataFrame(data)\n",
    "        \n",
    "        # Calculate relative values for each group\n",
    "        for group in selected_groups:\n",
    "            avg_col = f'Avg_{group}'\n",
    "            rel_avg_col = f'Rel_Avg_{group}'\n",
    "            count_col = f'Count_{group}'\n",
    "            rel_count_col = f'Rel_Count_{group}'\n",
    "            \n",
    "            # Calculate total absorbance and count for this group\n",
    "            total_absorbance = self.function_df[avg_col].sum()\n",
    "            total_count = self.function_df[count_col].sum()\n",
    "            \n",
    "            # Calculate relative values\n",
    "            if total_absorbance > 0:\n",
    "                self.function_df[rel_avg_col] = (self.function_df[avg_col] / total_absorbance * 100).round(6)\n",
    "            \n",
    "            if total_count > 0:\n",
    "                self.function_df[rel_count_col] = (self.function_df[count_col] / total_count * 100).round(6)\n",
    "        \n",
    "        # Sort by total absorbance across all groups (similar to protein_df)\n",
    "        absorbance_cols = [col for col in self.function_df.columns if col.startswith('Avg_')]\n",
    "        self.function_df['avg_absorbance_all'] = (\n",
    "            self.function_df[absorbance_cols].sum(axis=1) / \n",
    "            self.function_df[absorbance_cols].sum().sum() * 100\n",
    "        ).round(6)\n",
    "        \n",
    "        # Sort by total absorbance\n",
    "        self.function_df = self.function_df.sort_values('avg_absorbance_all', ascending=False)\n",
    "        \n",
    "        use_all_functions = False\n",
    "        # Handle Minor Functions if needed\n",
    "        selected_functions = list(self.function_selector.value)\n",
    "        selected_functions = [f for f in selected_functions if f != '---Select Individual Functions---']\n",
    "        if self.plot_type.value != 'Functional vs Non-Functional Peptides':\n",
    "            if self.plot_minor.value  == True:\n",
    "                if 'All Functional Peptides' in selected_functions:\n",
    "                    selected_functions = self.all_functions\n",
    "                    use_all_functions = 'All Functional Peptides' in selected_functions\n",
    "\n",
    "                selected_functions = selected_functions.remove('All Functional Peptides') if 'All Functional Peptides' in selected_functions else selected_functions\n",
    "                if len(selected_functions) != self.all_functions:\n",
    "                    self.selected_functions = selected_functions.append('Minor Functions')\n",
    "\n",
    "            else: # if plot_minor is False\n",
    "\n",
    "                if 'All Functional Peptides' in selected_functions:\n",
    "                    selected_functions = self.all_functions\n",
    "                    use_all_functions = True\n",
    "                    selected_functions = [f for f in selected_functions if f != 'All Functional Peptides'] if 'All Functional Peptides' in selected_functions else selected_functions\n",
    "                selected_functions = [f for f in selected_functions if f != 'Minor Functions'] if 'Minor Functions' in selected_functions else selected_functions\n",
    "            if self.plot_func_or_pro.value == 'No Filter':\n",
    "                selected_functions = self.all_functions\n",
    "            if (len(selected_functions) - 1) == len(self.all_functions):\n",
    "                selected_functions = [f for f in selected_functions if f != 'Minor Functions'] if 'Minor Functions' in selected_functions else selected_functions\n",
    "        else:\n",
    "            selected_functions = ['All Functional Peptides', 'Non-Functional Peptides']\n",
    "        # Preserve order but remove redundant minor function occurrences\n",
    "        self.selected_functions = []\n",
    "        for func in selected_functions:\n",
    "            if func not in self.selected_functions:\n",
    "                self.selected_functions.append(func)\n",
    "        \n",
    "        if self.plot_func_or_pro.value != 'No Filter' or self.plot_func_or_pro.value != 'Functional vs Non-Functional Peptides':\n",
    "        \n",
    "            if not use_all_functions:\n",
    "                major_functions = [f for f in selected_functions if f != 'All Functional Peptides']\n",
    "                major_functions.remove('Minor Functions') if 'Minor Functions' in major_functions else major_functions\n",
    "                minor_functions_data = {\n",
    "                    'Description': 'Minor Functions'\n",
    "                }\n",
    "                # Calculate aggregated values for minor functions\n",
    "                for group in selected_groups:\n",
    "                    avg_col = f'Avg_{group}'\n",
    "                    rel_avg_col = f'Rel_Avg_{group}'\n",
    "                    count_col = f'Count_{group}'\n",
    "                    rel_count_col = f'Rel_Count_{group}'\n",
    "                    \n",
    "                    # Filter minor functions\n",
    "                    minor_mask = ~self.function_df['Description'].isin(major_functions)\n",
    "                    minor_functions = self.function_df[minor_mask]\n",
    "                    \n",
    "                    # Sum values for minor functions\n",
    "                    minor_functions_data[avg_col] = minor_functions[avg_col].sum()\n",
    "                    minor_functions_data[count_col] = minor_functions[count_col].sum()\n",
    "                    \n",
    "                    # Calculate relative values\n",
    "                    total_absorbance = self.function_df[avg_col].sum()\n",
    "                    total_count = self.function_df[count_col].sum()\n",
    "                    \n",
    "                    if total_absorbance > 0:\n",
    "                        minor_functions_data[rel_avg_col] = (minor_functions_data[avg_col] / total_absorbance * 100)\n",
    "                    else:\n",
    "                        minor_functions_data[rel_avg_col] = 0.0\n",
    "                        \n",
    "                    if total_count > 0:\n",
    "                        minor_functions_data[rel_count_col] = (minor_functions_data[count_col] / total_count * 100)\n",
    "                    else:\n",
    "                        minor_functions_data[rel_count_col] = 0.0\n",
    "                \n",
    "                # Calculate avg_absorbance_all for Minor Functions\n",
    "                absorbance_sum = sum(minor_functions_data[col] for col in absorbance_cols)\n",
    "                total_absorbance_sum = self.function_df[absorbance_cols].sum().sum()\n",
    "                if total_absorbance_sum > 0:\n",
    "                    minor_functions_data['avg_absorbance_all'] = (absorbance_sum / total_absorbance_sum * 100)\n",
    "                else:\n",
    "                    minor_functions_data['avg_absorbance_all'] = 0.0\n",
    "                \n",
    "                # Remove minor functions from main DataFrame and add aggregated Minor Functions row\n",
    "                self.function_df = self.function_df[self.function_df['Description'].isin(major_functions)]\n",
    "                self.function_df = safe_concat([\n",
    "                    self.function_df,\n",
    "                    pd.DataFrame([minor_functions_data])\n",
    "                ], ignore_index=True)\n",
    "        \n",
    "        elif self.plot_type.value == 'Functional vs Non-Functional Peptides':\n",
    "            # Create a simplified DataFrame with just two rows: functional and non-functional\n",
    "            func_data = []\n",
    "            self.function_df = pd.DataFrame()\n",
    "            for group in selected_groups:\n",
    "                # Extract the values from dictionaries\n",
    "                if group in self.unique_function_absorbance_dict and group in self.unique_function_counts_dict:\n",
    "                    # Get non-bioactive values\n",
    "                    non_bioactive_abs = self.unique_function_absorbance_dict[group].get('Non-Functional Peptides', 0)\n",
    "                    non_bioactive_count = self.unique_function_counts_dict[group].get('Non-Functional Peptides', 0)\n",
    "                    \n",
    "                    # Get all bioactive values\n",
    "                    all_bioactive_abs = self.unique_function_absorbance_dict[group].get('Functional Peptides', 0)\n",
    "                    all_bioactive_count = self.unique_function_counts_dict[group].get('Functional Peptides', 0)\n",
    "                    \n",
    "                    # Add functional row\n",
    "                    func_row = {\n",
    "                        'Description': 'All Functional Peptides',\n",
    "                        f'Avg_{group}': all_bioactive_abs,\n",
    "                        f'Count_{group}': all_bioactive_count\n",
    "                    }\n",
    "                    \n",
    "                    # Add non-functional row\n",
    "                    non_func_row = {\n",
    "                        'Description': 'Non-Functional Peptides',\n",
    "                        f'Avg_{group}': non_bioactive_abs,\n",
    "                        f'Count_{group}': non_bioactive_count\n",
    "                    }\n",
    "                    \n",
    "                    # Add rows if they don't exist yet\n",
    "                    if not func_data:\n",
    "                        func_data.append(func_row)\n",
    "                        func_data.append(non_func_row)\n",
    "                    else:\n",
    "                        # Update existing rows with additional group data\n",
    "                        func_data[0].update({\n",
    "                            f'Avg_{group}': all_bioactive_abs,\n",
    "                            f'Count_{group}': all_bioactive_count\n",
    "                        })\n",
    "                        func_data[1].update({\n",
    "                            f'Avg_{group}': non_bioactive_abs,\n",
    "                            f'Count_{group}': non_bioactive_count\n",
    "                        })\n",
    "            \n",
    "            # Create new DataFrame with just these two rows\n",
    "            self.function_df = pd.DataFrame(func_data)\n",
    "            \n",
    "            # Calculate relative values for each group\n",
    "            for group in selected_groups:\n",
    "                avg_col = f'Avg_{group}'\n",
    "                rel_avg_col = f'Rel_Avg_{group}'\n",
    "                count_col = f'Count_{group}'\n",
    "                rel_count_col = f'Rel_Count_{group}'\n",
    "                \n",
    "                # Calculate total absorbance and count for this group\n",
    "                total_absorbance = self.function_df[avg_col].sum()\n",
    "                total_count = self.function_df[count_col].sum()\n",
    "                \n",
    "                # Calculate relative values\n",
    "                if total_absorbance > 0:\n",
    "                    self.function_df[rel_avg_col] = (self.function_df[avg_col] / total_absorbance * 100).round(6)\n",
    "                \n",
    "                if total_count > 0:\n",
    "                    self.function_df[rel_count_col] = (self.function_df[count_col] / total_count * 100).round(6)\n",
    "            \n",
    "            # Calculate average absorbance across all groups for sorting\n",
    "            absorbance_cols = [col for col in self.function_df.columns if col.startswith('Avg_')]\n",
    "            if not self.function_df.empty and absorbance_cols:\n",
    "                total_sum = self.function_df[absorbance_cols].sum().sum()\n",
    "                if total_sum > 0:\n",
    "                    self.function_df['avg_absorbance_all'] = (\n",
    "                        self.function_df[absorbance_cols].sum(axis=1) / total_sum * 100\n",
    "                    ).round(6)\n",
    "                else:\n",
    "                    self.function_df['avg_absorbance_all'] = 0\n",
    "            \n",
    "            # Set the selected functions list for proper filtering and legend\n",
    "            self.selected_functions = ['All Functional Peptides', 'Non-Functional Peptides']            \n",
    "        \n",
    "        return self.function_df\n",
    "    \n",
    "    def get_selected_proteins(self):\n",
    "        \"\"\"Get the list of proteins to plot based on user selection\"\"\"\n",
    "        selected_proteins = []\n",
    "\n",
    "        all_proteins = self.all_proteins\n",
    "        \n",
    "        if self.plot_func_or_pro.value == 'Selected Protein(s)' or self.plot_func_or_pro.value == 'Both':\n",
    "            if hasattr(self, 'protein_selector'):\n",
    "                if self.protein_selector.value:\n",
    "                    selected = list(self.protein_selector.value)\n",
    "                    \n",
    "                    # Handle 'All' selection\n",
    "                    if 'All Proteins (No Filter)' in selected:\n",
    "                        selected_proteins = all_proteins.copy()\n",
    "                    else:\n",
    "                        selected_proteins = selected.copy()\n",
    "                        \n",
    "                        # Add Minor Proteins if needed\n",
    "                        if self.plot_minor.value and len(selected_proteins) != len(all_proteins):\n",
    "                            if 'Minor Proteins' not in selected_proteins:\n",
    "                                selected_proteins.append('Minor Proteins')\n",
    "                else:\n",
    "                    selected_proteins = all_proteins.copy()\n",
    "            else:\n",
    "                selected_proteins = all_proteins.copy()\n",
    "        else:\n",
    "            selected_proteins = all_proteins.copy()\n",
    "        \n",
    "        # Preserve order but remove redundant protein occurrences\n",
    "        self.selected_proteins = []\n",
    "        for pro in selected_proteins:\n",
    "            if pro not in self.selected_proteins:\n",
    "                self.selected_proteins.append(pro)\n",
    "        \n",
    "        return self.selected_proteins  # Return the list for immediate use\n",
    "    \n",
    "    def process_protein_data(self):\n",
    "        if self.merged_df is None or not self.protein_dict:\n",
    "            return False\n",
    "\n",
    "        # First, update the protein list to plot\n",
    "        selected_proteins = self.get_selected_proteins()\n",
    "        # For other modes, use the merged dataframe\n",
    "        df = self.merged_df.copy() if self.merged_df is not None else None\n",
    "\n",
    "\n",
    "        # Get Absorbance columns based on selected groups\n",
    "        selected_groups = self.group_selector.value\n",
    "        if selected_groups:\n",
    "            Absorbance_cols = [f'Avg_{var}' for var in self.group_selector.value]\n",
    "        for col in self.avg_columns:\n",
    "            if col not in Absorbance_cols:\n",
    "                df.drop(columns=[col], inplace=True)    \n",
    "        \n",
    "        # Filter rows based on selected proteins\n",
    "        filtered_rows = []\n",
    "        for index, row in df.iterrows():\n",
    "            if row['protein_name'] not in selected_proteins:\n",
    "                filtered_rows.append(index)\n",
    "        \n",
    "        if filtered_rows:\n",
    "            df_filtered_by_proteinds = df.drop(index=filtered_rows)\n",
    "            #if self.plot_minor.value:\n",
    "            #    df = df_filtered_by_proteinds.copy()\n",
    "\n",
    "        df['Total_Absorbance'] = df[Absorbance_cols].sum(axis=1).astype(int)\n",
    "        \n",
    "        # Filter out zero Absorbance entries\n",
    "        result_df = df[['unique ID', 'Total_Absorbance']]\n",
    "        result_df = result_df[result_df['Total_Absorbance'] == 0]\n",
    "        all_zero_list = list(result_df['unique ID'])\n",
    "        peptides_df = df[~df['unique ID'].isin(all_zero_list)]\n",
    "\n",
    "        # Process protein positions and create proteins DataFrame\n",
    "        additional_columns = ['Master Protein Accessions', 'unique ID']\n",
    "        selected_columns = additional_columns + Absorbance_cols\n",
    "        \n",
    "        peptides_df.loc[:, 'Master Protein Accessions'] = peptides_df['Master Protein Accessions']\n",
    "        \n",
    "        temp_df = peptides_df.copy()\n",
    "        temp_df.loc[:, 'Protein_ID'] = temp_df['Master Protein Accessions']\n",
    "        \n",
    "        # Create proteins DataFrame with selected columns\n",
    "        self.protein_df = temp_df.groupby('Protein_ID').agg(\n",
    "            {**{col: 'first' for col in ['Master Protein Accessions']},\n",
    "            **{col: 'sum' for col in Absorbance_cols}}\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Calculate relative Absorbance for selected groups\n",
    "        for col in Absorbance_cols:\n",
    "            col_sum = self.protein_df[col].sum()\n",
    "            if col_sum > 0:  # Avoid division by zero\n",
    "                self.protein_df[f'Rel_{col}'] = (self.protein_df[col] / col_sum) * 100\n",
    "            else:\n",
    "                self.protein_df[f'Rel_{col}'] = 0\n",
    "                \n",
    "        # Create sum DataFrame for selected groups\n",
    "        self.sum_df = pd.DataFrame({\n",
    "            'Sample': Absorbance_cols,\n",
    "            'Total_Sum': [self.protein_df[col].sum() for col in Absorbance_cols]\n",
    "        })\n",
    "        \n",
    "\n",
    "        name_list = []\n",
    "        for _, row in self.protein_df.iterrows():\n",
    "            if ',' in row['Protein_ID']:\n",
    "                strrow = row['Protein_ID'].split(',')\n",
    "                named_combo = self._fetch_protein_names('; '.join(strrow))\n",
    "            else:\n",
    "                named_combo = self._fetch_protein_names(row['Protein_ID'])\n",
    "            name_list.append(named_combo)\n",
    "        \n",
    "        # Drop the 'Protein_ID' column\n",
    "        self.protein_df = self.protein_df.drop(columns=['Protein_ID'])    \n",
    "        \n",
    "        self.protein_df['Description'] = name_list\n",
    "        self.protein_df['Description'] = self.protein_df['Description'].astype(str).str.replace(r\"['\\['\\]]\", \"\", regex=True)\n",
    "        \n",
    "        # Calculate average Absorbance for sorting using only selected groups\n",
    "       \n",
    "        # Calculate sum of all selected columns\n",
    "        total_sum = self.protein_df[Absorbance_cols].sum().sum()\n",
    "        \n",
    "        # Calculate row sums\n",
    "        row_sums = self.protein_df[Absorbance_cols].sum(axis=1)\n",
    "        \n",
    "        # Calculate relative percentage contribution\n",
    "        self.protein_df['avg_absorbance_all'] = (row_sums / total_sum * 100).round(2)\n",
    "        \n",
    "        # Sort proteins by abundance for consistent ordering\n",
    "        self.protein_df = self.protein_df.sort_values('avg_absorbance_all', ascending=False)\n",
    "                                \n",
    "        # Create a dictionary to store the actual peptide counts per group\n",
    "        self.protein_count_bysample_dict = {}\n",
    "        \n",
    "        # Dictionary to store unique peptide counts per protein\n",
    "        self.protein_count_byprotein_dict = {}\n",
    "        \n",
    "        # Track which peptides belong to which proteins\n",
    "        protein_to_peptides = defaultdict(set)\n",
    "        \n",
    "        # Track which peptides belong to which proteins in each group\n",
    "        protein_to_group_peptides = defaultdict(lambda: defaultdict(set))\n",
    "        \n",
    "        # Determine counts based on merged_df and add to protein_df\n",
    "        if selected_groups and self.protein_df is not None and df is not None:\n",
    "            # Add count columns to the protein_df (initialize with zeros)\n",
    "            for group in selected_groups:\n",
    "                count_col = f'Count_{group}'\n",
    "                rel_count_col = f'Rel_Count_{group}'\n",
    "                # Initialize with float64 dtype\n",
    "                self.protein_df[count_col] = pd.Series(dtype='float64')\n",
    "                self.protein_df[rel_count_col] = pd.Series(dtype='float64')\n",
    "                # Set initial values to 0.0\n",
    "                self.protein_df[count_col] = 0.0\n",
    "                self.protein_df[rel_count_col] = 0.0\n",
    "            \n",
    "            # Create a mapping from accession to protein index in protein_df\n",
    "            accession_to_idx = {}\n",
    "            accession_to_description = {}  # Map accessions to descriptions for counting\n",
    "            for idx, row in self.protein_df.iterrows():\n",
    "                if 'Master Protein Accessions' in row and pd.notna(row['Master Protein Accessions']):\n",
    "                    accession_to_idx[row['Master Protein Accessions']] = idx\n",
    "                    accession_to_description[row['Master Protein Accessions']] = row['Description']\n",
    "                elif 'Accession' in row and pd.notna(row['Accession']):\n",
    "                    accession_to_idx[row['Accession']] = idx\n",
    "                    accession_to_description[row['Accession']] = row['Description']\n",
    "            \n",
    "            # For each group, count peptides per protein\n",
    "            for group in selected_groups:\n",
    "                # Filter peptides that are present in this group\n",
    "                group_peptides = df[df[f'Avg_{group}'] > 0]\n",
    "                \n",
    "                # Store the total number of peptides for this group\n",
    "                self.protein_count_bysample_dict[group] = len(group_peptides)\n",
    "                \n",
    "                # Track which peptides have already been counted\n",
    "                counted_peptides = set()\n",
    "                \n",
    "                # Track warning stats\n",
    "                peptides_with_no_accession = 0\n",
    "                peptides_with_no_id = 0\n",
    "                peptides_already_counted = 0\n",
    "                peptides_with_multi_accessions = set()\n",
    "                peptides_with_no_protein_match = 0\n",
    "                \n",
    "                # Count peptides for each protein\n",
    "                for _, peptide in group_peptides.iterrows():\n",
    "                    if 'Master Protein Accessions' not in peptide or pd.isna(peptide['Master Protein Accessions']):\n",
    "                        peptides_with_no_accession += 1\n",
    "                        continue\n",
    "                        \n",
    "                    # Get unique peptide ID to track counting\n",
    "                    peptide_id = peptide.get('unique ID', None)\n",
    "                    if peptide_id is None or pd.isna(peptide_id):\n",
    "                        peptides_with_no_id += 1\n",
    "                        continue  # Skip if no unique ID\n",
    "                    \n",
    "                    # Skip if we've already counted this peptide for this group\n",
    "                    if peptide_id in counted_peptides:\n",
    "                        peptides_already_counted += 1\n",
    "                        continue\n",
    "                    \n",
    "                    accession = peptide['Master Protein Accessions']\n",
    "                    found_match = False\n",
    "                    \n",
    "                    # Check if this peptide maps to multiple proteins\n",
    "                    if ';' in accession:\n",
    "                        peptides_with_multi_accessions.add(peptide_id)\n",
    "                        accessions = [acc.strip() for acc in accession.split(';') if acc.strip()]\n",
    "                        \n",
    "                        # Only count for the first valid protein in the list\n",
    "                        for acc in accessions:\n",
    "                            if acc in accession_to_idx:\n",
    "                                idx = accession_to_idx[acc]\n",
    "                                count_col = f'Count_{group}'\n",
    "                                self.protein_df.at[idx, count_col] += 1\n",
    "                                \n",
    "                                # Add this peptide to the protein's set for protein-specific counting\n",
    "                                protein_desc = accession_to_description.get(acc, acc)\n",
    "                                protein_to_peptides[protein_desc].add(peptide_id)\n",
    "                                protein_to_group_peptides[protein_desc][group].add(peptide_id)\n",
    "                                \n",
    "                                counted_peptides.add(peptide_id)  # Mark as counted\n",
    "                                found_match = True\n",
    "                                break  # Count only once\n",
    "                    else:\n",
    "                        # Handle direct match - only single protein\n",
    "                        if accession in accession_to_idx:\n",
    "                            idx = accession_to_idx[accession]\n",
    "                            count_col = f'Count_{group}'\n",
    "                            self.protein_df.at[idx, count_col] += 1\n",
    "                            \n",
    "                            # Add this peptide to the protein's set for protein-specific counting\n",
    "                            protein_desc = accession_to_description.get(accession, accession)\n",
    "                            protein_to_peptides[protein_desc].add(peptide_id)\n",
    "                            protein_to_group_peptides[protein_desc][group].add(peptide_id)\n",
    "                            \n",
    "                            counted_peptides.add(peptide_id)  # Mark as counted\n",
    "                            found_match = True\n",
    "                    \n",
    "                    # Track peptides that didn't match any protein in our list\n",
    "                    if not found_match:\n",
    "                        peptides_with_no_protein_match += 1\n",
    "                        \n",
    "                # After counting all peptides for this group, calculate relative counts\n",
    "                count_col = f'Count_{group}'\n",
    "                rel_count_col = f'Rel_Count_{group}'\n",
    "                total_value = self.protein_count_bysample_dict[group]\n",
    "                \n",
    "                # Calculate relative counts as percentages of total peptides\n",
    "                # When calculating relative counts\n",
    "                if total_value > 0:\n",
    "                    for idx in range(len(self.protein_df)):\n",
    "                        protein_count = float(self.protein_df.at[idx, count_col])  # Ensure float\n",
    "                        rel_value = (protein_count / total_value) * 100\n",
    "                        self.protein_df.at[idx, rel_count_col] = rel_value\n",
    "\n",
    "                \n",
    "                # Display warning about peptides mapping to multiple proteins\n",
    "                warning_html = '<div style=\"color: orange; margin: 5px 0;\"><b>Warning:</b> Peptide counting stats for group {0}:<br>'\n",
    "                \n",
    "                if peptides_with_no_accession > 0:\n",
    "                    warning_html += f'• Skipped {peptides_with_no_accession} peptides with no accession<br>'\n",
    "                    \n",
    "                if peptides_with_no_id > 0:\n",
    "                    warning_html += f'• Skipped {peptides_with_no_id} peptides with no unique ID<br>'\n",
    "                    \n",
    "                if peptides_already_counted > 0:\n",
    "                    warning_html += f'• Skipped {peptides_already_counted} duplicate peptides (already counted)<br>'\n",
    "                    \n",
    "                if len(peptides_with_multi_accessions) > 0:\n",
    "                    warning_html += f'• Found {len(peptides_with_multi_accessions)} peptides mapping to multiple proteins<br>'\n",
    "                    warning_html += f'  (Each counted only once for the first matching protein)<br>'\n",
    "                    \n",
    "                if peptides_with_no_protein_match > 0:\n",
    "                    warning_html += f'• {peptides_with_no_protein_match} peptides had no matching protein in the protein list<br>'\n",
    "                    \n",
    "                total_peptides = len(group_peptides)\n",
    "                warning_html += f'• Total peptides processed: {total_peptides}, successfully counted: {len(counted_peptides)}'\n",
    "                warning_html += '</div>'\n",
    "                \n",
    "                #display(HTML(warning_html.format(group)))\n",
    "\n",
    "        # Calculate the number of unique peptides per protein\n",
    "        for protein, peptides in protein_to_peptides.items():\n",
    "            self.protein_count_byprotein_dict[protein] = len(peptides)\n",
    "\n",
    "        # Create a copy of the proteins DataFrame for protein sample distribution calculation\n",
    "        working_df = self.protein_df.copy()\n",
    "        \n",
    "        # Calculate protein distributions across samples (for both counts and absorbance)\n",
    "        self.protein_sample_distribution_dict = {}\n",
    "        \n",
    "        # Calculate data for major proteins (based on selected_proteins)\n",
    "        major_proteins = []\n",
    "        if hasattr(self, 'selected_proteins') and selected_proteins:\n",
    "            major_proteins = selected_proteins.copy()\n",
    "            if 'Minor Proteins' in major_proteins:\n",
    "                major_proteins.remove('Minor Proteins')\n",
    "            \n",
    "        # Add \"Minor Proteins\" data structures to hold aggregated values\n",
    "        minor_data = {\n",
    "            'counts': {group: 0 for group in selected_groups},\n",
    "            'count_relative': {group: 0 for group in selected_groups},\n",
    "            'absorbance': {group: 0 for group in selected_groups},\n",
    "            'absorbance_relative': {group: 0 for group in selected_groups},\n",
    "            'unique_peptide_count': 0,\n",
    "            'total_value': 0,\n",
    "            'total_absorbance': 0,\n",
    "            'total_count': 0\n",
    "        }\n",
    "        \n",
    "        # Counts to track minor proteins' peptides\n",
    "        minor_peptides = set()\n",
    "        \n",
    "        # Process each protein\n",
    "        for _, row in working_df.iterrows():\n",
    "            protein_name = row['Description']\n",
    "            \n",
    "            # Skip if protein name is empty or NaN\n",
    "            if pd.isna(protein_name) or not protein_name:\n",
    "                continue\n",
    "            \n",
    "            # Initialize data structure for this protein\n",
    "            protein_data = {\n",
    "                'counts': {},\n",
    "                'count_relative': {},\n",
    "                'absorbance': {},\n",
    "                'absorbance_relative': {},\n",
    "                'unique_peptide_count': 0\n",
    "            }\n",
    "            \n",
    "            # Get count values for each group\n",
    "            count_values = {}\n",
    "            absorbance_values = {}\n",
    "            \n",
    "            for group in selected_groups:\n",
    "                # Get count values from protein_df\n",
    "                count_col = f'Count_{group}'\n",
    "                if count_col in row:\n",
    "                    count_values[group] = row[count_col]\n",
    "                else:\n",
    "                    count_values[group] = 0\n",
    "                \n",
    "                # Get absorbance values\n",
    "                absorbance_col = f'Avg_{group}'\n",
    "                if absorbance_col in row:\n",
    "                    absorbance_values[group] = row[absorbance_col]\n",
    "                else:\n",
    "                    absorbance_values[group] = 0\n",
    "            \n",
    "            # Get the actual count of unique peptides for this protein (across all groups)\n",
    "            if protein_name in protein_to_peptides:\n",
    "                protein_data['unique_peptide_count'] = len(protein_to_peptides[protein_name])\n",
    "            \n",
    "            # Store the count and absorbance values\n",
    "            protein_data['counts'] = count_values\n",
    "            protein_data['absorbance'] = absorbance_values\n",
    "            \n",
    "            # Calculate totals as sums across groups\n",
    "            protein_total_count = sum(count_values.values())\n",
    "            protein_total_absorbance = sum(absorbance_values.values())\n",
    "            \n",
    "            protein_data['total_count'] = protein_total_count\n",
    "            protein_data['total_absorbance'] = protein_total_absorbance\n",
    "            \n",
    "            # Calculate relative distributions\n",
    "            # Count relative distribution - percentage of this protein's total count in each group\n",
    "            if protein_total_count > 0:\n",
    "                for group, count in count_values.items():\n",
    "                    protein_data['count_relative'][group] = (count / protein_total_count) * 100\n",
    "            else:\n",
    "                for group in selected_groups:\n",
    "                    protein_data['count_relative'][group] = 0\n",
    "            \n",
    "            # Absorbance relative distribution\n",
    "            if protein_total_absorbance > 0:\n",
    "                for group, absorbance in absorbance_values.items():\n",
    "                    protein_data['absorbance_relative'][group] = (absorbance / protein_total_absorbance) * 100\n",
    "            else:\n",
    "                for group in selected_groups:\n",
    "                    protein_data['absorbance_relative'][group] = 0\n",
    "            \n",
    "            # Add backward compatibility\n",
    "            use_count = hasattr(self, 'abs_or_count') and ('count' in getattr(self, 'abs_or_count').value.lower() \n",
    "                                                        if hasattr(getattr(self, 'abs_or_count'), 'value') else True)\n",
    "            \n",
    "            if use_count:\n",
    "                protein_data['total'] = protein_total_count\n",
    "                protein_data['values'] = count_values\n",
    "                protein_data['relative'] = protein_data['count_relative']\n",
    "            else:\n",
    "                protein_data['total'] = protein_total_absorbance\n",
    "                protein_data['values'] = absorbance_values\n",
    "                protein_data['relative'] = protein_data['absorbance_relative']\n",
    "            \n",
    "            # Check if this is a major or minor protein\n",
    "            if major_proteins and protein_name not in major_proteins:\n",
    "                # This is a minor protein - add its data to the minor proteins aggregated data\n",
    "                for group in selected_groups:\n",
    "                    minor_data['counts'][group] += count_values[group]\n",
    "                    minor_data['absorbance'][group] += absorbance_values[group]\n",
    "                \n",
    "                # For minor proteins, track both the sum and the unique peptide count\n",
    "                if protein_name in protein_to_peptides:\n",
    "                    minor_peptides.update(protein_to_peptides[protein_name])\n",
    "                \n",
    "                minor_data['total_count'] += protein_total_count\n",
    "                minor_data['total_absorbance'] += protein_total_absorbance\n",
    "            else:\n",
    "                # This is a major protein - store its individual data\n",
    "                self.protein_sample_distribution_dict[protein_name] = protein_data\n",
    "        \n",
    "        # Set unique peptide count for minor proteins\n",
    "        minor_data['unique_peptide_count'] = len(minor_peptides)\n",
    "        \n",
    "        # Calculate relative distributions for minor proteins\n",
    "        if minor_data['total_count'] > 0:\n",
    "            for group in selected_groups:\n",
    "                minor_data['count_relative'][group] = (minor_data['counts'][group] / minor_data['total_count'] * 100)\n",
    "        \n",
    "        if minor_data['total_absorbance'] > 0:\n",
    "            for group in selected_groups:\n",
    "                minor_data['absorbance_relative'][group] = (minor_data['absorbance'][group] / minor_data['total_absorbance'] * 100)\n",
    "        \n",
    "        # Add backward compatibility for minor proteins\n",
    "        if use_count:\n",
    "            minor_data['total'] = minor_data['total_count']\n",
    "            minor_data['values'] = minor_data['counts']\n",
    "            minor_data['relative'] = minor_data['count_relative']\n",
    "        else:\n",
    "            minor_data['total'] = minor_data['total_absorbance']\n",
    "            minor_data['values'] = minor_data['absorbance']\n",
    "            minor_data['relative'] = minor_data['absorbance_relative']\n",
    "        \n",
    "        # Add minor proteins to the distribution dictionary and peptide counts\n",
    "        self.protein_sample_distribution_dict['Minor Proteins'] = minor_data\n",
    "        self.protein_count_byprotein_dict['Minor Proteins'] = minor_data['unique_peptide_count']\n",
    "        \n",
    "        # Add a row for \"Minor Proteins\" to the protein_df if not already present\n",
    "        if 'Minor Proteins' not in self.protein_df['Description'].values and major_proteins:\n",
    "            minor_row = {\n",
    "                'Description': 'Minor Proteins', \n",
    "                'Master Protein Accessions': 'Minor Proteins'\n",
    "            }\n",
    "            # Add counts and relative counts\n",
    "            for group in selected_groups:\n",
    "                count_col = f'Count_{group}'\n",
    "                rel_count_col = f'Rel_Count_{group}'\n",
    "                avg_col = f'Avg_{group}'\n",
    "                rel_avg_col = f'Rel_{avg_col}'\n",
    "                \n",
    "                # Use float values\n",
    "                minor_row[count_col] = float(minor_data['counts'][group])\n",
    "                minor_row[rel_count_col] = 0.0  # Will be recalculated\n",
    "                minor_row[avg_col] = float(minor_data['absorbance'][group])\n",
    "                \n",
    "                if rel_avg_col in self.protein_df.columns:\n",
    "                    total_absorbance = self.sum_df[self.sum_df['Sample'] == avg_col]['Total_Sum'].values[0]\n",
    "                    if total_absorbance > 0:\n",
    "                        minor_row[rel_avg_col] = float((minor_data['absorbance'][group] / total_absorbance) * 100)\n",
    "                    else:\n",
    "                        minor_row[rel_avg_col] = 0.0\n",
    "            \n",
    "            # Add the row\n",
    "            self.protein_df = safe_concat([self.protein_df, pd.DataFrame([minor_row])], ignore_index=True)\n",
    "            \n",
    "            # Recalculate relative counts for all proteins\n",
    "            for group in selected_groups:\n",
    "                count_col = f'Count_{group}'\n",
    "                rel_count_col = f'Rel_Count_{group}'\n",
    "                total_count = self.protein_count_bysample_dict[group]\n",
    "                \n",
    "                if total_count > 0:\n",
    "                    for idx in range(len(self.protein_df)):\n",
    "                        protein_count = self.protein_df.at[idx, count_col]\n",
    "                        self.protein_df.at[idx, rel_count_col] = (protein_count / total_count) * 100\n",
    "        self.protein_df_full = self.protein_df.copy() \n",
    "\n",
    "        \n",
    "        # Filter rows based on selected proteins\n",
    "        filtered_rows = []\n",
    "        for index, row in self.protein_df.iterrows():\n",
    "            if row['Description'] not in selected_proteins:\n",
    "                filtered_rows.append(index)\n",
    "        \n",
    "        if filtered_rows:\n",
    "            self.protein_df.drop(index=filtered_rows, inplace=True)\n",
    "            #if self.plot_minor.value:\n",
    "            #    df = df_filtered_by_proteinds.copy()\n",
    "\n",
    "        return True\n",
    "\n",
    "    def reorganize_by_function(self):\n",
    "        \"\"\"\n",
    "        Reorganize protein data by function instead of protein.\n",
    "        Creates self.function_distribution_dict dictionary with Minor Functions handling.\n",
    "        \"\"\"\n",
    "        self.process_bioactive_data()\n",
    "        \n",
    "        # Initialize the result dictionary\n",
    "        self.function_distribution_dict = {}\n",
    "        \n",
    "        # Determine whether to use count or absorbance as primary metric\n",
    "        use_count = hasattr(self, 'abs_or_count') and self.abs_or_count.value.lower() == 'count'\n",
    "        \n",
    "        # Get all groups (excluding special columns)\n",
    "        all_groups = [col.replace('Avg_', '') for col in self.function_df.columns \n",
    "                    if col.startswith('Avg_')]\n",
    "        \n",
    "        # Create value_cols dictionary\n",
    "        self.value_cols = {group: f'Avg_{group}' for group in all_groups}\n",
    "        self.rel_cols = {group: f'Rel_Avg_{group}' for group in all_groups}\n",
    "        if use_count:\n",
    "            self.value_cols = {group: f'Count_{group}' for group in all_groups}\n",
    "            self.rel_cols = {group: f'Rel_Count_{group}' for group in all_groups}\n",
    "        \n",
    "        # Process each function in the DataFrame\n",
    "        for _, row in self.function_df.iterrows():\n",
    "            function = row['Description']  # Use Description instead of Description\n",
    "            if function in self.selected_functions:\n",
    "                # Initialize data structure for this function\n",
    "                self.function_distribution_dict[function] = {\n",
    "                    'counts': {},\n",
    "                    'count_relative': {},\n",
    "                    'absorbance': {},\n",
    "                    'absorbance_relative': {},\n",
    "                    'unique_peptide_count': 0,\n",
    "                    'total_count': 0,\n",
    "                    'total_absorbance': 0,\n",
    "                }\n",
    "                \n",
    "                # Skip metrics population if function_group_metrics_dict is not available\n",
    "                if hasattr(self, 'function_group_metrics_dict') and function in self.function_group_metrics_dict:\n",
    "                    # Get function metrics\n",
    "                    function_metrics = self.function_group_metrics_dict[function]\n",
    "                    \n",
    "                    # Set total values from metrics\n",
    "                    self.function_distribution_dict[function]['total_count'] = function_metrics.get('total_count', 0)\n",
    "                    self.function_distribution_dict[function]['total_absorbance'] = function_metrics.get('total_absorbance', 0)\n",
    "                    self.function_distribution_dict[function]['unique_peptide_count'] = function_metrics.get('unique_peptide_count', 0)\n",
    "\n",
    "                    # Populate data for each group\n",
    "                    for group in all_groups:\n",
    "                        # Skip if group not in metrics\n",
    "                        if group not in function_metrics:\n",
    "                            continue\n",
    "                        \n",
    "                        group_metrics = function_metrics[group]\n",
    "                        \n",
    "                        # Get absolute and relative values from metrics\n",
    "                        count = group_metrics.get('count', 0)\n",
    "                        count_rel = group_metrics.get('rel_count', 0)\n",
    "                        absorbance = group_metrics.get('absorbance', 0)\n",
    "                        absorbance_rel = group_metrics.get('rel_absorbance', 0)\n",
    "                        \n",
    "                        # Store values\n",
    "                        self.function_distribution_dict[function]['counts'][group] = count\n",
    "                        self.function_distribution_dict[function]['count_relative'][group] = count_rel\n",
    "                        self.function_distribution_dict[function]['absorbance'][group] = absorbance\n",
    "                        self.function_distribution_dict[function]['absorbance_relative'][group] = absorbance_rel\n",
    "                    \n",
    "                    # Set backward compatibility fields\n",
    "                    if use_count:\n",
    "                        self.function_distribution_dict[function]['values'] = self.function_distribution_dict[function]['counts']\n",
    "                        self.function_distribution_dict[function]['relative'] = self.function_distribution_dict[function]['count_relative']\n",
    "                        self.function_distribution_dict[function]['total'] = self.function_distribution_dict[function]['total_count']\n",
    "                    else:\n",
    "                        self.function_distribution_dict[function]['values'] = self.function_distribution_dict[function]['absorbance']\n",
    "                        self.function_distribution_dict[function]['relative'] = self.function_distribution_dict[function]['absorbance_relative']\n",
    "                        self.function_distribution_dict[function]['total'] = self.function_distribution_dict[function]['total_absorbance']\n",
    "            # After processing main functions, handle Minor Functions\n",
    "        if self.plot_minor.value:\n",
    "            minor_functions = {}\n",
    "            for group in all_groups:\n",
    "                minor_functions[group] = {\n",
    "                    'count': 0,\n",
    "                    'absorbance': 0,\n",
    "                    'rel_count': 0,\n",
    "                    'rel_absorbance': 0\n",
    "                }\n",
    "            \n",
    "            # Get all functions that aren't in the main functions list\n",
    "            all_functions = set()\n",
    "            if hasattr(self, 'data_transformer') and self.merged_df is not None:\n",
    "                all_functions = set([f.strip() for funcs in self.merged_df['function'].dropna() \n",
    "                                for f in funcs.split(';')])\n",
    "            \n",
    "            minor_function_list = [f for f in all_functions if f not in self.selected_functions]\n",
    "            \n",
    "            # Calculate totals for minor functions\n",
    "            total_count = 0\n",
    "            total_absorbance = 0\n",
    "            \n",
    "            for function in minor_function_list:\n",
    "                if function in self.function_group_metrics_dict:\n",
    "                    metrics = self.function_group_metrics_dict[function]\n",
    "                    for group in all_groups:\n",
    "                        if group in metrics:\n",
    "                            group_metrics = metrics[group]\n",
    "                            minor_functions[group]['count'] += group_metrics.get('count', 0)\n",
    "                            minor_functions[group]['absorbance'] += group_metrics.get('absorbance', 0)\n",
    "                            total_count += group_metrics.get('count', 0)\n",
    "                            total_absorbance += group_metrics.get('absorbance', 0)\n",
    "            \n",
    "            # Calculate relative values\n",
    "            if total_count > 0:\n",
    "                for group in all_groups:\n",
    "                    minor_functions[group]['rel_count'] = (minor_functions[group]['count'] / total_count) * 100\n",
    "            \n",
    "            if total_absorbance > 0:\n",
    "                for group in all_groups:\n",
    "                    minor_functions[group]['rel_absorbance'] = (minor_functions[group]['absorbance'] / total_absorbance) * 100\n",
    "                        # extract unique peptides that dont conaint selected funcs\n",
    "            \n",
    "            if minor_function_list:    \n",
    "                minor_unique_peptides = set()\n",
    "                for func in minor_function_list:\n",
    "                    # Filter peptides that contain this function\n",
    "                    peptides_with_func = self.filtered_df[\n",
    "                        self.filtered_df['function'].apply(lambda x: self.contains_function(x, func))\n",
    "                    ]\n",
    "                    # Add peptide IDs to the set\n",
    "                    minor_unique_peptides.update(peptides_with_func['unique ID'].unique())\n",
    "\n",
    "            else:\n",
    "                minor_unique_peptides = []\n",
    "           \n",
    " \n",
    "            # Populate Minor Functions in function_distribution_dict\n",
    "            self.function_distribution_dict['Minor Functions'] = {\n",
    "                'counts': {group: minor_functions[group]['count'] for group in all_groups},\n",
    "                'count_relative': {group: minor_functions[group]['rel_count'] for group in all_groups},\n",
    "                'absorbance': {group: minor_functions[group]['absorbance'] for group in all_groups},\n",
    "                'absorbance_relative': {group: minor_functions[group]['rel_absorbance'] for group in all_groups},\n",
    "                'unique_peptide_count': len(minor_unique_peptides),\n",
    "                'total_count': total_count,\n",
    "                'total_absorbance': total_absorbance,\n",
    "            }\n",
    "\n",
    "                           # Set backward compatibility fields\n",
    "            if use_count:\n",
    "                self.function_distribution_dict['Minor Functions']['values'] = self.function_distribution_dict['Minor Functions']['counts']\n",
    "                self.function_distribution_dict['Minor Functions']['relative'] = self.function_distribution_dict['Minor Functions']['count_relative']\n",
    "                self.function_distribution_dict['Minor Functions']['total'] = self.function_distribution_dict['Minor Functions']['total_count']\n",
    "            else:\n",
    "                self.function_distribution_dict['Minor Functions']['values'] = self.function_distribution_dict['Minor Functions']['absorbance']\n",
    "                self.function_distribution_dict['Minor Functions']['relative'] = self.function_distribution_dict['Minor Functions']['absorbance_relative']\n",
    "                self.function_distribution_dict['Minor Functions']['total'] = self.function_distribution_dict['Minor Functions']['total_absorbance']\n",
    "        \n",
    "    def process_total_peptide_data_and_filter_dataframe(self):\n",
    "       \n",
    "        if self.merged_df is None or self.group_data_dict is None:\n",
    "            return None\n",
    "            \n",
    "        # Initialize dictionary to store results for all groups\n",
    "        total_peptide_results_dict = {}\n",
    "        \n",
    "        # Use consistent reference to merged dataframe\n",
    "        self.filtered_df = self.merged_df.copy()\n",
    "     \n",
    "        # Initialize masks\n",
    "        protein_mask = pd.Series(True, index=self.filtered_df.index)\n",
    "        function_mask = pd.Series(True, index=self.filtered_df.index)\n",
    "        \n",
    "        protein_col = 'protein_name'\n",
    "    \n",
    "        # Create protein filter mask if applicable\n",
    "        if self.protein_selector:\n",
    "            if 'All Proteins (No Filter)' not in self.protein_selector.value and protein_col is not None:\n",
    "                # First, update the protein list to plot\n",
    "                selected_proteins = self.get_selected_proteins()\n",
    "        \n",
    "                # Create mask for matching proteins in description - fixed to properly match proteins\n",
    "                protein_mask = self.filtered_df[protein_col].fillna('').apply(\n",
    "                    lambda x: any(protein == x for protein in selected_proteins)\n",
    "                )\n",
    "                \n",
    "                # If still no matches, try partial matching\n",
    "                if protein_mask.sum() == 0:\n",
    "                    protein_mask = self.filtered_df[protein_col].fillna('').apply(\n",
    "                        lambda x: any(protein in x for protein in selected_proteins)\n",
    "                    )\n",
    "                \n",
    "                # If still no matches, try case-insensitive matching\n",
    "                if protein_mask.sum() == 0:\n",
    "                    protein_mask = self.filtered_df[protein_col].fillna('').apply(\n",
    "                        lambda x: any(protein.lower() in x.lower() for protein in selected_proteins)\n",
    "                    )\n",
    "            else:\n",
    "                # Keep all rows if \"All Proteins\" is selected\n",
    "                protein_mask = pd.Series(True, index=self.filtered_df.index)\n",
    "        \n",
    "        # Create function filter mask if applicable\n",
    "        if self.function_selector:\n",
    "            function_col = None\n",
    "            for col_name in ['function', 'Function', 'FUNCTION']:\n",
    "                if col_name in self.filtered_df.columns:\n",
    "                    function_col = col_name\n",
    "                    break\n",
    "            \n",
    "            if function_col:\n",
    "                if 'All Functional Peptides' in self.function_selector.value:\n",
    "                    # Keep all rows if \"All Functional Peptides\" is selected\n",
    "                    selected_functions = self.all_functions\n",
    "                    function_mask = self.filtered_df[function_col].apply(\n",
    "                        lambda x: any(self.contains_function(x, func) for func in selected_functions))   \n",
    "\n",
    "                elif 'Non-Functional Peptides' in self.function_selector.value:\n",
    "                    # For non-functional peptides, select rows where function column is NaN\n",
    "                    function_mask = self.filtered_df[function_col].isna()\n",
    "\n",
    "                elif 'All Peptides (No Filter)' in self.function_selector.value:\n",
    "                    function_mask = pd.Series(True, index=self.filtered_df.index)\n",
    "                \n",
    "                else: # Select individual functions\n",
    "                    selected_functions = self.function_selector.value\n",
    "                    function_mask = self.filtered_df[function_col].apply(\n",
    "                        lambda x: any(self.contains_function(x, func) for func in selected_functions)\n",
    "                    )\n",
    "\n",
    "\n",
    "        # Apply both masks together\n",
    "        if self.plot_func_or_pro.value == 'Both':\n",
    "            combined_mask = protein_mask & function_mask\n",
    "        elif self.plot_func_or_pro.value == 'Selected Protein(s)':\n",
    "            combined_mask = protein_mask\n",
    "        elif self.plot_func_or_pro.value == 'Selected Function(s)':\n",
    "            combined_mask = function_mask\n",
    "        else: # None\n",
    "            combined_mask = pd.Series(True, index=self.filtered_df.index)\n",
    "        #print(\"length of filtered df\", len(self.filtered_df))\n",
    "        self.filtered_df = self.filtered_df[combined_mask]\n",
    "\n",
    "        # Debug output\n",
    "        #print(f\"Total rows before filtering: {len(self.merged_df)}\")\n",
    "        #print(f\"Rows after protein filter: {protein_mask.sum()}\")\n",
    "        #print(f\"Rows after function filter: {function_mask.sum()}\")\n",
    "        #print(f\"Rows after combined filters: {combined_mask.sum()}\")\n",
    "        #print(f\"Filtered DataFrame columns: {self.filtered_df.shape}\")\n",
    "        \n",
    "\n",
    "        #print(f\"Rows after OR filtering: {combined_mask.sum()}\")\n",
    "        \n",
    "        # Process each group from the simplified group data structure\n",
    "\n",
    "        for group_name, abundance_columns in self.group_data_dict.items():\n",
    "            # Check if abundance_columns is a string or a list with a single item\n",
    "            if isinstance(abundance_columns, str):\n",
    "                abundance_columns = [abundance_columns]\n",
    "            elif hasattr(abundance_columns, '__iter__') and not isinstance(abundance_columns, str) and len(abundance_columns) == 1:\n",
    "                # If it's an iterable (like list) with one item, keep it as a list\n",
    "                abundance_columns = list(abundance_columns)\n",
    "            else:\n",
    "                # If it's already a proper collection, convert to list to ensure consistency\n",
    "                abundance_columns = list(abundance_columns)\n",
    "            abundance_columns = list(abundance_columns)\n",
    "\n",
    "            if group_name in self.group_selector.value:\n",
    "                # Add \"Avg_\" prefix to abundance columns\n",
    "                valid_abundance_cols = [col for col in abundance_columns if col in self.filtered_df.columns]\n",
    "                if not valid_abundance_cols:\n",
    "                    print(f\"Warning: No valid abundance columns found for group {group_name}\")\n",
    "                    continue\n",
    "                                \n",
    "                # Calculate total abundance and SEM from the abundance columns\n",
    "                temp_df = self.filtered_df[['unique ID'] + valid_abundance_cols].copy()\n",
    "                \n",
    "                # Convert abundance columns to numeric, forcing non-numeric values to NaN\n",
    "                for col in valid_abundance_cols:\n",
    "                    temp_df[col] = pd.to_numeric(temp_df[col], errors='coerce')\n",
    "                \n",
    "                # Additional filtering for valid data\n",
    "                valid_data_mask = (\n",
    "                    temp_df[valid_abundance_cols].notna().any(axis=1) & \n",
    "                    (temp_df[valid_abundance_cols] != 0).any(axis=1) &\n",
    "                    temp_df['unique ID'].notna()\n",
    "                )\n",
    "                temp_df = temp_df[valid_data_mask]\n",
    "                if temp_df.empty:\n",
    "                    print(f\"Warning: No valid data for group {group_name}\")\n",
    "                    # Add empty results to maintain group in output\n",
    "                    total_peptide_results_dict[group_name] = {\n",
    "                        'unique_peptides': 0,\n",
    "                        'total_Absorbance': 0,\n",
    "                        'total_sem': 0,\n",
    "                        'abundance_sem': 0,\n",
    "                        'count_sem': 0,\n",
    "                        'replicate_data': {\n",
    "                            'abundance_columns': valid_abundance_cols,\n",
    "                            'replicate_counts': [0] * len(valid_abundance_cols),\n",
    "                            'replicate_abundances': [0] * len(valid_abundance_cols)\n",
    "                        }\n",
    "                    }\n",
    "                    continue\n",
    "                    \n",
    "                # Rest of the function remains the same...\n",
    "                # Calculate peptide counts for each replicate\n",
    "                replicate_counts = []\n",
    "                for col in valid_abundance_cols:\n",
    "                    count = temp_df[temp_df[col].notna() & (temp_df[col] != 0)]['unique ID'].nunique()\n",
    "                    replicate_counts.append(count)\n",
    "                \n",
    "                # Calculate mean count and SEM across replicates\n",
    "                if len(replicate_counts) > 1:\n",
    "                    count_sem = np.std(replicate_counts, ddof=1) / np.sqrt(len(replicate_counts))\n",
    "                else:\n",
    "                    count_sem = 0\n",
    "                    \n",
    "                # Calculate abundance statistics\n",
    "                abundances = temp_df[valid_abundance_cols].values.astype(float)\n",
    "                peptide_means = np.nanmean(abundances, axis=1)\n",
    "                total_abundance = np.nansum(peptide_means)\n",
    "                # Calculate SEM for abundance\n",
    "                peptide_sems = np.nanstd(abundances, axis=1) / np.sqrt(abundances.shape[1])\n",
    "                total_sem = np.sqrt(np.nansum(peptide_sems ** 2))\n",
    "\n",
    "                # Calculate total count for group\n",
    "                all_unique_peptides = temp_df[\n",
    "                    (temp_df[valid_abundance_cols] > 0).any(axis=1)\n",
    "                ]['unique ID'].nunique()\n",
    "                \n",
    "                # Store results for this group\n",
    "                total_peptide_results_dict[group_name] = {\n",
    "                    'unique_peptides': all_unique_peptides,\n",
    "                    'total_Absorbance': total_abundance,\n",
    "                    'total_sem': total_sem,\n",
    "                    'abundance_sem': total_sem,\n",
    "                    'count_sem': count_sem,\n",
    "                    'replicate_data': {\n",
    "                        'abundance_columns': valid_abundance_cols,\n",
    "                        'replicate_counts': replicate_counts,\n",
    "                        'replicate_abundances': [temp_df[col].replace(0, np.nan).sum() for col in valid_abundance_cols]\n",
    "                    }\n",
    "                }\n",
    "        self.total_peptide_results_dict = total_peptide_results_dict    \n",
    "            # Debug output\n",
    "\n",
    "        if self.abs_or_count.value == 'Count':\n",
    "            use_count = True\n",
    "        else:\n",
    "            use_count = False\n",
    "        self.sample_distribution_summary_df = self.create_sample_summary_df(use_count=use_count)\n",
    "                        \n",
    "    def process_bioactive_data(self):\n",
    "        selected_groups = []\n",
    "        for group in self.group_selector.value:\n",
    "            if group not in selected_groups:\n",
    "                selected_groups.append(group)\n",
    "        # For other modes, use the merged dataframe\n",
    "        df = self.merged_df.copy() if self.merged_df is not None else None\n",
    "       # Create column names for selected groups\n",
    "        Absorbance_cols = [f'Avg_{var}' for var in selected_groups]\n",
    "        df_avg_cols = [col for col in df.columns if col.startswith('Avg_')]\n",
    "        \n",
    "        # Filter columns to only include selected groups\n",
    "        for i in df_avg_cols:\n",
    "            if i not in Absorbance_cols:\n",
    "                del df[i]\n",
    "        # Check if we have valid data with a function column\n",
    "        if df is None or 'function' not in df.columns:\n",
    "            print(\"Error: No valid dataframe or missing 'function' column\")\n",
    "            return None, None, None, None\n",
    "\n",
    "        \n",
    "        # Drop duplicates to get unique peptide counts\n",
    "        unique_peptides_df = df.drop_duplicates(subset='unique ID')\n",
    "        # Now calculate the derived metrics\n",
    "        function_count_totals_dict = {}\n",
    "        function_absorbance_totals_dict = {}\n",
    "        function_group_metrics_dict = {}\n",
    "        \n",
    "        if self.plot_func_or_pro.value != 'Functional vs Non-Functional Peptides':\n",
    "            # First, get all unique functions from the data\n",
    "            all_functions = set()\n",
    "            for func_str in df['function'].dropna():\n",
    "                if isinstance(func_str, str):\n",
    "                    funcs = [f.strip() for f in func_str.split(';')]\n",
    "                    all_functions.update(funcs)\n",
    "        else:\n",
    "            all_functions = ['Functional Peptides','Non-Functional Peptides']\n",
    "\n",
    "        # Calculate unique peptide counts and absorbance sums for each function\n",
    "        function_unique_peptides = {}\n",
    "        function_unique_absorbance = {}\n",
    "        \n",
    "        for function in all_functions:\n",
    "            if self.plot_func_or_pro.value != 'Functional vs Non-Functional Peptides':\n",
    "                # Create a mask for entries containing this function\n",
    "                function_mask = df['function'].apply(lambda x: self.contains_function(x, function))\n",
    "            else:\n",
    "                if function == 'Functional Peptides':\n",
    "                    function_mask = df['function'].notna()\n",
    "                elif function == 'Non-Functional Peptides':\n",
    "                    function_mask = df['function'].isna()\n",
    "                \n",
    "            # Get data for this function\n",
    "            function_data = df[function_mask]\n",
    "            \n",
    "            # Store the unique peptide count\n",
    "            function_unique_peptides[function] = function_data['unique ID'].nunique()\n",
    "            \n",
    "            # Calculate unique absorbance sum for each group\n",
    "            function_unique_absorbance[function] = {}\n",
    "            for group in selected_groups:\n",
    "                column = f'Avg_{group}'\n",
    "                if column in df.columns:\n",
    "                    # Filter for non-zero values and sum\n",
    "                    valid_data = function_data[(function_data[column] > 0) & function_data[column].notna()]\n",
    "                    function_unique_absorbance[function][group] = valid_data[column].sum()\n",
    "        \n",
    "        # Calculate totals for each group\n",
    "        Absorbance_cols = [f'Avg_{var}' for var in selected_groups]\n",
    "        for column in Absorbance_cols:\n",
    "            grouping_variable = column.replace('Avg_', '')\n",
    "            \n",
    "            # Filter and process data\n",
    "            temp_df = df[['unique ID', 'function', column]].copy() if column in df.columns else None\n",
    "            if temp_df is not None and not temp_df.empty:\n",
    "                temp_df = temp_df[\n",
    "                    (temp_df[column] != 0) & \n",
    "                    temp_df[column].notna() &\n",
    "                    temp_df['function'].notna()\n",
    "                ]\n",
    "                \n",
    "                if not temp_df.empty:\n",
    "                    # Drop duplicates to get unique peptide counts\n",
    "                    unique_peptides_df = temp_df.drop_duplicates(subset='unique ID')\n",
    "                    \n",
    "                    # Store total counts and absorbance for this group\n",
    "                    function_count_totals_dict[grouping_variable] = len(unique_peptides_df)\n",
    "                    function_absorbance_totals_dict[grouping_variable] = temp_df[column].sum()\n",
    "        \n",
    "        # Calculate totals for each function across all groups\n",
    "        function_totals_dict = {}\n",
    "        for function in all_functions:\n",
    "            total_absorbance = 0\n",
    "            total_count = 0\n",
    "            \n",
    "            for group in selected_groups:\n",
    "                absorbance = self.unique_function_absorbance_dict.get(group, {}).get(function, 0)\n",
    "                count = self.unique_function_counts_dict.get(group, {}).get(function, 0)\n",
    "                total_absorbance += absorbance\n",
    "                total_count += count\n",
    "            \n",
    "            function_totals_dict[function] = {\n",
    "                'total_absorbance': total_absorbance,\n",
    "                'total_count': total_count\n",
    "            }\n",
    "        \n",
    "        # Create the metrics with the correct relative values\n",
    "        for function in all_functions:\n",
    "            function_group_metrics_dict[function] = {}\n",
    "            \n",
    "            # Store function totals\n",
    "            function_total_absorbance = function_totals_dict[function]['total_absorbance']\n",
    "            function_total_count = function_totals_dict[function]['total_count']\n",
    "            \n",
    "            function_group_metrics_dict[function]['total_absorbance'] = function_total_absorbance\n",
    "            function_group_metrics_dict[function]['total_count'] = function_total_count\n",
    "            \n",
    "            # Add the unique peptide count and total absorbance sum for this function\n",
    "            function_group_metrics_dict[function]['unique_peptide_count'] = function_unique_peptides.get(function, 0)\n",
    "            \n",
    "            # Now calculate the distribution of this function across groups\n",
    "            for group in selected_groups:\n",
    "                # Get absorbance and count for this function in this group\n",
    "                absorbance = self.unique_function_absorbance_dict.get(group, {}).get(function, 0)\n",
    "                count = self.unique_function_counts_dict.get(group, {}).get(function, 0)\n",
    "                \n",
    "                # Calculate relative metrics as percentage of function's total (distribution across samples)\n",
    "                rel_absorbance = 0\n",
    "                if function_total_absorbance > 0:\n",
    "                    rel_absorbance = (absorbance / function_total_absorbance) * 100\n",
    "                \n",
    "                rel_count = 0\n",
    "                if function_total_count > 0:\n",
    "                    rel_count = (count / function_total_count) * 100\n",
    "                \n",
    "                # Store all metrics for this function and group\n",
    "                function_group_metrics_dict[function][group] = {\n",
    "                    'absorbance': absorbance,\n",
    "                    'count': count,\n",
    "                    'rel_absorbance': rel_absorbance,  # % of function's total absorbance across all groups\n",
    "                    'rel_count': rel_count,  # % of function's total count across all groups\n",
    "                }\n",
    "                \n",
    "                # Also store the group's unique absorbance for this function\n",
    "                function_group_metrics_dict[function][group]['total_absorbance'] = function_unique_absorbance.get(function, {}).get(group, 0)\n",
    "        \n",
    "        # Save all calculated dictionaries as instance attributes\n",
    "\n",
    "        self.function_count_totals_dict = function_count_totals_dict\n",
    "        self.function_absorbance_totals_dict = function_absorbance_totals_dict\n",
    "        self.function_group_metrics_dict = function_group_metrics_dict\n",
    "        #return (unique_function_absorbance_dict, unique_function_counts_dict, \n",
    "        #        function_count_totals, function_absorbance_totals)  \n",
    "\n",
    "    def on_color_scheme_change(self, change):\n",
    "        \"\"\"Update plot when color scheme changes\"\"\"\n",
    "        if self.current_fig is not None and hasattr(self, 'plot_button'):\n",
    "            # Trigger plot update by simulating a button click\n",
    "                \n",
    "            self.on_data_loaded_func_and_color_gen(change)\n",
    "            \n",
    "            self.on_plot_button_click(None)\n",
    "        \n",
    "    def _initialize_instructions(self):\n",
    "        self.steptwo_output_html_message = \"\"\"\n",
    "        <div style='padding: 10px; background-color: #f8f9fa; border-left: 5px solid #007bff; margin: 10px 0;'>\n",
    "            <h3>Step 2: Select Data to Visualize</h3>\n",
    "            <p>Choose which data to include in your visualization:</p>\n",
    "            \n",
    "            <details>\n",
    "                <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Sample Groups</summary>\n",
    "                <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                    <li><b>Select Groups:</b> Choose which sample groups to include in your visualization</li>\n",
    "                    <li><b>Multi-select:</b> You can select multiple groups to compare in the same plot</li>\n",
    "                </ul>\n",
    "            </details>\n",
    "            \n",
    "            <details>\n",
    "                <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Proteins & Functions</summary>\n",
    "                <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                    <li><b>Select Proteins:</b> Choose specific proteins to visualize from your dataset. Defualt option is top 10 proteins by Absorbance</li>\n",
    "                    <li><b>Select Functions:</b> Choose specific bioactivitiesto analyze. Default option is all bioactivities</li>\n",
    "                    <li><b>Multi-select:</b> You can select multiple items to include in your visualization</li>\n",
    "                </ul>\n",
    "            </details>\n",
    "            \n",
    "            <details>\n",
    "                <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Plot Filter</summary>\n",
    "                <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                    <li><b>No Filter:</b> Visualize all data without filtering</li>\n",
    "                    <li><b>Selected Protein(s):</b> Focus visualization on chosen proteins only</li>\n",
    "                    <li><b>Selected Function(s):</b> Focus visualization on chosen bioactivitiesonly</li>\n",
    "                    <li><b>Both:</b> Apply both protein and function filters simultaneously</li>\n",
    "                    <li><b>Functional vs Non-Functional:</b> Compare peptides by categorizing them based on presence or absence of bioactive functions</li>                </ul>\n",
    "            </details>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        self.steptwo_status_output = widgets.Output(\n",
    "            layout=widgets.Layout(\n",
    "                max_width='1000px',\n",
    "                width='100%'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        with self.steptwo_status_output:\n",
    "            display(HTML(self.steptwo_output_html_message))\n",
    "\n",
    "        self.stepthree_output_html_message = \"\"\"\n",
    "        <div style='padding: 10px; background-color: #f8f9fa; border-left: 5px solid #007bff; margin: 10px 0;'>\n",
    "            <h3>Step 3: Visualization Options</h3>\n",
    "            <p>Choose how to visualize your selected data:</p>\n",
    "            \n",
    "            <!-- Primary Dropdown 1: Visualization Settings -->\n",
    "            <details style=\"margin-bottom: 10px;\">\n",
    "                <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee; background-color: #f8f9fa;\">\n",
    "                    Visualization Settings\n",
    "                </summary>\n",
    "                \n",
    "                <!-- Plot Type Options -->\n",
    "                <details style=\"margin-left: 20px; margin-top: 8px;\">\n",
    "                    <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Plot Type</summary>\n",
    "                    <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                        <li><b>Grouped Bar Plots:</b> Compare data across categories with bars grouped by category</li>\n",
    "                        <li><b>Stacked Bar Plots:</b> Show composition of each category with stacked segments</li>\n",
    "                        <li><b>Pie Charts:</b> Display proportion of each component as a slice of the whole</li>\n",
    "                        <li><b>Correlation Scatter Plots:</b> Visualize relationships between sample groups</li>\n",
    "                    </ul>\n",
    "                </details>\n",
    "                \n",
    "                <!-- Scale Absorbance Options -->\n",
    "                <details style=\"margin-left: 20px; margin-top: 8px;\">\n",
    "                    <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Scale Absorbance</summary>\n",
    "                    <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                        <li><b>Absolute:</b> Display raw values of either abudnance or peptide count on the y-axis</li>\n",
    "                        <li><b>Relative:</b> Display as percentages of the total on the y-axis, with a scale of 0-100</li>\n",
    "                    </ul>\n",
    "                </details>\n",
    "                \n",
    "                <!-- Data Type Options -->\n",
    "                <details style=\"margin-left: 20px; margin-top: 8px;\">\n",
    "                    <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Data Type</summary>\n",
    "                    <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                        <li><b>Absorbance:</b> Use absorbance values for visualization</li>\n",
    "                        <li><b>Count:</b> Use peptide count values for visualization</li>\n",
    "                    </ul>\n",
    "                </details>\n",
    "                \n",
    "                <!-- Plot Orientation Options -->\n",
    "                <details style=\"margin-left: 20px; margin-top: 8px;\">\n",
    "                    <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Plot Orientation</summary>\n",
    "                    <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                        <li><b>By Sample:</b> Organize data with samples as primary grouping and samples plotted on the x-axis</li>\n",
    "                        <li><b>By Protein:</b> Organize data with proteins as primary grouping and proteins plotted on the x-axis</li>\n",
    "                        <li><b>By Function:</b> Organize data with functions as primary grouping and functions plotted on the x-axis</li>\n",
    "                    </ul>\n",
    "                </details>\n",
    "                \n",
    "                <!-- Group Unselected Options -->\n",
    "                <details style=\"margin-left: 20px; margin-top: 8px;\">\n",
    "                    <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Group Unselected Items</summary>\n",
    "                    <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                        <li><b>Group Unselected Proteins or Functions:</b> Combine unselected proteins or functions into a \"Minor\" category to deal with insignificant data</li>\n",
    "                    </ul>\n",
    "                </details>\n",
    "                <!-- Log Transform Options -->\n",
    "                <details style=\"margin-left: 20px; margin-top: 8px;\">\n",
    "                    <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Log Transform Data</summary>\n",
    "                    <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                        <li><b>Log Transform:</b> Apply log10 transformation before correlation analysis</li>\n",
    "                    </ul>\n",
    "                </details>\n",
    "                <!-- Correlation Type Options -->\n",
    "                <details style=\"margin-left: 20px; margin-top: 8px;\">\n",
    "                    <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Correlation Type</summary>\n",
    "                    <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                        <li><b>Pearson:</b> Linear correlation between variables</li>\n",
    "                        <li><b>Spearman:</b> Rank-based correlation that detects monotonic relationships</li>\n",
    "                    </ul>\n",
    "                </details>\n",
    "            </details>\n",
    "            \n",
    "            <!-- Primary Dropdown 2: Appearance Settings -->\n",
    "            <details style=\"margin-bottom: 10px;\">\n",
    "                <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee; background-color: #f8f9fa;\">\n",
    "                    Appearance Settings\n",
    "                </summary>\n",
    "                \n",
    "                <!-- Labels -->\n",
    "                <details style=\"margin-left: 20px; margin-top: 8px;\">\n",
    "                    <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Labels and Titles</summary>\n",
    "                    <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                        <li><b>X Label:</b> Enter a custom label for the x-axis otherwise a default label will be used</li>\n",
    "                        <li><b>Y Label:</b> Enter a custom label for the y-axis otherwise a default label will be used</li>\n",
    "                        <li><b>Legend Title:</b> Enter a custom title for the plot legend otherwise a default title will be used</li>\n",
    "                        <li><b>Plot Title:</b> Enter a custom title for the entire plot otherwise a default title will be used</li> \n",
    "                    </ul>\n",
    "                </details>\n",
    "                \n",
    "                <!-- Color Scheme -->\n",
    "                <details style=\"margin-left: 20px; margin-top: 8px;\">\n",
    "                    <summary style=\"font-weight: bold; cursor: pointer; padding: 5px; border-bottom: 1px solid #eee;\">Color Scheme</summary>\n",
    "                    <ul style='list-style-type: none; margin-left: 20px;'>\n",
    "                        <li><b>DEFAULT PALETTE (HSV):</b> Standard color rotation for visualizations</li>\n",
    "                        <li style=\"margin-top: 10px;\"><b>QUALITATIVE PALETTES (RECOMMENDED):</b> Distinct colors for categorical data\n",
    "                            <ul style='list-style-type: none; margin-left: 15px;'>\n",
    "                                <li><i>Plotly, D3, G10, T10, Alphabet, Set1, Set2, Set3, Pastel1, Pastel2, Paired</i></li>\n",
    "                                <li>Best for distinguishing between different categories</li>\n",
    "                            </ul>\n",
    "                        </li>\n",
    "                        <li style=\"margin-top: 10px;\"><b>SEQUENTIAL PALETTES:</b> Gradient from light to dark\n",
    "                            <ul style='list-style-type: none; margin-left: 15px;'>\n",
    "                                <li><i>Viridis, Cividis, Inferno, Magma, Plasma, Hot, Jet, Blues, Greens, Reds, etc.</i></li>\n",
    "                                <li>Best for showing intensity or magnitude</li>\n",
    "                            </ul>\n",
    "                        </li>\n",
    "                        <li style=\"margin-top: 10px;\"><b>DIVERGING PALETTES:</b> Two contrasting colors with neutral middle\n",
    "                            <ul style='list-style-type: none; margin-left: 15px;'>\n",
    "                                <li><i>Spectral, RdBu, RdYlBu, RdYlGn, PiYG, PRGn, BrBG, RdGy</i></li>\n",
    "                                <li>Best for data with meaningful midpoint (like correlations)</li>\n",
    "                            </ul>\n",
    "                        </li>\n",
    "                        <li style=\"margin-top: 10px;\"><b>CYCLICAL PALETTES:</b> Colors that loop smoothly\n",
    "                            <ul style='list-style-type: none; margin-left: 15px;'>\n",
    "                                <li><i>IceFire, Edge, Twilight</i></li>\n",
    "                                <li>Best for circular or periodic data</li>\n",
    "                            </ul>\n",
    "                        </li>\n",
    "                        <li style=\"margin-top: 10px;\"><b>SINGLE COLORS:</b> Individual color options\n",
    "                            <ul style='list-style-type: none; margin-left: 15px;'>\n",
    "                                <li><i>red, green, blue, yellow, purple, orange, cyan, etc.</i></li>\n",
    "                                <li>Used for correlation plots and some grouped bar plots</li>\n",
    "                                <li>Applied to all elements or as a base color</li>\n",
    "                            </ul>\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </details>\n",
    "            </details>\n",
    "            \n",
    "            <p style=\"margin-top: 10px;\">Configure your visualization options and click \"Generate/Update Data\" to create your plots.</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        self.stepthree_status_output = widgets.Output(\n",
    "            layout=widgets.Layout(\n",
    "                max_width='1000px',\n",
    "                width='100%'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        with self.stepthree_status_output:\n",
    "            display(HTML(self.stepthree_output_html_message))\n",
    "\n",
    "    def display_handler(self):\n",
    "        \"\"\"Display the protein analysis interface\"\"\"\n",
    "\n",
    "                # Create layout\n",
    "        self.handler_widget_box = widgets.VBox([\n",
    "            self.steptwo_status_output,\n",
    "            self.groups_grid,\n",
    "            self.profunc_grid, \n",
    "            self.plot_func_or_pro,\n",
    "        ], layout=widgets.Layout(\n",
    "            width='1000px',\n",
    "            height='auto',\n",
    "            margin='0px',\n",
    "            padding='0px',\n",
    "            overflow='hidden'\n",
    "        ))\n",
    "        display(self.handler_widget_box)\n",
    "        display(self.stepthree_status_output)\n",
    "           \n",
    "        grid = GridspecLayout(\n",
    "            1, 2,  # 1 rows, 2 columns\n",
    "            width='750px', \n",
    "            height='auto',\n",
    "            overflow='hidden',\n",
    "            grid_gap='0px',  # Already set to zero\n",
    "        )\n",
    "        \n",
    "        # Left column widgets\n",
    "        left_column = VBox([\n",
    "            widgets.HTML(\"<h3><u>Visualization Settings:</u></h3>\"),\n",
    "            self.plot_type_row,\n",
    "            self.plot_type_row_two,\n",
    "            self.minor_row,\n",
    "            self.corr_box,\n",
    "        ], layout=widgets.Layout(\n",
    "            width='350px',\n",
    "            margin='0px',\n",
    "            padding='0px',\n",
    "            overflow='hidden'\n",
    "        ))\n",
    "        \n",
    "        # Right column widgets\n",
    "        right_column = VBox([\n",
    "            widgets.HTML(\"<h3><u>Appearance Settings:</u></h3>\"),\n",
    "            self.xlabel_widget,\n",
    "            self.ylabel_widget,\n",
    "            self.legend_widget,\n",
    "            self.title_widget,\n",
    "            self.color_scheme\n",
    "        ], layout=widgets.Layout(\n",
    "            width='400px',\n",
    "            margin='0px',\n",
    "            padding='0px',\n",
    "            overflow='hidden'\n",
    "        ))\n",
    "        \n",
    "\n",
    "        # Place widgets in the grid\n",
    "        grid[0, 0] = left_column    # First row, first column\n",
    "        grid[0, 1] = right_column   # First row, second column\n",
    "        \n",
    "        \n",
    "        display(grid)\n",
    "\n",
    "    def _fetch_protein_names(self, accession_str):\n",
    "        \"\"\"\n",
    "        Fetch protein names from the proteins dictionary.\n",
    "        Returns a list of protein names, using the full protein name.\n",
    "        \"\"\"\n",
    "        names = []\n",
    "        for acc in accession_str.split('; '):\n",
    "            if acc in self.protein_dict:\n",
    "                # Use the full protein name instead of splitting it\n",
    "                name = self.protein_dict[acc]['name']\n",
    "                names.append(name)\n",
    "            else:\n",
    "                names.append(acc)\n",
    "        return names\n",
    "\n",
    "  \n",
    "    def create_sample_summary_df(self, use_count=False):\n",
    "        \"\"\"\n",
    "        Create a summary DataFrame from total_peptide_results_dict.\n",
    "        \n",
    "        Args:\n",
    "            use_count (bool): If True, use peptide counts, otherwise use abundance values\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame with sample metrics including relative values\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Check if we have the required dictionary\n",
    "            if not hasattr(self, 'total_peptide_results_dict') or not self.total_peptide_results_dict:\n",
    "                print(\"Missing total_peptide_results_dict\")\n",
    "                return None\n",
    "                \n",
    "            # Create a list for DataFrame\n",
    "            data_rows = []\n",
    "            \n",
    "            # Determine which values to use based on use_count parameter\n",
    "            if use_count:\n",
    "                value_key = 'unique_peptides'\n",
    "                error_key = 'count_sem'\n",
    "                value_column = 'Peptide_Count'\n",
    "                error_column = 'Count_SEM'\n",
    "            else:\n",
    "                value_key = 'total_Absorbance'\n",
    "                error_key = 'abundance_sem'\n",
    "                value_column = 'Total_Abundance'\n",
    "                error_column = 'Abundance_SEM'\n",
    "            \n",
    "            # Calculate total for relative values\n",
    "            total_value = sum(group_data_dict[value_key] for group_data_dict in self.total_peptide_results_dict.values())\n",
    "            \n",
    "            # Create a row for each sample\n",
    "            for sample, data in self.total_peptide_results_dict.items():\n",
    "                value = data[value_key]\n",
    "                error = data[error_key]\n",
    "                \n",
    "                # Calculate relative percentage\n",
    "                rel_value = (value / total_value * 100) if total_value > 0 else 0\n",
    "                \n",
    "                # Get number of replicates\n",
    "                num_replicates = len(data.get('replicate_data', {}).get('replicate_counts', []))\n",
    "                \n",
    "                # Create the row\n",
    "                row = {\n",
    "                    'Sample': sample,\n",
    "                    value_column: value,\n",
    "                    error_column: error,\n",
    "                    f'Relative_{value_column}': rel_value,\n",
    "                    'Replicates': num_replicates\n",
    "                }\n",
    "                \n",
    "                # Add additional data if available\n",
    "                if 'replicate_data' in data:\n",
    "                    # Calculate mean of replicates for more accurate CV%\n",
    "                    if use_count:\n",
    "                        replicate_values = data['replicate_data'].get('replicate_counts', [])\n",
    "                    else:\n",
    "                        replicate_values = data['replicate_data'].get('replicate_abundances', [])\n",
    "                    \n",
    "                    if replicate_values:\n",
    "                        mean = sum(replicate_values) / len(replicate_values)\n",
    "                        # Calculate SD from SEM: SD = SEM * sqrt(n)\n",
    "                        sd = error * (len(replicate_values) ** 0.5) if len(replicate_values) > 0 else 0\n",
    "                        # Calculate CV%\n",
    "                        cv_percent = (sd / mean * 100) if mean > 0 else 0\n",
    "                        row['CV%'] = cv_percent\n",
    "                \n",
    "                data_rows.append(row)\n",
    "                \n",
    "            # Create DataFrame\n",
    "            df = pd.DataFrame(data_rows)\n",
    "            \n",
    "            # Sort by sample name for consistency\n",
    "            df = df.sort_values('Sample')\n",
    "            \n",
    "            # Format numeric columns\n",
    "            df[f'Relative_{value_column}'] = df[f'Relative_{value_column}'].round(2)\n",
    "            if 'CV%' in df.columns:\n",
    "                df['CV%'] = df['CV%'].round(2)\n",
    "            \n",
    "            if not use_count:\n",
    "                # Format abundance values in scientific notation\n",
    "                df[value_column] = df[value_column].apply(lambda x: f\"{x:.2e}\")\n",
    "                df[error_column] = df[error_column].apply(lambda x: f\"{x:.2e}\")\n",
    "            else:\n",
    "                # Format count values as integers\n",
    "                df[value_column] = df[value_column].astype(int)\n",
    "                df[error_column] = df[error_column].round(2)\n",
    "                \n",
    "            # Add a Total row\n",
    "            total_row = {\n",
    "                'Sample': 'Total',\n",
    "                value_column: total_value if use_count else f\"{total_value:.2e}\",\n",
    "                error_column: None,  # Can't meaningfully combine SEMs\n",
    "                f'Relative_{value_column}': 100.0,\n",
    "                'Replicates': sum(row['Replicates'] for row in data_rows)\n",
    "            }\n",
    "            \n",
    "            if 'CV%' in df.columns:\n",
    "                total_row['CV%'] = None  # Can't meaningfully combine CVs\n",
    "                \n",
    "            df = safe_concat([df, pd.DataFrame([total_row])], ignore_index=True)\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating sample summary DataFrame: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1612897",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plotter:\n",
    "    def __init__(self, data_transformer, data_handler):\n",
    "        self.data_transformer = data_transformer\n",
    "        self.data_handler = data_handler\n",
    "        #self.state_manager = PlotState()\n",
    "        # Set up output widgets\n",
    "        self.plot_output = widgets.Output()\n",
    "        self.export_output = widgets.Output()\n",
    "        # Initialize necessary properties\n",
    "        self.current_fig = None\n",
    "        self.protein_df = None\n",
    "        self.sum_df = None\n",
    "        \n",
    "        # Create UI buttons\n",
    "        self._create_buttons()\n",
    "    \n",
    "        # Connect event handlers explicitly\n",
    "        self.plot_button.on_click(self.on_plot_button_click)\n",
    "        self.download_plot_button.on_click(self.on_download_plot_click)\n",
    "\n",
    "        data_handler_methods = [\n",
    "            # Data processing methods\n",
    "            'process_total_peptide_data_and_filter_dataframe',\n",
    "            'process_protein_data',\n",
    "            'process_bioactive_data',\n",
    "            'calculate_bioactivt_count_and_dict',\n",
    "            'calculate_group_metrics',\n",
    "            'create_function_df',\n",
    "            'reorganize_by_function',\n",
    "            \n",
    "            # Helper methods\n",
    "            'get_selected_proteins',\n",
    "            'contains_function',\n",
    "            'get_color_sequence',\n",
    "            '_fetch_protein_names',\n",
    "            \n",
    "            # UI related methods\n",
    "            #'update_group_options',\n",
    "            #'populate_protein_selector',\n",
    "            #'on_plot_func_or_pro_change',\n",
    "            #'on_plot_type_change',\n",
    "            #'on_data_loaded_func_and_color_gen',\n",
    "            'on_color_scheme_change',\n",
    "            'get_single_color'\n",
    "\n",
    "        ]\n",
    "        # Import important methods\n",
    "        self._import_methods_from_data_handler(data_handler_methods)\n",
    "        \n",
    "        self.data_transformer.plot_lock.observe(self._on_plot_lock_change_plotter, names='value')\n",
    "\n",
    "    def _on_plot_lock_change_plotter(self, change):\n",
    "        \"\"\"Handle changes in Plot_lock state\"\"\"\n",
    "        if change.new == False and change.old == True:\n",
    "            self.plot_button.disabled = self.data_transformer.plot_lock.value\n",
    "       \n",
    "    def _import_methods_from_data_handler(self, method_list):\n",
    "        \"\"\"Import specific methods from data_handler\"\"\"\n",
    "        for method_name in method_list:\n",
    "            if hasattr(self.data_handler, method_name):\n",
    "                setattr(self, method_name, getattr(self.data_handler, method_name))\n",
    "                #print(f\"Imported {method_name} from data_handler\")\n",
    "            else:\n",
    "                print(f\"WARNING: {method_name} not found in data_handler\")\n",
    "     \n",
    "    def _create_buttons(self):\n",
    "        \"\"\"Create the UI buttons\"\"\"\n",
    "        self.download_plot_button = widgets.Button(\n",
    "            description='Download Interactive Plot',\n",
    "            button_style='info',\n",
    "            icon='file',\n",
    "            layout=widgets.Layout(width='200px'),\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.plot_button = widgets.Button(\n",
    "            description='Generate/Update Data',\n",
    "            button_style='success',\n",
    "            icon='refresh',\n",
    "            layout=widgets.Layout(width='200px'),\n",
    "            disabled=self.data_transformer.plot_lock.value\n",
    "        )\n",
    "        \n",
    "    def get_data_attribute(self, attr_name, default=None):\n",
    "        \"\"\"Safely get an attribute from data_handler or data_transformer\"\"\"\n",
    "        # Try data_handler first\n",
    "        if hasattr(self.data_handler, attr_name):\n",
    "            return getattr(self.data_handler, attr_name)\n",
    "        \n",
    "        # Try data_transformer next\n",
    "        elif hasattr(self.data_transformer, attr_name):\n",
    "            return getattr(self.data_transformer, attr_name)\n",
    "        \n",
    "        # Finally try self\n",
    "        elif hasattr(self, attr_name):\n",
    "            return getattr(self, attr_name)\n",
    "        \n",
    "        # Return default if not found\n",
    "        return default\n",
    "    \n",
    "    def generate_download_link(self, content, filename, filetype='text/csv'):\n",
    "        \"\"\"Generate a download link for any content\"\"\"\n",
    "        if isinstance(content, pd.DataFrame):\n",
    "            if filetype == 'text/csv':\n",
    "                content = content.to_csv(index=False)\n",
    "            else:\n",
    "                content = content.to_csv(index=True)\n",
    "        if isinstance(content, str):\n",
    "            content = content.encode()\n",
    "        b64 = base64.b64encode(content).decode()\n",
    "        return f\"\"\"\n",
    "            <a id=\"download_link\" href=\"data:{filetype};base64,{b64}\" \n",
    "               download=\"{filename}\"\n",
    "               style=\"display: none;\">\n",
    "                Download {filename}\n",
    "            </a>\n",
    "            <script>\n",
    "                document.getElementById('download_link').click();\n",
    "            </script>\n",
    "            \"\"\"\n",
    "    \n",
    "    def on_download_plot_click(self, b):\n",
    "        \"\"\"Handle plot download button click with automatic download\"\"\"\n",
    "        if self.current_fig is not None:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            plot_filename = f'protein_plot_{timestamp}.html'\n",
    "            \n",
    "            with self.export_output:\n",
    "                self.export_output.clear_output(wait=True)\n",
    "                display(HTML(self.generate_download_link(\n",
    "                    self.current_fig.to_html(),\n",
    "                    plot_filename,\n",
    "                    'text/html'\n",
    "                )))\n",
    "        else:\n",
    "            print(\"Please generate a plot first.\")\n",
    "    \n",
    "    def display(self):\n",
    "        widget_box = widgets.HBox([\n",
    "            self.plot_button,\n",
    "            self.download_plot_button,\n",
    "        ])\n",
    "        # Bottom row spanning both columns\n",
    "        bottom_row = VBox([\n",
    "            widgets.HTML(\"<h3><u>Display and Export</u></h3>\"),\n",
    "            widget_box,\n",
    "            self.export_output\n",
    "        ], layout=widgets.Layout(\n",
    "            width='900px',\n",
    "            margin='0px',\n",
    "            padding='0px',\n",
    "            overflow='hidden',\n",
    "        ))\n",
    "\n",
    "        display(bottom_row)\n",
    "        display(self.plot_output)\n",
    "        \n",
    "    def on_export_button_click(self, b):\n",
    "        \"\"\"Handle data export with automatic download\"\"\"\n",
    "        if self.protein_df is not None:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            data_filename = f'protein_absorbance_analysis_{timestamp}.csv'\n",
    "            \n",
    "            with self.export_output:\n",
    "                self.export_output.clear_output(wait=True)\n",
    "                display(HTML(self.generate_download_link(\n",
    "                    self.protein_df,\n",
    "                    data_filename,\n",
    "                    'text/csv'\n",
    "                )))\n",
    "        else:\n",
    "            print(\"Please generate the analysis first.\")       \n",
    "        if self.data_transformer.merged_df is None or self.data_transformer.group_data_dict is None:\n",
    "            return None\n",
    "            \n",
    "        # Initialize dictionary to store results for all groups\n",
    "        total_peptide_results_dict = {}\n",
    "        \n",
    "        # Use consistent reference to merged dataframe\n",
    "        self.filtered_df = self.data_transformer.merged_df.copy()\n",
    "       \n",
    "        # Initialize masks\n",
    "        protein_mask = pd.Series(True, index=self.filtered_df.index)\n",
    "        function_mask = pd.Series(True, index=self.filtered_df.index)\n",
    "\n",
    "        protein_col = 'protein_name'\n",
    "\n",
    "\n",
    "        # Create protein filter mask if applicable\n",
    "        if self.protein_selector:\n",
    "            if 'All Proteins (No Filter)' not in self.protein_selector.value and protein_col is not None:\n",
    "                selected_proteins = self.selected_proteins\n",
    "                #print(f\"Selected proteins ({len(selected_proteins)}): {selected_proteins[:3]}...\")\n",
    "        \n",
    "                # Create mask for matching proteins in description\n",
    "                protein_mask = self.filtered_df[protein_col].fillna('').apply(\n",
    "                    lambda x: any(protein in x for protein in selected_proteins)\n",
    "                )\n",
    "                \n",
    "                # Debug output\n",
    "                #print(f\"Rows matched with protein matching: {protein_mask.sum()}\")\n",
    "                \n",
    "                # If still no matches, try case-insensitive matching\n",
    "                if protein_mask.sum() == 0:\n",
    "                    protein_mask = self.filtered_df[protein_col].fillna('').apply(\n",
    "                        lambda x: any(protein.lower() in x.lower() for protein in selected_proteins)\n",
    "                    )\n",
    "                    #print(f\"Rows matched with case-insensitive matching: {protein_mask.sum()}\")\n",
    "            else:\n",
    "                # Keep all rows if \"All Proteins\" is selected\n",
    "                protein_mask = pd.Series(True, index=self.filtered_df.index)\n",
    "        \n",
    "        # Create function filter mask if applicable\n",
    "        if self.function_selector:\n",
    "            function_col = None\n",
    "            for col_name in ['function', 'Function', 'FUNCTION']:\n",
    "                if col_name in self.filtered_df.columns:\n",
    "                    function_col = col_name\n",
    "                    break\n",
    "            \n",
    "            if function_col:\n",
    "                if 'All Functional Peptides' not in self.function_selector.value:\n",
    "                    selected_functions = self.function_selector.value\n",
    "                    function_mask = self.filtered_df[function_col].apply(\n",
    "                        lambda x: any(self.contains_function(x, func) for func in selected_functions)\n",
    "                    )\n",
    "                else:\n",
    "                    # Keep all rows if \"All Functional Peptides\" is selected\n",
    "                    function_mask = pd.Series(True, index=self.filtered_df.index)\n",
    "\n",
    "        # Apply both masks together\n",
    "        if self.plot_func_or_pro.value == 'Both':\n",
    "            combined_mask = protein_mask & function_mask\n",
    "        elif self.plot_func_or_pro.value == 'Selected Protein(s)':\n",
    "            combined_mask = protein_mask\n",
    "        elif self.plot_func_or_pro.value == 'Selected Function(s)':\n",
    "            combined_mask = function_mask\n",
    "        else: # None\n",
    "            combined_mask = pd.Series(True, index=self.filtered_df.index)\n",
    "        #print(\"length of filtered df\", len(self.filtered_df))\n",
    "        self.filtered_df = self.filtered_df[combined_mask]\n",
    "        # Debug output\n",
    "        #print(f\"Total rows before filtering: {len(self.data_transformer.merged_df)}\")\n",
    "        #print(f\"Rows after protein filter: {protein_mask.sum()}\")\n",
    "        #print(f\"Rows after function filter: {function_mask.sum()}\")\n",
    "        #print(f\"Rows after combined filters: {combined_mask.sum()}\")\n",
    "        #print(f\"Filtered DataFrame columns: {self.filtered_df.shape}\")\n",
    "        \n",
    "\n",
    "        #print(f\"Rows after OR filtering: {combined_mask.sum()}\")\n",
    "\n",
    "        # Process each group from the simplified group data structure\n",
    "        for group_name, abundance_columns in self.data_transformer.group_data_dict.items():\n",
    "            if group_name in self.group_selector.value:\n",
    "                # Calculate total abundance and SEM from the abundance columns\n",
    "\n",
    "                valid_abundance_cols = [f\"Avg_{col}\" for col in abundance_columns \n",
    "                                    if f\"Avg_{col}\" in self.filtered_df.columns]\n",
    "                \n",
    "                if not valid_abundance_cols:\n",
    "                    print(f\"Warning: No valid abundance columns found for group {group_name}\")\n",
    "                    continue\n",
    "                            \n",
    "                # Filter for non-zero, non-null values in any abundance column\n",
    "                temp_df = self.filtered_df[['unique ID'] + valid_abundance_cols].copy()\n",
    "                \n",
    "                # Convert abundance columns to numeric, forcing non-numeric values to NaN\n",
    "                for col in valid_abundance_cols:\n",
    "                    temp_df[col] = pd.to_numeric(temp_df[col], errors='coerce')\n",
    "                \n",
    "                # Additional filtering for valid data\n",
    "                valid_data_mask = (\n",
    "                    temp_df[valid_abundance_cols].notna().any(axis=1) & \n",
    "                    (temp_df[valid_abundance_cols] != 0).any(axis=1) &\n",
    "                    temp_df['unique ID'].notna()\n",
    "                )\n",
    "                temp_df = temp_df[valid_data_mask]\n",
    "                \n",
    "                if temp_df.empty:\n",
    "                    print(f\"Warning: No valid data for group {group_name}\")\n",
    "                    # Add empty results to maintain group in output\n",
    "                    total_peptide_results_dict[group_name] = {\n",
    "                        'unique_peptides': 0,\n",
    "                        'total_Absorbance': 0,\n",
    "                        'total_sem': 0,\n",
    "                        'abundance_sem': 0,\n",
    "                        'count_sem': 0,\n",
    "                        'replicate_data': {\n",
    "                            'abundance_columns': valid_abundance_cols,\n",
    "                            'replicate_counts': [0] * len(valid_abundance_cols),\n",
    "                            'replicate_abundances': [0] * len(valid_abundance_cols)\n",
    "                        }\n",
    "                    }\n",
    "                    continue\n",
    "                    \n",
    "                # Rest of the function remains the same...\n",
    "                # Calculate peptide counts for each replicate\n",
    "                replicate_counts = []\n",
    "                for col in valid_abundance_cols:\n",
    "                    count = temp_df[temp_df[col].notna() & (temp_df[col] != 0)]['unique ID'].nunique()\n",
    "                    replicate_counts.append(count)\n",
    "                \n",
    "                # Calculate mean count and SEM across replicates\n",
    "                if len(replicate_counts) > 1:\n",
    "                    count_sem = np.std(replicate_counts, ddof=1) / np.sqrt(len(replicate_counts))\n",
    "                else:\n",
    "                    count_sem = 0\n",
    "                    \n",
    "                # Calculate abundance statistics\n",
    "                abundances = temp_df[valid_abundance_cols].values.astype(float)\n",
    "                peptide_means = np.nanmean(abundances, axis=1)\n",
    "                total_abundance = np.nansum(peptide_means)\n",
    "                \n",
    "                # Calculate SEM for abundance\n",
    "                peptide_sems = np.nanstd(abundances, axis=1) / np.sqrt(abundances.shape[1])\n",
    "                total_sem = np.sqrt(np.nansum(peptide_sems ** 2))\n",
    "\n",
    "                # Calculate total count for group\n",
    "                all_unique_peptides = temp_df[\n",
    "                    (temp_df[valid_abundance_cols] > 0).any(axis=1)\n",
    "                ]['unique ID'].nunique()\n",
    "                \n",
    "                # Store results for this group\n",
    "                total_peptide_results_dict[group_name] = {\n",
    "                    'unique_peptides': all_unique_peptides,\n",
    "                    'total_Absorbance': total_abundance,\n",
    "                    'total_sem': total_sem,\n",
    "                    'abundance_sem': total_sem,\n",
    "                    'count_sem': count_sem,\n",
    "                    'replicate_data': {\n",
    "                        'abundance_columns': valid_abundance_cols,\n",
    "                        'replicate_counts': replicate_counts,\n",
    "                        'replicate_abundances': [temp_df[col].replace(0, np.nan).sum() for col in valid_abundance_cols]\n",
    "                    }\n",
    "                }\n",
    "           \n",
    "            return total_peptide_results_dict, self.filtered_df\n",
    "\n",
    "    def plot_total_peptides(self):\n",
    "        \"\"\"Plot total peptides for each group\"\"\"\n",
    "        data = self.total_peptide_results_dict\n",
    "        if not data:\n",
    "            print(\"No data to plot\")\n",
    "            return None, None\n",
    "\n",
    "        first_color = self.get_single_color()  # Get first element from the list\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "        # Common styling configurations\n",
    "        COMMON_LAYOUT = {\n",
    "            'template': 'plotly_white',\n",
    "            'height': 800,\n",
    "            'width': 1000,\n",
    "            'margin': dict(t=100, l=100, r=100),\n",
    "            'showlegend': False,\n",
    "            'font': {'color': 'black'},\n",
    "        }\n",
    "        \n",
    "        AXIS_STYLE = {\n",
    "            'showline': True,\n",
    "            'linewidth': 1,\n",
    "            'linecolor': 'black',\n",
    "            'mirror': False,\n",
    "            'gridcolor': 'lightgray',\n",
    "            'showgrid': True,\n",
    "            'zeroline': False,\n",
    "        }\n",
    "        \n",
    "        def create_title(text):\n",
    "            return {\n",
    "                'text': text,\n",
    "                'y': 0.95,\n",
    "                'x': 0.5,\n",
    "                'xanchor': 'center',\n",
    "                'yanchor': 'top',\n",
    "                'font': {'size': 18, 'color': 'black'}\n",
    "            }\n",
    "\n",
    "        # Prepare data\n",
    "        groups = list(data.keys())\n",
    "        plot_data = {\n",
    "            'abundances': [data[group]['total_Absorbance'] for group in groups],\n",
    "            'abundance_sems': [data[group]['abundance_sem'] for group in groups],\n",
    "            'counts': [data[group]['unique_peptides'] for group in groups],\n",
    "            'count_sems': [data[group]['count_sem'] for group in groups]\n",
    "        }\n",
    "          \n",
    "        # Determine which plot to create based on use_count\n",
    "        if hasattr(self, 'abs_or_count') and self.abs_or_count.value:\n",
    "            if self.abs_or_count.value == 'Count':\n",
    "                # Create count figure\n",
    "                fig = go.Figure()\n",
    "                # Add count bars\n",
    "                fig.add_trace(go.Bar(\n",
    "                    x=groups,\n",
    "                    y=plot_data['counts'],\n",
    "                    name='Peptide Count',\n",
    "                    marker=dict(\n",
    "                        color=first_color,\n",
    "                        line=dict(color='black', width=1)\n",
    "                    ),\n",
    "                    error_y=dict(\n",
    "                        type='data',\n",
    "                        array=plot_data['count_sems'],\n",
    "                        visible=True,\n",
    "                        thickness=1.5,\n",
    "                        width=4,\n",
    "                        color='#000000'\n",
    "                    ),\n",
    "                    hovertemplate=(\n",
    "                        \"Group: %{x}<br>\"\n",
    "                        \"Unique Peptides: %{y:.0f}<br>\"\n",
    "                        \"SEM: %{error_y.array:.1f}<br>\"\n",
    "                        \"<extra></extra>\"\n",
    "                    )\n",
    "                ))\n",
    "                \n",
    "                # Add count labels\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=groups,\n",
    "                    y=[c + (s * 1.2) for c, s in zip(plot_data['counts'], plot_data['count_sems'])],\n",
    "                    mode='text',\n",
    "                    text=[f\"{int(c):,}\" for c in plot_data['counts']],\n",
    "                    textposition='top center',\n",
    "                    textfont=dict(size=12),\n",
    "                    showlegend=False,\n",
    "                    hoverinfo='none'\n",
    "                ))\n",
    "      \n",
    "                fig.update_yaxes(tickformat=\",d\")\n",
    "                \n",
    "            else: # Create abundance figure\n",
    "                fig = go.Figure()\n",
    "                # Add abundance bars\n",
    "                fig.add_trace(go.Bar(\n",
    "                    x=groups,\n",
    "                    y=plot_data['abundances'],\n",
    "                    name='Total Absorbance',\n",
    "                    marker=dict(\n",
    "                        color=first_color,\n",
    "                        line=dict(color='black', width=1)\n",
    "                    ),\n",
    "                    error_y=dict(\n",
    "                        type='data',\n",
    "                        array=plot_data['abundance_sems'],\n",
    "                        visible=True,\n",
    "                        thickness=1.5,\n",
    "                        width=4,\n",
    "                        color='#000000'\n",
    "                    ),\n",
    "                    hovertemplate=(\n",
    "                        \"Group: %{x}<br>\"\n",
    "                        \"Total Abundance: %{y:.2e}<br>\"\n",
    "                        \"SEM: %{error_y.array:.2e}<br>\"\n",
    "                        \"<extra></extra>\"\n",
    "                    )\n",
    "                ))\n",
    "                \n",
    "                # Add abundance labels\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=groups,\n",
    "                    y=[a + s for a, s in zip(plot_data['abundances'], plot_data['abundance_sems'])],\n",
    "                    mode='text',\n",
    "                    text=[f\"{a:.2e}\" for a in plot_data['abundances']],\n",
    "                    textposition='top center',\n",
    "                    textfont=dict(size=14),\n",
    "                    showlegend=False,\n",
    "                    hoverinfo='none'\n",
    "                ))\n",
    "\n",
    "\n",
    "            # Update layout\n",
    "            fig.update_layout(\n",
    "                **COMMON_LAYOUT,\n",
    "                title=create_title(self.plot_title),\n",
    "                xaxis_title=self.x_axis_label,\n",
    "                yaxis_title=self.y_axis_label,\n",
    "                xaxis=AXIS_STYLE,\n",
    "                yaxis=AXIS_STYLE\n",
    "            )\n",
    "            \n",
    "            # Configure axes\n",
    "            fig.update_xaxes(\n",
    "                tickangle=45,\n",
    "                title_font={\"size\": 18},\n",
    "                tickfont={\"size\": 16}\n",
    "            )\n",
    "            \n",
    "            fig.update_yaxes(\n",
    "                title_font={\"size\": 18},\n",
    "                tickfont={\"size\": 16},\n",
    "                gridcolor=\"lightgray\",\n",
    "                showgrid=True,\n",
    "                type=\"log\",\n",
    "                exponentformat=\"e\"\n",
    "            )\n",
    "                # Mark generation as complete\n",
    "        #self.state_manager.generate_completed()\n",
    "        \n",
    "        return fig\n",
    "   \n",
    "    def generate_plot_title(self):\n",
    "        selected_groups = self.selected_groups\n",
    "        if self.plot_type.value != 'Corr. Scatter Plots':\n",
    "            base_title = f'{self.abs_or_count.value} Distribution - {self.invert_plot.value}' \n",
    "        else:\n",
    "            if len(selected_groups) >2:\n",
    "                base_title = f'Scatter Plot Matrix'\n",
    "            else:\n",
    "                base_title = f\"Correlation Scatter Plot {selected_groups[0]} vs. {selected_groups[1]}\"\n",
    "\n",
    "        protein_title = \"\"\n",
    "        function_title = \"\"\n",
    "        function_filter_prefix = \"\"\n",
    "\n",
    "        # Add protein/function filter info\n",
    "        if hasattr(self, 'plot_func_or_pro'):\n",
    "            function_filter_prefix = \"Filtered By:\"\n",
    "            protein_title = \"\"\n",
    "            function_title = \"\"\n",
    "            \n",
    "            # Handle protein selector\n",
    "            if self.plot_func_or_pro.value in ['Selected Protein(s)', 'Both']:\n",
    "                    if 'All Proteins' in self.selected_proteins:\n",
    "                        protein_title = \"<br>Protein(s): All\"\n",
    "                    else:\n",
    "                        selected_proteins = self.selected_proteins\n",
    "                        if len(selected_proteins) > 3:\n",
    "                            protein_display = \", \".join(selected_proteins[:3]) + f\"... (+{len(selected_proteins)-3} more)\"\n",
    "                        else:\n",
    "                            protein_display = \", \".join(selected_proteins)\n",
    "                        protein_title = f\"<br>Protein(s): {protein_display}\"\n",
    "\n",
    "            # Handle function selector\n",
    "            if self.plot_func_or_pro.value in ['Selected Function(s)', 'Both']:\n",
    "                    if 'All Functions' in self.selected_functions:\n",
    "                        function_title = \"<br>Function(s): All\"\n",
    "                    else:\n",
    "                        selected_functions = self.selected_functions\n",
    "                        if len(selected_functions) > 3:\n",
    "                            function_display = \", \".join(selected_functions[:3]) + f\"... (+{len(selected_functions)-3} more)\"\n",
    "                        else:\n",
    "                            function_display = \", \".join(selected_functions)\n",
    "                        function_title = f\"<br>Function(s): {function_display}\"\n",
    "\n",
    "\n",
    "            # Only add prefix if we have actual filters\n",
    "            if not protein_title and not function_title:\n",
    "                function_filter_prefix = \"\"\n",
    "\n",
    "            # Combine filter titles without extra spaces\n",
    "            self.filters_combined = \"\".join(filter(None, [function_filter_prefix, protein_title, function_title]))\n",
    "        else:\n",
    "            # Ensure filters_combined is set even if plot_func_or_pro doesn't exist\n",
    "            self.filters_combined = \"\"\n",
    "\n",
    "        # Generate final title\n",
    "        if self.title_widget.value != '':\n",
    "            return self.title_widget.value\n",
    "            \n",
    "        if self.plot_func_or_pro.value == 'Both':\n",
    "            if self.plot_type.value != 'Corr. Scatter Plots':\n",
    "                return f\"{base_title} - {self.invert_plot.value} ({self.filters_combined})\"\n",
    "            else:\n",
    "                return f\"{base_title} - ({self.filters_combined})\"\n",
    "\n",
    "        return base_title\n",
    "    \n",
    "    def get_plot_labels(self, use_count=False, selected_groups=None, title=None, orientation=None, is_relative_metric=None):\n",
    "        \"\"\"Generate standardized plot labels including x_axis, y_axis, title, and legend title.\"\"\"\n",
    "        # Determine if we're using count based on widget value if not explicitly provided\n",
    "        if self.abs_or_count.value == 'Count':\n",
    "            use_count = True\n",
    "        else:\n",
    "            use_count = False\n",
    "        selected_groups = self.selected_groups \n",
    "        plot_type = self.plot_func_or_pro.value\n",
    "        # Use provided orientation or get from widget\n",
    "        if orientation is None:\n",
    "            orientation = self.invert_plot.value\n",
    "            \n",
    "        # Determine if metric is relative if not explicitly provided\n",
    "        relative_metric = self.metric_type.value\n",
    "        \n",
    "        # Get the plot title from custom method or generate based on parameters\n",
    "        if title is None:\n",
    "            plot_title = self.generate_plot_title()\n",
    "\n",
    "        # Get log transform setting\n",
    "        use_log = self.log_transform.value if hasattr(self, 'log_transform') else False\n",
    "\n",
    "        # Determine y-axis title based on metric type\n",
    "        if use_count:\n",
    "            metric_base = \"Peptide Count\"\n",
    "        else:\n",
    "            metric_base = \"Summed Absorbance\"\n",
    "\n",
    "        if plot_type == 'Both' or plot_type == 'No Filter':\n",
    "            if self.plot_type.value == 'Grouped Bar Plots':\n",
    "                if use_count:\n",
    "                    y_axis_label = f\"Unique Peptide Count\"\n",
    "                else:\n",
    "                    y_axis_label = f\"Summed Absorbance\"\n",
    "\n",
    "        if relative_metric == 'Relative':\n",
    "            y_axis_label = f\"Relative {metric_base} (%)\"\n",
    "        else:\n",
    "            # Add log10 to the y-axis title if log transform is enabled\n",
    "            if use_log:\n",
    "                y_axis_label = f\"log<sub>10</sub> ({metric_base})\"\n",
    "            else:\n",
    "                y_axis_label = f\"{metric_base}\"\n",
    "       \n",
    "        # Determine x-axis title and legend title based on orientation\n",
    "        if orientation == 'By Protein':\n",
    "            x_axis_label = 'Proteins'\n",
    "            legend_title = 'Samples'\n",
    "        elif orientation == 'By Function':\n",
    "            x_axis_label = 'Functions'\n",
    "            legend_title = 'Samples'\n",
    "        else: # By Sample\n",
    "            x_axis_label = 'Samples'\n",
    "            if plot_type == 'Selected Function(s)' or plot_type == 'Functional vs Non-Functional Peptides':\n",
    "                legend_title = 'Functions'\n",
    "            elif plot_type == 'Selectd Protein(s)':\n",
    "                legend_title = 'Proteins'\n",
    "            else:\n",
    "                legend_title = ''\n",
    "\n",
    "        # Update titles from widgets if available\n",
    "        if hasattr(self, 'legend_widget') and self.legend_widget.value:\n",
    "            legend_title = self.legend_widget.value\n",
    "        \n",
    "        if hasattr(self, 'xlabel_widget') and self.xlabel_widget.value:\n",
    "            x_axis_label = self.xlabel_widget.value\n",
    "            \n",
    "        if hasattr(self, 'ylabel_widget') and self.ylabel_widget.value:\n",
    "            y_axis_label = self.ylabel_widget.value\n",
    "            \n",
    "        # Store as strings, not tuples\n",
    "        self.x_axis_label = str(x_axis_label)\n",
    "        self.y_axis_label = str(y_axis_label)\n",
    "        self.plot_title = str(plot_title)\n",
    "        self.legend_title = str(legend_title)\n",
    "        \n",
    "        return (self.x_axis_label, self.y_axis_label, self.plot_title, self.legend_title)\n",
    " \n",
    "    def plot_stacked_bar_scaled(self, selected_groups, use_count=False):\n",
    "\n",
    "        # Set up items to display based on plot type\n",
    "        plot_type = self.plot_func_or_pro.value\n",
    "        \n",
    "        # Create figure object before adding traces\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Check if we're using relative metrics\n",
    "        is_relative_metric = hasattr(self, 'metric_type') and 'relative' in self.metric_type.value.lower()\n",
    "        orientation = self.invert_plot.value\n",
    "\n",
    "        # Get log transform setting\n",
    "        use_log = self.log_transform.value if hasattr(self, 'log_transform') else False\n",
    "\n",
    "        if orientation== 'By Sample':\n",
    "            # Initialize the scaled_df based on plot type\n",
    "            if plot_type == 'Selected Function(s)' or plot_type == 'Functional vs Non-Functional Peptides':\n",
    "                scaled_df = self.function_df.copy()\n",
    "            elif plot_type == 'Selected Protein(s)':  # Selected Protein(s)\n",
    "                scaled_df = self.protein_df.copy()\n",
    "            elif plot_type == 'No Filter':\n",
    "                scaled_df = self.sample_distribution_summary_df.copy()\n",
    "            elif plot_type == 'Both':\n",
    "                scaled_df = safe_concat([self.function_df, self.protein_df])\n",
    "\n",
    "            # For relative metric, ensure all relative columns are properly calculated\n",
    "            if is_relative_metric:\n",
    "                for group in selected_groups:\n",
    "                    value_col = self.value_cols[group]\n",
    "                    rel_col = self.rel_cols[group]\n",
    "\n",
    "\n",
    "            # Calculate total sums for each group\n",
    "            total_sums = {}\n",
    "            for group in selected_groups:\n",
    "                if use_count:\n",
    "                    if plot_type == 'Selected Function(s)':\n",
    "                        total_sum = self.function_count_totals_dict[group]\n",
    "                    elif plot_type == 'Selected Protein(s)':  # Selected Protein(s)\n",
    "                        total_sum = self.protein_count_bysample_dict[group]\n",
    "                    elif plot_type == 'Both':\n",
    "                        total_sum = self.abundance_count_by_sample_dict[group]['unique_peptides']\n",
    "                    elif plot_type == 'Functional vs Non-Functional Peptides': \n",
    "                        total_sum = self.abundance_count_by_sample_dict[group]['unique_peptides']\n",
    "\n",
    "                else:  # abundance\n",
    "                    if plot_type == 'Selected Function(s)':\n",
    "                        total_sum = self.function_absorbance_totals_dict[group]\n",
    "\n",
    "                    elif plot_type == 'Selected Protein(s)':  # Selected Protein(s)\n",
    "                        sample_key = self.value_cols[group]\n",
    "                        if sample_key in self.sum_df['Sample'].values:\n",
    "                            total_sum = self.sum_df.loc[self.sum_df['Sample'] == sample_key, 'Total_Sum'].values[0]\n",
    "                        else:\n",
    "                            total_sum = self.protein_df[sample_key].sum()\n",
    "                    elif plot_type == 'Both':\n",
    "                        total_sum = self.abundance_count_by_sample_dict[group]['total_abundance']\n",
    "                    elif plot_type == 'Functional vs Non-Functional Peptides': \n",
    "                        total_sum = self.abundance_count_by_sample_dict[group]['total_abundance']\n",
    "\n",
    "                if plot_type != 'No Filter':\n",
    "                    total_sums[group] = total_sum\n",
    "\n",
    "             # Handle minor items and get selected items\n",
    "            if plot_type == 'Selected Function(s)':\n",
    "                selected_items =  self.selected_functions\n",
    "                #minor_label = 'Minor Functions'\n",
    "            elif plot_type == 'Selected Protein(s)':# Selected Protein(s)\n",
    "                selected_items = self.selected_proteins\n",
    "               #minor_label = 'Minor Proteins'\n",
    "            elif plot_type == 'No Filter':\n",
    "                selected_items = selected_groups\n",
    "                if use_count:\n",
    "                    total_sum = scaled_df[scaled_df['Sample'] =='Total']['Peptide_Count'].sum()\n",
    "                else:\n",
    "                    total_sum = scaled_df[scaled_df['Sample'] == 'Total']['Total_Abundance'].sum()\n",
    "            elif plot_type == 'Functional vs Non-Functional Peptides':\n",
    "                selected_items = list(self.function_df['Description'].unique())\n",
    "            # Get colors\n",
    "            if plot_type == 'Selected Function(s)' or plot_type == 'Both' or plot_type == 'Functional vs Non-Functional Peptides':\n",
    "                colors = [self.function_color_map.get(f, '#CCCCCC') for f in selected_items]\n",
    "            elif plot_type == 'Selected Protein(s)' or plot_type == 'Both':  # Selected Protein(s)\n",
    "                colors = self.get_color_sequence(len(self.selected_proteins))\n",
    "                if self.plot_minor.value:\n",
    "                    colors.append('#808080')\n",
    "            elif plot_type == 'No Filter':\n",
    "                colors = self.get_color_sequence(len(selected_groups))\n",
    "\n",
    "            # Add traces for each item\n",
    "            for i, item in enumerate(selected_items):\n",
    "                y_values = []\n",
    "                hover_texts = []\n",
    "                \n",
    "                # Create display name for the item\n",
    "                display_name = self.redact_string_descriptions(item)\n",
    "\n",
    "                if plot_type != 'No Filter':\n",
    "                    item_data = scaled_df[scaled_df['Description'] == item]\n",
    "                    for group in selected_groups:\n",
    "                        if len(item_data) > 0:\n",
    "                            value_col = self.value_cols[group]\n",
    "                            rel_col = self.rel_cols[group]\n",
    "                            total_value_unique = total_sums[group]\n",
    "                            if len(item_data) > 0:\n",
    "                                value = item_data[value_col].iloc[0]\n",
    "                                rel_value = item_data[rel_col].iloc[0] if rel_col in item_data.columns else 0\n",
    "\n",
    "\n",
    "                                # Calculate y-value based on metric type\n",
    "                                if is_relative_metric:\n",
    "                                    y_value = rel_value\n",
    "                                else:\n",
    "                                    y_value = rel_value/100 * total_value_unique if total_value_unique > 0 else 0\n",
    "                    \n",
    "                            y_values.append(y_value)\n",
    "\n",
    "                            # Create hover text\n",
    "                            hover_text = (\n",
    "                                f\"{'Function' if plot_type == 'Selected Function(s)' else 'Protein'}: {item}<br>\"\n",
    "                                f\"Sample: {group}<br>\"\n",
    "                                f\"Relative {self.metric_name}: {rel_value:.2f}%<br>\"\n",
    "                                f\"Absolute {self.metric_name}: {value:{self.num_format}}<br>\"\n",
    "                            )\n",
    "                            hover_texts.append(hover_text)\n",
    "                        \n",
    "                        else:\n",
    "                            y_values.append(0)\n",
    "                            hover_texts.append(f\"No data for {item} in {group}\")\n",
    "                else:  \n",
    "                    item_data = scaled_df[scaled_df['Sample'] == item]\n",
    "                    if len(item_data) > 0:\n",
    "                        if plot_type == 'No Filter':\n",
    "                            value_col = 'Peptide_Count' if use_count else 'Total_Abundance'\n",
    "                            rel_col = 'Relative_Peptide_Count' if use_count else 'Relative_Total_Abundance'\n",
    "                            rel_value = item_data[rel_col].iloc[0] if rel_col in item_data.columns else 0\n",
    "\n",
    "                            #total_value_unique = total_sums[group][0]\n",
    "                            value = item_data[value_col].iloc[0]\n",
    "                            value = int(float(value))\n",
    "                            rel_value = int(float(rel_value))\n",
    "\n",
    "                            # Calculate y-value based on metric type\n",
    "                            if is_relative_metric:\n",
    "                                y_value = rel_value\n",
    "                            else:\n",
    "                               # y_value = rel_value/100 * total_value_unique if total_value_unique > 0 else 0\n",
    "                                y_value = value\n",
    "                            y_values.append(y_value)\n",
    "\n",
    "                            # Create hover text\n",
    "                            new_name = 'Peptide Count' if use_count else 'Total Absorbance'\n",
    "                            hover_text = (\n",
    "\n",
    "                                f\"Sample: {group}<br>\"\n",
    "                                f\"Relative {new_name}: {rel_value:.2f}%<br>\"\n",
    "                                f\"Absolute {new_name}: {value:{self.num_format}}<br>\"\n",
    "                            )\n",
    "                            hover_texts.append(hover_text)\n",
    "                color = colors[i] if i < len(colors) else '#CCCCCC'\n",
    "                if plot_type != 'No Filter' and self.plot_minor.value == True:\n",
    "                    if item == 'Minor Functions' or item == 'Minor Proteins':\n",
    "                        color = '#808080'\n",
    "                # Add trace with explicit legend settings\n",
    "                fig.add_trace(go.Bar(\n",
    "                    name=display_name,\n",
    "                    x=selected_groups if plot_type != 'No Filter' else ['Total'],\n",
    "                    y=y_values,\n",
    "                    marker_color=color,\n",
    "                    hovertext=hover_texts,\n",
    "                    hoverinfo='text',\n",
    "                    showlegend=True  # Explicitly show in legend\n",
    "                ))\n",
    "\n",
    "            # Filter out zero values and sort the data\n",
    "            if plot_type == 'Selected Function(s)' or plot_type == 'Functional vs Non-Functional Peptides':\n",
    "                # Sort functions based on total values\n",
    "                if not is_relative_metric:\n",
    "                    function_totals_dict = scaled_df[self.value_cols.values()].sum(axis=1)\n",
    "                    scaled_df['Order'] = function_totals_dict\n",
    "                    scaled_df = scaled_df.sort_values(by='Order', ascending=False).reset_index(drop=True)\n",
    "            elif plot_type == 'Selected Protein(s)':  # Selected Protein(s)\n",
    "                # Sort proteins based on selected_proteins order\n",
    "                if hasattr(self, 'selected_proteins'):\n",
    "                    description_order = {desc: i for i, desc in enumerate(self.selected_proteins)}\n",
    "                    scaled_df['Order'] = scaled_df['Description'].map(description_order)\n",
    "                    scaled_df = scaled_df.sort_values(by='Order').reset_index(drop=True)              \n",
    "\n",
    "        else:  # 'By Protein or Function'\n",
    "            # Get colors based on selected color scheme\n",
    "            colors = self.get_color_sequence(len(selected_groups))\n",
    "        \n",
    "            all_items = []\n",
    "            items_to_process = []\n",
    "            if orientation == 'By Function' or plot_type == 'Selected Function(s)' or plot_type == 'Both':\n",
    "                items_to_process = self.selected_functions\n",
    "            elif orientation == 'By Protein' or plot_type == 'Selected Protein(s)' or plot_type == 'Both':\n",
    "                items_to_process = self.selected_proteins\n",
    "            if plot_type == 'Functional vs Non-Functional Peptides':\n",
    "                items_to_process = []\n",
    "                items_to_process = list(self.function_df['Description'].unique())\n",
    "\n",
    "            # Define dictionary to store totals\n",
    "            proteinfunc_totals = {}\n",
    "            # Populate proteinfunc_totals dictionary\n",
    "            for profunc in items_to_process:\n",
    "                if (orientation == 'By Function' and profunc in self.function_distribution_dict):\n",
    "                    proteinfunc_totals[profunc] = self.function_distribution_dict[profunc]\n",
    "                elif (orientation == 'By Protein' and profunc in self.protein_sample_distribution_dict):\n",
    "                    proteinfunc_totals[profunc] = self.protein_sample_distribution_dict[profunc]        \n",
    "                if plot_type == 'Functional vs Non-Functional Peptides':\n",
    "                    proteinfunc_totals[profunc] = self.function_distribution_dict[profunc]\n",
    "\n",
    "            # Get unique proteins/functions for x-axis\n",
    "            all_items = list(proteinfunc_totals.keys())\n",
    "            # Create display names for all items\n",
    "            display_items = [self.redact_string_descriptions(item) for item in all_items]\n",
    "\n",
    "            # Create a trace for each group\n",
    "            for i, group in enumerate(selected_groups):\n",
    "                y_values = []\n",
    "                hover_texts = []\n",
    "                \n",
    "                # For each protein/function, get its value for this group\n",
    "                for profunc in all_items:\n",
    "                    data = proteinfunc_totals[profunc]\n",
    "                                \n",
    "\n",
    "                    # Skip if no data for this group\n",
    "                    if 'values' not in data or group not in data['values']:\n",
    "                        y_values.append(0)\n",
    "                        hover_texts.append(f\"No data for {profunc} in {group}\")\n",
    "                        continue\n",
    "                        \n",
    "                    #print(\"data\",data)\n",
    "                    abs_value = data['values'][group]\n",
    "                    total_value = data['total_absorbance']\n",
    "                    rel_percentage = data['relative'][group] if 'relative' in data and group in data['relative'] else 0\n",
    "                    \n",
    "                    # Calculate y-value based on metric type\n",
    "                    if is_relative_metric:\n",
    "                        y_value = rel_percentage\n",
    "                    else:\n",
    "                        if use_count:\n",
    "                            # Get unique peptide count for the function\n",
    "                            unique_peptide_total = data.get('unique_peptide_count', 0)\n",
    "                            # Scale by the relative percentage\n",
    "                            y_value = unique_peptide_total * (rel_percentage / 100) if unique_peptide_total > 0 else 0\n",
    "                        else:\n",
    "                            # Get the total absorbance for the function\n",
    "                            total_absorbance = data.get('total_absorbance', 0)\n",
    "                            # Scale by the relative percentage\n",
    "                            y_value = total_absorbance * (rel_percentage / 100) if total_absorbance > 0 else 0\n",
    "\n",
    "                    y_values.append(y_value)\n",
    "                    \n",
    "                    # Format hover text\n",
    "                    abs_count_label = \"Count\" if use_count else \"Abundance\"\n",
    "                    hover_text = (\n",
    "                        f\"{'Function' if plot_type == 'Selected Function(s)' else 'Protein'}: {profunc}<br>\"\n",
    "                        f\"Sample: {group}<br>\"\n",
    "                        f\"Sample's contribution: {rel_percentage:.2f}%<br>\"\n",
    "                        f\"{abs_count_label} in sample: {abs_value:{self.num_format}}<br>\"\n",
    "                    )\n",
    "                    hover_texts.append(hover_text)\n",
    "                                # Get color for this item\n",
    "\n",
    "                color = colors[i] if i < len(colors) else '#CCCCCC'\n",
    "                # Add trace for this group (moved outside the inner loop)\n",
    "                fig.add_trace(go.Bar(\n",
    "                    name=group,\n",
    "                    x=display_items,  # Use display_items for x-axis\n",
    "                    y=y_values,\n",
    "                    marker_color=color,\n",
    "                    hovertext=hover_texts,\n",
    "                    hoverinfo='text',\n",
    "                    showlegend=True\n",
    "                ))\n",
    "        if is_relative_metric:\n",
    "            fig.update_layout(yaxis_range=[0, 100])\n",
    "    \n",
    "  \n",
    "\n",
    "        fig.update_layout(\n",
    "            barmode='stack',\n",
    "            title={\n",
    "                'text': self.plot_title,\n",
    "                'y': 0.95,\n",
    "                'x': 0.5,\n",
    "                'xanchor': 'center',\n",
    "                'yanchor': 'top',\n",
    "                'font': {\"size\": 18, 'color': 'black'}\n",
    "            },\n",
    "            xaxis_title=self.x_axis_label,\n",
    "            yaxis_title=self.y_axis_label,\n",
    "            yaxis=dict(\n",
    "                showline=True,\n",
    "                gridcolor='lightgray',\n",
    "                showgrid=True,\n",
    "                showticklabels=True,\n",
    "                linewidth=1,\n",
    "                linecolor='black',\n",
    "                mirror=False,\n",
    "                zeroline=False,  # Don't show zero line\n",
    "                type='log' if use_log and not is_relative_metric else 'linear',\n",
    "                range=[0, 100] if is_relative_metric else None,  # Set range to [0,100] for relative metrics\n",
    "                exponentformat='E' if use_log and not is_relative_metric else None,\n",
    "                showexponent='all' if use_log and not is_relative_metric else None\n",
    "            ),\n",
    "            xaxis=dict(\n",
    "                showline=True,\n",
    "                linewidth=1,\n",
    "                linecolor='black',\n",
    "                mirror=False,\n",
    "                tickangle=-90 if orientation == 'By Sample' else 45  # Adjust tick angle based on orientation\n",
    "            ),\n",
    "            legend_title=self.legend_title,\n",
    "            legend={\n",
    "                'yanchor': \"top\",\n",
    "                'y': 0.95,\n",
    "                'xanchor': \"left\",\n",
    "                'x': 1.05,\n",
    "                'traceorder': 'normal',\n",
    "                'font': {\"size\": 16, 'color': 'black'},\n",
    "                'bgcolor': 'rgba(255, 255, 255, 0.9)'\n",
    "            },\n",
    "            showlegend=True,\n",
    "            template='plotly_white',\n",
    "            height=820,\n",
    "            width=1200,\n",
    "            margin=dict(\n",
    "                t=100,\n",
    "                l=100,\n",
    "                r=100,\n",
    "                b=100\n",
    "            ),\n",
    "            hoverlabel=dict(\n",
    "                bgcolor=\"white\",\n",
    "                font_size=14,\n",
    "                font_family=\"Arial\"\n",
    "            ))\n",
    "        \n",
    "        fig.update_xaxes(\n",
    "            tickangle=45,\n",
    "            title_font={\"size\": 18},\n",
    "            tickfont={\"size\": 16},\n",
    "            tickfont_color=\"black\",  # Black tick labels\n",
    "            title_font_color=\"black\",  # Black axis title                \n",
    "        )\n",
    "        \n",
    "        # Update Y axis formatting based on metric\n",
    "        if is_relative_metric:\n",
    "            tick_format = \".1f\"  # Format as percentage with one decimal place for relative metrics\n",
    "            showticklabels_tf = True\n",
    "        else:\n",
    "            if use_count:\n",
    "                tick_format = \"\"  # Regular integers for counts\n",
    "            else:\n",
    "                tick_format = \".1e\"  # Scientific notation for abundance\n",
    "            showticklabels_tf = False\n",
    "        fig.update_yaxes(\n",
    "            title_font={\"size\": 18},\n",
    "            tickfont={\"size\": 16},\n",
    "            tickfont_color=\"black\",  # Black tick labels\n",
    "            title_font_color=\"black\",  # Black axis title\n",
    "            gridcolor=\"lightgray\",  # Light gray grid lines\n",
    "            showgrid=True,  # Show grid lines\n",
    "            zeroline=False,  # Hide zero line\n",
    "            exponentformat='E',\n",
    "            showexponent='all',\n",
    "            tickformat=tick_format,\n",
    "            showticklabels=showticklabels_tf\n",
    "        )\n",
    "        \n",
    "        # Always add scatter trace for totals, but calculate differently based on orientation\n",
    "        if not is_relative_metric:  # Only show totals for absolute metrics\n",
    "            if orientation== 'By Sample':\n",
    "                # Sample-wise totals calculation\n",
    "                # Format based on metric\n",
    "                if plot_type == 'No Filter':\n",
    "                    total_sum = int(float(total_sums[group] for group in selected_groups))\n",
    "\n",
    "                if use_count:\n",
    "                    text_format = [f\"{int(total_sums[group])}\" for group in selected_groups] if plot_type != 'No Filter' else [f\"{int(total_sum)}\"]\n",
    "                else: #abundance\n",
    "                    text_format = [f\"{total_sums[group]:.2e}\" for group in selected_groups] if plot_type != 'No Filter' else [f\"{total_sum:.2e}\"]\n",
    "        \n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=selected_groups if plot_type != 'No Filter' else ['Total'],\n",
    "                    y=[total_sums[group] for group in selected_groups] if plot_type != 'No Filter' else [total_sum],\n",
    "                    mode='text',\n",
    "                    text=text_format,\n",
    "                    textposition='top center',\n",
    "                    textfont=dict(size=12, color='black'),\n",
    "                    showlegend=True,\n",
    "                    name=f'Show Total {self.metric_name}',\n",
    "                    hoverinfo='none',\n",
    "                    texttemplate='%{text}'\n",
    "                ))\n",
    "            else: #By Protein\n",
    "                # Add totals display\n",
    "                if plot_type == 'Selected Function(s)' or self.invert_plot.value == 'By Function':\n",
    "                    # Function-wise totals\n",
    "                    items_to_show_temp = [f for f in self.selected_functions]\n",
    "                elif plot_type == 'Selected Protein(s)' or self.invert_plot.value == 'By Protein':\n",
    "                    items_to_show_temp = [p for p in self.selected_proteins]\n",
    "                if plot_type == 'Functional vs Non-Functional Peptides':\n",
    "                    items_to_show_temp = list(self.function_df['Description'].unique())\n",
    "                text_format = []\n",
    "                y_values = []\n",
    "                \n",
    "                items_to_show = []\n",
    "                # Convert set to list to avoid the error\n",
    "                for item in items_to_show_temp:\n",
    "                    if item not in items_to_show:\n",
    "\n",
    "                        items_to_show.append(item)\n",
    "\n",
    "                # Create display names for items to show\n",
    "                display_items_to_show = [self.redact_string_descriptions(item) for item in items_to_show]\n",
    "\n",
    "                for item in items_to_show:\n",
    "                    if item in proteinfunc_totals:\n",
    "                        if use_count:\n",
    "                            # Use the unique peptide count\n",
    "                            total = proteinfunc_totals[item]['unique_peptide_count']\n",
    "                            text_format.append(f\"{int(total)}\")\n",
    "                            y_values.append(total)\n",
    "                        else: #abundance\n",
    "                            # Sum the unique peptide absorbance values\n",
    "                            total = proteinfunc_totals[item]['total_absorbance']\n",
    "                            text_format.append(f\"{total:.2e}\")\n",
    "                            y_values.append(total)\n",
    "                    else:\n",
    "                        text_format.append(\"0\")\n",
    "                        y_values.append(0)\n",
    "                # Add the totals trace\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=display_items_to_show,\n",
    "                    y=y_values,\n",
    "                    mode='text',\n",
    "                    text=text_format,\n",
    "                    textposition='top center',\n",
    "                    textfont=dict(size=12, color='black'),\n",
    "                    showlegend=True,\n",
    "                    name=f'Show Total {self.metric_name}',\n",
    "                    hoverinfo='none',\n",
    "                    texttemplate='%{text}'\n",
    "                ))     \n",
    "                    \n",
    "        # Mark generation as complete\n",
    "       #self.state_manager.generate_completed()\n",
    "        \n",
    "        return fig     \n",
    "    \n",
    "    def create_grouped_bar_plot(self, selected_groups, use_count=False):\n",
    "        \"\"\"Generate interactive Plotly grouped bar plots for proteins or functions\"\"\"\n",
    "        # Check if we have dat\n",
    "        if (self.plot_func_or_pro.value == 'Selected Function(s)' and not self.function_distribution_dict) or \\\n",
    "        (self.plot_func_or_pro.value != 'Selected Function(s)' and (self.protein_df is None or len(self.protein_df) == 0)):\n",
    "            print(\"No data available for plotting.\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            # Check if we're using relative metrics\n",
    "            is_relative_metric = hasattr(self, 'metric_type') and 'relative' in self.metric_type.value.lower()\n",
    "            \n",
    "            # Get log transform setting\n",
    "            use_log = self.log_transform.value if hasattr(self, 'log_transform') else False\n",
    "            \n",
    "            # Create figure\n",
    "            fig = go.Figure()\n",
    "            display_items = []\n",
    "            # Determine orientation\n",
    "            orientation = self.invert_plot.value if hasattr(self, 'invert_plot') else 'By Sample'\n",
    "            \n",
    "            # Set up items to display based on plot type\n",
    "            plot_type = self.plot_func_or_pro.value\n",
    "            if orientation == 'By Function':\n",
    "                display_items = self.selected_functions\n",
    "                data_dict = self.function_distribution_dict\n",
    "            elif orientation == 'By Protein': # orientation == 'By Protein'\n",
    "                display_items = self.selected_proteins\n",
    "                data_dict = self.protein_sample_distribution_dict\n",
    " \n",
    "            if orientation == 'By Sample' and plot_type == 'Selected Function(s)':\n",
    "                display_items = self.selected_functions\n",
    "                data_dict = self.function_distribution_dict\n",
    "            elif orientation == 'By Sample' and plot_type == 'Selected Protein(s)':\n",
    "                display_items = self.selected_proteins\n",
    "                data_dict = self.protein_sample_distribution_dict\n",
    "            \n",
    "            if plot_type == 'Functional vs Non-Functional Peptides':\n",
    "                display_items = ['Functional Peptides','Non-Functional Peptides']\n",
    "                data_dict = self.function_distribution_dict\n",
    "\n",
    "            # Based on orientation, determine categories and bars\n",
    "            if orientation != 'By Sample':\n",
    "                # Filter to only include items that have data\n",
    "                display_items = [item for item in display_items if item in data_dict]\n",
    "                \n",
    "                if not selected_groups or not display_items:\n",
    "                    print(\"No valid groups or items selected for plotting.\")\n",
    "                    return None\n",
    "                categories = display_items\n",
    "                bar_groups = selected_groups\n",
    "                color_sequence = self.get_color_sequence(len(selected_groups))\n",
    "                color_mapping = {group: color_sequence[i] for i, group in enumerate(selected_groups)}\n",
    "            else:  # 'By Sample'\n",
    "                categories = selected_groups\n",
    "                bar_groups = display_items\n",
    "                color_sequence = self.get_color_sequence(len(display_items))\n",
    "                color_mapping = {item: color_sequence[i] for i, item in enumerate(display_items)}\n",
    "                # Special color for Minor items\n",
    "                minor_key = 'Minor Functions' if plot_type == 'Selected Function(s)' else 'Minor Proteins'\n",
    "                if minor_key in bar_groups:\n",
    "                    color_mapping[minor_key] = '#808080'  # Grey\n",
    "            \n",
    "            # Calculate bar positions\n",
    "            n_bar_groups = len(bar_groups)\n",
    "            bar_width = 0.8 / n_bar_groups\n",
    "            \n",
    "            # Create display names for categories\n",
    "            display_categories = [self.redact_string_descriptions(cat) for cat in categories]\n",
    "            \n",
    "            # For each bar group, create a trace\n",
    "            for idx, bar_group in enumerate(bar_groups):\n",
    "                x_positions = [i + (idx - n_bar_groups/2 + 0.5) * bar_width for i in range(len(categories))]\n",
    "                values = []\n",
    "                hover_text = []\n",
    "                \n",
    "                # Create display name for the bar group\n",
    "                display_bar_group = self.redact_string_descriptions(bar_group)\n",
    "                \n",
    "                for i, category in enumerate(categories):\n",
    "                    if orientation != 'By Sample':\n",
    "                        item = category\n",
    "                        group = bar_group\n",
    "                    else:\n",
    "                        item = bar_group\n",
    "                        group = category\n",
    "                    \n",
    "                    # Skip if item doesn't have data\n",
    "                    if item not in data_dict:\n",
    "                        values.append(0)\n",
    "                        hover_text.append(f\"{'Function' if orientation == 'By Function' else 'Protein'}: {item}<br>\"\n",
    "                                        f\"Sample: {group}<br>Value: 0\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Get data\n",
    "                    item_data = data_dict[item]\n",
    "                    # Get the appropriate values based on metric type\n",
    "                        \n",
    "                    if use_count:\n",
    "                        abs_value = item_data['counts'].get(group, 0)\n",
    "                        rel_percentage = item_data['count_relative'].get(group, 0)\n",
    "                    else:\n",
    "                        abs_value = item_data['absorbance'].get(group, 0)\n",
    "                        rel_percentage = item_data['absorbance_relative'].get(group, 0)\n",
    "                    \n",
    "                    # Determine y-value based on metric type\n",
    "                    if is_relative_metric:\n",
    "                        y_value = rel_percentage\n",
    "                        hover = (f\"{'Function' if plot_type == 'Selected Function(s)' else 'Protein'}: {item}<br>\"\n",
    "                                f\"Sample: {group}<br>\"\n",
    "                                f\"Relative Contribution: {rel_percentage:.1f}%<br>\"\n",
    "                                f\"{self.metric_name}: {abs_value:{self.num_format}}\")\n",
    "                    else:\n",
    "                        y_value = abs_value\n",
    "                        hover = (f\"{'Function' if plot_type == 'Selected Function(s)' else 'Protein'}: {item}<br>\"\n",
    "                                f\"Sample: {group}<br>\"\n",
    "                                f\"{self.metric_name}: {abs_value:{self.num_format}}<br>\"\n",
    "                                f\"Relative Contribution: {rel_percentage:.1f}%\")\n",
    "                    \n",
    "                    values.append(y_value)\n",
    "                    hover_text.append(hover)\n",
    "                \n",
    "                # Only add trace if we have valid values\n",
    "                if any(v > 0 for v in values):\n",
    "                    fig.add_trace(go.Bar(\n",
    "                        name=display_bar_group,\n",
    "                        x=x_positions,\n",
    "                        y=values,\n",
    "                        width=bar_width * 0.9,\n",
    "                        marker_color=color_mapping.get(bar_group, 'gray'),\n",
    "                        hovertext=hover_text,\n",
    "                        hoverinfo='text'\n",
    "                    ))\n",
    "                        \n",
    "        \n",
    "            # Update layout\n",
    "            fig.update_layout(\n",
    "                title={\n",
    "                    'text': self.plot_title,\n",
    "                    'y': .975,\n",
    "                    'x': 0.5,\n",
    "                    'xanchor': 'center',\n",
    "                    'yanchor': 'top',\n",
    "                    'font': {'size': 18, 'color': 'black'}\n",
    "                },\n",
    "                xaxis_title=self.x_axis_label,\n",
    "                yaxis_title=self.y_axis_label,\n",
    "                legend_title=self.legend_title,\n",
    "                legend={'yanchor': \"top\", 'y': 1.0, 'xanchor': \"left\", 'x': 1.05, 'traceorder': 'normal', 'font': {'size': 12, 'color': 'black'}},\n",
    "                showlegend=True,\n",
    "                template='plotly_white',\n",
    "                height=750,\n",
    "                width=1100,\n",
    "                margin=dict(t=100, l=100, r=200),\n",
    "                hoverlabel=dict(\n",
    "                    bgcolor=\"white\",\n",
    "                    font_size=12,\n",
    "                    font_family=\"Arial\"\n",
    "                ),\n",
    "                barmode='group',\n",
    "                xaxis=dict(\n",
    "                    showline=True,\n",
    "                    linewidth=1,\n",
    "                    linecolor='black',\n",
    "                    mirror=False\n",
    "                ),\n",
    "                yaxis=dict(\n",
    "                    showline=True,\n",
    "                    linewidth=1,\n",
    "                    linecolor='black',\n",
    "                    mirror=False\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Update axis properties\n",
    "            fig.update_xaxes(\n",
    "                ticktext=display_categories,\n",
    "                tickvals=list(range(len(categories))),\n",
    "                tickangle=45,\n",
    "                title_font={\"size\": 18},\n",
    "                tickfont={\"size\": 16},\n",
    "                tickfont_color=\"black\",\n",
    "                title_font_color=\"black\",\n",
    "            )\n",
    "            \n",
    "            # Set y-axis format based on plot type and log transform\n",
    "            if use_count and not is_relative_metric:\n",
    "                # Absolute count\n",
    "                fig.update_yaxes(\n",
    "                    type='log' if use_log else 'linear',\n",
    "                    tickformat=\",d\",  # Format with commas for thousands\n",
    "                    title_font={\"size\": 18},\n",
    "                    tickfont={\"size\": 16},\n",
    "                    tickfont_color=\"black\",\n",
    "                    title_font_color=\"black\",\n",
    "                    gridcolor=\"lightgray\",\n",
    "                    showgrid=True,\n",
    "                    zeroline=False,\n",
    "                    exponentformat='E' if use_log else None,\n",
    "                    showexponent='all' if use_log else None\n",
    "                )\n",
    "            elif not use_count and not is_relative_metric:\n",
    "                # Absolute abundance\n",
    "                if use_log:\n",
    "                    fig.update_yaxes(\n",
    "                        type='log',\n",
    "                        exponentformat='E',\n",
    "                        showexponent='all',\n",
    "                        title_font={\"size\": 18},\n",
    "                        tickfont={\"size\": 16},\n",
    "                        tickfont_color=\"black\",\n",
    "                        title_font_color=\"black\",\n",
    "                        gridcolor=\"lightgray\",\n",
    "                        showgrid=True,\n",
    "                        zeroline=False,\n",
    "                    )\n",
    "                else:\n",
    "                    fig.update_yaxes(\n",
    "                        type='linear',\n",
    "                        exponentformat='E',\n",
    "                        showexponent='all',\n",
    "                        title_font={\"size\": 18},\n",
    "                        tickfont={\"size\": 16},\n",
    "                        tickfont_color=\"black\",\n",
    "                        title_font_color=\"black\",\n",
    "                        gridcolor=\"lightgray\",\n",
    "                        showgrid=True,\n",
    "                        zeroline=False,\n",
    "                    )\n",
    "            else:\n",
    "                # Relative metrics (both count and abundance)\n",
    "                fig.update_yaxes(\n",
    "                    type='linear',\n",
    "                    range=[0, 100],\n",
    "                    title_font={\"size\": 18},\n",
    "                    tickfont={\"size\": 16},\n",
    "                    tickfont_color=\"black\",\n",
    "                    title_font_color=\"black\",\n",
    "                    gridcolor=\"lightgray\",\n",
    "                    showgrid=True,\n",
    "                    zeroline=False,\n",
    "                )\n",
    "                \n",
    "            # Mark generation as complete\n",
    "            #self.state_manager.generate_completed()\n",
    "            \n",
    "            return fig\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating grouped bar plot: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "           \n",
    "    def create_pie_charts(self, selected_groups, use_count=False):\n",
    "        \"\"\"Create pie charts for protein or function data with pre-calculated counts or abundance\"\"\"\n",
    "        try:\n",
    "            # Determine if we're plotting proteins, functions, or both\n",
    "            plot_type = self.plot_func_or_pro.value if hasattr(self, 'plot_func_or_pro') else 'Selected Protein(s)'\n",
    "\n",
    "            if hasattr(self, 'invert_plot'):\n",
    "                orientation = self.invert_plot.value\n",
    "\n",
    "            # Get log transform setting\n",
    "            use_log = self.log_transform.value if hasattr(self, 'log_transform') else False\n",
    "\n",
    "            if orientation == 'By Sample':\n",
    "                # One pie chart per sample\n",
    "                # Use function_df or protein_df based on plot type\n",
    "                if plot_type == 'Selected Function(s)' or plot_type == 'Functional vs Non-Functional Peptides':\n",
    "                    if not hasattr(self, 'function_df') or self.function_df is None or self.function_df.empty:\n",
    "                        print(\"No function data available to plot\")\n",
    "                        return None\n",
    "                    scaled_df = self.function_df.copy()\n",
    "                elif plot_type == 'Selected Protein(s)':  # Default to protein plotting\n",
    "                    if not hasattr(self, 'protein_df') or self.protein_df is None or self.protein_df.empty:\n",
    "                        print(\"No protein data available to plot\")\n",
    "                        return None\n",
    "                    scaled_df = self.protein_df.copy()\n",
    "               \n",
    "                # Inside create_pie_charts, modify the section for 'Both' or 'No Filter':\n",
    "                elif plot_type == 'Both' or plot_type == 'No Filter':\n",
    "                    try:\n",
    "                        # Get metrics for all samples\n",
    "                        metrics_dict = self.abundance_count_by_sample_dict\n",
    "                        if not metrics_dict:\n",
    "                            print(\"No data available for plotting\")\n",
    "                            return None\n",
    "                            \n",
    "                        # Create a single figure\n",
    "                        fig = go.Figure()\n",
    "                                        \n",
    "                        # Prepare data for plotting\n",
    "                        labels = list(metrics_dict.keys())\n",
    "                        if use_count:\n",
    "                            values = [group_data_dict['unique_peptides'] for group_data_dict in metrics_dict.values()]\n",
    "                            relative_values = [group_data_dict['relative_peptides'] for group_data_dict in metrics_dict.values()]\n",
    "                            metric_label = 'Peptide Count'\n",
    "                            hover_format = ',.0f'  # Format as integer with commas\n",
    "                        else:\n",
    "                            values = [group_data_dict['total_abundance'] for group_data_dict in metrics_dict.values()]\n",
    "                            relative_values = [group_data_dict['relative_abundance'] for group_data_dict in metrics_dict.values()]\n",
    "                            metric_label = 'Total Abundance'\n",
    "                            hover_format = '.2e'  # Scientific notation\n",
    "                            \n",
    "                        # Get colors for samples\n",
    "                        sample_colors = self.get_color_sequence(len(metrics_dict))\n",
    "                        \n",
    "                        # Create customdata array for hover template\n",
    "                        customdata = relative_values\n",
    "                        \n",
    "                        # Create single pie chart\n",
    "                        fig.add_trace(\n",
    "                            go.Pie(\n",
    "                                labels=labels,\n",
    "                                values=values,\n",
    "                                name='Sample Distribution',\n",
    "                                marker_colors=sample_colors,\n",
    "                                textposition='inside',\n",
    "                                textinfo='percent',\n",
    "                                customdata=customdata,  # Add the relative values as custom data\n",
    "                                hovertemplate=(\n",
    "                                    \"Sample: %{label}<br>\"\n",
    "                                    f\"{metric_label}: %{{value:{hover_format}}}<br>\"\n",
    "                                    \"Percentage: %{percent}<br>\"\n",
    "                                    f\"Relative {metric_label}: %{{customdata:.1f}}%<br>\"\n",
    "                                    \"<extra></extra>\"\n",
    "                                ),\n",
    "                                hole=0.0,\n",
    "                                showlegend=True\n",
    "                            )\n",
    "                        )\n",
    "                        \n",
    "                        # Update layout for single pie chart\n",
    "                        fig.update_layout(\n",
    "                            height=600,\n",
    "                            width=800,\n",
    "                            title={\n",
    "                                'text': self.plot_title,\n",
    "                                'y': 0.95 ,\n",
    "                                'x': 0.5,\n",
    "                                'xanchor': 'center',\n",
    "                                'yanchor': 'top',\n",
    "                                'font': {\"size\": 20, 'color': 'black'}\n",
    "                            },\n",
    "                            showlegend=True,\n",
    "                            legend={\n",
    "                                'title': 'Samples',\n",
    "                                'yanchor': \"middle\",\n",
    "                                'y': 0.5,\n",
    "                                'xanchor': \"left\",\n",
    "                                'x': 1.1,\n",
    "                                'font': {\"size\": 12},\n",
    "                            },\n",
    "                            margin=dict(t=100, b=50, l=50, r=150),\n",
    "                            paper_bgcolor='rgba(255,255,255,1)',\n",
    "                            plot_bgcolor='rgba(255,255,255,1)',\n",
    "                            font=dict(\n",
    "                                family=\"Arial, sans-serif\",\n",
    "                                size=14,\n",
    "                                color=\"black\"\n",
    "                            )\n",
    "                        )\n",
    "                        \n",
    "                        return fig\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error creating single pie chart: {str(e)}\")\n",
    "                        import traceback\n",
    "                        traceback.print_exc()\n",
    "                        return None\n",
    "\n",
    "                # Get the list of groups/samples to plot\n",
    "                if hasattr(self, 'selected_groups'):\n",
    "                    selected_groups = self.group_selector.value\n",
    "                else:\n",
    "                    # Fallback if selected_groups is not available\n",
    "                    selected_groups = list(self.value_cols.keys()) if isinstance(self.value_cols, dict) else [col.replace(self.value_prefix, '') for col in self.value_cols]\n",
    "                \n",
    "                # Map group names to actual column names\n",
    "                sample_columns = []\n",
    "                sample_names = []\n",
    "                \n",
    "                if isinstance(self.value_cols, dict):\n",
    "                    # If value_cols is a dictionary (group -> column)\n",
    "                    for group in selected_groups:\n",
    "                        if group in self.value_cols:\n",
    "                            sample_columns.append(self.value_cols[group])\n",
    "                            sample_names.append(group)\n",
    "                else:\n",
    "                    # If value_cols is a list of columns\n",
    "                    sample_columns = self.value_cols\n",
    "                    sample_names = [col.replace(self.value_prefix, '') for col in sample_columns]\n",
    "                \n",
    "                # Filter to only selected items (proteins or functions)\n",
    "                if (plot_type == 'Selected Function(s)' or plot_type == 'Both'):\n",
    "                    display_items = list(self.selected_functions)\n",
    "                    if 'All Functions' in display_items:\n",
    "                        display_items = [f for f in scaled_df['Description'].unique() if f != 'All Functions']\n",
    "                    if hasattr(self, 'plot_minor') and self.plot_minor.value:\n",
    "                        if 'Minor Functions' in scaled_df['Description'].values:\n",
    "                            display_items.append('Minor Functions')\n",
    "                \n",
    "                elif (plot_type == 'Selected Protein(s)' or plot_type == 'Both'):  # Proteins\n",
    "                    if hasattr(self, 'selected_proteins') and self.selected_proteins:\n",
    "                        display_items = self.selected_proteins.copy()\n",
    "                elif plot_type == 'Functional vs Non-Functional Peptides':\n",
    "                    display_items = list(self.function_df['Description'].unique())\n",
    "\n",
    "                scaled_df = scaled_df[scaled_df['Description'].isin(display_items)]\n",
    "                \n",
    "                # Calculate grid layout\n",
    "                num_samples = len(sample_columns)\n",
    "                num_cols = min(3, num_samples)  # Maximum 3 columns\n",
    "                num_rows = (num_samples + num_cols - 1) // num_cols  # Ceiling division\n",
    "                if num_rows > 4:\n",
    "                    display(HTML(f\"\"\"\n",
    "                    <div style='color: #856404; background-color: #fff3cd; border: 1px solid #ffeeba; border-radius: 4px; padding: 10px; margin: 10px 0;'>\n",
    "                        <strong>Warning:</strong> Creating a large subplot grid with {num_rows} rows and {num_cols} columns.<br>\n",
    "                        This may affect performance. Consider limiting the number through the protein or function selector.\n",
    "                    </div>\n",
    "                    \"\"\"))\n",
    "\n",
    "                # Apply redact function to sample names for subplot titles\n",
    "                redacted_sample_names = [self.redact_string_descriptions(name, max_length=50) for name in sample_names]\n",
    "\n",
    "                # Create figure with grid layout\n",
    "                fig = make_subplots(\n",
    "                    rows=num_rows,\n",
    "                    cols=num_cols,\n",
    "                    specs=[[{'type': 'pie'} for _ in range(num_cols)] for _ in range(num_rows)],\n",
    "                    subplot_titles=redacted_sample_names\n",
    "                )\n",
    "                \n",
    "                # Get unique items for coloring\n",
    "                if (plot_type == 'Selected Function(s)' or plot_type == 'Both'):\n",
    "                    # Use existing function color map\n",
    "                    color_map = self.function_color_map\n",
    "                    unique_items = scaled_df['Description'].unique().tolist()\n",
    "\n",
    "                elif (plot_type == 'Selected Protein(s)' or plot_type == 'Both'):  # Proteins\n",
    "                    unique_items = scaled_df['Description'].unique().tolist()\n",
    "                    if 'Minor Proteins' in unique_items:\n",
    "                       unique_items.remove('Minor Proteins')\n",
    "\n",
    "                elif plot_type == 'Functional vs Non-Functional Peptides':\n",
    "                    unique_items = list(self.function_df['Description'].unique())\n",
    "\n",
    "                # Use the existing color sequence function for proteins\n",
    "                item_colors = self.get_color_sequence(len(unique_items))\n",
    "                \n",
    "                # Create a color map, setting Minor Proteins to grey\n",
    "                color_map = {item: color for item, color in zip(unique_items, item_colors)}\n",
    "                if 'Minor Proteins' in scaled_df['Description'].values:\n",
    "                    color_map['Minor Proteins'] = '#808080'  # Grey color for minor proteins\n",
    "\n",
    "                # First pie chart will set the legend for all\n",
    "                first_chart = True\n",
    "                \n",
    "                # Create a pie chart for each sample\n",
    "                for i, col_name in enumerate(sample_columns):\n",
    "                    # Calculate which row and column this chart belongs in\n",
    "                    row_idx = i // num_cols + 1\n",
    "                    col_idx = i % num_cols + 1\n",
    "                    \n",
    "                    sample_name = sample_names[i]\n",
    "                    \n",
    "                    # Get data for this sample\n",
    "                    sample_data = scaled_df[['Description', col_name]].copy()\n",
    "                    sample_data = sample_data[sample_data[col_name] > 0]\n",
    "                    \n",
    "                    if sample_data.empty:\n",
    "                        continue\n",
    "                                        \n",
    "                    # Sort by value but ensure Minor items are at the end\n",
    "                    try:\n",
    "                        # Check for either Minor Proteins or Minor Functions using any()\n",
    "                        has_minor = (\n",
    "                            sample_data['Description'].str.contains('Minor Proteins', na=False).any() or \n",
    "                            sample_data['Description'].str.contains('Minor Functions', na=False).any()\n",
    "                        )\n",
    "                        \n",
    "                        if has_minor:\n",
    "                            # Create mask for minor items\n",
    "                            minor_mask = (\n",
    "                                sample_data['Description'].str.contains('Minor Proteins', na=False) | \n",
    "                                sample_data['Description'].str.contains('Minor Functions', na=False)\n",
    "                            )\n",
    "                            \n",
    "                            # Separate minor and other rows\n",
    "                            minor_rows = sample_data[minor_mask]\n",
    "                            other_rows = sample_data[~minor_mask]\n",
    "                            \n",
    "                            # Sort other rows and concatenate with minor rows\n",
    "                            other_rows = other_rows.sort_values(by=col_name, ascending=False)\n",
    "                            sample_data = safe_concat([other_rows, minor_rows], ignore_index=True)\n",
    "                        else:\n",
    "                            # If no minor items, just sort normally\n",
    "                            sample_data = sample_data.sort_values(by=col_name, ascending=False)\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error during sorting: {str(e)}\")\n",
    "                        # Fallback to basic sorting if anything goes wrong\n",
    "                        sample_data = sample_data.sort_values(by=col_name, ascending=False)\n",
    "                    \n",
    "                    # Get colors for the current sample's items\n",
    "                    colors = [color_map.get(item, '#CCCCCC') for item in sample_data['Description']]\n",
    "                                        \n",
    "                    # First determine the label type\n",
    "                    try:\n",
    "                        # Split the plot type and get base word\n",
    "                        plot_words = orientation.split()\n",
    "                        if len(plot_words) > 1:\n",
    "                            base_word = plot_words[1]  # e.g., \"Proteins\" or \"Functions\"\n",
    "                            plot_type_label = base_word[:-1]  # e.g., \"Protein\" or \"Function\"\n",
    "                        else:\n",
    "                            # Fallback if plot_type doesn't have multiple words\n",
    "                            plot_type_label = \"Item\"\n",
    "                                                # Create the pie chart\n",
    "                        display_label = [self.redact_string_descriptions(l) for l in sample_data['Description']]\n",
    "                        # Create the pie chart\n",
    "                        fig.add_trace(\n",
    "                            go.Pie(\n",
    "                                labels=display_label,\n",
    "                                values=sample_data[col_name],\n",
    "                                name=sample_name,\n",
    "                                marker_colors=colors,\n",
    "                                textposition='inside',\n",
    "                                textinfo='percent',\n",
    "                                hovertemplate=(\n",
    "                                    f\"{plot_type_label}: %{{label}}<br>\"\n",
    "                                    f\"{self.metric_name}: %{{value:{self.num_format}}}<br>\"\n",
    "                                    f\"Percentage: %{{percent}}<br>\"\n",
    "                                    f\"Sample: {sample_name}<br>\"\n",
    "                                    f\"<extra></extra>\"\n",
    "                                ),\n",
    "                                hole=0.0,\n",
    "                                showlegend=first_chart\n",
    "                            ),\n",
    "                            row=row_idx, col=col_idx  # Add these parameters\n",
    "\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing plot type label: {str(e)}\")\n",
    "                        # Fallback to generic label if there's an error\n",
    "                        plot_type_label = \"Item\"\n",
    "                        \n",
    "            else:  # 'By Protein or By Function'\n",
    "                if orientation == 'By Function':\n",
    "                    # Use function distribution data\n",
    "                    if not hasattr(self, 'function_distribution_dict') or not self.function_distribution_dict:\n",
    "                        print(\"No function distribution data available\")\n",
    "                        return None\n",
    "                    \n",
    "                    distribution_data = self.function_distribution_dict\n",
    "                    unique_items = list(distribution_data.keys())\n",
    "                    \n",
    "                    # Filter functions based on selection\n",
    "                    if plot_type != 'Functional vs Non-Functional Peptides':\n",
    "                        selected_functions = self.selected_functions\n",
    "                        if 'All Functions' not in selected_functions:\n",
    "                            filtered_items = []\n",
    "                            for item in selected_functions:\n",
    "                                if item in distribution_data:\n",
    "                                    filtered_items.append(item)\n",
    "                            \n",
    "                            if self.plot_minor.value and 'Minor Functions' in distribution_data:\n",
    "                                filtered_items.append('Minor Functions')\n",
    "                            \n",
    "                            unique_items = filtered_items\n",
    "                        \n",
    "                else:  # ortientation == 'By Protein'\n",
    "                    if not hasattr(self, 'protein_sample_distribution_dict') or not self.protein_sample_distribution_dict:\n",
    "                        print(\"No protein distribution data available\")\n",
    "                        return None\n",
    "                    \n",
    "                    distribution_data = self.protein_sample_distribution_dict\n",
    "                    unique_items = list(distribution_data.keys())\n",
    "                    \n",
    "                    # Filter to only include proteins we want to plot\n",
    "                    if hasattr(self, 'selected_proteins') and self.selected_proteins:\n",
    "                        filtered_items = []\n",
    "                        for item in self.selected_proteins:\n",
    "                            if item in distribution_data:\n",
    "                                filtered_items.append(item)\n",
    "                                               \n",
    "                        unique_items = filtered_items\n",
    "                \n",
    "                \n",
    "                \n",
    "                #unique_items_temp = unique_items\n",
    "                #unique_items = []\n",
    "\n",
    "                #for item in unique_items_temp:\n",
    "                #    if item not in unique_items:\n",
    "                #        unique_items.append(item)\n",
    "                \n",
    "                # Create pie charts using the selected distribution data\n",
    "                num_items = len(unique_items)\n",
    "                num_cols = min(3, num_items)\n",
    "                num_rows = (num_items + num_cols - 1) // num_cols\n",
    "                # Add this before creating the figure\n",
    "                if num_rows > 4:\n",
    "                    display(HTML(f\"\"\"\n",
    "                    <div style='color: #856404; background-color: #fff3cd; border: 1px solid #ffeeba; border-radius: 4px; padding: 10px; margin: 10px 0;'>\n",
    "                        <strong>Warning:</strong> Creating a large subplot grid with {num_rows} rows and {num_cols} columns.<br>\n",
    "                        This may affect performance. Consider limiting the number through the protein or function selector.\n",
    "                    </div>\n",
    "                    \"\"\"))\n",
    "\n",
    "                # Apply redact function to unique items for subplot titles\n",
    "                redacted_items = [self.redact_string_descriptions(item, max_length=50) for item in unique_items]\n",
    "\n",
    "                # Create figure with grid layout\n",
    "                fig = make_subplots(\n",
    "                    rows=num_rows, cols=num_cols,\n",
    "                    specs=[[{'type': 'pie'} for _ in range(num_cols)] for _ in range(num_rows)],\n",
    "                    subplot_titles=redacted_items\n",
    "                )\n",
    "                \n",
    "                # Get sample colors - use a different color sequence for samples\n",
    "                sample_colors = self.get_color_sequence(len(selected_groups))\n",
    "                sample_color_map = {\n",
    "                    group.replace('Avg_', ''): color \n",
    "                    for group, color in zip(selected_groups, sample_colors)\n",
    "                }\n",
    "                \n",
    "                # First pie chart will set the legend for all\n",
    "                first_chart = True\n",
    "                \n",
    "                # Create a pie chart for each protein/function\n",
    "                for i, item in enumerate(unique_items):\n",
    "                    row_idx = i // num_cols + 1\n",
    "                    col_idx = i % num_cols + 1\n",
    "                    \n",
    "                    item_data = distribution_data[item]\n",
    "                    \n",
    "                    if use_count:\n",
    "                        values_dict = item_data['counts']\n",
    "                        total = item_data['total_count']\n",
    "                    else:\n",
    "                        values_dict = item_data['absorbance']\n",
    "                        total = item_data['total_absorbance']\n",
    "                    \n",
    "                    values = []\n",
    "                    labels = []\n",
    "                    colors_list = []\n",
    "                    \n",
    "                    for group in selected_groups:\n",
    "                        # Remove 'Avg_' prefix if present for matching\n",
    "                        group_key = group.replace('Avg_', '')\n",
    "                        value = values_dict.get(group_key, 0)\n",
    "                        if value > 0:\n",
    "                            values.append(value)\n",
    "                            labels.append(group_key)\n",
    "                            colors_list.append(sample_color_map[group_key])\n",
    "                    \n",
    "                    if not values:\n",
    "                        continue\n",
    "                    display_label = [self.redact_string_descriptions(l) for l in labels]\n",
    "                    fig.add_trace(\n",
    "                        go.Pie(\n",
    "                            labels=display_label,\n",
    "                            values=values,\n",
    "                            name=item,\n",
    "                            marker_colors=colors_list,\n",
    "                            textposition='inside',\n",
    "                            textinfo='percent',\n",
    "                            hovertemplate=(\n",
    "                                f\"Sample: %{{label}}<br>\"\n",
    "                                f\"{self.metric_name}: %{{value:{self.num_format}}}<br>\"\n",
    "                                f\"Percentage: %{{percent}}<br>\"\n",
    "                                f\"Total {self.metric_name}: {total:{self.num_format}}<br>\"\n",
    "                                f\"<extra></extra>\"\n",
    "                            ),\n",
    "                            hole=0.0,\n",
    "                            showlegend=first_chart\n",
    "                        ),\n",
    "                        row=row_idx, col=col_idx\n",
    "                    )\n",
    "                    first_chart = False\n",
    "\n",
    "            y_val = 0.95 if num_rows < 3 else 0.98\n",
    "            # Set text size based on number of rows\n",
    "            plot_title = self.plot_title\n",
    "            if num_rows > 6:\n",
    "                plot_title = ''\n",
    "                text_size = 12\n",
    "            elif num_rows <= 3:\n",
    "                text_size = 18\n",
    "            elif num_rows >= 3 and num_rows <= 6:\n",
    "                text_size = 14\n",
    "\n",
    "                \n",
    "            fig.update_layout(\n",
    "                height=500 * num_rows,\n",
    "                width=min(1400, 450 * num_cols),\n",
    "                title_text = plot_title,\n",
    "                title={\n",
    "                    'y': y_val,\n",
    "                    'x': 0.5,\n",
    "                    'xanchor': 'center',\n",
    "                    'yanchor': 'top',\n",
    "                    'font': {\"size\": text_size, 'color': 'black'}\n",
    "                },\n",
    "                showlegend=True,\n",
    "                legend={\n",
    "                    'title': self.legend_title,\n",
    "                    'yanchor': \"top\",\n",
    "                    'y': 0.99,\n",
    "                    'xanchor': \"left\",\n",
    "                    'x': 1.02,\n",
    "                    'font': {\"size\": 12},\n",
    "                },\n",
    "                margin=dict(t=100, b=50, l=50, r=150),\n",
    "                paper_bgcolor='rgba(255,255,255,1)',\n",
    "                plot_bgcolor='rgba(255,255,255,1)',\n",
    "                font=dict(\n",
    "                    family=\"Arial, sans-serif\",\n",
    "                    size=14,\n",
    "                    color=\"black\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Mark generation as complete\n",
    "            #self.state_manager.generate_completed()\n",
    "            self.download_plot_button.disabled = False\n",
    "            \n",
    "            return fig\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating pie charts: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None    \n",
    "    \n",
    "    def on_plot_button_click(self, b):       \n",
    "        # Disable the plot button to prevent multiple clicks\n",
    "        self.plot_button.disabled = True\n",
    "        \n",
    "        if self.current_fig is not None:\n",
    "            #self.state_manager.generate_completed()\n",
    "            self.download_plot_button.disabled = False\n",
    "        \n",
    "        with self.plot_output:\n",
    "            self.plot_output.clear_output(wait=True)\n",
    "            \n",
    "            # Create and display progress bar\n",
    "            progress = widgets.FloatProgress(\n",
    "                value=0,\n",
    "                min=0,\n",
    "                max=3,\n",
    "                description='Loading:',\n",
    "                bar_style='info',\n",
    "                style={'bar_color': '#2196F3'},\n",
    "                orientation='horizontal'\n",
    "            )\n",
    "            display(progress)\n",
    "            \n",
    "            # Retrieve data for the plot from data handler\n",
    "            selected_groups,  plot_type, use_count, orientation, plot_filter = self.retrieve_data_for_plot()\n",
    "            \n",
    "            # Update progress bar to 1/3\n",
    "            progress.value = 1\n",
    "\n",
    "            # check for invalid user selection\n",
    "            warnings = list(set(self.check_invalid_user_selection(selected_groups, plot_type, use_count, orientation, plot_filter)))\n",
    "            # Display any warnings before continuing\n",
    "            if len(warnings) == 1:\n",
    "                display_warning(warnings[0])\n",
    "            elif len(warnings) > 1:\n",
    "                for warning in warnings:\n",
    "                    display_warning(warning)\n",
    "\n",
    "            # create the plot based on the plot type and orientation\n",
    "            if plot_type == 'Grouped Bar Plots':           \n",
    "                if orientation == 'By Sample':\n",
    "                    if (plot_filter == 'No Filter' or plot_filter == 'Both') and self.metric_type.value == 'Absolute':\n",
    "                        self.current_fig = self.plot_total_peptides()\n",
    "                    elif (plot_filter == 'No Filter' or plot_filter == 'Both') and self.metric_type.value == 'Relative':\n",
    "                        display_warning(\"Invalid combination of Plot Filter 'No Filter' or 'Both', Plot Orientation 'By Sample', and Plot Metric of 'Relative'.<br>Currently this combination is not supported, A Relative Stacked Bar Plot Is being generated instead.<br>In the generation of a Grouped Bar Plot Plot Filter 'No Filter' or 'Both' can be used in combination with Plot Orientation of 'By Sample', and Plot Metric of <b>'Absolute'</b>.\")\n",
    "                        self.current_fig = self.plot_stacked_bar_scaled(\n",
    "                            selected_groups=selected_groups,\n",
    "                            use_count=use_count\n",
    "                        )\n",
    "                    else:\n",
    "                        self.current_fig = self.create_grouped_bar_plot(\n",
    "                                selected_groups=selected_groups,\n",
    "                                use_count=use_count\n",
    "                            )\n",
    "                else: # invert_plot == 'By Function or Protein'\n",
    "                    # Modified plot_stacked_bar_scaled to use count columns if needed\n",
    "                    self.current_fig = self.create_grouped_bar_plot(\n",
    "                            selected_groups=selected_groups,\n",
    "                            use_count=use_count\n",
    "                        )\n",
    "                if self.current_fig is None:\n",
    "                    display_warning(\"Error generating Grouped Bar Plot.<br>Please upload all required files first.<br>Error creating plot. Please check your data.\")\n",
    "                    # Re-enable the plot button\n",
    "                    self.plot_button.disabled = False\n",
    "                    return None\n",
    "\n",
    "            # Create and display the appropriate plot based on selection and metric\n",
    "            if plot_type == 'Stacked Bar Plots':\n",
    "                if plot_filter == 'Both':\n",
    "                    display_warning(\"Invalid combination of Plot Filter 'Both', for Stack Bar Plot plot type'.<br>Currently this combination is not supported.<br>Plot Filter 'No Filter' or 'Selected Function(s)' or 'Selected Protein(s)' can be used for stack bar plot type.\")\n",
    "                    # Re-enable the plot button\n",
    "                    self.plot_button.disabled = False\n",
    "                    return None\n",
    "                #elif plot_filter == 'No Filter':\n",
    "                #    display_warning(\"Invalid combination of Plot Filter 'No Filter', for Stack Bar Plot plot type'.<br>Currently this combination is not supported.<br>Plot Filter 'No Filter' or 'Selected Function(s)' or 'Selected Protein(s)' can be used for stack bar plot type.\")\n",
    "                #    display_warning(\"We recommend using the Grouped Bar Plot option when the Plot Filter is set to <b>'No Filter'</b>.\")\n",
    "                #    # Re-enable the plot button\n",
    "                #    self.plot_button.disabled = False\n",
    "                #    return None\n",
    "                else:\n",
    "                    try:\n",
    "                        self.current_fig = self.plot_stacked_bar_scaled(\n",
    "                            selected_groups=selected_groups,\n",
    "                            use_count=use_count\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error creating stacked bar plots: {str(e)}\")\n",
    "                        traceback.print_exc()\n",
    "                        # Re-enable the plot button\n",
    "                        self.plot_button.disabled = False\n",
    "\n",
    "            # create the pie chart plot\n",
    "            if plot_type == 'Pie Charts':  # Pie Chart\n",
    "                try:\n",
    "                    self.current_fig = self.create_pie_charts(\n",
    "                        selected_groups=selected_groups, \n",
    "                        use_count=use_count\n",
    "                    )\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error creating pie charts: {str(e)}\")\n",
    "                    traceback.print_exc()\n",
    "                    # Re-enable the plot button\n",
    "                    self.plot_button.disabled = False\n",
    "            \n",
    "            # create the correlation scatter plot\n",
    "            if plot_type == 'Corr. Scatter Plots':\n",
    "                # If exactly 2 groups, use original scatter plot\n",
    "                if len(selected_groups) == 2:\n",
    "                    # Use original correlation plot with same groups for both axes\n",
    "                    self.current_fig = self.create_correlation_plot(selected_groups)\n",
    "                elif len(selected_groups) > 2:\n",
    "                    # Use SPLOM for 3+ groups\n",
    "                    self.current_fig = self.create_correlation_splom(selected_groups)\n",
    "                else:\n",
    "                    # Handle the case where there are fewer than 2 groups\n",
    "                    display_warning(\"Please select at least 2 groups for correlation analysis\")\n",
    "                    # Re-enable the plot button\n",
    "                    self.plot_button.disabled = False\n",
    "                    return None\n",
    "            \n",
    "            # Update progress bar to 2/3\n",
    "            progress.value = 2\n",
    "                \n",
    "            # display the plot if it is not None else display an error message\n",
    "            if self.current_fig:\n",
    "                # Update progress bar to complete\n",
    "                progress.value = 3\n",
    "                progress.description = \"Loaded\"\n",
    "                # Create a new output area for the plot to preserve warnings\n",
    "                #plot_display = widgets.Output()\n",
    "                #with plot_display:\n",
    "                #   display(self.current_fig)\n",
    "                \n",
    "                # Display the plot below any warnings\n",
    "                #display(plot_display)\n",
    "                display(self.current_fig)\n",
    "\n",
    "            else:\n",
    "                display_warning(\"Error generating Plot.<br>Please upload all required files first.<br>Error creating plot. Please check your data.\")\n",
    "                # Re-enable the plot button\n",
    "                self.plot_button.disabled = False\n",
    "                return None\n",
    "            \n",
    "            # Re-enable the plot button after successful plot generation\n",
    "            self.plot_button.disabled = False\n",
    "            self.download_plot_button.disabled = False\n",
    "    \n",
    "    def redact_string_descriptions(self, input_str, max_length=35):\n",
    "        \"\"\"Redacts protein or function descriptions in a string to a maximum length.\"\"\"\n",
    "\n",
    "        if not isinstance(input_str, str):\n",
    "            return str(input_str)  # Convert non-strings to string\n",
    "            \n",
    "        # If the entire string is shorter than max_length, return as is\n",
    "        if len(input_str) <= max_length:\n",
    "            return input_str\n",
    "        \n",
    "        # For entries that are too long, truncate and add ellipsis\n",
    "        return input_str[:max_length-3] + '...'\n",
    "\n",
    "    def retrieve_data_for_plot(self):\n",
    "        # Get plot configuration\n",
    "        self.plot_func_or_pro = self.get_data_attribute('plot_func_or_pro')\n",
    "        self.plot_type = self.get_data_attribute('plot_type')\n",
    "        self.plot_minor= self.get_data_attribute('plot_minor')\n",
    "        self.invert_plot = self.get_data_attribute('invert_plot')\n",
    "        self.abs_or_count = self.get_data_attribute('abs_or_count')\n",
    "        self.group_selector = self.get_data_attribute('group_selector')\n",
    "\n",
    "        self.xlabel_widget = self.get_data_attribute('xlabel_widget')\n",
    "        self.ylabel_widget = self.get_data_attribute('ylabel_widget')\n",
    "        self.legend_widget = self.get_data_attribute('legend_widget')\n",
    "        self.title_widget = self.get_data_attribute('title_widget')\n",
    "        self.metric_type = self.get_data_attribute('metric_type')\n",
    "        self.function_color_map = self.get_data_attribute('function_color_map')\n",
    "        self.selected_groups = selected_groups = self.group_selector.value\n",
    "        self.process_total_peptide_data_and_filter_dataframe()\n",
    "        self.total_peptide_results_dict = self.get_data_attribute('total_peptide_results_dict')\n",
    "        self.filtered_df = self.get_data_attribute('filtered_df')\n",
    "        self.log_transform = self.get_data_attribute('log_transform')\n",
    "        self.correlation_type = self.get_data_attribute('correlation_type')\n",
    "        self.abundance_count_by_sample_dict = self.calculate_group_metrics()\n",
    "\n",
    "        # function data\n",
    "        self.create_function_df()\n",
    "        self.function_selector = self.get_data_attribute('function_selector')\n",
    "\n",
    "        if self.plot_func_or_pro != 'No Filter':\n",
    "            self.selected_functions = self.get_data_attribute('selected_functions')\n",
    "        else:\n",
    "            self.selected_functions = [func for func in self.get_data_attribute('selected_functions') if func not in ['Minor Functions', 'Functional Peptides', 'Non-Functional Peptides']]\n",
    "        if self.function_selector.value == ('All Functional Peptides',) and self.plot_func_or_pro != 'Functional vs Non-Functional Peptides':\n",
    "            self.selected_functions = [func for func in self.get_data_attribute('selected_functions') if func not in ['Minor Functions', 'Functional Peptides', 'Non-Functional Peptides']]\n",
    "        self.function_df = self.get_data_attribute('function_df')\n",
    "        self.reorganize_by_function()\n",
    "        self.function_absorbance_totals_dict = self.get_data_attribute('function_absorbance_totals_dict')\n",
    "        self.function_count_totals_dict = self.get_data_attribute('function_count_totals_dict')\n",
    "        self.function_group_metrics_dict = self.get_data_attribute('function_group_metrics_dict')\n",
    "        self.function_distribution_dict = self.get_data_attribute('function_distribution_dict') \n",
    "\n",
    "        # protein data\n",
    "        self.process_protein_data()\n",
    "        self.protein_selector = self.get_data_attribute('protein_selector')\n",
    "        self.selected_proteins = self.get_data_attribute('selected_proteins')\n",
    "        self.all_proteins = self.get_data_attribute('all_proteins')\n",
    "        self.protein_df = self.get_data_attribute('protein_df')\n",
    "        self.protein_count_bysample_dict = self.get_data_attribute('protein_count_bysample_dict')\n",
    "        self.protein_sample_distribution_dict = self.get_data_attribute('protein_sample_distribution_dict')\n",
    "        self.sum_df = self.get_data_attribute('sum_df')\n",
    "        self.sample_distribution_summary_df = self.get_data_attribute('sample_distribution_summary_df')\n",
    "\n",
    "\n",
    "        # Check if using count metric\n",
    "        use_count = False\n",
    "        self.metric_name = \"Abundance\"\n",
    "        if hasattr(self, 'abs_or_count'):\n",
    "            if self.abs_or_count.value == 'Count':\n",
    "                use_count = True\n",
    "                self.metric_name = \"Unique Peptide Count\"\n",
    "                self.value_prefix = \"Count_\"\n",
    "                self.rel_prefix = \"Rel_Count_\"\n",
    "                self.num_format = \",.0f\"  # Integer format for counts\n",
    "                \n",
    "            else: #abundance\n",
    "                self.metric_name = \"Summed Absorbance\"\n",
    "                self.value_prefix = \"Avg_\"\n",
    "                self.rel_prefix = \"Rel_Avg_\"\n",
    "                self.num_format = \",.2e\"  # Scientific notation for abundance\n",
    "    \n",
    "        # Create mapping from sample name to column names\n",
    "        self.value_cols = {var: f'{self.value_prefix}{var}' for var in selected_groups}\n",
    "        self.rel_cols = {var: f'{self.rel_prefix}{var}' for var in selected_groups}\n",
    "            \n",
    "        # Get the selected plot type (Bar or Pie)\n",
    "        if hasattr(self, 'plot_type'):\n",
    "            plot_type = self.plot_type.value\n",
    "\n",
    "        if hasattr(self, 'invert_plot'):\n",
    "            orientation = self.invert_plot.value\n",
    "\n",
    "        if hasattr(self, 'plot_func_or_pro'):\n",
    "            plot_filter = self.plot_func_or_pro.value\n",
    "            \n",
    "        return selected_groups,  plot_type, use_count, orientation, plot_filter\n",
    "\n",
    "    def create_correlation_splom(self, selected_groups):\n",
    "        \"\"\"Generate correlation matrix as a SPLOM using pre-filtered data\"\"\"\n",
    "        if self.data_transformer.merged_df is None or self.data_transformer.group_data_dict is None:\n",
    "            return None\n",
    "        \n",
    "        if not selected_groups or len(selected_groups) < 3:\n",
    "            display_warning(\"At least 3 groups are required for SPLOM visualization\")\n",
    "            return None\n",
    "            \n",
    "        # Get the already filtered dataframe\n",
    "        df = self.filtered_df.copy() if hasattr(self, 'filtered_df') else self.data_transformer.merged_df.copy()\n",
    "        \n",
    "        # Check if all required columns exist\n",
    "        dimensions = []\n",
    "        for group in selected_groups:\n",
    "            col_name = f\"Avg_{group}\"\n",
    "            if col_name not in df.columns:\n",
    "                display_warning(f\"Column {col_name} not found in the dataframe\")\n",
    "                continue\n",
    "            dimensions.append(group)\n",
    "        \n",
    "        \n",
    "        if len(dimensions) < 3:\n",
    "            display_warning(\"Not enough valid columns found for SPLOM visualization\")\n",
    "            return None\n",
    "        \n",
    "        # Try to get color scheme from self, default to Carolina Blue if multiple schemes selected\n",
    "        try:\n",
    "            color_result = self.get_single_color()\n",
    "            # Fix: Ensure colors is always a list, even if a single string is returned\n",
    "            if isinstance(color_result, list) and len(color_result) > 0:\n",
    "                colors = color_result\n",
    "            elif isinstance(color_result, str):\n",
    "                # If a single string color is returned, wrap it in a list\n",
    "                colors = [color_result]\n",
    "            else:\n",
    "                colors = ['#4B9CD3']  # Carolina Blue\n",
    "                display_warning(\"Please choose a single color scheme otherwise Carolina Blue will be used by default.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting colors: {e}\")\n",
    "            colors = ['#4B9CD3']  # Carolina Blue\n",
    "            display_warning(\"Please choose a single color scheme otherwise Carolina Blue will be used by default.\")\n",
    "        \n",
    "        \n",
    "        # Get log transform and correlation type settings from plotter\n",
    "        use_log = self.log_transform.value if hasattr(self, 'log_transform') else False\n",
    "        correlation_type = self.correlation_type.value if hasattr(self, 'correlation_type') else 'Pearson'\n",
    "        \n",
    "        # Create dimensions list for the SPLOM\n",
    "        splom_dimensions = []\n",
    "        \n",
    "        # Ensure positive values for all dimensions\n",
    "        filtered_df = df.copy()\n",
    "        for group in dimensions:\n",
    "            col_name = f\"Avg_{group}\"\n",
    "            filtered_df = filtered_df[filtered_df[col_name] > 0]\n",
    "        \n",
    "        if len(filtered_df) == 0:\n",
    "            display_warning(\"No valid data points found for the selected groups\")\n",
    "            return None\n",
    "        \n",
    "        # Process data for each dimension\n",
    "        splom_dimensions = []\n",
    "        for group in dimensions:\n",
    "            col_name = f\"Avg_{group}\"\n",
    "            # Apply log transformation based on setting\n",
    "            if use_log:\n",
    "                values = np.log10(filtered_df[col_name])\n",
    "                label = f\"Log<sub>10</sub> ({group})\"\n",
    "            else:\n",
    "                values = filtered_df[col_name]\n",
    "                label = group\n",
    "                \n",
    "            splom_dimensions.append(dict(values=values, label=label))\n",
    "                \n",
    "        # Store all correlations for legend\n",
    "        all_correlations = []\n",
    "        correlation_traces = []\n",
    "        \n",
    "        # Calculate all pairwise correlations using selected correlation type\n",
    "        for i, group1 in enumerate(dimensions):\n",
    "            for j, group2 in enumerate(dimensions):\n",
    "                if i >= j:  # Skip diagonal and lower half\n",
    "                    continue\n",
    "                \n",
    "                col1 = f\"Avg_{group1}\"\n",
    "                col2 = f\"Avg_{group2}\"\n",
    "                \n",
    "                # Calculate correlation\n",
    "                if len(filtered_df) <= 1:\n",
    "                    corr_text = \"n/a\"\n",
    "                    continue\n",
    "                else:\n",
    "                    if use_log:\n",
    "                        x_values = np.log10(filtered_df[col1])\n",
    "                        y_values = np.log10(filtered_df[col2])\n",
    "                        tickformater = '.2f'\n",
    "                    else:\n",
    "                        x_values = filtered_df[col1]\n",
    "                        y_values = filtered_df[col2]\n",
    "                        tickformater = '.2e'\n",
    "                    \n",
    "                    if correlation_type == 'Pearson':\n",
    "                        corr, _ = pearsonr(x_values, y_values)\n",
    "                        corr_text = f\"{corr:.3f}\"\n",
    "                        corr_symbol = \"<i>r</i>\"\n",
    "                    elif correlation_type == 'Spearman':\n",
    "                        corr, _ = spearmanr(x_values, y_values)\n",
    "                        corr_text = f\"{corr:.3f}\"\n",
    "                        corr_symbol = \"ρ\"\n",
    "                                    \n",
    "                # Create legend entries as invisible traces\n",
    "                legend_text = f\"{group1}-{group2}: {corr_symbol} = {corr_text}\"\n",
    "                correlation_traces.append(\n",
    "                    go.Scatter(\n",
    "                        x=[None],\n",
    "                        y=[None],\n",
    "                        mode='markers',\n",
    "                        marker=dict(color=colors[0]),\n",
    "                        name=legend_text,\n",
    "                        showlegend=True,\n",
    "                        legendgroup=f\"corr_{i}_{j}\"\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # Prepare custom data for hover text\n",
    "        id_column = 'unique ID' if 'unique ID' in filtered_df.columns else 'Peptide ID'\n",
    "        function_column = 'function' if 'function' in filtered_df.columns else 'Function'\n",
    "        protein_column = 'protein_name' if 'protein_name' in filtered_df.columns else 'Protein'\n",
    "        \n",
    "        # Ensure all required columns exist or provide defaults\n",
    "        if id_column not in filtered_df.columns:\n",
    "            filtered_df[id_column] = \"Unknown\"\n",
    "        if function_column not in filtered_df.columns:\n",
    "            filtered_df[function_column] = \"Unknown\"\n",
    "        if protein_column not in filtered_df.columns:\n",
    "            filtered_df[protein_column] = \"Unknown\"\n",
    "            \n",
    "        # Create custom data array with all relevant data\n",
    "        customdata = []\n",
    "        for i in range(len(filtered_df)):\n",
    "            row_data = [\n",
    "                filtered_df[id_column].iloc[i],\n",
    "                filtered_df[function_column].fillna('N/A').iloc[i],\n",
    "                filtered_df[protein_column].fillna('N/A').iloc[i]\n",
    "            ]\n",
    "            customdata.append(row_data)\n",
    "        \n",
    "        # Create the SPLOM trace with custom hover template\n",
    "        splom_trace = go.Splom(\n",
    "            dimensions=splom_dimensions,\n",
    "            #name=f'{correlation_type} Correlation Values',\n",
    "            marker=dict(\n",
    "                color=colors[0],\n",
    "                size=8,\n",
    "                line=dict(width=1, color='white')\n",
    "            ),\n",
    "            diagonal=dict(visible=False),\n",
    "            hovertemplate=\"<b>Peptide ID:</b> %{customdata[0]}<br>\" +\n",
    "                        \"<b>Function:</b> %{customdata[1]}<br>\" +\n",
    "                        \"<b>Protein:</b> %{customdata[2]}<br>\" +\n",
    "                        \"<b>%{xaxis.title.text}:</b> %{x:\" + tickformater + \"}<br>\" +\n",
    "                        \"<b>%{yaxis.title.text}:</b> %{y:\" + tickformater + \"}<br>\" +\n",
    "                        \"<extra></extra>\",\n",
    "            customdata=customdata,\n",
    "            showlegend=False,\n",
    "            showupperhalf=False,\n",
    "        )\n",
    "        \n",
    "        # Combine the main trace with correlation legend traces\n",
    "        all_traces = [splom_trace] + correlation_traces\n",
    "        \n",
    "        # Create figure with all traces\n",
    "        fig = go.Figure(data=all_traces)\n",
    "        \n",
    "        # Use existing plot labels if available\n",
    "        plot_title = self.plot_title if hasattr(self, 'plot_title') else \"Correlation Matrix\"\n",
    "                \n",
    "        # Update layout for title, size, etc.\n",
    "        fig.update_layout(\n",
    "            title=dict(\n",
    "                text=plot_title,\n",
    "                font=dict(size=14 if 'Filtered By' in plot_title else 18, color='black'),\n",
    "                x=0.5,\n",
    "                xanchor='center'\n",
    "            ),\n",
    "            width=250 * len(dimensions),\n",
    "            height=250 * len(dimensions),\n",
    "            template='plotly_white',\n",
    "        )\n",
    "\n",
    "        # Calculate appropriate ranges for each dimension to avoid including zero\n",
    "        axis_ranges = []\n",
    "        for dimension in splom_dimensions:\n",
    "            values = dimension['values']\n",
    "            min_val = values.min() * 0.95  # 5% padding below min\n",
    "            max_val = values.max() * 1.05  # 5% padding above max\n",
    "            axis_ranges.append([min_val, max_val])\n",
    "\n",
    "        # For SPLOM, we need to update each axis individually in the layout\n",
    "        for i in range(1, len(dimensions) + 1):\n",
    "            fig.update_layout({\n",
    "                f'xaxis{i}': dict(\n",
    "                    tickfont=dict(color='black', size=14),\n",
    "                    title_font=dict(color='black', size=16),\n",
    "                    zeroline=False,\n",
    "                    range=axis_ranges[i-1]\n",
    "                ),\n",
    "                f'yaxis{i}': dict(\n",
    "                    tickfont=dict(color='black', size=14),\n",
    "                    title_font=dict(color='black', size=16),\n",
    "                    zeroline=False,\n",
    "                    range=axis_ranges[i-1]\n",
    "                )\n",
    "            })\n",
    "        legend_title = self.legend_title if self.legend_title != '' else f'{correlation_type} Correlation Values'\n",
    "        fig.update_layout(\n",
    "            #xaxis=dict(visible=False),\n",
    "            yaxis=dict(visible=False),\n",
    "            showlegend=True,  # Add this line to enable the legend\n",
    "            legend=dict(\n",
    "                title=dict(text=legend_title, font=dict(size=16, color=\"black\")),\n",
    "                y=1,\n",
    "                x=0.8,\n",
    "                font=dict(size=14, color=\"black\")\n",
    "            )\n",
    "        )\n",
    "        # Mark generation as complete\n",
    "        #self.state_manager.generate_completed()\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def create_correlation_plot(self, selected_groups):\n",
    "        \"\"\"Generate correlation plot with custom labels using pre-filtered data\"\"\"\n",
    "        if self.data_transformer.merged_df is None or self.data_transformer.group_data_dict is None:\n",
    "            return None\n",
    "        \n",
    "        if len(selected_groups) != 2:\n",
    "            display_warning(\"Exactly 2 groups are required for the scatter plot visualization\")\n",
    "            return None\n",
    "            \n",
    "        # Get the already filtered dataframe\n",
    "        df = self.filtered_df.copy() if hasattr(self, 'filtered_df') else self.data_transformer.merged_df.copy()\n",
    "        \n",
    "        # Use the 2 selected groups\n",
    "        group1 = selected_groups[0]\n",
    "        group2 = selected_groups[1]\n",
    "        \n",
    "        # Create a single subplot\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Column names for the two groups\n",
    "        col1 = f\"Avg_{group1}\"\n",
    "        col2 = f\"Avg_{group2}\"\n",
    "        \n",
    "        if col1 not in df.columns or col2 not in df.columns:\n",
    "            display_warning(f\"Columns {col1} or {col2} not found in the dataframe\")\n",
    "            return None\n",
    "        \n",
    "        # Use Carolina Blue as default color\n",
    "        carolina_blue = '#4B9CD3'\n",
    "        \n",
    "        # Try to get color scheme from plotter\n",
    "        try:\n",
    "            color_result = self.get_single_color()\n",
    "            # Fix: Ensure colors is always a list, even if a single string is returned\n",
    "            if isinstance(color_result, list) and len(color_result) > 0:\n",
    "                colors = color_result\n",
    "            elif isinstance(color_result, str):\n",
    "                # If a single string color is returned, wrap it in a list\n",
    "                colors = [color_result]\n",
    "            else:\n",
    "                colors = [carolina_blue]\n",
    "                display_warning(\"Please choose a single color scheme otherwise Carolina Blue will be used by default.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting colors: {e}\")\n",
    "            colors = [carolina_blue]\n",
    "            display_warning(\"Please choose a single color scheme otherwise Carolina Blue will be used by default.\")\n",
    "        \n",
    "        \n",
    "        # Get log transform and correlation type settings from plotter\n",
    "        use_log = self.log_transform.value if hasattr(self, 'log_transform') else False\n",
    "        correlation_type = self.correlation_type.value if hasattr(self, 'correlation_type') else 'Pearson'\n",
    "        \n",
    "        # Ensure positive values\n",
    "        filtered_df = df[(df[col1] > 0) & (df[col2] > 0)].copy()\n",
    "        \n",
    "        if len(filtered_df) == 0:\n",
    "            display_warning(f\"No valid data points found for {group1} vs {group2}\")\n",
    "            return None\n",
    "            \n",
    "        # Apply log transformation if requested\n",
    "        if use_log:\n",
    "            x_values = np.log10(filtered_df[col1])\n",
    "            y_values = np.log10(filtered_df[col2])\n",
    "            x_label_prefix = \"Log<sub>10</sub> \"\n",
    "            y_label_prefix = \"Log<sub>10</sub> \"\n",
    "            tickformater = '.2f'  # 2 decimal places for log values\n",
    "            xaxislabel = f'{x_label_prefix}({group1})'\n",
    "            yaxislabel = f'{y_label_prefix}({group2})'\n",
    "        else:\n",
    "            x_values = filtered_df[col1]\n",
    "            y_values = filtered_df[col2]\n",
    "            x_label_prefix = \"\"\n",
    "            y_label_prefix = \"\"\n",
    "            tickformater = '.1e'  # 1 decimal place with exponential notation\n",
    "            xaxislabel = f'{group1}'\n",
    "            yaxislabel = f'{group2}'\n",
    "        \n",
    "        # Calculate correlation based on selected method\n",
    "        correlation_text = 'n/a'\n",
    "        if len(filtered_df) > 1:\n",
    "            if correlation_type == 'Pearson':\n",
    "                corr, _ = pearsonr(x_values, y_values)\n",
    "                correlation_text = f'<i>r</i> = {corr:.3f}'\n",
    "            elif correlation_type == 'Spearman':\n",
    "                corr, _ = spearmanr(x_values, y_values)\n",
    "                correlation_text = f'ρ = {corr:.3f}'\n",
    "        \n",
    "        # Create hover data\n",
    "        hover_data = [filtered_df['unique ID']]\n",
    "        if 'function' in filtered_df.columns:\n",
    "            hover_data.append(filtered_df['function'].fillna('N/A'))\n",
    "        else:\n",
    "            hover_data.append(['N/A'] * len(filtered_df))\n",
    "            \n",
    "        if 'protein_name' in filtered_df.columns:\n",
    "            hover_data.append(filtered_df['protein_name'])\n",
    "            \n",
    "        # Create hover data\n",
    "        hover_columns = ['unique ID']\n",
    "        if 'function' in filtered_df.columns:\n",
    "            hover_columns.append('function')\n",
    "        if 'protein_name' in filtered_df.columns:\n",
    "            hover_columns.append('protein_name')\n",
    "            \n",
    "        # Create customdata array\n",
    "        customdata = []\n",
    "        for col in hover_columns:\n",
    "            if col == 'function':\n",
    "                customdata.append(filtered_df[col].fillna('N/A'))\n",
    "            else:\n",
    "                customdata.append(filtered_df[col])\n",
    "\n",
    "        # Add scatter trace\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_values,\n",
    "                y=y_values,\n",
    "                mode='markers',\n",
    "                name=f'Correlation: {correlation_text}',\n",
    "                marker=dict(color=colors[0]),\n",
    "                hovertemplate=\"<b>Peptide ID:</b> %{customdata[0]}<br>\" +\n",
    "                            \"<b>Function:</b> %{customdata[1]}<br>\" +\n",
    "                            \"<b>Protein:</b> %{customdata[2]}<br>\" +\n",
    "                            \"<b>%{xaxis.title.text}:</b> %{x:\" + tickformater + \"}<br>\" +\n",
    "                            \"<b>%{yaxis.title.text}:</b> %{y:\" + tickformater + \"}<br>\" +\n",
    "                            \"<extra></extra>\",              \n",
    "                customdata=np.column_stack(customdata)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Add trendline if we have enough points\n",
    "        if len(filtered_df) > 1:\n",
    "            z = np.polyfit(x_values, y_values, 1)\n",
    "            x_range = np.linspace(x_values.min(), x_values.max(), 100)\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=x_range,\n",
    "                    y=np.poly1d(z)(x_range),\n",
    "                    mode='lines',\n",
    "                    line=dict(color=colors[0], dash='dash'),\n",
    "                    name='Trendline',\n",
    "                    showlegend=True,\n",
    "                    hovertemplate='<extra></extra>'\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Use existing plot labels if available\n",
    "        plot_title = self.plot_title if hasattr(self, 'plot_title') else \"Correlation Matrix\"\n",
    "        legend_title = self.legend_title if self.legend_title != '' else f'{correlation_type} Correlation Values'\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=dict(\n",
    "                text=plot_title,\n",
    "                font=dict(size=12 if 'Filtered By' in plot_title else 18, color='black'),\n",
    "                x=0.5,\n",
    "                xanchor='center'\n",
    "            ),\n",
    "            xaxis_title=xaxislabel,\n",
    "            yaxis_title=yaxislabel,\n",
    "            xaxis=dict(\n",
    "                    title_font={\"size\": 16},\n",
    "                    tickfont={\"size\": 14},\n",
    "                    tickfont_color=\"black\",  # Black tick labels\n",
    "                    title_font_color=\"black\",  # Black axis title      \n",
    "                    tickformat=tickformater,\n",
    "               \n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                    title_font={\"size\": 16},\n",
    "                    tickfont={\"size\": 14},\n",
    "                    tickfont_color=\"black\",  # Black tick labels\n",
    "                    title_font_color=\"black\",  # Black axis title     \n",
    "                    tickformat=tickformater,\n",
    "                \n",
    "            ),\n",
    "            height=500,\n",
    "            width=600,\n",
    "            template='plotly_white',\n",
    "            showlegend=True,\n",
    "            legend=dict(\n",
    "                yanchor=\"top\",\n",
    "                title=dict(text=legend_title, font=dict(size=16, color=\"black\")),\n",
    "                y=0.99,\n",
    "                xanchor=\"right\",\n",
    "                x=0.99,\n",
    "                bgcolor=\"rgba(255, 255, 255, 0.8)\",\n",
    "                font=dict(size=14)\n",
    "            ),\n",
    "            margin=dict(t=100, b=80, l=80, r=50)\n",
    "        )\n",
    "        \n",
    "        # Mark generation as complete\n",
    "        #self.state_manager.generate_completed()\n",
    "        \n",
    "        return fig     \n",
    "\n",
    "    def check_invalid_user_selection(self, selected_groups, plot_type, use_count, orientation, plot_filter):\n",
    "        # Initialize warnings list\n",
    "        warnings = []\n",
    "        \n",
    "        # Check if any groups are selected\n",
    "        if not selected_groups:\n",
    "            warnings.append(\"No sample groups selected.<br>Please select at least one sample group to generate a plot.\")\n",
    "            \n",
    "        selected_proteins = self.protein_selector.value\n",
    "        selected_functions = self.function_selector.value\n",
    "        \n",
    "        # Check for protein selection when needed\n",
    "        if plot_filter in ['Selected Protein(s)', 'Both']:\n",
    "            if not hasattr(self, 'selected_proteins') or not self.selected_proteins or (len(self.selected_proteins) == 1 and 'All Proteins (No Filter)' in self.selected_proteins):\n",
    "                warnings.append(f\"No proteins selected.<br>Please select at least one specific protein for '{plot_filter}' filter type.\")\n",
    "            \n",
    "            # Check if 'All Proteins' is selected along with individual proteins\n",
    "            elif hasattr(self, 'selected_proteins') and 'All Proteins (No Filter)' in selected_proteins:\n",
    "                # Check if any individual proteins are also selected\n",
    "                if len(selected_proteins) > 1 and 'All Proteins (No Filter)' in selected_proteins:\n",
    "                    warnings.append(\"All Proteins (No Filter)' is selected along with individual proteins.<br>All proteins will be used for analysis.\")\n",
    "                \n",
    "        # Check for function selection when needed\n",
    "        if plot_filter in ['Selected Function(s)', 'Both']:\n",
    "            if not hasattr(self, 'selected_functions') or not self.selected_functions or (len(self.selected_functions) == 1 and 'All Functional Peptides' in self.selected_functions):\n",
    "                warnings.append(f\"No functions selected.<br>Please select at least one specific function for '{plot_filter}' filter type.\")\n",
    "                           \n",
    "                \n",
    "            elif 'All Functional Peptides' in selected_functions:\n",
    "                for func in selected_functions:\n",
    "                    if func in selected_functions and func != 'All Functional Peptides':\n",
    "                        warnings.append(\"Invalid selection: 'All Functional Peptides' cannot be combined with other Individual functions criteria.\")\n",
    "\n",
    "\n",
    "        # Check if merged data is available\n",
    "        if self.data_transformer.merged_df is None:\n",
    "            warnings.append(\"No data available.<br>Please upload the merged data file first.\")\n",
    "\n",
    "        self.get_plot_labels()\n",
    "\n",
    "        # check for invalid combinations of plot types and orientations\n",
    "        if plot_filter == 'Selected Function(s)' and orientation == 'By Protein':\n",
    "            warnings.append(\"Invalid combination of Plot Filter and Plot Orientation.<br>Current selection: 'Selected Function(s)' for Plot Filter and 'By Protein' for Plot Orientation.\")\n",
    "            \n",
    "        if plot_filter == 'Selected Protein(s)' and orientation == 'By Function':\n",
    "            warnings.append(\"Invalid combination of Plot Filter and Plot Orientation.<br>Current selection: 'Selected Protein(s)' for Plot Filter and 'By Function' for Plot Orientation.\")\n",
    "            \n",
    "        return warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3301cf25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854afc76377544dea1afef97dde091d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(layout=Layout(max_width='1000px', width='100%')), HTML(value='<u>Upload Data File:</u>')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        .ellipsis-select select option {\n",
       "            text-overflow: ellipsis;\n",
       "            overflow: hidden;\n",
       "            white-space: nowrap;\n",
       "        }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b640b22e57845cd8b499bb264a77587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(layout=Layout(max_width='1000px', width='100%')), GridBox(children=(VBox(children=(HTML(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485db43ff668417db99b47515543a66b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(max_width='1000px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330bd9414a8949cfbacc12c986a0232d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(VBox(children=(HTML(value='<h3><u>Visualization Settings:</u></h3>'), HBox(children=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764769105c784787b26db31eaeb2be87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3><u>Display and Export</u></h3>'), HBox(children=(Button(button_style='success',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0586c227c45a47cc9090c2ff18d65717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "hovertext": [
          "Protein: Functional Peptides<br>Sample: Threshold<br>Relative Summed Absorbance: 70.31%<br>Absolute Summed Absorbance: 5.51e+10<br>",
          "Protein: Functional Peptides<br>Sample: Low<br>Relative Summed Absorbance: 76.02%<br>Absolute Summed Absorbance: 3.61e+10<br>",
          "Protein: Functional Peptides<br>Sample: Moderate<br>Relative Summed Absorbance: 83.39%<br>Absolute Summed Absorbance: 2.51e+10<br>",
          "Protein: Functional Peptides<br>Sample: Extreme<br>Relative Summed Absorbance: 79.29%<br>Absolute Summed Absorbance: 2.92e+10<br>",
          "Protein: Functional Peptides<br>Sample: Non_bitter<br>Relative Summed Absorbance: 69.91%<br>Absolute Summed Absorbance: 4.73e+10<br>",
          "Protein: Functional Peptides<br>Sample: Bitter<br>Relative Summed Absorbance: 80.33%<br>Absolute Summed Absorbance: 2.78e+10<br>"
         ],
         "marker": {
          "color": "hsl(0.0,70%,60%)"
         },
         "name": "Functional Peptides",
         "showlegend": true,
         "type": "bar",
         "x": [
          "Threshold",
          "Low",
          "Moderate",
          "Extreme",
          "Non_bitter",
          "Bitter"
         ],
         "y": [
          55100754415.67597,
          36056739029.04178,
          25057830172.204903,
          29192109675.262306,
          47303122571.641884,
          27834124244.486988
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Protein: Non-Functional Peptides<br>Sample: Threshold<br>Relative Summed Absorbance: 29.69%<br>Absolute Summed Absorbance: 2.33e+10<br>",
          "Protein: Non-Functional Peptides<br>Sample: Low<br>Relative Summed Absorbance: 23.98%<br>Absolute Summed Absorbance: 1.14e+10<br>",
          "Protein: Non-Functional Peptides<br>Sample: Moderate<br>Relative Summed Absorbance: 16.61%<br>Absolute Summed Absorbance: 4.99e+09<br>",
          "Protein: Non-Functional Peptides<br>Sample: Extreme<br>Relative Summed Absorbance: 20.71%<br>Absolute Summed Absorbance: 7.62e+09<br>",
          "Protein: Non-Functional Peptides<br>Sample: Non_bitter<br>Relative Summed Absorbance: 30.09%<br>Absolute Summed Absorbance: 2.04e+10<br>",
          "Protein: Non-Functional Peptides<br>Sample: Bitter<br>Relative Summed Absorbance: 19.67%<br>Absolute Summed Absorbance: 6.81e+09<br>"
         ],
         "marker": {
          "color": "hsl(41.25,70%,60%)"
         },
         "name": "Non-Functional Peptides",
         "showlegend": true,
         "type": "bar",
         "x": [
          "Threshold",
          "Low",
          "Moderate",
          "Extreme",
          "Non_bitter",
          "Bitter"
         ],
         "y": [
          23265779441.696114,
          11376919938.809458,
          4992492733.888609,
          7623203272.339387,
          20362272667.94387,
          6814379426.449184
         ]
        },
        {
         "hoverinfo": "none",
         "mode": "text",
         "name": "Show Total Summed Absorbance",
         "showlegend": true,
         "text": [
          "7.84e+10",
          "4.74e+10",
          "3.01e+10",
          "3.68e+10",
          "6.77e+10",
          "3.46e+10"
         ],
         "textfont": {
          "color": "black",
          "size": 12
         },
         "textposition": "top center",
         "texttemplate": "%{text}",
         "type": "scatter",
         "x": [
          "Threshold",
          "Low",
          "Moderate",
          "Extreme",
          "Non_bitter",
          "Bitter"
         ],
         "y": [
          78366533857.37209,
          47433658967.851234,
          30050322906.093513,
          36815312947.60169,
          67665395239.58576,
          34648503670.93617
         ]
        }
       ],
       "layout": {
        "barmode": "stack",
        "height": 820,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Arial",
          "size": 14
         }
        },
        "legend": {
         "bgcolor": "rgba(255, 255, 255, 0.9)",
         "font": {
          "color": "black",
          "size": 16
         },
         "title": {
          "text": "Functions"
         },
         "traceorder": "normal",
         "x": 1.05,
         "xanchor": "left",
         "y": 0.95,
         "yanchor": "top"
        },
        "margin": {
         "b": 100,
         "l": 100,
         "r": 100,
         "t": 100
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "black",
          "size": 18
         },
         "text": "Absorbance Distribution - By Sample",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1200,
        "xaxis": {
         "linecolor": "black",
         "linewidth": 1,
         "mirror": false,
         "showline": true,
         "tickangle": 45,
         "tickfont": {
          "color": "black",
          "size": 16
         },
         "title": {
          "font": {
           "color": "black",
           "size": 18
          },
          "text": "Samples"
         }
        },
        "yaxis": {
         "exponentformat": "E",
         "gridcolor": "lightgray",
         "linecolor": "black",
         "linewidth": 1,
         "mirror": false,
         "showexponent": "all",
         "showgrid": true,
         "showline": true,
         "showticklabels": false,
         "tickfont": {
          "color": "black",
          "size": 16
         },
         "tickformat": ".1e",
         "title": {
          "font": {
           "color": "black",
           "size": 18
          },
          "text": "log<sub>10</sub> (Summed Absorbance)"
         },
         "type": "log",
         "zeroline": false
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"0ca272ba-0140-45cb-b455-761ce06b182c\" class=\"plotly-graph-div\" style=\"height:820px; width:1200px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0ca272ba-0140-45cb-b455-761ce06b182c\")) {                    Plotly.newPlot(                        \"0ca272ba-0140-45cb-b455-761ce06b182c\",                        [{\"hoverinfo\":\"text\",\"hovertext\":[\"Protein: Functional Peptides\\u003cbr\\u003eSample: Threshold\\u003cbr\\u003eRelative Summed Absorbance: 70.31%\\u003cbr\\u003eAbsolute Summed Absorbance: 5.51e+10\\u003cbr\\u003e\",\"Protein: Functional Peptides\\u003cbr\\u003eSample: Low\\u003cbr\\u003eRelative Summed Absorbance: 76.02%\\u003cbr\\u003eAbsolute Summed Absorbance: 3.61e+10\\u003cbr\\u003e\",\"Protein: Functional Peptides\\u003cbr\\u003eSample: Moderate\\u003cbr\\u003eRelative Summed Absorbance: 83.39%\\u003cbr\\u003eAbsolute Summed Absorbance: 2.51e+10\\u003cbr\\u003e\",\"Protein: Functional Peptides\\u003cbr\\u003eSample: Extreme\\u003cbr\\u003eRelative Summed Absorbance: 79.29%\\u003cbr\\u003eAbsolute Summed Absorbance: 2.92e+10\\u003cbr\\u003e\",\"Protein: Functional Peptides\\u003cbr\\u003eSample: Non_bitter\\u003cbr\\u003eRelative Summed Absorbance: 69.91%\\u003cbr\\u003eAbsolute Summed Absorbance: 4.73e+10\\u003cbr\\u003e\",\"Protein: Functional Peptides\\u003cbr\\u003eSample: Bitter\\u003cbr\\u003eRelative Summed Absorbance: 80.33%\\u003cbr\\u003eAbsolute Summed Absorbance: 2.78e+10\\u003cbr\\u003e\"],\"marker\":{\"color\":\"hsl(0.0,70%,60%)\"},\"name\":\"Functional Peptides\",\"showlegend\":true,\"x\":[\"Threshold\",\"Low\",\"Moderate\",\"Extreme\",\"Non_bitter\",\"Bitter\"],\"y\":[55100754415.67597,36056739029.04178,25057830172.204903,29192109675.262306,47303122571.641884,27834124244.486988],\"type\":\"bar\"},{\"hoverinfo\":\"text\",\"hovertext\":[\"Protein: Non-Functional Peptides\\u003cbr\\u003eSample: Threshold\\u003cbr\\u003eRelative Summed Absorbance: 29.69%\\u003cbr\\u003eAbsolute Summed Absorbance: 2.33e+10\\u003cbr\\u003e\",\"Protein: Non-Functional Peptides\\u003cbr\\u003eSample: Low\\u003cbr\\u003eRelative Summed Absorbance: 23.98%\\u003cbr\\u003eAbsolute Summed Absorbance: 1.14e+10\\u003cbr\\u003e\",\"Protein: Non-Functional Peptides\\u003cbr\\u003eSample: Moderate\\u003cbr\\u003eRelative Summed Absorbance: 16.61%\\u003cbr\\u003eAbsolute Summed Absorbance: 4.99e+09\\u003cbr\\u003e\",\"Protein: Non-Functional Peptides\\u003cbr\\u003eSample: Extreme\\u003cbr\\u003eRelative Summed Absorbance: 20.71%\\u003cbr\\u003eAbsolute Summed Absorbance: 7.62e+09\\u003cbr\\u003e\",\"Protein: Non-Functional Peptides\\u003cbr\\u003eSample: Non_bitter\\u003cbr\\u003eRelative Summed Absorbance: 30.09%\\u003cbr\\u003eAbsolute Summed Absorbance: 2.04e+10\\u003cbr\\u003e\",\"Protein: Non-Functional Peptides\\u003cbr\\u003eSample: Bitter\\u003cbr\\u003eRelative Summed Absorbance: 19.67%\\u003cbr\\u003eAbsolute Summed Absorbance: 6.81e+09\\u003cbr\\u003e\"],\"marker\":{\"color\":\"hsl(41.25,70%,60%)\"},\"name\":\"Non-Functional Peptides\",\"showlegend\":true,\"x\":[\"Threshold\",\"Low\",\"Moderate\",\"Extreme\",\"Non_bitter\",\"Bitter\"],\"y\":[23265779441.696114,11376919938.809458,4992492733.888609,7623203272.339387,20362272667.94387,6814379426.449184],\"type\":\"bar\"},{\"hoverinfo\":\"none\",\"mode\":\"text\",\"name\":\"Show Total Summed Absorbance\",\"showlegend\":true,\"text\":[\"7.84e+10\",\"4.74e+10\",\"3.01e+10\",\"3.68e+10\",\"6.77e+10\",\"3.46e+10\"],\"textfont\":{\"color\":\"black\",\"size\":12},\"textposition\":\"top center\",\"texttemplate\":\"%{text}\",\"x\":[\"Threshold\",\"Low\",\"Moderate\",\"Extreme\",\"Non_bitter\",\"Bitter\"],\"y\":[78366533857.37209,47433658967.851234,30050322906.093513,36815312947.60169,67665395239.58576,34648503670.93617],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"size\":18,\"color\":\"black\"},\"text\":\"Absorbance Distribution - By Sample\",\"y\":0.95,\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"yaxis\":{\"title\":{\"text\":\"log\\u003csub\\u003e10\\u003c\\u002fsub\\u003e (Summed Absorbance)\",\"font\":{\"size\":18,\"color\":\"black\"}},\"showline\":true,\"gridcolor\":\"lightgray\",\"showgrid\":true,\"showticklabels\":false,\"linewidth\":1,\"linecolor\":\"black\",\"mirror\":false,\"zeroline\":false,\"type\":\"log\",\"exponentformat\":\"E\",\"showexponent\":\"all\",\"tickfont\":{\"size\":16,\"color\":\"black\"},\"tickformat\":\".1e\"},\"xaxis\":{\"title\":{\"text\":\"Samples\",\"font\":{\"size\":18,\"color\":\"black\"}},\"showline\":true,\"linewidth\":1,\"linecolor\":\"black\",\"mirror\":false,\"tickangle\":45,\"tickfont\":{\"size\":16,\"color\":\"black\"}},\"legend\":{\"font\":{\"size\":16,\"color\":\"black\"},\"title\":{\"text\":\"Functions\"},\"yanchor\":\"top\",\"y\":0.95,\"xanchor\":\"left\",\"x\":1.05,\"traceorder\":\"normal\",\"bgcolor\":\"rgba(255, 255, 255, 0.9)\"},\"margin\":{\"t\":100,\"l\":100,\"r\":100,\"b\":100},\"hoverlabel\":{\"font\":{\"size\":14,\"family\":\"Arial\"},\"bgcolor\":\"white\"},\"barmode\":\"stack\",\"showlegend\":true,\"height\":820,\"width\":1200},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0ca272ba-0140-45cb-b455-761ce06b182c');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_transformer = DataTransformation()\n",
    "# Initialize the interface\n",
    "data_transformer.setup_data_loading_ui()\n",
    "\n",
    "# Create instances\n",
    "data_handler = DataHandler(data_transformer)\n",
    "data_handler.display_handler()\n",
    "\n",
    "# Create Plotter\n",
    "plotter = Plotter(data_transformer, data_handler)\n",
    "plotter.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (newenv)",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
